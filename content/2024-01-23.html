<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Tue Jan 23 2024 15:47:30 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Main-bold;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size1;src:url(data:application/font-woff;base64,d09GRk9UVE8AABagAAsAAAAAIDwAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAAFcAAAEGQAABUO0gggUEZGVE0AABaEAAAAHAAAABxfvEZXR0RFRgAAFdQAAAAdAAAAIABeAARPUy8yAAABZAAAAE4AAABgQztYj2NtYXAAAAR0AAAA5wAAAhoVJZqOaGVhZAAAAQgAAAA0AAAANgXjDbVoaGVhAAABPAAAACAAAAAkBjkC2GhtdHgAABX0AAAAjwAAAMR1kQmkbWF4cAAAAVwAAAAGAAAABgAxUABuYW1lAAABtAAAAr0AAAZv+wCdtHBvc3QAAAVcAAAAEwAAACD/hgAyeNpjYGRgYGBmYPCu/ZQcz2/zlYGb+QVQhOHiu6d5MPrvmX+LWCWYg4BcDgYmkCgAluYOwHjaY2BkYGAO+reIgYGl7++Z/2WsEgxAERRgCACVCwYWAABQAAAxAAB42mNgZupgnMDAysDA1MW0h4GBoQdCMz5gMGRkYkACDQwM7wUY3ryF8QPSXFMYHBgU3v9nDvq3iIGBOYgxToGBoT+OGapAAQgZARyoEFgAAHjarVTLTttAFD2GBNRUiWBBF2w6m0pQOc5D3RAQEgJFCkpBEITabpBxhniQ40S2kwBS1/2CfkDVL+gndNlFu+sX9Ae67LLHk6GQilSibSx7zty5c+65984EwCOrAAvjn41XBlvI473BM5jHR4Nn8cRaMjiDJatjcBYPrbcGz9H+2eA8fsx+NbiA5WzG4AXks+sGL2I++5LMVuYBZy90lBRbWMYbg2e4+4PBs9jFJ4MzeGqtG5xlLq8NnqP9ncF567v1zeACnmW+GLxAPY8NXkQh28A2eujjEhEUOvCRQGAFHlY5VlHms4aiRhW+AjuQiLVvyFmLnoqWkKNkLQUaGjvAdq9/GamOn4gVb1VUy+W1YrVcKYsdGatOKFqekqEnbdEIPXo/h8vQPtN0cYETEitckbLCJTfxd92Lk5a6kpwe0trBAAE9I05lZxC4BHUmEpIjHSN6SJ2Ao0XX+E6PUPyds94Lk3ov6khRdcqiJiYUFH9FvAfjFIZjekW6nD1dzgr1MsVjGcWqF4qKU/kfUe7XYvseTU55NjDSj4OuUXqulTqmD5uMYyNHD6VXhVYd68yH/LZpue6dwB73dnXvpuftkC2HI64p8tze3SI6IxrpeqQsY4+Ao6cziE3EAXFbaxA6itS7G2hy3Ge1pM78hrk5wZDW4O7eORPKJuMKqhryVbpfp/ymtpu6uDriFg40Tnhqc7pbCfXUUOITky3tYp+2mLFizXVd6RKV16l02tWz77x7YmVjNBo5XZ6dc/fC4bHfXLVzI5X44lDGMhrKtkgvhNhzu3LyKji53JGv4vFyq3eWjNxIChoC5ckw5sZB2JaRSHwpWo2m2O/LcOzcHDvY4tZRd8ZkZq9wh64K3NNACq3FFfWtA+EmtZyfJP1aqRR7keonsROrIBVd2q8z878q158I//l/6ScbPUGCAAAAeNpjYGBgZoBgGQZGIMnAKALkMYL5LAw/gLQVgwKQJQUkNRn0GWIZqhlqGRYwHWO6w8ysIKY4UXGy4kXFy0qCSlJKykqqSnpKh5W5lS+ov9Ri0mLRYnv///9/oBkKDBpAvdFIepmQ9PJD9WorHVDmAOp9ocUA1vsXqPnh/1v/r/5f9b/3f8//rL+ufw3+ct//ea/+Xt09x3sO91jv/r379e6Xu+/vxt2VuhN2w/6a5jWNa+oChhC/kAsY2RgIGgCTZ2IGUywkGM/Kxo5XnoOBk2yni4kAowoKxCEUFwnauXlgLAB1JkksAHjaY2BmAIP/zQxGDFgAAChEAbgAeNqlVwt4FMWW7mbopEgwKHHwlQ+QN34RQ1hR9lMUJLAiEgS8AkFISCIk5k1ek2TeMz0zfXoePe/J5EUIIOEhIYBICCivIMYXKOL1Kqh3cb3uXhR2rQ41uFuTAcXd6939vp3q6b/r1DmnTp+uc+oUywwdyrAsO+r5nMoNC3Nq1y4rqMuf/vDS/PVVRTkVDDuEYZmH5acZeQ4rzx0iP6OQ5w2NnCZXU7h7By5zKUOUI1IY5s6UIdV3pTCjU0bOG8k8FBVBzAjmXmYMM4l5hJnFZDCLmGXMaiaXKWTKGRWjYyyMg/ExTcxmppPpYg4yR5lTzHvMx8znzNfMd8wPDGZ+Zjl2OJvMjmLnsi+xeWxhVUlBWtqctCjMSEuvLCjKy88tLV5H++lp02fmVFSU1lSVDUJeaU1J7GFd0S3SuqIotayiNK8qtzIqkz49bWNVcXFOZUFpSUVOXkFuTtEgOX1GDB4tKKnMX19xi/pMDObFIGMQnkmLwfQYpMdgUH5G2uMxmBWDOTGYOwjzBuUey3g8BoMsc9LSYjA9Bukx+IcYzKSQMX/+vBhkxGD+jGlpz5SWqSoK1m+oHDsld+rY9LS0WQ9Tb6SNnZe/sWB9ydhluQX5Jbn5qWOfLcmd9je/8G+Ii0srinOKGPpjmWFMAnMn8wTzJDObfrk1rIXRMFrWytpYgQVWZO2sg3WyLlZi3ayH9bI+1s8G2CAbYhvZMNvENrMtbCvbxm5i29nNbAe7hd3KbmNfY7eznewOZnp0kYxjJjI1TB8zwN7HPscWDZmreFAxQZGuWKnYoJAUexTy0KeGvsst507GzYz7KT47viS+J/6D+CvovmGuYQMJhYmJiaMTZyZmJq5P1Ca6Er8YPnX4m3csTkpN6hnx0IhnRqwcsYGcgV45o5ftpT9F7yj8kLydPBTXG6lRUmokIz6JnEmaiFMvKnAqdiqBtH1DcvAUkoy2xdntTic4wCHYDT6SiB9YipcAdgGWjuMleDh+wOsT7dFxi9NmR6VxhErNINlUBaIay6nGk1GNuHUGziFTcDLSxNXzoBsj2lwmyYQTyf3HSCYQFxDncpJJaN9s4k2CDemdQtPoYByeipO/xtmAN6GkZrlq4I9KXht5PIWYBAuo/QY/uMHjdHpcAfnxlKENohNCOq8O9MCbLWaURMaTH7uvX+tm8ZpuBV5DflTi5d0k9fo1nNpNlsdRjS3kj0rBGYkK8wGL2+gyggYMGlEvWuToNC6t0+ixuMEPfi+Ebtc4t1uxaeCIEqf+fI2k5uLlKUNfj6psvzXu+FIhl5PvlaF4CAt2k/2l0KId9d18CHjAs+AqHBUka7OhTReu7MzZktmGGqSAkzsc7t7U0dHaGuxwbhElOEr5KDPvCoW7z+w4GnLbqbPDCEJmSQ2cCYyCAAIYrAbrnJpV5eWFOrWpnq9BApnJCSRDDJjrtcWlpeuqdLzWrDLVmwGgDuoBwuZmU8Ds59G+qm2lgWKpXgiIJAOJ5FHOVS3VB9Sbiw5W9Nfu0juEEKAgfat/x7WPXUzW4SED/6y0WAUr9VKDaJNsDsFt9dhO13SXBgtR8tMuNdBPOQsmwEui2aHyVvvr24sOlvbVoIClwcxlVueUVxbp6g3VVpVghpcoH7kTigWzpc6kaWioqSmqW6dB1WZBsFlRsk6wgQUMUCsKLRAEp7jT199ysGNzZyAkhV1tSMSPciLOELRSOLz/xL4TTW5H1D3QSN3tWNq0dF/9fnNY1Ao4Awl4Jse3msPa0MbONR0LWwp8VlEDyAg8nQNFl79F7sEvsnjHwHTl2ATa++5d67sjk3XHBmYoH0xIfnpcQrJuPEVtSG/gknUT6OPEhKTIiUEpsj0mRbs3xSK2vyuHS9qqWew7gOcfUGDfqAPyX7PjcHnkr8rBp6SfoqP9dOhP8jfK1XOfXphejHgbrKUL5L2OU129PSgYgIh4AEAWg1quN+tU/nsV1MPwBm/nHu18+tSqT5HJz/2qp/97pSbArexZ0vVsB9I6Ya3Lxn1VdH7J4aeQW+fycoc+Pt//5+3IZYc3tBbu2Yol+SuzkEZL1WcD9xtr5bvkz5Urxs9Mm7CkTp9fW2dGGh6yOY9zm6/Z29N+qHPfTuTzQISJGjc1EODaOzo6W15zeVwSQHvh1le2lqCAFiJT6TheKOKFPiPXXXioqKey2bBN77EgOKBxcXVSfkudb8KpmZdXXLN4afjRn8VkMSBqy6bbPId1Sr2HW7dzdWdWu8pb6jM6EWQHea7J3FXbpL+65FLakfFOg9MUlXe6nd4j1y5dvnqqydfV0iShoAsOcEZLqV5lyKpcXZRbiPRGAS+kZmUDNVCr5SorKopqS3gjTwOncmfZnrLXkDZAXyvqFPlu4ui+nkoDPR0PlSdjTjGwlTyiHDga73u9o/EtBwp13/gkNxR32LpF7S9GDhPcOGo1crricvUqK1Ln4rPd6rg/OMobDXuQIM8DOUOeDHDjP36P5/8yITn72wl/ilCVcoYoZ3C/y/MbowY+uX1CE3G8c31UN3t6QBeLeTUSdfh54uF+JGMvkngQEHmOFHOTyPDHpgg2m5XGkg2sDt4hOGxvgpwESH5C/Ap7coEzNxiqjZpXXliSPbf6Zc0q8xxrg0CGAmEBEWYciGPws7iQu4ITvvg3UXQ4BZdFEuzkU3mJxQliH3wKeATgx4RG4SP+TdM+Nfqi/KPM7U+gVqEVOEuwfn/Fh2gdHhJ5ArhIOujAaqP2L7pe2KXAYWxXklSSuKWcE6Ex0BxCu7bQp8OE6yNjEGaJFBC4RrCLkmS345G4CU/DHyO8Q/4cJE5wm/w6MIKJt5gFC0HETMaSg4h4Ils5m52slUsH00cNnkiX4yRZVk6iuYN28IJf+rhiFNgEkgqDl0jvNrvBa/aBF7yS3UszFk795RLsyOo1SAa6gxlNNiNVfWrP9U172GMn5edOKq6RScrJNHsEfqHi/Se/jd5uDuEro+i4fPW/jY/5n0wxzl/4du+99B3m9u6K8ZRW1xSPgQZnrUfdtOH1ssPQAi3OZu+O8JZtrft3f+D+l9APSPRxfkeLw+96q23vvqa33W1iADpgsxAwtTUcerUrexNvV3lARACu9x27PZhzHwjtDHQ2t+2CEIQsfqNEX5RuXoLaYrOheqOxDupQeWvla9vaWrePhjNZBxY7DXSD46GK7hwq7eqigvn1aTZtA+GsVUjQczprrVXH/6E6b13di6ZqQQsboULUuqsbV+/IP1DltLUY6foEEFS2Si1J59eq84wVGlWDwWDWWbWgBrVT5zE7DN6ojWLIabeHPZ4maEJbatpLRuMV8i6l4SndNH6BoKbNgszxa9pzD0I/nDv89vFGp2gXRRCpegCEF5BxSng2e0WWymDRWilJFP32kPczzznXGTEohkSaliSPhdtX8/pKyKRJbMuxC3L/BcW/EruyGbxuj9/h3H4JK/A5hMfKk/CDkUkcHkLObZ/psHh0XlMzbIbmZmgHGhe02cnZ61N4j9GvcasB1YFGb9bZLOTczxOsOhql0VYVrtkCv050bGCFEnjRIvJ2yzmS/w1x4jkRs3aX3+gxSzY/DBrhc3kwVSzakegSXeCEdlXzRlCBwWTUWS3FMwm1CBFqG6E2coRaW3zJ6jT6dZ466vu6WqiMTjgw7Uv22EX56JcKPIYU08rvvIg/tQe5xm+Of/jJnu7WHf4T8C28+0pPVlde+2rvi8iusd+4j5NUPnUHbIJg0BW2S3Ry3A94LeBhgsf0p8Kzy06+fGjJrkVNqNBT6SgAo2gGMy2kLCDQF6ZPAnm8jowjd9STfxKMQIYBWYuA9IPFbnbVBzWb6NL0NnqaogYS+6CBvZcUHw3UKqckJA0cua0+7E4ZasG53QTiYnTVzSovN4WouqMlHh2gFd5tBSV0k1wqlHuTTgWwiryjJLm5GKhA7m3beX9sp0/CcpdCHjZwWWkAC28xmWuJFDlOQ16PKUq1TqNk8YIPPB7RB5LgICNxFyJ3432Y/jmaorpEB6V7jV4t/cYXuhQXBj5Wglm04pGkC+G7yT5C/xyhvah3RL3HGM02Eq2TpRYsycepbh+haG6xeHiHUURaMBoEurvKPcRxCX9LTwHfXmKPX8SXaS68fFFxd0RGA2uVUxPkv0TylfCqoObLSshsOksSeTjvVWOJNR9eBbVY5kpvfPTQkvcXv7/hM91lJPigKdZEXwdegcfjsThje9je5uigK45+EQGvqsRPkxlAGlBEN2rNjqKDB3d0HjxU8Nrq3MLC7NHUHpx3UUZfsbLvouKmDfhBoleSxREUL7q4EE44ffX7j47s+aDz/GBxLAISIZ9MGYNZvFB52vBu2ZH1f8k4PSFEEpDIR2hCkJFL4OzgEzw2RNgb/Upe5MiQ4ORj87/K6iv+xPAZElwyAk7O4pVV5Hm6qtLJmkrEC1QySh900sWBc1EHDZz91azaFcrzhg/L+tagkJ7cQ+6ljd7xPeQefG/Ix73V/c6Wfv/tL4+ILnJAGWUzBLmX+8o+MHx2u8e8n2394M0+5A1iykHV3MvJKfQodTBzW4Z3tqinhfxgE/SGJ8sWvJyJDJpbs2HKzp37uO9UdINeFlmpjEqr9VzmmgVlsw16oU4YlKRnnNneBVszDyK1D0fFqCAXCxB54kUaI1h7EWtuhQl+OJKnhHqfJmD2mZ3QB+jY0jgogI2i1VnbrG6msRsOO5voytwMu9CJY/F9NIh9UkDyBWlJ3qRvVLuR2UnuADjBwWkQeZ8pqHPX2bVgEniet5qMVp7X03y6GC0lw+PrDQ1aqLoVrye+kI9cHDTEbOGNNqMtGvyRtdGLpxHe4Dc08mhgYlyzW/J6wkjOjwd5Luy2SZawOlQFVaDR8PUxoQUosihyRF5EORaAyyaZmzTBKqABYDFHD4xBuMLClStXFDD0ypXJcXj1ZGUUkzIH6Tep8oSb1Ej27eQkuehu+YRydILC/9TwYTA8oTehN3F0Qtx/Dh+ZwoxOZhKiZ/1/ZBYxrzA6ppHZzvyZbR8yY4iXJrsAQXbBLoh2ar23mXTj6eTBJ7knc55bHz3gRS9aNVgkLfKqOLcdSxj5ACXCi3nmMSBET9IooPZ5ucQ3du1v7qZHMNqErdZmvreqU00PezxKDFqDtiDsg31Nb+wCeHsvSPQbuM1ulLi2IEeVO5hMebHUoXKt3LSupVqqdKJEXjTR5IpWwgZVTiGd7m+UMdE89b+XMYl/t6Jo2unf63nD2daCx7v7UAjHSx/58P1BPF86FN77/y4ZLFUqMtb4vJrEm+fpyf1IS540r/79YiBWC6Dbi4HEXxadJbqnkLV0gxFN7lk75x1/oSerb8P79Z3GdttuQLuh3b7D8164b3dPz/GTO8+6vxDddAsb3Mj6wWmT+HB0saGNoFeb6pDtxn02DWdYXrk6Py8ra9Er06KGiAaR3NX8yNc1OBHZggI+D/hTq4szN6oDNbeWaSIZtWLSpBVEWfmCbhXMhtn+le1LjxDlD5PwqBXHK3u1F+ACHA6cbEdYeeSHH45gZfsJfy+ltUKL4DeeqT9e/vY8PI48cIWkbS2RVOKr9CgsGui3zoRlDStqUOJ/AetYXB942mNgZGBg4ANiCQYQYGJgBEIDIGYB8xgABloAYwAAAHjaY/jFYMTwi4GB8RTDDCBWZnJiMGdcyHAKSJsBaTEmd4ZMEAapYdL5/4NJh4GRgeHvGSC+yszFyMg0m6EAhJm5GCzBeAODOQizKDBYML9gyGf0ZZgI1DOR8QZQ3Bgo3gc0H8R2RMVAsVNALAajmWYzWgDpRCD2ZQlnsIBhuHodoJu/MDAwpDAwAAAG9ymMAAAAAAEAAAAAxtQumQAAAADG+TJPAAAAANHu5W4=)format("woff")}@font-face{font-family:MathJax_Size3;src:url(data:application/font-woff;base64,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)format("woff")}.MathJax .noError{text-align:left;color:black;padding:1px 3px}</style><style>@font-face{font-family:MathJax_Typewriter;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><style>@font-face{font-family:MathJax_SansSerif;src:url(data:application/font-woff;base64,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)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,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 aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Fri 19 Jan 24 to Mon 22 Jan 24, announced Tue, 23 Jan 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item573>Cross-lists</a></li>
<li><a href=#item634>Replacements</a></li>
</ul>
<small>[ total of 1015 entries: <b>1-1015</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Tue, 23 Jan 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10893 title=Abstract>arXiv:2401.10893</a> [<a href=https://arxiv.org/pdf/2401.10893 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10893 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10893 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Location Sensitive Embedding for Knowledge Graph Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+D">Deepak Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishaan%2C+A">Anjali Ishaan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Knowledge graph embedding transforms knowledge graphs into a continuous,
low-dimensional space, facilitating inference and completion tasks. This field
is mainly divided into translational distance models and semantic matching
models. A key challenge in translational distance models is their inability to
effectively differentiate between 'head' and 'tail' entities in graphs. To
address this, the novel location-sensitive embedding (LSE) method has been
developed. LSE innovatively modifies the head entity using relation-specific
mappings, conceptualizing relations as linear transformations rather than mere
translations. The theoretical foundations of LSE, including its
representational capabilities and its connections to existing models, have been
thoroughly examined. A more streamlined variant, LSEd, employs a diagonal
matrix for transformations to enhance practical efficiency. In tests conducted
on four large-scale datasets for link prediction, LSEd either outperforms or is
competitive with leading contemporary models.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10895 title=Abstract>arXiv:2401.10895</a> [<a href=https://arxiv.org/pdf/2401.10895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI in Supply Chain Risk Assessment: A Systematic Literature Review and Bibliometric Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naife%2C+S+A">Saleh Akram Naife</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+A+K">Anik Kumar Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mridha%2C+M+F">M. F. Mridha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>Supply chain risk assessment (SCRA) has witnessed a profound evolution
through the integration of artificial intelligence (AI) and machine learning
(ML) techniques, revolutionizing predictive capabilities and risk mitigation
strategies. The significance of this evolution stems from the critical role of
robust risk management strategies in ensuring operational resilience and
continuity within modern supply chains. Previous reviews have outlined
established methodologies but have overlooked emerging AI/ML techniques,
leaving a notable research gap in understanding their practical implications
within SCRA. This paper conducts a systematic literature review combined with a
comprehensive bibliometric analysis. We meticulously examined 1,717 papers and
derived key insights from a select group of 48 articles published between 2014
and 2023. The review fills this research gap by addressing pivotal research
questions, and exploring existing AI/ML techniques, methodologies, findings,
and future trajectories, thereby providing a more encompassing view of the
evolving landscape of SCRA. Our study unveils the transformative impact of
AI/ML models, such as Random Forest, XGBoost, and hybrids, in substantially
enhancing precision within SCRA. It underscores adaptable post-COVID
strategies, advocating for resilient contingency plans and aligning with
evolving risk landscapes. Significantly, this review surpasses previous
examinations by accentuating emerging AI/ML techniques and their practical
implications within SCRA. Furthermore, it highlights the contributions through
a comprehensive bibliometric analysis, revealing publication trends,
influential authors, and highly cited articles.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10896 title=Abstract>arXiv:2401.10896</a> [<a href=https://arxiv.org/pdf/2401.10896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Responsible AI Governance: A Systematic Literature Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batool%2C+A">Amna Batool</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zowghi%2C+D">Didar Zowghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bano%2C+M">Muneera Bano</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>As artificial intelligence transforms a wide range of sectors and drives
innovation, it also introduces complex challenges concerning ethics,
transparency, bias, and fairness. The imperative for integrating Responsible AI
(RAI) principles within governance frameworks is paramount to mitigate these
emerging risks. While there are many solutions for AI governance, significant
questions remain about their effectiveness in practice. Addressing this
knowledge gap, this paper aims to examine the existing literature on AI
Governance. The focus of this study is to analyse the literature to answer key
questions: WHO is accountable for AI systems' governance, WHAT elements are
being governed, WHEN governance occurs within the AI development life cycle,
and HOW it is executed through various mechanisms like frameworks, tools,
standards, policies, or models. Employing a systematic literature review
methodology, a rigorous search and selection process has been employed. This
effort resulted in the identification of 61 relevant articles on the subject of
AI Governance. Out of the 61 studies analysed, only 5 provided complete
responses to all questions. The findings from this review aid research in
formulating more holistic and comprehensive Responsible AI (RAI) governance
frameworks. This study highlights important role of AI governance on various
levels specially organisational in establishing effective and responsible AI
practices. The findings of this study provides a foundational basis for future
research and development of comprehensive governance models that align with RAI
principles.
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10897 title=Abstract>arXiv:2401.10897</a> [<a href=https://arxiv.org/pdf/2401.10897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10897 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transformations in the Time of The Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faratin%2C+P">Peyman Faratin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+R">Ray Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corbo%2C+J">Jacomo Corbo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Foundation models offer a new opportunity to redesign existing systems and
workflows with a new AI first perspective. However, operationalizing this
opportunity faces several challenges and tradeoffs. The goal of this article is
to offer an organizational framework for making rational choices as enterprises
start their transformation journey towards an AI first organization. The
choices provided are holistic, intentional and informed while avoiding
distractions. The field may appear to be moving fast, but there are core
fundamental factors that are relatively more slow moving. We focus on these
invariant factors to build the logic of the argument.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10898 title=Abstract>arXiv:2401.10898</a> [<a href=https://arxiv.org/pdf/2401.10898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unified Pandemic Tracking System Based on Open Geospatial Consortium SensorThings API
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paniagua%2C+R">Robinson Paniagua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sultan%2C+R">Rdawa Sultan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Refaey%2C+A">Ahmed Refaey</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>With the current nations struggling to track the pandemic's trajectories.
There has been a lack of transparency or real-live data streaming for pandemic
cases and symptoms. This phenomenon has led to a rapid and uncontrolled spread
of these deadly pandemics. One of the main issues in creating a global pandemic
tracking system is the lack of standardization of communications protocols and
the deployment of Internet-of-Things (IoT) device sensors. The Open Geospatial
Consortium (OGC) has developed several sensor web Enablement standards that
allow the expeditious deployment of communications protocols within IoT devices
and other sensor devices like the OGC SensorThings application programming
interface (API). In this paper, to address this issue, we outline the
interoperability challenge and provide a qualitative and quantitative study of
the OGC SensorThings API's deployment and its respective server. The OGC
SensorThings API is developed to provide data exchange services between sensors
and their observations. The OGC SensorThings API would play a primary and
essential role in creating an automated pandemic tracking system. This API
would reduce the deployment of any set of sensors and provide real-time data
tracking. Accordingly, global health organizations would react expeditiously
and concentrate their efforts on high infection rates.
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10899 title=Abstract>arXiv:2401.10899</a> [<a href=https://arxiv.org/pdf/2401.10899 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10899 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10899 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Concrete Problems in AI Safety, Revisited
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raji%2C+I+D">Inioluwa Deborah Raji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dobbe%2C+R">Roel Dobbe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at ICLR workshop on ML in the Real World, 2020
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As AI systems proliferate in society, the AI community is increasingly
preoccupied with the concept of AI Safety, namely the prevention of failures
due to accidents that arise from an unanticipated departure of a system's
behavior from designer intent in AI deployment. We demonstrate through an
analysis of real world cases of such incidents that although current vocabulary
captures a range of the encountered issues of AI deployment, an expanded
socio-technical framing will be required for a more complete understanding of
how AI systems and implemented safety mechanisms fail and succeed in real life.
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10900 title=Abstract>arXiv:2401.10900</a> [<a href=https://arxiv.org/pdf/2401.10900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10900 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fuster%2C+E">Enric Fuster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez%2C+T">Tatiana Fernández</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carretero%2C+H">Hermes Carretero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duran-Silva%2C+N">Nicolau Duran-Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guix%C3%A9%2C+R">Roger Guixé</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pujol%2C+J">Josep Pujol</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rondelli%2C+B">Bernardo Rondelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rull%2C+G">Guillem Rull</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cortijo%2C+M">Marta Cortijo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romagosa%2C+M">Montserrat Romagosa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted and presented at the 27th International Conference on Science, Technology and Innovation Indicators (STI 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>In the new research and innovation (R&amp;I) paradigm, aimed at a transformation
towards more sustainable, inclusive and fair pathways to address societal and
environmental challenges, and at generating new patterns of specialisation and
new trajectories for socioeconomic development, it is essential to provide
monitoring systems and tools to map and understand the contribution of R&amp;I
policies and projects. To address this transformation, we present the RIS3-MCAT
platform, the result of a line of work aimed at exploring the potential of open
data, semantic analysis, and data visualisation, for monitoring
challenge-oriented smart specialisation in Catalonia. RIS3-MCAT is an
interactive platform that facilitates access to R&amp;I project data in formats
that allow for sophisticated analyses of a large volume of texts, enabling the
detailed study of thematic specialisations and challenges beyond classical
classification systems. Its conceptualisation, development framework and use
are presented in this paper.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10901 title=Abstract>arXiv:2401.10901</a> [<a href=https://arxiv.org/pdf/2401.10901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling Technologies for Web 3.0: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassan%2C+M+A">Md Arif Hassan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jamshidi%2C+M+B">Mohammad Behdad Jamshidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manh%2C+B+D">Bui Duc Manh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+N+H">Nam H. Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+C">Chi-Hieu Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hieu%2C+N+Q">Nguyen Quang Hieu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+C+T">Cong T. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alsheikh%2C+M+A">Mohammad Abu Alsheikh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Web 3.0 represents the next stage of Internet evolution, aiming to empower
users with increased autonomy, efficiency, quality, security, and privacy. This
evolution can potentially democratize content access by utilizing the latest
developments in enabling technologies. In this paper, we conduct an in-depth
survey of enabling technologies in the context of Web 3.0, such as blockchain,
semantic web, 3D interactive web, Metaverse, Virtual reality/Augmented reality,
Internet of Things technology, and their roles in shaping Web 3.0. We commence
by providing a comprehensive background of Web 3.0, including its concept,
basic architecture, potential applications, and industry adoption.
Subsequently, we examine recent breakthroughs in IoT, 5G, and blockchain
technologies that are pivotal to Web 3.0 development. Following that, other
enabling technologies, including AI, semantic web, and 3D interactive web, are
discussed. Utilizing these technologies can effectively address the critical
challenges in realizing Web 3.0, such as ensuring decentralized identity,
platform interoperability, data transparency, reducing latency, and enhancing
the system's scalability. Finally, we highlight significant challenges
associated with Web 3.0 implementation, emphasizing potential solutions and
providing insights into future research directions in this field.
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10902 title=Abstract>arXiv:2401.10902</a> [<a href=https://arxiv.org/pdf/2401.10902 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10902 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10902 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The lower energy consumption in cryptocurrency mining processes by SHA-256 Quantum circuit design used in hybrid computing domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orun%2C+A">Ahmet Orun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurugollu%2C+F">Fatih Kurugollu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Cryptography and Security (cs.CR); Quantum Physics (quant-ph)
</div>
<p class=mathjax>Cryptocurrency mining processes always lead to a high energy consumption at
considerably high production cost, which is nearly one-third of cryptocurrency
(e.g. Bitcoin) price itself. As the core of mining process is based on SHA-256
cryptographic hashing function, by using the alternative quantum computers,
hybrid quantum computers or more larger quantum computing devices like quantum
annealers, it would be possible to reduce the mining energy consumption with a
quantum hardware's low-energy-operation characteristics. Within this work we
demonstrated the use of optimized quantum mining facilities which would replace
the classical SHA-256 and high energy consuming classical hardware in near
future.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10904 title=Abstract>arXiv:2401.10904</a> [<a href=https://arxiv.org/pdf/2401.10904 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10904 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10904 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leon%2C+F">Florin Leon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 143 pages, 49 figures, 244 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>This review aims to contribute to the quest for artificial general
intelligence by examining neuroscience and cognitive psychology methods for
potential inspiration. Despite the impressive advancements achieved by deep
learning models in various domains, they still have shortcomings in abstract
reasoning and causal understanding. Such capabilities should be ultimately
integrated into artificial intelligence systems in order to surpass data-driven
limitations and support decision making in a way more similar to human
intelligence. This work is a vertical review that attempts a wide-ranging
exploration of brain function, spanning from lower-level biological neurons,
spiking neural networks, and neuronal ensembles to higher-level concepts such
as brain anatomy, vector symbolic architectures, cognitive and categorization
models, and cognitive architectures. The hope is that these concepts may offer
insights for solutions in artificial general intelligence.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10914 title=Abstract>arXiv:2401.10914</a> [<a href=https://arxiv.org/pdf/2401.10914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Neural Network Software Testing, Analysis, and Code Optimization for Advanced IoT Systems: Design, Implementation, and Visualization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Soohyun Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Joongheon Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>This paper introduces a novel run-time testing, analysis, and code
optimization (TACO) method for quantum neural network (QNN) software in
advanced Internet-of-Things (IoT) systems, which visually presents the learning
performance that is called a barren plateau. The run-time visual presentation
of barren plateau situations is helpful for real-time quantum-based advanced
IoT software testing because the software engineers can easily be aware of the
training performances of QNN. Moreover, this tool is obviously useful for
software engineers because it can intuitively guide them in designing and
implementing high-accurate QNN-based advanced IoT software even if they are not
familiar with quantum mechanics and quantum computing. Lastly, the proposed
TACO is also capable of visual feedback because software engineers visually
identify the barren plateau situations using tensorboard. In turn, they are
also able to modify QNN structures based on the information.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10917 title=Abstract>arXiv:2401.10917</a> [<a href=https://arxiv.org/pdf/2401.10917 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10917 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Artificial intelligence to automate the systematic review of scientific literature
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+la+Torre-L%C3%B3pez%2C+J">José de la Torre-López</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ram%C3%ADrez%2C+A">Aurora Ramírez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romero%2C+J+R">José Raúl Romero</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 3 figures, 1 table, journal paper
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Computing, Volume 105, pages 2171-2194, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Artificial intelligence (AI) has acquired notorious relevance in modern
computing as it effectively solves complex tasks traditionally done by humans.
AI provides methods to represent and infer knowledge, efficiently manipulate
texts and learn from vast amount of data. These characteristics are applicable
in many activities that human find laborious or repetitive, as is the case of
the analysis of scientific literature. Manually preparing and writing a
systematic literature review (SLR) takes considerable time and effort, since it
requires planning a strategy, conducting the literature search and analysis,
and reporting the findings. Depending on the area under study, the number of
papers retrieved can be of hundreds or thousands, meaning that filtering those
relevant ones and extracting the key information becomes a costly and
error-prone process. However, some of the involved tasks are repetitive and,
therefore, subject to automation by means of AI. In this paper, we present a
survey of AI techniques proposed in the last 15 years to help researchers
conduct systematic analyses of scientific literature. We describe the tasks
currently supported, the types of algorithms applied, and available tools
proposed in 34 primary studies. This survey also provides a historical
perspective of the evolution of the field and the role that humans can play in
an increasingly automated SLR process.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10921 title=Abstract>arXiv:2401.10921</a> [<a href=https://arxiv.org/pdf/2401.10921 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10921 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Push- and Pull-based Effective Communication in Cyber-Physical Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Talli%2C+P">Pietro Talli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mason%2C+F">Federico Mason</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chiariotti%2C+F">Federico Chiariotti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zanella%2C+A">Andrea Zanella</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>In Cyber Physical Systems (CPSs), two groups of actors interact toward the
maximization of system performance: the sensors, observing and disseminating
the system state, and the actuators, performing physical decisions based on the
received information. While it is generally assumed that sensors periodically
transmit updates, returning the feedback signal only when necessary, and
consequently adapting the physical decisions to the communication policy, can
significantly improve the efficiency of the system. In particular, the choice
between push-based communication, in which updates are initiated autonomously
by the sensors, and pull-based communication, in which they are requested by
the actuators, is a key design step. In this work, we propose an analytical
model for optimizing push- and pull-based communication in CPSs, observing that
the policy optimality coincides with Value of Information (VoI) maximization.
Our results also highlight that, despite providing a better optimal solution,
implementable push-based communication strategies may underperform even in
relatively simple scenarios.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10926 title=Abstract>arXiv:2401.10926</a> [<a href=https://arxiv.org/pdf/2401.10926 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10926 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A VR Serious Game to Increase Empathy towards Students with Phonological Dyslexia
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alcalde-Llergo%2C+J+M">José M. Alcalde-Llergo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeguas-Bol%C3%ADvar%2C+E">Enrique Yeguas-Bolívar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aparicio-Mart%C3%ADnez%2C+P">Pilar Aparicio-Martínez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zingoni%2C+A">Andrea Zingoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taborri%2C+J">Juri Taborri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinzi%2C+S">Sara Pinzi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 5 figures, MetroXRAINE 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE International Conference on Metrology for Extended
 Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE),
 Milano, Italy, 2023, pp. 184-188
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)
</div>
<p class=mathjax>Dyslexia is a neurodevelopmental disorder that is estimated to affect about
5-10% of the population. In particular, phonological dyslexia causes problems
in connecting the sounds of words with their written forms. This results in
difficulties such as slow reading speed, inaccurate reading, and difficulty
decoding unfamiliar words. Moreover, dyslexia can also be a challenging and
frustrating experience for students as they may feel misunderstood or
stigmatized by their peers or educators. For these reasons, the use of
compensatory tools and strategies is of crucial importance for dyslexic
students to have the same opportunities as non-dyslexic ones. However,
generally, people underestimate the problem and are not aware of the importance
of support methodologies. In the light of this, the main purpose of this paper
is to propose a virtual reality (VR) serious game through which teachers,
students and, in general, non-dyslexic people could understand which are some
of the issues of student with dyslexia and the fundamental utility of offering
support to them. In the game, players must create a potion by following a
recipe written in an alphabet that is specifically designed to replicate the
reading difficulties experienced by individuals with dyslexia. The task must be
solved first without any help and then by receiving supporting tools and
strategies with the idea that the player can put himself in the place of the
dyslexic person and understand the real need for support methodologies.
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10934 title=Abstract>arXiv:2401.10934</a> [<a href=https://arxiv.org/pdf/2401.10934 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10934 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jianxin Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Shuai Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Linhe Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuo Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yifan Zeng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In online advertising scenario, sellers often create multiple creatives to
provide comprehensive demonstrations, making it essential to present the most
appealing design to maximize the Click-Through Rate (CTR). However, sellers
generally struggle to consider users preferences for creative design, leading
to the relatively lower aesthetics and quantities compared to Artificial
Intelligence (AI)-based approaches. Traditional AI-based approaches still face
the same problem of not considering user information while having limited
aesthetic knowledge from designers. In fact that fusing the user information,
the generated creatives can be more attractive because different users may have
different preferences. To optimize the results, the generated creatives in
traditional methods are then ranked by another module named creative ranking
model. The ranking model can predict the CTR score for each creative
considering user features. However, the two above stages are regarded as two
different tasks and are optimized separately. In this paper, we proposed a new
automated Creative Generation pipeline for Click-Through Rate (CG4CTR) with the
goal of improving CTR during the creative generation stage. Our contributions
have 4 parts: 1) The inpainting mode in stable diffusion is firstly applied to
creative generation task in online advertising scene. A self-cyclic generation
pipeline is proposed to ensure the convergence of training. 2) Prompt model is
designed to generate individualized creatives for different user groups, which
can further improve the diversity and quality. 3) Reward model comprehensively
considers the multimodal features of image and text to improve the
effectiveness of creative ranking task, and it is also critical in self-cyclic
pipeline. 4) The significant benefits obtained in online and offline
experiments verify the significance of our proposed method.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10935 title=Abstract>arXiv:2401.10935</a> [<a href=https://arxiv.org/pdf/2401.10935 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10935 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+K">Kanzhi Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qiushi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Y">Yougang Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Fangzhi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yantao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianbing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyong Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Graphical User Interface (GUI) agents are designed to automate complex tasks
on digital devices, such as smartphones and desktops. Most existing GUI agents
interact with the environment through extracted structured data, which can be
notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops).
To alleviate this issue, we propose a visual GUI agent -- SeeClick, which only
relies on screenshots for task automation. In our preliminary study, we have
discovered a key challenge in developing visual GUI agents: GUI grounding --
the capacity to accurately locate screen elements based on instructions. To
tackle this challenge, we propose to enhance SeeClick with GUI grounding
pre-training and devise a method to automate the curation of GUI grounding
data. Along with the efforts above, we have also created ScreenSpot, the first
realistic GUI grounding dataset that encompasses mobile, desktop, and web
environments. After pre-training, SeeClick demonstrates significant improvement
in ScreenSpot over various baselines. Moreover, comprehensive evaluations on
three widely used benchmarks consistently support our finding that advancements
in GUI grounding directly correlate with enhanced performance in downstream GUI
agent tasks. The model, data and code are available at
https://github.com/njucckevin/SeeClick.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10938 title=Abstract>arXiv:2401.10938</a> [<a href=https://arxiv.org/pdf/2401.10938 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10938 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10938 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Even-if Explanations: Formal Foundations, Priorities and Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alfano%2C+G">Gianvincenzo Alfano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greco%2C+S">Sergio Greco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandaglio%2C+D">Domenico Mandaglio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parisi%2C+F">Francesco Parisi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahbazian%2C+R">Reza Shahbazian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trubitsyna%2C+I">Irina Trubitsyna</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2010.12265>arXiv:2010.12265</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>EXplainable AI has received significant attention in recent years. Machine
learning models often operate as black boxes, lacking explainability and
transparency while supporting decision-making processes. Local post-hoc
explainability queries attempt to answer why individual inputs are classified
in a certain way by a given model. While there has been important work on
counterfactual explanations, less attention has been devoted to semifactual
ones. In this paper, we focus on local post-hoc explainability queries within
the semifactual `even-if' thinking and their computational complexity among
different classes of models, and show that both linear and tree-based models
are strictly more interpretable than neural networks. After this, we introduce
a preference-based framework that enables users to personalize explanations
based on their preferences, both in the case of semifactuals and
counterfactuals, enhancing interpretability and user-centricity. Finally, we
explore the complexity of several interpretability problems in the proposed
preference-based framework and provide algorithms for polynomial cases.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10940 title=Abstract>arXiv:2401.10940</a> [<a href=https://arxiv.org/pdf/2401.10940 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10940 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10940 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramezani%2C+M">Majid Ramezani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammad-Shahi%2C+H">Hamed Mohammad-Shahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daliry%2C+M">Mahshid Daliry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahmani%2C+S">Soroor Rahmani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asghari%2C+A">Amir-Hosein Asghari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>In the era of information proliferation, discerning the credibility of news
content poses an ever-growing challenge. This paper introduces RELIANCE, a
pioneering ensemble learning system designed for robust information and fake
news credibility evaluation. Comprising five diverse base models, including
Support Vector Machine (SVM), naive Bayes, logistic regression, random forest,
and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs
an innovative approach to integrate their strengths, harnessing the collective
intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the
superiority of RELIANCE over individual models, indicating its efficacy in
distinguishing between credible and non-credible information sources. RELIANCE,
also surpasses baseline models in information and news credibility assessment,
establishing itself as an effective solution for evaluating the reliability of
information sources.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10941 title=Abstract>arXiv:2401.10941</a> [<a href=https://arxiv.org/pdf/2401.10941 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10941 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Crowd-PrefRL: Preference-Based Reward Learning from Crowds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chhan%2C+D">David Chhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Novoseller%2C+E">Ellen Novoseller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lawhern%2C+V+J">Vernon J. Lawhern</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Preference-based reinforcement learning (RL) provides a framework to train
agents using human feedback through pairwise preferences over pairs of
behaviors, enabling agents to learn desired behaviors when it is difficult to
specify a numerical reward function. While this paradigm leverages human
feedback, it currently treats the feedback as given by a single human user.
Meanwhile, incorporating preference feedback from crowds (i.e. ensembles of
users) in a robust manner remains a challenge, and the problem of training RL
agents using feedback from multiple human users remains understudied. In this
work, we introduce Crowd-PrefRL, a framework for performing preference-based RL
leveraging feedback from crowds. This work demonstrates the viability of
learning reward functions from preference feedback provided by crowds of
unknown expertise and reliability. Crowd-PrefRL not only robustly aggregates
the crowd preference feedback, but also estimates the reliability of each user
within the crowd using only the (noisy) crowdsourced preference comparisons.
Most importantly, we show that agents trained with Crowd-PrefRL outperform
agents trained with majority-vote preferences or preferences from any
individual user in most cases, especially when the spread of user error rates
among the crowd is large. Results further suggest that our method can identify
minority viewpoints within the crowd.
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10942 title=Abstract>arXiv:2401.10942</a> [<a href=https://arxiv.org/pdf/2401.10942 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10942 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10942 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine Unlearning for Recommendation Systems: An Insight
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sachdeva%2C+B">Bhavika Sachdeva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rathee%2C+H">Harshita Rathee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sristi">Sristi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+A">Arun Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wydma%C5%84ski%2C+W">Witold Wydmański</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings of 7th INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION 2024 (<a href=https://icicc-conf.com/>this https URL</a>)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This review explores machine unlearning (MUL) in recommendation systems,
addressing adaptability, personalization, privacy, and bias challenges. Unlike
traditional models, MUL dynamically adjusts system knowledge based on shifts in
user preferences and ethical considerations. The paper critically examines
MUL's basics, real-world applications, and challenges like algorithmic
transparency. It sifts through literature, offering insights into how MUL could
transform recommendations, discussing user trust, and suggesting paths for
future research in responsible and user-focused artificial intelligence (AI).
The document guides researchers through challenges involving the trade-off
between personalization and privacy, encouraging contributions to meet
practical demands for targeted data removal. Emphasizing MUL's role in secure
and adaptive machine learning, the paper proposes ways to push its boundaries.
The novelty of this paper lies in its exploration of the limitations of the
methods, which highlights exciting prospects for advancing the field.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10945 title=Abstract>arXiv:2401.10945</a> [<a href=https://arxiv.org/pdf/2401.10945 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10945 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automatic dimensionality reduction of Twin-in-the-Loop Observers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delcaro%2C+G">Giacomo Delcaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dett%C3%B9%2C+F">Federico Dettù</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Formentin%2C+S">Simone Formentin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Savaresi%2C+S+M">Sergio Matteo Savaresi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>State-of-the-art vehicle dynamics estimation techniques usually share one
common drawback: each variable to estimate is computed with an independent,
simplified filtering module. These modules run in parallel and need to be
calibrated separately. To solve this issue, a unified Twin-in-the-Loop (TiL)
Observer architecture has recently been proposed: the classical simplified
control-oriented vehicle model in the estimators is replaced by a full-fledged
vehicle simulator, or digital twin (DT). The states of the DT are corrected in
real time with a linear time invariant output error law. Since the simulator is
a black-box, no explicit analytical formulation is available, hence classical
filter tuning techniques cannot be used. Due to this reason, Bayesian
Optimization will be used to solve a data-driven optimization problem to tune
the filter. Due to the complexity of the DT, the optimization problem is
high-dimensional. This paper aims to find a procedure to tune the
high-complexity observer by lowering its dimensionality. In particular, in this
work we will analyze both a supervised and an unsupervised learning approach.
The strategies have been validated for speed and yaw-rate estimation on
real-world data.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10946 title=Abstract>arXiv:2401.10946</a> [<a href=https://arxiv.org/pdf/2401.10946 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10946 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self context-aware emotion perception on human-robot interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zihan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cruz%2C+F">Francisco Cruz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandoval%2C+E+B">Eduardo Benitez Sandoval</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Australasian Conference on Robotics and Automation (ACRA). 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Emotion recognition plays a crucial role in various domains of human-robot
interaction. In long-term interactions with humans, robots need to respond
continuously and accurately, however, the mainstream emotion recognition
methods mostly focus on short-term emotion recognition, disregarding the
context in which emotions are perceived. Humans consider that contextual
information and different contexts can lead to completely different emotional
expressions. In this paper, we introduce self context-aware model (SCAM) that
employs a two-dimensional emotion coordinate system for anchoring and
re-labeling distinct emotions. Simultaneously, it incorporates its distinctive
information retention structure and contextual loss. This approach has yielded
significant improvements across audio, video, and multimodal. In the auditory
modality, there has been a notable enhancement in accuracy, rising from 63.10%
to 72.46%. Similarly, the visual modality has demonstrated improved accuracy,
increasing from 77.03% to 80.82%. In the multimodal, accuracy has experienced
an elevation from 77.48% to 78.93%. In the future, we will validate the
reliability and usability of SCAM on robots through psychology experiments.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10948 title=Abstract>arXiv:2401.10948</a> [<a href=https://arxiv.org/pdf/2401.10948 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10948 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10948 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design Principles &amp; Issues for Gaze and Pinch Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfeuffer%2C+K">Ken Pfeuffer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>With the imminent release of the Apple Vision Pro, a wave of innovative
technology will be going to get into people's hands. The "eyes and hands"
interface mixes up interaction design, indicating a need for principles,
frameworks, and standards. This article highlights 5 design principles and 5
issues for designing eyes &amp; hands interfaces, drawing insights from both my
personal experience and scientific articles in the area of human-computer
interaction. Whether you're interested in design, tech, or research in this
evolving space, the article provides valuable perspectives to enhance your
understanding.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10949 title=Abstract>arXiv:2401.10949</a> [<a href=https://arxiv.org/pdf/2401.10949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10949 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Synergy Between Optimal Transport Theory and Multi-Agent Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baheri%2C+A">Ali Baheri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kochenderfer%2C+a+M+J">and Mykel J. Kochenderfer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper explores the integration of optimal transport (OT) theory with
multi-agent reinforcement learning (MARL). This integration uses OT to handle
distributions and transportation problems to enhance the efficiency,
coordination, and adaptability of MARL. There are five key areas where OT can
impact MARL: (1) policy alignment, where OT's Wasserstein metric is used to
align divergent agent strategies towards unified goals; (2) distributed
resource management, employing OT to optimize resource allocation among agents;
(3) addressing non-stationarity, using OT to adapt to dynamic environmental
shifts; (4) scalable multi-agent learning, harnessing OT for decomposing
large-scale learning objectives into manageable tasks; and (5) enhancing energy
efficiency, applying OT principles to develop sustainable MARL systems. This
paper articulates how the synergy between OT and MARL can address scalability
issues, optimize resource distribution, align agent policies in cooperative
environments, and ensure adaptability in dynamically changing conditions.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10953 title=Abstract>arXiv:2401.10953</a> [<a href=https://arxiv.org/pdf/2401.10953 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10953 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10953 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How customers' satisfaction change with the use of AR shopping application: A conceptuall model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanaei%2C+F">Fariba Sanaei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2023 AMA Winter Academic Conference
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 AMA Winter Academic Conference Proceedings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The paper proposes a conceptual model of how different perceived levels of
experiential AR application features have effects on customer experience, and
in turn their satisfaction and purchase behavior. In addition, it put forward
the mediation role of immersion between perceived levels of experiential AR
application features and customers experience.
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10956 title=Abstract>arXiv:2401.10956</a> [<a href=https://arxiv.org/pdf/2401.10956 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10956 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+S">Sida Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swiatek%2C+W">Wojciech Swiatek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+A">Allen Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cullivan%2C+P">Paul Cullivan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+H">Haoge Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>In recent years, generative AI has undergone major advancements,
demonstrating significant promise in augmenting human productivity. Notably,
large language models (LLM), with ChatGPT-4 as an example, have drawn
considerable attention. Numerous articles have examined the impact of LLM-based
tools on human productivity in lab settings and designed tasks or in
observational studies. Despite recent advances, field experiments applying
LLM-based tools in realistic settings are limited. This paper presents the
findings of a field randomized controlled trial assessing the effectiveness of
LLM-based tools in providing unmonitored support services for information
retrieval.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10959 title=Abstract>arXiv:2401.10959</a> [<a href=https://arxiv.org/pdf/2401.10959 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10959 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10959 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine learning classification of power converter control mode
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ouali%2C+R">Rabah Ouali</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dieulot%2C+J">Jean-Yves Dieulot</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yim%2C+P">Pascal Yim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guillaud%2C+X">Xavier Guillaud</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Colas%2C+F">Frédéric Colas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+Y">Yang Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+H">Heng Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>To ensure the proper functioning of the current and future electrical grid,
it is necessary for Transmission System Operators (TSOs) to verify that energy
providers comply with the grid code and specifications provided by TSOs. A lot
of energy production are conntected to the grid through a power electronic
inverter. Grid Forming (GFM) and Grid Following (GFL) are the two types of
operating modes used to control power electronic converters. The choice of
control mode by TSOs to avoid impacting the stability of the grid is crucial,
as is the commitment to these choices by energy suppliers. This article
proposes a comparison between commonplace machine learning algorithms for
converter control mode classification: GFL or GFM. The classification is based
on frequency-domain admittance obtained by external measurement methods. Most
algorithms are able to classify accurately when the control structure belongs
to the training data, but they fail to classify modified control structures
with the exception of the random forest algorithm.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10961 title=Abstract>arXiv:2401.10961</a> [<a href=https://arxiv.org/pdf/2401.10961 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10961 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Positive unlabeled learning for building recommender systems in a parliamentary setting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Camposa%2C+L+M">Luis M. de Camposa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fernández-Luna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huete%2C+J+F">Juan F. Huete</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Redondo-Exp%C3%B3sito%2C+L">Luis Redondo-Expósito</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Our goal is to learn about the political interests and preferences of the
Members of Parliament by mining their parliamentary activity, in order to
develop a recommendation/filtering system that, given a stream of documents to
be distributed among them, is able to decide which documents should receive
each Member of Parliament. We propose to use positive unlabeled learning to
tackle this problem, because we only have information about relevant documents
(the own interventions of each Member of Parliament in the debates) but not
about irrelevant documents, so that we cannot use standard binary classifiers
trained with positive and negative examples. We have also developed a new
algorithm of this type, which compares favourably with: a) the baseline
approach assuming that all the interventions of other Members of Parliament are
irrelevant, b) another well-known positive unlabeled learning method and c) an
approach based on information retrieval methods that matches documents and
legislators' representations. The experiments have been carried out with data
from the regional Andalusian Parliament at Spain.
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10962 title=Abstract>arXiv:2401.10962</a> [<a href=https://arxiv.org/pdf/2401.10962 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10962 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> One Step Learning, One Step Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaolong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qiankun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xueran Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xuesong Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Visual fine-tuning has garnered significant attention with the rise of
pre-trained vision models. The current prevailing method, full fine-tuning,
suffers from the issue of knowledge forgetting as it focuses solely on fitting
the downstream training set. In this paper, we propose a novel weight
rollback-based fine-tuning method called OLOR (One step Learning, One step
Review). OLOR combines fine-tuning with optimizers, incorporating a weight
rollback term into the weight update term at each step. This ensures
consistency in the weight range of upstream and downstream models, effectively
mitigating knowledge forgetting and enhancing fine-tuning performance. In
addition, a layer-wise penalty is presented to employ penalty decay and the
diversified decay rate to adjust the weight rollback levels of layers for
adapting varying downstream tasks. Through extensive experiments on various
tasks such as image classification, object detection, semantic segmentation,
and instance segmentation, we demonstrate the general applicability and
state-of-the-art performance of our proposed OLOR. Code is available at
https://github.com/rainbow-xiao/OLOR-AAAI-2024.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10963 title=Abstract>arXiv:2401.10963</a> [<a href=https://arxiv.org/pdf/2401.10963 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10963 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the selection of the correct number of terms for profile construction: theoretical and empirical analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fernández-Luna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huete%2C+J+F">Juan F. Huete</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>In this paper, we examine the problem of building a user profile from a set
of documents. This profile will consist of a subset of the most representative
terms in the documents that best represent user preferences or interests.
Inspired by the discrete concentration theory we have conducted an axiomatic
study of seven properties that a selection function should fulfill: the minimum
and maximum uncertainty principle, invariant to adding zeros, invariant to
scale transformations, principle of nominal increase, transfer principle and
the richest get richer inequality. We also present a novel selection function
based on the use of similarity metrics, and more specifically the cosine
measure which is commonly used in information retrieval, and demonstrate that
this verifies six of the properties in addition to a weaker variant of the
transfer principle, thereby representing a good selection approach. The
theoretical study was complemented with an empirical study to compare the
performance of different selection criteria (weight- and unweight-based) using
real data in a parliamentary setting. In this study, we analyze the performance
of the different functions focusing on the two main factors affecting the
selection process: profile size (number of terms) and weight distribution.
These profiles are then used in a document filtering task to show that our
similarity-based approach performs well in terms not only of recommendation
accuracy but also efficiency (we obtain smaller profiles and consequently
faster recommendations).
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10965 title=Abstract>arXiv:2401.10965</a> [<a href=https://arxiv.org/pdf/2401.10965 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10965 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lujak%2C+M">Marin Lujak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giordani%2C+S">Stefano Giordani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omicini%2C+A">Andrea Omicini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Complexity, Volume 2020, Article ID 1047369
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>One of the major challenges in the coordination of large, open,
collaborative, and commercial vehicle fleets is dynamic task allocation.
Self-concerned individually rational vehicle drivers have both local and global
objectives, which require coordination using some fair and efficient task
allocation method. In this paper, we review the literature on scalable and
dynamic task allocation focusing on deterministic and dynamic two-dimensional
linear assignment problems. We focus on multiagent system representation of
open vehicle fleets where dynamically appearing vehicles are represented by
software agents that should be allocated to a set of dynamically appearing
tasks. We give a comparison and critical analysis of recent research results
focusing on centralized, distributed, and decentralized solution approaches.
Moreover, we propose mathematical models for dynamic versions of the following
assignment problems well known in combinatorial optimization: the assignment
problem, bottleneck assignment problem, fair matching problem, dynamic minimum
deviation assignment problem, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:1.855em;display:inline-block><span style=display:inline-block;position:relative;width:1.508em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1001.51em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-2><span class=munderover id=MathJax-Span-3><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.99em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-4 style=font-family:MathJax_Size1;vertical-align:0em>∑</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.701em;left:1.045em><span class=texatom id=MathJax-Span-5><span class=mrow id=MathJax-Span-6><span class=mi id=MathJax-Span-7 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span>-assignment problem, the semiassignment
problem, the assignment problem with side constraints, and the assignment
problem while recognizing agent qualification; all while considering the main
aspect of open vehicle fleets: random arrival of tasks and vehicles (agents)
that may become available after assisting previous tasks or by participating in
the fleet at times based on individual interest.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10967 title=Abstract>arXiv:2401.10967</a> [<a href=https://arxiv.org/pdf/2401.10967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HOSC: A Periodic Activation Function for Preserving Sharp Features in Implicit Neural Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serrano%2C+D">Danzel Serrano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szymkowiak%2C+J">Jakub Szymkowiak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Musialski%2C+P">Przemyslaw Musialski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG)
</div>
<p class=mathjax>Recently proposed methods for implicitly representing signals such as images,
scenes, or geometries using coordinate-based neural network architectures often
do not leverage the choice of activation functions, or do so only to a limited
extent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC),
a novel activation function with a controllable sharpness parameter. Unlike any
previous activations, HOSC has been specifically designed to better capture
sudden changes in the input signal, and hence sharp or acute features of the
underlying data, as well as smooth low-frequency transitions. Due to its
simplicity and modularity, HOSC offers a plug-and-play functionality that can
be easily incorporated into any existing method employing a neural network as a
way of implicitly representing a signal. We benchmark HOSC against other
popular activations in an array of general tasks, empirically showing an
improvement in the quality of obtained representations, provide the
mathematical motivation behind the efficacy of HOSC, and discuss its
limitations.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10969 title=Abstract>arXiv:2401.10969</a> [<a href=https://arxiv.org/pdf/2401.10969 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10969 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MacroSwarm: A Field-based Compositional Framework for Swarm Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aguzzi%2C+G">Gianluca Aguzzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casadei%2C+R">Roberto Casadei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viroli%2C+M">Mirko Viroli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)
</div>
<p class=mathjax>Swarm behaviour engineering is an area of research that seeks to investigate
methods and techniques for coordinating computation and action within groups of
simple agents to achieve complex global goals like pattern formation,
collective movement, clustering, and distributed sensing. Despite recent
progress in the analysis and engineering of swarms (of drones, robots,
vehicles), there is still a need for general design and implementation methods
and tools that can be used to define complex swarm behaviour in a principled
way. To contribute to this quest, this article proposes a new field-based
coordination approach, called MacroSwarm, to design and program swarm behaviour
in terms of reusable and fully composable functional blocks embedding
collective computation and coordination. Based on the macroprogramming paradigm
of aggregate computing, MacroSwarm builds on the idea of expressing each swarm
behaviour block as a pure function mapping sensing fields into actuation goal
fields, e.g. including movement vectors. In order to demonstrate the
expressiveness, compositionality, and practicality of MacroSwarm as a framework
for collective intelligence, we perform a variety of simulations covering
common patterns of flocking, morphogenesis, and collective decision-making.
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10973 title=Abstract>arXiv:2401.10973</a> [<a href=https://arxiv.org/pdf/2401.10973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> T2MAC: Targeted and Trusted Multi-Agent Communication through Selective Engagement and Evidence-Driven Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+C">Chuxiong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+Z">Zehua Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiabao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiangmeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+C">Changwen Zheng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Communication stands as a potent mechanism to harmonize the behaviors of
multiple agents. However, existing works primarily concentrate on broadcast
communication, which not only lacks practicality, but also leads to information
redundancy. This surplus, one-fits-all information could adversely impact the
communication efficiency. Furthermore, existing works often resort to basic
mechanisms to integrate observed and received information, impairing the
learning process. To tackle these difficulties, we propose Targeted and Trusted
Multi-Agent Communication (T2MAC), a straightforward yet effective method that
enables agents to learn selective engagement and evidence-driven integration.
With T2MAC, agents have the capability to craft individualized messages,
pinpoint ideal communication windows, and engage with reliable partners,
thereby refining communication efficiency. Following the reception of messages,
the agents integrate information observed and received from different sources
at an evidence level. This process enables agents to collectively use evidence
garnered from multiple perspectives, fostering trusted and cooperative
behaviors. We evaluate our method on a diverse set of cooperative multi-agent
tasks, with varying difficulties, involving different scales and ranging from
Hallway, MPE to SMAC. The experiments indicate that the proposed model not only
surpasses the state-of-the-art methods in terms of cooperative performance and
communication efficiency, but also exhibits impressive generalization.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10990 title=Abstract>arXiv:2401.10990</a> [<a href=https://arxiv.org/pdf/2401.10990 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10990 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Nonlinear Observer Design for the Discrete-time Systems: Exploiting Matrix-Multiplier-based LMI Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mohite%2C+S">Shivaraj Mohite</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This letter focuses on the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-8 style=width:1.97em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.62em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-9><span class=msubsup id=MathJax-Span-10><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.227em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-11><span class=mrow id=MathJax-Span-12><span class=mi id=MathJax-Span-13 style=font-family:MathJax_Caligraphic>H</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-14 style=font-size:70.7%;font-family:MathJax_Main>∞</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> observer design for a class
of nonlinear discrete systems under the presence of measurement noise or
external disturbances. A novel Linear Matrix Inequality (LMI) condition is
developed in this method through the utilisation of the reformulated Lipschitz
property, a new variant of Young inequality and the well-known Linear Parameter
Varying (LPV) approach. One of the key components of the proposed LMI is the
generalised matrix multipliers. The deliberate use of these multipliers enables
us to introduce more numbers of decision variables inside LMIs than the one
illustrated in the literature. It aids in adding some extra degrees of freedom
from a feasibility point of view, thus enhancing the LMI conditions. Thus, the
proposed LMIs are less conservative than existing ones. Later on, the
effectiveness of the developed LMIs and observer is highlighted through the
numerical example and an application of state of charge (SoC) estimation in the
Li-ion battery model.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10995 title=Abstract>arXiv:2401.10995</a> [<a href=https://arxiv.org/pdf/2401.10995 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10995 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Radiation Oncology NLP Database
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holmes%2C+J">Jason Holmes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+W">Wenxiong Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenbin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+H">Hongying Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Peilong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elahi%2C+M+A">Muhammad Ali Elahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+H">Hongmin Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Quanzheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+J">Jiajian Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 7 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Medical Physics (physics.med-ph)
</div>
<p class=mathjax>We present the Radiation Oncology NLP Database (ROND), the first dedicated
Natural Language Processing (NLP) dataset for radiation oncology, an important
medical specialty that has received limited attention from the NLP community in
the past. With the advent of Artificial General Intelligence (AGI), there is an
increasing need for specialized datasets and benchmarks to facilitate research
and development. ROND is specifically designed to address this gap in the
domain of radiation oncology, a field that offers many opportunities for NLP
exploration. It encompasses various NLP tasks including Logic Reasoning, Text
Classification, Named Entity Recognition (NER), Question Answering (QA), Text
Summarization, and Patient-Clinician Conversations, each with a distinct focus
on radiation oncology concepts and application cases. In addition, we have
developed an instruction-tuning dataset consisting of over 20k instruction
pairs (based on ROND) and trained a large language model, CancerChat. This
serves to demonstrate the potential of instruction-tuning large language models
within a highly-specialized medical domain. The evaluation results in this
study could serve as baseline results for future research. ROND aims to
stimulate advancements in radiation oncology and clinical NLP by offering a
platform for testing and improving algorithms and models in a domain-specific
context. The ROND dataset is a joint effort of multiple U.S. health
institutions. The data is available at
https://github.com/zl-liu/Radiation-Oncology-NLP-Database.
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10997 title=Abstract>arXiv:2401.10997</a> [<a href=https://arxiv.org/pdf/2401.10997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10997 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Novel and Accurate BiLSTM Configuration Controller for Modular Soft Robots with Module Number Adaptability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zixi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernabei%2C+M">Matteo Bernabei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mainardi%2C+V">Vanessa Mainardi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xuyang Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ciuti%2C+G">Gastone Ciuti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stefanini%2C+C">Cesare Stefanini</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Modular soft robots have shown higher potential in sophisticated tasks than
single-module robots. However, the modular structure incurs the complexity of
accurate control and necessitates a control strategy specifically for modular
robots. In this paper, we introduce a data collection strategy and a novel and
accurate bidirectional LSTM configuration controller for modular soft robots
with module number adaptability. Such a controller can control module
configurations in robots with different module numbers. Simulation cable-driven
robots and real pneumatic robots have been included in experiments to validate
the proposed approaches, and we have proven that our controller can be
leveraged even with the increase or decrease of module number. This is the
first paper that gets inspiration from the physical structure of modular robots
and utilizes bidirectional LSTM for module number adaptability. Future work may
include a planning method that bridges the task and configuration spaces and
the integration of an online controller.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11002 title=Abstract>arXiv:2401.11002</a> [<a href=https://arxiv.org/pdf/2401.11002 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11002 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Registration of Photorealistic Avatars for VR Facial Animation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patel%2C+C">Chaitanya Patel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+S">Shaojie Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Te-Li Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saragih%2C+J">Jason Saragih</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+S">Shih-En Wei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://chaitanya100100.github.io/FastRegistration/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Virtual Reality (VR) bares promise of social interactions that can feel more
immersive than other media. Key to this is the ability to accurately animate a
photorealistic avatar of one's likeness while wearing a VR headset. Although
high quality registration of person-specific avatars to headset-mounted camera
(HMC) images is possible in an offline setting, the performance of generic
realtime models are significantly degraded. Online registration is also
challenging due to oblique camera views and differences in modality. In this
work, we first show that the domain gap between the avatar and headset-camera
images is one of the primary sources of difficulty, where a transformer-based
architecture achieves high accuracy on domain-consistent data, but degrades
when the domain-gap is re-introduced. Building on this finding, we develop a
system design that decouples the problem into two parts: 1) an iterative
refinement module that takes in-domain inputs, and 2) a generic avatar-guided
image-to-image style transfer module that is conditioned on current estimation
of expression and head pose. These two modules reinforce each other, as image
style transfer becomes easier when close-to-ground-truth examples are shown,
and better domain-gap removal helps registration. Our system produces
high-quality results efficiently, obviating the need for costly offline
registration to generate personalized labels. We validate the accuracy and
efficiency of our approach through extensive experiments on a commodity
headset, demonstrating significant improvements over direct regression methods
as well as offline registration.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11008 title=Abstract>arXiv:2401.11008</a> [<a href=https://arxiv.org/pdf/2401.11008 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11008 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Helmholtz-Decomposition and Optical Flow: A new method to characterize GCamP recordings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerstenberger%2C+M">Michael Gerstenberger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Juestel%2C+D">Dominic Juestel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodea%2C+S">Silviu Bodea</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>During deep sleep and under anaesthesia spontaneous patterns of cortical
activation frequently take the form of slow travelling waves. Slow wave sleep
is an important cognitive state especially because of its relevance for memory
consolidation. However, despite extensive research the exact mechanisms are
still ill-understood. Novel methods such as high speed widefield imaging of
GCamP activity offer new potentials. Here we show how data recorded from
transgenic mice under anesthesia can be processed to analyze sources, sinks and
patterns of flow. To make the best possible use of the data novel means of data
processing are necessary. Therefore, we (1) give a an brief account on
processes that play a role in generating slow waves and demonstrate (2) a novel
approach to characterize its patterns in GCamP recordings. While slow waves are
highly variable, it shows that some are surprisingly similar. To enable
quantitative means of analysis and examine the structure of such prototypical
events we propose a novel approach for the characterization of slow waves: The
Helmholtz-Decomposition of gradient-based Dense Optical Flow of the pixeldense
GCamP contrast (df/f). It allows to detect the sources and sinks of activation
and discern them from global patterns of neural flow. Aggregated features can
be analyzed with variational autoencoders. The results unravel regularities
between slow waves and shows how they relate to the experimental conditions.
The approach reveals a complex topology of different features in latent slow
wave space and identifies prototypical examples for each stage.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11012 title=Abstract>arXiv:2401.11012</a> [<a href=https://arxiv.org/pdf/2401.11012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11012 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Warum wir es für eine gute Idee gehalten haben, eine DACH-Spieledatenbank aufzubauen
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfister%2C+E">Eugen Pfister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brandenburg%2C+A">Aurelia Brandenburg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demleitner%2C+A">Adrian Demleitner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klausner%2C+L+D">Lukas Daniel Klausner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, in German language
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Game-Journalismus: Grundlagen - Themen - Spannungsfelder. Ein
 Handbuch, Springer VS, Wiesbaden 2024, 307-316
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>We are in the process of creating a database of digital games from the DACH
region. This article provides an insight into the context in which it was
created and the underlying methodological considerations behind the games
database. The database was compiled collaboratively and lists digital games
developed in Germany, Austria and Switzerland up to the year 2000. In this
report, we outline our initial considerations and the various stages of
realisation as well as the input data on which the database was built, the aims
of the data model and the difficulties we faced during the creation process. We
then pin down the current status of the games database and give an outlook on
the project's future plans.
<br>--
<br>Unser Werkstattbericht gibt Einblick in den Entstehungskontext sowie die
zugrundeliegenden methodischen \"Uberlegungen hinter der von den Autor*innen
publizierten Spieledatenbank. Diese wurde kollaborativ erarbeitet und f\"uhrt
digitale Spiele, die in Deutschland, \"Osterreich und der Schweiz bis zum Jahr
2000 entwickelt wurden. In diesem Bericht skizzieren wir neben unseren
Ausgangs\"uberlegungen und den verschiedenen Arbeitsschritten bei der
Realisierung au{\ss}erdem auch, auf welcher Datenbasis die Datenbank aufgebaut
und gepr\"uft wurde, was die Ziele des Datenmodells sind und mit welchen
Schwierigkeiten wir im Prozess der Erstellung konfrontiert waren. Hiernach
ordnen wir den aktuellen Stand der Spieledatenbank ein und geben einen Ausblick
auf die weiteren Pl\"ane des Projekts.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11013 title=Abstract>arXiv:2401.11013</a> [<a href=https://arxiv.org/pdf/2401.11013 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11013 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Custom Developer GPT for Ethical AI Solutions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olson%2C+L">Lauren Olson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>The main goal of this project is to create a new software artefact: a custom
Generative Pre-trained Transformer (GPT) for developers to discuss and solve
ethical issues through AI engineering. This conversational agent will provide
developers with practical application on (1) how to comply with legal
frameworks which regard AI systems (like the EU AI Act~\cite{aiact} and
GDPR~\cite{gdpr}) and (2) present alternate ethical perspectives to allow
developers to understand and incorporate alternate moral positions. In this
paper, we provide motivation for the need of such an agent, detail our idea and
demonstrate a use case. The use of such a tool can allow practitioners to
engineer AI solutions which meet legal requirements and satisfy diverse ethical
perspectives.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11016 title=Abstract>arXiv:2401.11016</a> [<a href=https://arxiv.org/pdf/2401.11016 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11016 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11016 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aoki-Sherwood%2C+B">Ben Aoki-Sherwood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bregou%2C+C">Catherine Bregou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liben-Nowell%2C+D">David Liben-Nowell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tomlinson%2C+K">Kiran Tomlinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+T">Thomas Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages; accepted as an extended abstract to AAMAS '24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Econometrics (econ.EM)
</div>
<p class=mathjax>A common theory of choice posits that individuals make choices in a two-step
process, first selecting some subset of the alternatives to consider before
making a selection from the resulting consideration set. However, inferring
unobserved consideration sets (or item consideration probabilities) in this
"consider then choose" setting poses significant challenges, because even
simple models of consideration with strong independence assumptions are not
identifiable, even if item utilities are known. We consider a natural extension
of consider-then-choose models to a top-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-15 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-16><span class=mi id=MathJax-Span-17 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> ranking setting, where we assume
rankings are constructed according to a Plackett-Luce model after sampling a
consideration set. While item consideration probabilities remain non-identified
in this setting, we prove that knowledge of item utilities allows us to infer
bounds on the relative sizes of consideration probabilities. Additionally,
given a condition on the expected consideration set size, we derive absolute
upper and lower bounds on item consideration probabilities. We also provide
algorithms to tighten those bounds on consideration probabilities by
propagating inferred constraints. Thus, we show that we can learn useful
information about consideration probabilities despite not being able to
identify them precisely. We demonstrate our methods on a ranking dataset from a
psychology experiment with two different ranking tasks (one with fixed
consideration sets and one with unknown consideration sets). This combination
of data allows us to estimate utilities and then learn about unknown
consideration probabilities using our bounds.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11018 title=Abstract>arXiv:2401.11018</a> [<a href=https://arxiv.org/pdf/2401.11018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Communication Efficient and Provable Federated Unlearning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+Y">Youming Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Cheng-Long Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+M">Miao Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+D">Dongxiao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xiuzhen Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Di Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>We study federated unlearning, a novel problem to eliminate the impact of
specific clients or data points on the global model learned via federated
learning (FL). This problem is driven by the right to be forgotten and the
privacy challenges in FL. We introduce a new framework for exact federated
unlearning that meets two essential criteria: \textit{communication efficiency}
and \textit{exact unlearning provability}. To our knowledge, this is the first
work to tackle both aspects coherently. We start by giving a rigorous
definition of \textit{exact} federated unlearning, which guarantees that the
unlearned model is statistically indistinguishable from the one trained without
the deleted data. We then pinpoint the key property that enables fast exact
federated unlearning: total variation (TV) stability, which measures the
sensitivity of the model parameters to slight changes in the dataset.
Leveraging this insight, we develop a TV-stable FL algorithm called
\texttt{FATS}, which modifies the classical
\texttt{\underline{F}ed\underline{A}vg} algorithm for \underline{T}V
\underline{S}tability and employs local SGD with periodic averaging to lower
the communication round. We also design efficient unlearning algorithms for
\texttt{FATS} under two settings: client-level and sample-level unlearning. We
provide theoretical guarantees for our learning and unlearning algorithms,
proving that they achieve exact federated unlearning with reasonable
convergence rates for both the original and unlearned models. We empirically
validate our framework on 6 benchmark datasets, and show its superiority over
state-of-the-art methods in terms of accuracy, communication cost, computation
cost, and unlearning efficacy.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11021 title=Abstract>arXiv:2401.11021</a> [<a href=https://arxiv.org/pdf/2401.11021 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11021 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11021 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+A">Arijit Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nandy%2C+S">Somashree Nandy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+R">Rupam Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+S">Srijan Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+D">Diganta Saha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Hate speech is harmful content that directly attacks or promotes hatred
against members of groups or individuals based on actual or perceived aspects
of identity, such as racism, religion, or sexual orientation. This can affect
social life on social media platforms as hateful content shared through social
media can harm both individuals and communities. As the prevalence of hate
speech increases online, the demand for automated detection as an NLP task is
increasing. In this work, the proposed method is using transformer-based model
to detect hate speech in social media, like twitter, Facebook, WhatsApp,
Instagram, etc. The proposed model is independent of languages and has been
tested on Italian, English, German, Bengali. The Gold standard datasets were
collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,
and Rezaul Karim. The success rate of the proposed model for hate speech
detection is higher than the existing baseline and state-of-the-art models with
accuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and
in Italian dataset it is 77%. The proposed algorithm shows substantial
improvement to the benchmark method.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11022 title=Abstract>arXiv:2401.11022</a> [<a href=https://arxiv.org/pdf/2401.11022 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11022 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Formulating or Fixating: Effects of Examples on Problem Solving Vary as a Function of Example Presentation Interface Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+J">Joel Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Z">Zijian Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamrah%2C+E">Eesh Kamrah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fuge%2C+M">Mark Fuge</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Interactive systems that facilitate exposure to examples can augment problem
solving performance. However designers of such systems are often faced with
many practical design decisions about how users will interact with examples,
with little clear theoretical guidance. To understand how example interaction
design choices affect whether/how people benefit from examples, we conducted an
experiment where 182 participants worked on a controlled analog to an
exploratory creativity task, with access to examples of varying diversity and
presentation interfaces. Task performance was worse when examples were
presented in a list, compared to contextualized in the exploration space or
shown in a dropdown list. Example lists were associated with more fixation,
whereas contextualized examples were associated with using examples to
formulate a model of the problem space to guide exploration. We discuss
implications of these results for a theoretical framework that maps design
choices to fundamental psychological mechanisms of creative inspiration from
examples.
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11029 title=Abstract>arXiv:2401.11029</a> [<a href=https://arxiv.org/pdf/2401.11029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization of the Context-Free Language Reachability Matrix-Based Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muravev%2C+I">Ilia Muravev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
<p class=mathjax>Various static analysis problems are reformulated as instances of the
Context-Free Language Reachability (CFL-r) problem. One promising way to make
solving CFL-r more practical for large-scale interprocedural graphs is to
reduce CFL-r to linear algebra operations on sparse matrices, as they are
efficiently executed on modern hardware. In this work, we present five
optimizations for a matrix-based CFL-r algorithm that utilize the specific
properties of both the underlying semiring and the widely-used linear algebra
library SuiteSparse:GraphBlas. Our experimental results show that these
optimizations result in orders of magnitude speedup, with the optimized
matrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-r
solvers across four considered static analyses.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11030 title=Abstract>arXiv:2401.11030</a> [<a href=https://arxiv.org/pdf/2401.11030 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11030 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Highly Quantised Neural Networks for Intrusion Detection in Automotive CAN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shanker%2C+S">Shreejith Shanker</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 5 figures, 6 tables. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2401.10724>arXiv:2401.10724</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 33rd International Conference on Field-Programmable Logic and
 Applications (FPL)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>Vehicles today comprise intelligent systems like connected autonomous driving
and advanced driving assistance systems (ADAS) to enhance the driving
experience, which is enabled through increased connectivity to infrastructure
and fusion of information from different sensing modes. However, the rising
connectivity coupled with the legacy network architecture within vehicles can
be exploited for launching active and passive attacks on critical vehicle
systems and directly affecting the safety of passengers. Machine learning-based
intrusion detection models have been shown to successfully detect multiple
targeted attack vectors in recent literature, whose deployments are enabled
through quantised neural networks targeting low-power platforms. Multiple
models are often required to simultaneously detect multiple attack vectors,
increasing the area, (resource) cost, and energy consumption. In this paper, we
present a case for utilising custom-quantised MLP's (CQMLP) as a multi-class
classification model, capable of detecting multiple attacks from the benign
flow of controller area network (CAN) messages. The specific quantisation and
neural architecture are determined through a joint design space exploration,
resulting in our choice of the 2-bit precision and the n-layer MLP. Our 2-bit
version is trained using Brevitas and optimised as a dataflow hardware model
through the FINN toolflow from AMD/Xilinx, targeting an XCZU7EV device. We show
that the 2-bit CQMLP model, when integrated as the IDS, can detect malicious
attack messages (DoS, fuzzing, and spoofing attack) with a very high accuracy
of 99.9%, on par with the state-of-the-art methods in the literature.
Furthermore, the dataflow model can perform line rate detection at a latency of
0.11 ms from message reception while consuming 0.23 mJ/inference, making it
ideally suited for integration with an ECU in critical CAN networks.
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11032 title=Abstract>arXiv:2401.11032</a> [<a href=https://arxiv.org/pdf/2401.11032 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11032 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PressProtect: Helping Journalists Navigate Social Media in the Face of Online Harassment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+C">Catherine Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+A">Anne Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+D">Deepak Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Social media has become a critical tool for journalists to disseminate their
work, engage with their audience, and connect with sources. Unfortunately,
journalists also regularly endure significant online harassment on social media
platforms, ranging from personal attacks to doxxing to threats of physical
harm. In this paper, we seek to understand how we can make social media usable
for journalists who face constant digital harassment. To begin, we conduct a
set of need-finding interviews to understand where existing platform tools and
newsroom resources fall short in adequately protecting journalists. We map
journalists' unmet needs to concrete design goals, which we use to build
PressProtect, an interface that provides journalists greater agency over
engaging with readers on Twitter/X. Through user testing with eight
journalists, we evaluate PressProtect and find that participants felt it
effectively protected them against harassment and could also generalize to
serve other visible and vulnerable groups. We conclude with a discussion of our
findings and recommendations for social platforms hoping to build defensive
defaults for journalists facing online harassment.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11033 title=Abstract>arXiv:2401.11033</a> [<a href=https://arxiv.org/pdf/2401.11033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raza%2C+S">Shaina Raza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghuge%2C+S">Shardul Ghuge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+C">Chen Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pandya%2C+D">Deval Pandya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Advancements in Large Language Models (LLMs) highlight the need for ethical
practices and data integrity. We introduce a framework that embeds FAIR
(Findable, Accessible, Interoperable, Reusable) data principles into LLM
training. This approach marks a shift towards practices compliant with FAIR
standards. Our framework presents guidelines for integrating FAIR data
principles into LLM training. This initiative includes a checklist for
researchers and developers. We also demonstrate its practical application
through a case study focused on bias identification and mitigation in our
FAIR-compliant dataset. This work is a significant contribution to AI ethics
and data science, advocating for balanced and ethical training methods in LLMs.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11035 title=Abstract>arXiv:2401.11035</a> [<a href=https://arxiv.org/pdf/2401.11035 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11035 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bethany%2C+M">Mazal Bethany</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wherry%2C+B">Brandon Wherry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vishwamitra%2C+N">Nishant Vishwamitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Social media platforms are being increasingly used by malicious actors to
share unsafe content, such as images depicting sexual activity, cyberbullying,
and self-harm. Consequently, major platforms use artificial intelligence (AI)
and human moderation to obfuscate such images to make them safer. Two critical
needs for obfuscating unsafe images is that an accurate rationale for
obfuscating image regions must be provided, and the sensitive regions should be
obfuscated (\textit{e.g.} blurring) for users' safety. This process involves
addressing two key problems: (1) the reason for obfuscating unsafe images
demands the platform to provide an accurate rationale that must be grounded in
unsafe image-specific attributes, and (2) the unsafe regions in the image must
be minimally obfuscated while still depicting the safe regions. In this work,
we address these key issues by first performing visual reasoning by designing a
visual reasoning model (VLM) conditioned on pre-trained unsafe image
classifiers to provide an accurate rationale grounded in unsafe image
attributes, and then proposing a counterfactual explanation algorithm that
minimally identifies and obfuscates unsafe regions for safe viewing, by first
utilizing an unsafe image classifier attribution matrix to guide segmentation
for a more optimal subregion segmentation followed by an informed greedy search
to determine the minimum number of subregions required to modify the
classifier's output based on attribution score. Extensive experiments on
uncurated data from social networks emphasize the efficacy of our proposed
method. We make our code available at:
https://github.com/SecureAIAutonomyLab/ConditionalVLM
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11037 title=Abstract>arXiv:2401.11037</a> [<a href=https://arxiv.org/pdf/2401.11037 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11037 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivariant Graph Neural Operator for Modeling 3D Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Minkai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiaqi Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lou%2C+A">Aaron Lou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramanathan%2C+A">Arvind Ramanathan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azizzadenesheli%2C+K">Kamyar Azizzadenesheli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Modeling the complex three-dimensional (3D) dynamics of relational systems is
an important problem in the natural sciences, with applications ranging from
molecular simulations to particle mechanics. Machine learning methods have
achieved good success by learning graph neural networks to model spatial
interactions. However, these approaches do not faithfully capture temporal
correlations since they only model next-step predictions. In this work, we
propose Equivariant Graph Neural Operator (EGNO), a novel and principled method
that directly models dynamics as trajectories instead of just next-step
prediction. Different from existing methods, EGNO explicitly learns the
temporal evolution of 3D dynamics where we formulate the dynamics as a function
over time and learn neural operators to approximate it. To capture the temporal
correlations while keeping the intrinsic SE(3)-equivariance, we develop
equivariant temporal convolutions parameterized in the Fourier space and build
EGNO by stacking the Fourier layers over equivariant networks. EGNO is the
first operator learning framework that is capable of modeling solution dynamics
functions over time while retaining 3D equivariance. Comprehensive experiments
in multiple domains, including particle simulations, human motion capture, and
molecular dynamics, demonstrate the significantly superior performance of EGNO
against existing methods, thanks to the equivariant temporal modeling.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11040 title=Abstract>arXiv:2401.11040</a> [<a href=https://arxiv.org/pdf/2401.11040 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11040 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design Frameworks for Spatial Zone Agents in XRI Metaverse Smart Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+J">Jie Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiamin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morris%2C+A">Alexis Morris</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 6th IEEE International Conference on Artificial Intelligence &amp;
 extended and Virtual Reality (IEEE AIxVR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The spatial XR-IoT (XRI) Zone Agents concept combines Extended Reality (XR),
the Internet of Things (IoT), and spatial computing concepts to create
hyper-connected spaces for metaverse applications; envisioning space as zones
that are social, smart, scalable, expressive, and agent-based. These zone
agents serve as applications and agents (partners, assistants, or guides) for
users co-living and co-operating together in a shared spatial context. The zone
agent concept is toward reducing the gap between the physical environment
(space) and the classical two-dimensional user interface, through space-based
interactions for future metaverse applications. This integration aims to enrich
user engagement with their environments through intuitive and immersive
experiences and pave the way for innovative human-machine interaction in smart
spaces. Contributions include: i) a theoretical framework for creating XRI
zone/space-agents using Mixed-Reality Agents (MiRAs) and XRI theory, ii) agent
and scene design for spatial zone agents, and iii) prototype and user
interaction design scenario concepts for human-to-space agent relationships in
an early immersive smart-space application.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11042 title=Abstract>arXiv:2401.11042</a> [<a href=https://arxiv.org/pdf/2401.11042 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11042 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11042 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Does Using ChatGPT Result in Human Cognitive Augmentation?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fulbright%2C+R">Ron Fulbright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morrison%2C+M">Miranda Morrison</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Human cognitive performance is enhanced by the use of tools. For example, a
human can produce a much greater, and more accurate, volume of mathematical
calculation in a unit of time using a calculator or a spreadsheet application
on a computer. Such tools have taken over the burden of lower level cognitive
grunt work but the human still serves the role of the expert performing higher
level thinking and reasoning. Recently, however, unsupervised, deep, machine
learning has produced cognitive systems able to outperform humans in several
domains. When humans use these tools in a human cog ensemble, the cognitive
ability of the human is augmented. In some cases, even non experts can achieve,
and even exceed, the performance of experts in a particular domain, synthetic
expertise. A new cognitive system, ChatGPT, has burst onto the scene during the
past year. This paper investigates human cognitive augmentation due to using
ChatGPT by presenting the results of two experiments comparing responses
created using ChatGPT with results created not using ChatGPT. We find using
ChatGPT does not always result in cognitive augmentation and does not yet
replace human judgement, discernment, and evaluation in certain types of tasks.
In fact, ChatGPT was observed to result in misleading users resulting in
negative cognitive augmentation.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11044 title=Abstract>arXiv:2401.11044</a> [<a href=https://arxiv.org/pdf/2401.11044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Capa%C5%82a%2C+K">Karol Capała</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tworek%2C+P">Paulina Tworek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sousa%2C+J">Jose Sousa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 4 figures, 15 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The applicability of widely adopted machine learning (ML) methods to
classification is circumscribed by the imperatives of explicability and
uncertainty, particularly evident in domains such as healthcare, behavioural
sciences, and finances, wherein accountability assumes priority. Recently,
Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the
ability to perform classification in such domains, by developing a data
abstraction protocol using a ROC curve-based method. This paper focuses on
column-wise data transformations called abstractions, which are crucial for
SaNDA's classification process and explores alternative abstractions protocols,
such as constant binning and quantiles. The best-performing methods have been
compared against Random Forest as a baseline for explainable methods. The
results suggests that SaNDA can be a viable substitute for Random Forest when
data is incomplete, even with minimal missing values. It consistently maintains
high accuracy even when half of the dataset is missing, unlike Random Forest
which experiences a significant decline in accuracy under similar conditions.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11048 title=Abstract>arXiv:2401.11048</a> [<a href=https://arxiv.org/pdf/2401.11048 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11048 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11048 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+C">Chih-Hsuan Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allot%2C+A">Alexis Allot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+P">Po-Ting Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leaman%2C+R">Robert Leaman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+S">Shubo Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Ling Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhizheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a
biomedical literature resource using state-of-the-art AI techniques to offer
semantic and relation searches for key concepts like proteins, genetic
variants, diseases, and chemicals. It currently provides over one billion
entity and relation annotations across approximately 36 million PubMed
abstracts and 6 million full-text articles from the PMC open access subset,
updated weekly. PubTator 3.0's online interface and API utilize these
precomputed entity relations and synonyms to provide advanced search
capabilities and enable large-scale analyses, streamlining many complex
information needs. We showcase the retrieval quality of PubTator 3.0 using a
series of entity pair queries, demonstrating that PubTator 3.0 retrieves a
greater number of articles than either PubMed or Google Scholar, with higher
precision in the top 20 results. We further show that integrating ChatGPT
(GPT-4) with PubTator APIs dramatically improves the factuality and
verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive
set of features and tools that allow researchers to navigate the ever-expanding
wealth of biomedical literature, expediting research and unlocking valuable
insights for scientific discovery.
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11052 title=Abstract>arXiv:2401.11052</a> [<a href=https://arxiv.org/pdf/2401.11052 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11052 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mining experimental data from Materials Science literature with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foppiano%2C+L">Luca Foppiano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lambard%2C+G">Guillaume Lambard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amagasa%2C+T">Toshiyuki Amagasa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishii%2C+M">Masashi Ishii</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>This study is dedicated to evaluating the capabilities of advanced large
language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the
extraction of structured information from scientific documents within the field
of materials science. We introduce a novel methodology for the comparative
analysis of intricate material expressions, emphasising the standardisation of
chemical formulas to tackle the complexities inherent in materials science
information assessment. To this end, we primarily focus on two critical tasks
of information extraction: (i) a named entity recognition (NER) of studied
materials and physical properties and (ii) a relation extraction (RE) between
these entities. The performance of LLMs in executing these tasks is benchmarked
against traditional models based on the BERT architecture and rule-based
approaches. For NER, LLMs fail to outperform the baseline with zero-shot
prompting and exhibit only limited improvement with few-shot prompting.
However, for RE, a GPT-3.5-Turbo fine-tuned with the appropriate strategy
outperforms all models, including the baseline. Without any fine-tuning, GPT-4
and GPT-4-Turbo display remarkable reasoning and relationship extraction
capabilities after being provided with merely a couple of examples, surpassing
the baseline. Overall, the results suggest that although LLMs demonstrate
relevant reasoning skills in connecting concepts, for tasks requiring
extracting complex domain-specific entities like materials, specialised models
are currently a better choice.
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11058 title=Abstract>arXiv:2401.11058</a> [<a href=https://arxiv.org/pdf/2401.11058 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11058 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11058 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low Complexity Turbo SIC-MMSE Detection for Orthogonal Time Frequency Space Modulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jinhong Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+M">Min Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shuangyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yixuan Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 12 figures, accepted by IEEE Transactions on Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Recently, orthogonal time frequency space (OTFS) modulation has garnered
considerable attention due to its robustness against doubly-selective wireless
channels. In this paper, we propose a low-complexity iterative successive
interference cancellation based minimum mean squared error (SIC-MMSE) detection
algorithm for zero-padded OTFS (ZP-OTFS) modulation. In the proposed algorithm,
signals are detected based on layers processed by multiple SIC-MMSE linear
filters for each sub-channel, with interference on the targeted signal layer
being successively canceled either by hard or soft information. To reduce the
complexity of computing individual layer filter coefficients, we also propose a
novel filter coefficients recycling approach in place of generating the exact
form of MMSE filter weights. Moreover, we design a joint detection and decoding
algorithm for ZP-OTFS to enhance error performance. Compared to the
conventional SIC-MMSE detection, our proposed algorithms outperform other
linear detectors, e.g., maximal ratio combining (MRC), for ZP-OTFS with up to 3
dB gain while maintaining comparable computation complexity.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11061 title=Abstract>arXiv:2401.11061</a> [<a href=https://arxiv.org/pdf/2401.11061 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11061 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PhotoBot: Reference-Guided Interactive Photography via Natural Language
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Limoyo%2C+O">Oliver Limoyo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jimmy Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivkin%2C+D">Dmitriy Rivkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kelly%2C+J">Jonathan Kelly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)
</div>
<p class=mathjax>We introduce PhotoBot, a framework for automated photo acquisition based on
an interplay between high-level human language guidance and a robot
photographer. We propose to communicate photography suggestions to the user via
a reference picture that is retrieved from a curated gallery. We exploit a
visual language model (VLM) and an object detector to characterize reference
pictures via textual descriptions and use a large language model (LLM) to
retrieve relevant reference pictures based on a user's language query through
text-based reasoning. To correspond the reference picture and the observed
scene, we exploit pre-trained features from a vision transformer capable of
capturing semantic similarity across significantly varying images. Using these
features, we compute pose adjustments for an RGB-D camera by solving a
Perspective-n-Point (PnP) problem. We demonstrate our approach on a real-world
manipulator equipped with a wrist camera. Our user studies show that photos
taken by PhotoBot are often more aesthetically pleasing than those taken by
users themselves, as measured by human feedback.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11062 title=Abstract>arXiv:2401.11062</a> [<a href=https://arxiv.org/pdf/2401.11062 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11062 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11062 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learned Image resizing with efficient training (LRET) facilitates improved performance of large-scale digital histopathology image classification models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alom%2C+M+Z">Md Zahangir Alom</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+Q+T">Quynh T. Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orr%2C+B+A">Brent A. Orr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 6 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Histologic examination plays a crucial role in oncology research and
diagnostics. The adoption of digital scanning of whole slide images (WSI) has
created an opportunity to leverage deep learning-based image classification
methods to enhance diagnosis and risk stratification. Technical limitations of
current approaches to training deep convolutional neural networks (DCNN) result
in suboptimal model performance and make training and deployment of
comprehensive classification models unobtainable. In this study, we introduce a
novel approach that addresses the main limitations of traditional
histopathology classification model training. Our method, termed Learned
Resizing with Efficient Training (LRET), couples efficient training techniques
with image resizing to facilitate seamless integration of larger histology
image patches into state-of-the-art classification models while preserving
important structural information.
<br>We used the LRET method coupled with two distinct resizing techniques to
train three diverse histology image datasets using multiple diverse DCNN
architectures. Our findings demonstrate a significant enhancement in
classification performance and training efficiency. Across the spectrum of
experiments, LRET consistently outperforms existing methods, yielding a
substantial improvement of 15-28% in accuracy for a large-scale, multiclass
tumor classification task consisting of 74 distinct brain tumor types. LRET not
only elevates classification accuracy but also substantially reduces training
times, unlocking the potential for faster model development and iteration. The
implications of this work extend to broader applications within medical imaging
and beyond, where efficient integration of high-resolution images into deep
learning pipelines is paramount for driving advancements in research and
clinical practice.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11063 title=Abstract>arXiv:2401.11063</a> [<a href=https://arxiv.org/pdf/2401.11063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Best Ends for the Best Means: Ethical Concerns in App Reviews
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olson%2C+L">Lauren Olson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tjikhoeri%2C+N">Neelam Tjikhoeri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guzm%C3%A1n%2C+E">Emitzá Guzmán</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>This work analyzes ethical concerns found in users' app store reviews. We
performed this study because ethical concerns in mobile applications (apps) are
widespread, pose severe threats to end users and society, and lack systematic
analysis and methods for detection and classification. In addition, app store
reviews allow practitioners to collect users' perspectives, crucial for
identifying software flaws, from a geographically distributed and large-scale
audience. For our analysis, we collected five million user reviews, developed a
set of ethical concerns representative of user preferences, and manually
labeled a sample of these reviews. We found that (1) users highly report
ethical concerns about censorship, identity theft, and safety (2) user reviews
with ethical concerns are longer, more popular, and lowly rated, and (3) there
is high automation potential for the classification and filtering of these
reviews. Our results highlight the relevance of using app store reviews for the
systematic consideration of ethical concerns during software evolution.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11064 title=Abstract>arXiv:2401.11064</a> [<a href=https://arxiv.org/pdf/2401.11064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11064 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low-Complexity Integer Divider Architecture for Homomorphic Encryption
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akherati%2C+S">Sajjad Akherati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+J">Jiaxuan Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinmiao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
</div>
<p class=mathjax>Homomorphic encryption (HE) allows computations to be directly carried out on
ciphertexts and enables privacy-preserving cloud computing. The computations on
the coefficients of the polynomials involved in HE are always followed by
modular reduction, and the overall complexity of ciphertext multiplication can
be reduced by utilizing the quotient. Our previous design considers the cases
that the dividend is an integer multiple of the modulus and the modulus is in
the format of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-18 style=width:6.137em;display:inline-block><span style=display:inline-block;position:relative;width:5.095em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.04em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-19><span class=msubsup id=MathJax-Span-20><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-21 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-22 style=font-size:70.7%;font-family:MathJax_Math-italic>w</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-23 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=msubsup id=MathJax-Span-24 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-25 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-26 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-27 style=font-family:MathJax_Main;padding-left:0.234em>±</span><span class=mn id=MathJax-Span-28 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-29 style=width:4.401em;display:inline-block><span style=display:inline-block;position:relative;width:3.649em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.59em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-30><span class=mi id=MathJax-Span-31 style=font-family:MathJax_Math-italic>u</span><span class=mo id=MathJax-Span-32 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mi id=MathJax-Span-33 style=font-family:MathJax_Math-italic;padding-left:0.292em>w</span><span class=texatom id=MathJax-Span-34><span class=mrow id=MathJax-Span-35><span class=mo id=MathJax-Span-36 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-37 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. In this paper, the division is
generalized for larger <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-38 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-39><span class=mi id=MathJax-Span-40 style=font-family:MathJax_Math-italic>u</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and dividend not an integer multiple of the modulus.
An algorithm is proposed to compute the quotient and vigorous mathematical
proofs are provided. Moreover, efficient hardware architecture is developed for
implementing the proposed algorithm. Compared to alternative division
approaches that utilize the inverse of the divisor, for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-41 style=width:3.707em;display:inline-block><span style=display:inline-block;position:relative;width:3.07em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.01em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-42><span class=mi id=MathJax-Span-43 style=font-family:MathJax_Math-italic>w</span><span class=mo id=MathJax-Span-44 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-45 style=font-family:MathJax_Main;padding-left:0.292em>32</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, the proposed
design achieves at least 9% shorter latency and 79\% area reduction for 75%
possible values of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-46 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-47><span class=mi id=MathJax-Span-48 style=font-family:MathJax_Math-italic>u</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11067 title=Abstract>arXiv:2401.11067</a> [<a href=https://arxiv.org/pdf/2401.11067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Make-A-Shape: a Ten-Million-scale 3D Shape Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hui%2C+K">Ka-Hei Hui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rampini%2C+A">Arianna Rampini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malekshan%2C+K+R">Kamal Rahimi Malekshan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengzhe Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shayani%2C+H">Hooman Shayani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+C">Chi-Wing Fu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>Significant progress has been made in training large generative models for
natural language and images. Yet, the advancement of 3D generative models is
hindered by their substantial resource demands for training, along with
inefficient, non-compact, and less expressive representations. This paper
introduces Make-A-Shape, a new 3D generative model designed for efficient
training on a vast scale, capable of utilizing 10 millions publicly-available
shapes. Technical-wise, we first innovate a wavelet-tree representation to
compactly encode shapes by formulating the subband coefficient filtering scheme
to efficiently exploit coefficient relations. We then make the representation
generatable by a diffusion model by devising the subband coefficients packing
scheme to layout the representation in a low-resolution grid. Further, we
derive the subband adaptive training strategy to train our model to effectively
learn to generate coarse and detail wavelet coefficients. Last, we extend our
framework to be controlled by additional input conditions to enable it to
generate shapes from assorted modalities, e.g., single/multi-view images, point
clouds, and low-resolution voxels. In our extensive set of experiments, we
demonstrate various applications, such as unconditional generation, shape
completion, and conditional generation on a wide range of modalities. Our
approach not only surpasses the state of the art in delivering high-quality
results but also efficiently generates shapes within a few seconds, often
achieving this in just 2 seconds for most conditions.
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11074 title=Abstract>arXiv:2401.11074</a> [<a href=https://arxiv.org/pdf/2401.11074 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11074 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On The Temporal Domain of Differential Equation Inspired Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eliasof%2C+M">Moshe Eliasof</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haber%2C+E">Eldad Haber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treister%2C+E">Eran Treister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Schönlieb</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling
complex relationships in graph-structured data. A recent innovation in this
field is the family of Differential Equation-Inspired Graph Neural Networks
(DE-GNNs), which leverage principles from continuous dynamical systems to model
information flow on graphs with built-in properties such as feature smoothing
or preservation. However, existing DE-GNNs rely on first or second-order
temporal dependencies. In this paper, we propose a neural extension to those
pre-defined temporal dependencies. We show that our model, called TDE-GNN, can
capture a wide range of temporal dynamics that go beyond typical first or
second-order methods, and provide use cases where existing temporal models are
challenged. We demonstrate the benefit of learning the temporal dependencies
using our method rather than using pre-defined temporal dynamics on several
graph benchmarks.
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11076 title=Abstract>arXiv:2401.11076</a> [<a href=https://arxiv.org/pdf/2401.11076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11076 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Control of Malware Propagation in IoT Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jafar%2C+M+T">Mousa Tayseer Jafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lu-Xing Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Gang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaofan Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The rapid proliferation of Internet of Things (IoT) devices in recent years
has resulted in a significant surge in the number of cyber-attacks targeting
these devices. Recent data indicates that the number of such attacks has
increased by over 100 percent, highlighting the urgent need for robust
cybersecurity measures to mitigate these threats. In addition, a cyber-attack
will begin to spread malware across the network once it has successfully
compromised an IoT network. However, to mitigate this attack, a new patch must
be applied immediately. In reality, the time required to prepare and apply the
new patch can vary significantly depending on the nature of the cyber-attack.
In this paper, we address the issue of how to mitigate cyber-attacks before the
new patch is applied by formulating an optimal control strategy that reduces
the impact of malware propagation and minimise the number of infected devices
across IoT networks in the smart home. A novel node-based epidemiological model
susceptible, infected high, infected low, recover first, and recover
complete(SI_HI_LR_FR_C) is established with immediate response state for the
restricted environment. After that, the impact of malware on IoT devices using
both high and low infected rates will be analyzed. Finally, to illustrate the
main results, several numerical analyses are carried out in addition to
simulate the real-world scenario of IoT networks in the smart home, we built a
dataset to be used in the experiments.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11077 title=Abstract>arXiv:2401.11077</a> [<a href=https://arxiv.org/pdf/2401.11077 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11077 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chance-Constrained, Drift-Safe Guidance for Spacecraft Rendezvous
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Berning%2C+A+W">Andrew W. Berning Jr.</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Burnett%2C+E+R">Ethan R. Burnett</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bieniawski%2C+S">Stefan Bieniawski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAS Rocky Mountain Guidance, Navigation and Control Conference, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>A robust drift-safe rendezvous trajectory optimization tool is developed in
this work, with applications to orbital rendezvous and proximity operations.
The method is based on direct collocation and utilizes a sequential convex
programming framework, and is extended from previous work to include passive
safety constraints. The tool is then paired with a dispersion analysis
framework to allow trajectories to be optimized subject to plant, navigation,
and actuator uncertainties. The timing, direction, and magnitude of orbital
maneuvers are optimized subject to the expected propellant usage, for a given
navigation system performance. Representative trajectories are presented for
the LEO flight regime, but the approach can also be applied to GEO and NRHO
with minimal modification.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11078 title=Abstract>arXiv:2401.11078</a> [<a href=https://arxiv.org/pdf/2401.11078 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11078 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+M">Mingyuan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hyder%2C+R">Rakib Hyder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xuan%2C+Z">Ziwei Xuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+G">Guojun Qi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The project page is at <a href=http://usrc-sea.github.io/UltrAvatar/>this http URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent advances in 3D avatar generation have gained significant attentions.
These breakthroughs aim to produce more realistic animatable avatars, narrowing
the gap between virtual and real-world experiences. Most of existing works
employ Score Distillation Sampling (SDS) loss, combined with a differentiable
renderer and text condition, to guide a diffusion model in generating 3D
avatars. However, SDS often generates oversmoothed results with few facial
details, thereby lacking the diversity compared with ancestral sampling. On the
other hand, other works generate 3D avatar from a single image, where the
challenges of unwanted lighting effects, perspective views, and inferior image
quality make them difficult to reliably reconstruct the 3D face meshes with the
aligned complete textures. In this paper, we propose a novel 3D avatar
generation approach termed UltrAvatar with enhanced fidelity of geometry, and
superior quality of physically based rendering (PBR) textures without unwanted
lighting. To this end, the proposed approach presents a diffuse color
extraction model and an authenticity guided texture diffusion model. The former
removes the unwanted lighting effects to reveal true diffuse colors so that the
generated avatars can be rendered under various lighting conditions. The latter
follows two gradient-based guidances for generating PBR textures to render
diverse face-identity features and details better aligning with 3D mesh
geometry. We demonstrate the effectiveness and robustness of the proposed
method, outperforming the state-of-the-art methods by a large margin in the
experiments.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11081 title=Abstract>arXiv:2401.11081</a> [<a href=https://arxiv.org/pdf/2401.11081 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11081 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Javanmard%2C+A">Adel Javanmard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Badanidiyuru%2C+A">Ashwinkumar Badanidiyuru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+G">Gang Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in the Twelfth International Conference on Learning Representations (ICLR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
<p class=mathjax>Due to the rise of privacy concerns, in many practical applications the
training data is aggregated before being shared with the learner, in order to
protect privacy of users' sensitive responses. In an aggregate learning
framework, the dataset is grouped into bags of samples, where each bag is
available only with an aggregate response, providing a summary of individuals'
responses in that bag. In this paper, we study two natural loss functions for
learning from aggregate responses: bag-level loss and the instance-level loss.
In the former, the model is learnt by minimizing a loss between aggregate
responses and aggregate model predictions, while in the latter the model aims
to fit individual predictions to the aggregate responses. In this work, we show
that the instance-level loss can be perceived as a regularized form of the
bag-level loss. This observation lets us compare the two approaches with
respect to bias and variance of the resulting estimators, and introduce a novel
interpolating estimator which combines the two approaches. For linear
regression tasks, we provide a precise characterization of the risk of the
interpolating estimator in an asymptotic regime where the size of the training
set grows in proportion to the features dimension. Our analysis allows us to
theoretically understand the effect of different factors, such as bag size on
the model prediction risk. In addition, we propose a mechanism for
differentially private learning from aggregate responses and derive the optimal
bag size in terms of prediction risk-privacy trade-off. We also carry out
thorough experiments to corroborate our theory and show the efficacy of the
interpolating estimator.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11084 title=Abstract>arXiv:2401.11084</a> [<a href=https://arxiv.org/pdf/2401.11084 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11084 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interference-Aware Queuing Analysis for Distributed Transmission Control in UAV Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghazikor%2C+M">Masoud Ghazikor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roach%2C+K">Keenan Roach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+K">Kenny Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hashemi%2C+M">Morteza Hashemi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE International Conference on Communications (ICC)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we investigate the problem of distributed transmission control
for unmanned aerial vehicles (UAVs) operating in unlicensed spectrum bands. We
develop a rigorous interference-aware queuing analysis framework that jointly
considers two inter-dependent factors: (i) limited-size queues with
delay-constrained packet arrival, and (ii) in-band interference introduced by
other ground/aerial users. We aim to optimize the expected throughput by
jointly analyzing these factors. In the queuing analysis, we explore two packet
loss probabilities including, buffer overflow model and time threshold model.
For interference analysis, we investigate the outage probability and packet
losses due to low signal-to-interference-plus-noise ratio (SINR). We introduce
two algorithms namely, Interference-Aware Transmission Control (IA-TC), and
Interference-Aware Distributed Transmission Control (IA-DTC). These algorithms
maximize the expected throughput by adjusting transmission policies to balance
the trade-offs between packet drop from queues vs. transmission errors due to
low SINRs. We implement the proposed algorithms and demonstrate that the
optimal transmission policy under various scenarios is found.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11085 title=Abstract>arXiv:2401.11085</a> [<a href=https://arxiv.org/pdf/2401.11085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuefang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yuhao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Z+Z">Zeke Zexi Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianshui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Liang Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Domain shift poses a significant challenge in Cross-Domain Facial Expression
Recognition (CD-FER) due to the distribution variation across different
domains. Current works mainly focus on learning domain-invariant features
through global feature adaptation, while neglecting the transferability of
local features. Additionally, these methods lack discriminative supervision
during training on target datasets, resulting in deteriorated feature
representation in target domain. To address these limitations, we propose an
Adaptive Global-Local Representation Learning and Selection (AGLRLS) framework.
The framework incorporates global-local adversarial adaptation and
semantic-aware pseudo label generation to enhance the learning of
domain-invariant and discriminative feature during training. Meanwhile, a
global-local prediction consistency learning is introduced to improve
classification results during inference. Specifically, the framework consists
of separate global-local adversarial learning modules that learn
domain-invariant global and local features independently. We also design a
semantic-aware pseudo label generation module, which computes semantic labels
based on global and local features. Moreover, a novel dynamic threshold
strategy is employed to learn the optimal thresholds by leveraging independent
prediction of global and local features, ensuring filtering out the unreliable
pseudo labels while retaining reliable ones. These labels are utilized for
model optimization through the adversarial learning process in an end-to-end
manner. During inference, a global-local prediction consistency module is
developed to automatically learn an optimal result from multiple predictions.
We conduct comprehensive experiments and analysis based on a fair evaluation
benchmark. The results demonstrate that the proposed framework outperforms the
current competing methods by a substantial margin.
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11089 title=Abstract>arXiv:2401.11089</a> [<a href=https://arxiv.org/pdf/2401.11089 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11089 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+D">Dezhong Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tongtong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Q">Qi Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+H">Hai Jin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Federated Learning (FL) has emerged as a promising approach for preserving
data privacy in recommendation systems by training models locally. Recently,
Graph Neural Networks (GNN) have gained popularity in recommendation tasks due
to their ability to capture high-order interactions between users and items.
However, privacy concerns prevent the global sharing of the entire user-item
graph. To address this limitation, some methods create pseudo-interacted items
or users in the graph to compensate for missing information for each client.
Unfortunately, these methods introduce random noise and raise privacy concerns.
In this paper, we propose FedRKG, a novel federated recommendation system,
where a global knowledge graph (KG) is constructed and maintained on the server
using publicly available item information, enabling higher-order user-item
interactions. On the client side, a relation-aware GNN model leverages diverse
KG relationships. To protect local interaction items and obscure gradients, we
employ pseudo-labeling and Local Differential Privacy (LDP). Extensive
experiments conducted on three real-world datasets demonstrate the competitive
performance of our approach compared to centralized algorithms while ensuring
privacy preservation. Moreover, FedRKG achieves an average accuracy improvement
of 4% compared to existing federated learning baselines.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11090 title=Abstract>arXiv:2401.11090</a> [<a href=https://arxiv.org/pdf/2401.11090 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11090 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sharing Energy in Wide Area: A Two-Layer Energy Sharing Scheme for Massive Prosumers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Yifan Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+P">Peng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+K">Kai Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhaojian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+N">Ning Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tonghua Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Feng Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
<p class=mathjax>The popularization of distributed energy resources transforms end-users from
consumers into prosumers. Inspired by the sharing economy principle, energy
sharing markets for prosumers are proposed to facilitate the utilization of
renewable energy. This paper proposes a novel two-layer energy sharing market
for massive prosumers, which can promote social efficiency by wider-area
sharing. In this market, there is an upper-level wide-area market (WAM) in the
distribution system and numerous lower-level local-area markets (LAMs) in
communities. Prosumers in the same community share energy with each other in
the LAM, which can be uncleared. The energy surplus and shortage of LAMs are
cleared in the WAM. Thanks to the wide-area two-layer structure, the market
outcome is near-social-optimal in large-scale systems. However, the proposed
market forms a complex mathematical program with equilibrium constraints
(MPEC). To solve the problem, we propose an efficient and hierarchically
distributed bidding algorithm. The proposed two-layer market and bidding
algorithm are verified on the IEEE 123-bus system with 11250 prosumers, which
demonstrates the practicality and efficiency for large-scale markets.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11092 title=Abstract>arXiv:2401.11092</a> [<a href=https://arxiv.org/pdf/2401.11092 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11092 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boidae: Your Personal Mining Platform
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sigurdson%2C+B">Brian Sigurdson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Flint%2C+S+W">Samuel W. Flint</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dyer%2C+R">Robert Dyer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Mining software repositories is a useful technique for researchers and
practitioners to see what software developers actually do when developing
software. Tools like Boa provide users with the ability to easily mine these
open-source software repositories at a very large scale, with datasets
containing hundreds of thousands of projects. The trade-off is that users must
use the provided infrastructure, query language, runtime, and datasets and this
might not fit all analysis needs. In this work, we present Boidae: a family of
Boa installations controlled and customized by users. Boidae uses automation
tools such as Ansible and Docker to facilitate the deployment of a customized
Boa installation. In particular, Boidae allows the creation of custom datasets
generated from any set of Git repositories, with helper scripts to aid in
finding and cloning repositories from GitHub and SourceForge. In this paper, we
briefly describe the architecture of Boidae and how researchers can utilize the
infrastructure to generate custom datasets. Boidae's scripts and all
infrastructure it builds upon are open-sourced. A video demonstration of
Boidae's installation and extension is available at https://go.unl.edu/boidae.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11094 title=Abstract>arXiv:2401.11094</a> [<a href=https://arxiv.org/pdf/2401.11094 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11094 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+S">Shishi Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liangwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaojuan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Semantic typographic logos harmoniously blend typeface and imagery to
represent semantic concepts while maintaining legibility. Conventional methods
using spatial composition and shape substitution are hindered by the
conflicting requirement for achieving seamless spatial fusion between
geometrically dissimilar typefaces and semantics. While recent advances made AI
generation of semantic typography possible, the end-to-end approaches exclude
designer involvement and disregard personalized design. This paper presents
TypeDance, an AI-assisted tool incorporating design rationales with the
generative model for personalized semantic typographic logo design. It
leverages combinable design priors extracted from uploaded image exemplars and
supports type-imagery mapping at various structural granularity, achieving
diverse aesthetic designs with flexible control. Additionally, we instantiate a
comprehensive design workflow in TypeDance, including ideation, selection,
generation, evaluation, and iteration. A two-task user evaluation, including
imitation and creation, confirmed the usability of TypeDance in design across
different usage scenarios
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11095 title=Abstract>arXiv:2401.11095</a> [<a href=https://arxiv.org/pdf/2401.11095 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11095 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sound Unblending: Exploring Sound Manipulations for Accessible Mixed-Reality Awareness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+R">Ruei-Che Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hung%2C+C">Chia-Sheng Hung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Bing-Yu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+D">Dhruv Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+A">Anhong Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Mixed-reality (MR) soundscapes blend real-world sound with virtual audio from
hearing devices, presenting intricate auditory information that is hard to
discern and differentiate. This is particularly challenging for blind or
visually impaired individuals, who rely on sounds and descriptions in their
everyday lives. To understand how complex audio information is consumed, we
analyzed online forum posts within the blind community, identifying prevailing
challenges, needs, and desired solutions. We synthesized the results and
proposed Sound Unblending for increasing MR sound awareness, which includes six
sound manipulations: Ambience Builder, Feature Shifter, Earcon Generator,
Prioritizer, Spatializer, and Stylizer. To evaluate the effectiveness of sound
unblending, we conducted a user study with 18 blind participants across three
simulated MR scenarios, where participants identified specific sounds within
intricate soundscapes. We found that sound unblending increased MR sound
awareness and minimized cognitive load. Finally, we developed three real-world
example applications to demonstrate the practicality of sound unblending.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11102 title=Abstract>arXiv:2401.11102</a> [<a href=https://arxiv.org/pdf/2401.11102 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11102 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ASM: Audio Spectrogram Mixer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Q">Qingfeng Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jicun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxin Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Transformer structures have demonstrated outstanding skills in the deep
learning space recently, significantly increasing the accuracy of models across
a variety of domains. Researchers have started to question whether such a
sophisticated network structure is actually necessary and whether equally
outstanding results can be reached with reduced inference cost due to its
complicated network topology and high inference cost. In order to prove the
Mixer's efficacy on three datasets Speech Commands, UrbanSound8k, and CASIA
Chinese Sentiment Corpus this paper applies amore condensed version of the
Mixer to an audio classification task and conducts comparative experiments with
the Transformer-based Audio Spectrogram Transformer (AST)model. In addition,
this paper conducts comparative experiments on the application of several
activation functions in Mixer, namely GeLU, Mish, Swish and Acon-C.
Further-more, the use of various activation functions in Mixer, including GeLU,
Mish, Swish, and Acon-C, is compared in this research through comparison
experiments. Additionally, some AST model flaws are highlighted, and the model
suggested in this study is improved as a result. In conclusion, a model called
the Audio Spectrogram Mixer, which is the first model for audio classification
with Mixer, is suggested in this study and the model's future directions for
improvement are examined.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11103 title=Abstract>arXiv:2401.11103</a> [<a href=https://arxiv.org/pdf/2401.11103 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11103 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Data Shapley for Weighted Nearest Neighbor Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mittal%2C+P">Prateek Mittal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+R">Ruoxi Jia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AISTATS 2024 Oral
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>This work aims to address an open problem in data valuation literature
concerning the efficient computation of Data Shapley for weighted <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><nobr><span class=math id=MathJax-Span-49 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-50><span class=mi id=MathJax-Span-51 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> nearest
neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label
KNN with discretized weights as the utility function, we reframe the
computation of WKNN-Shapley into a counting problem and introduce a
quadratic-time algorithm, presenting a notable improvement from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-52 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-53><span class=mi id=MathJax-Span-54 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-55 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-56><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-57 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mi id=MathJax-Span-58 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-59 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, the
best result from existing literature. We develop a deterministic approximation
algorithm that further improves computational efficiency while maintaining the
key fairness properties of the Shapley value. Through extensive experiments, we
demonstrate WKNN-Shapley's computational efficiency and its superior
performance in discerning data quality compared to its unweighted counterpart.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11105 title=Abstract>arXiv:2401.11105</a> [<a href=https://arxiv.org/pdf/2401.11105 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11105 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Are Latent Vulnerabilities Hidden Gems for Software Vulnerability Prediction? An Empirical Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+T+H+M">Triet H. M. Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xiaoning Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babar%2C+M+A">M. Ali Babar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a full paper in the technical track at the 21st International Conference on Mining Software Repositories (MSR) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
<p class=mathjax>Collecting relevant and high-quality data is integral to the development of
effective Software Vulnerability (SV) prediction models. Most of the current SV
datasets rely on SV-fixing commits to extract vulnerable functions and lines.
However, none of these datasets have considered latent SVs existing between the
introduction and fix of the collected SVs. There is also little known about the
usefulness of these latent SVs for SV prediction. To bridge these gaps, we
conduct a large-scale study on the latent vulnerable functions in two commonly
used SV datasets and their utilization for function-level and line-level SV
predictions. Leveraging the state-of-the-art SZZ algorithm, we identify more
than 100k latent vulnerable functions in the studied datasets. We find that
these latent functions can increase the number of SVs by 4x on average and
correct up to 5k mislabeled functions, yet they have a noise level of around
6%. Despite the noise, we show that the state-of-the-art SV prediction model
can significantly benefit from such latent SVs. The improvements are up to
24.5% in the performance (F1-Score) of function-level SV predictions and up to
67% in the effectiveness of localizing vulnerable lines. Overall, our study
presents the first promising step toward the use of latent SVs to improve the
quality of SV datasets and enhance the performance of SV prediction tasks.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11107 title=Abstract>arXiv:2401.11107</a> [<a href=https://arxiv.org/pdf/2401.11107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploiting Duality in Open Information Extraction with Predicate Prompt
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jingping Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Deqing Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Huimin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zongyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+R">Rui Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xian%2C+Y">Yunsen Xian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>Open information extraction (OpenIE) aims to extract the schema-free triplets
in the form of (\emph{subject}, \emph{predicate}, \emph{object}) from a given
sentence. Compared with general information extraction (IE), OpenIE poses more
challenges for the IE models, {especially when multiple complicated triplets
exist in a sentence. To extract these complicated triplets more effectively, in
this paper we propose a novel generative OpenIE model, namely \emph{DualOIE},
which achieves a dual task at the same time as extracting some triplets from
the sentence, i.e., converting the triplets into the sentence.} Such dual task
encourages the model to correctly recognize the structure of the given sentence
and thus is helpful to extract all potential triplets from the sentence.
Specifically, DualOIE extracts the triplets in two steps: 1) first extracting a
sequence of all potential predicates, 2) then using the predicate sequence as a
prompt to induce the generation of triplets. Our experiments on two benchmarks
and our dataset constructed from Meituan demonstrate that DualOIE achieves the
best performance among the state-of-the-art baselines. Furthermore, the online
A/B test on Meituan platform shows that 0.93\% improvement of QV-CTR and 0.56\%
improvement of UV-CTR have been obtained when the triplets extracted by DualOIE
were leveraged in Meituan's search system.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11108 title=Abstract>arXiv:2401.11108</a> [<a href=https://arxiv.org/pdf/2401.11108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shou%2C+C">Chaofan Shou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+D">Doudou Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sen%2C+K">Koushik Sen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>As blockchain platforms grow exponentially, millions of lines of smart
contract code are being deployed to manage extensive digital assets. However,
vulnerabilities in this mission-critical code have led to significant
exploitations and asset losses. Thorough automated security analysis of smart
contracts is thus imperative. This paper introduces LLM4Fuzz to optimize
automated smart contract security analysis by leveraging large language models
(LLMs) to intelligently guide and prioritize fuzzing campaigns. While
traditional fuzzing suffers from low efficiency in exploring the vast state
space, LLM4Fuzz employs LLMs to direct fuzzers towards high-value code regions
and input sequences more likely to trigger vulnerabilities. Additionally,
LLM4Fuzz can leverage LLMs to guide fuzzers based on user-defined invariants,
reducing blind exploration overhead. Evaluations of LLM4Fuzz on real-world DeFi
projects show substantial gains in efficiency, coverage, and vulnerability
detection compared to baseline fuzzing. LLM4Fuzz also uncovered five critical
vulnerabilities that can lead to a loss of more than $247k.
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11110 title=Abstract>arXiv:2401.11110</a> [<a href=https://arxiv.org/pdf/2401.11110 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11110 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VONet: Unsupervised Video Object Learning With Parallel U-Net Attention and Object-wise Sequential VAE
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Haonan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Unsupervised video object learning seeks to decompose video scenes into
structural object representations without any supervision from depth, optical
flow, or segmentation. We present VONet, an innovative approach that is
inspired by MONet. While utilizing a U-Net architecture, VONet employs an
efficient and effective parallel attention inference process, generating
attention masks for all slots simultaneously. Additionally, to enhance the
temporal consistency of each mask across consecutive video frames, VONet
develops an object-wise sequential VAE framework. The integration of these
innovative encoder-side techniques, in conjunction with an expressive
transformer-based decoder, establishes VONet as the leading unsupervised method
for object learning across five MOVI datasets, encompassing videos of diverse
complexities. Code is available at https://github.com/hnyu/vonet.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11113 title=Abstract>arXiv:2401.11113</a> [<a href=https://arxiv.org/pdf/2401.11113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SPAND: Sleep Prediction Architecture using Network Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalid%2C+M">Maryam Khalid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klerman%2C+E+B">Elizabeth B. Klerman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mchill%2C+A+W">Andrew W. Mchill</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phillips%2C+A+J+K">Andrew J. K. Phillips</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sano%2C+A">Akane Sano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 8 (March 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Signal Processing (eess.SP)
</div>
<p class=mathjax>Sleep behavior significantly impacts health and acts as an indicator of
physical and mental well-being. Monitoring and predicting sleep behavior with
ubiquitous sensors may therefore assist in both sleep management and tracking
of related health conditions. While sleep behavior depends on, and is reflected
in the physiology of a person, it is also impacted by external factors such as
digital media usage, social network contagion, and the surrounding weather. In
this work, we propose SPAND (Sleep Prediction Architecture using Network
Dynamics), a system that exploits social contagion in sleep behavior through
graph networks and integrates it with physiological and phone data extracted
from ubiquitous mobile and wearable devices for predicting next-day sleep
labels about sleep duration. Our architecture overcomes the limitations of
large-scale graphs containing connections irrelevant to sleep behavior by
devising an attention mechanism. The extensive experimental evaluation
highlights the improvement provided by incorporating social networks in the
model. Additionally, we conduct robustness analysis to demonstrate the system's
performance in real-life conditions. The outcomes affirm the stability of SPAND
against perturbations in input data. Further analyses emphasize the
significance of network topology in prediction performance revealing that users
with higher eigenvalue centrality are more vulnerable to data perturbations.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11114 title=Abstract>arXiv:2401.11114</a> [<a href=https://arxiv.org/pdf/2401.11114 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11114 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for Resource-Limited Countries
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuo%2C+K">Kuan-Ting Kuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moukheiber%2C+D">Dana Moukheiber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ordonez%2C+S+C">Sebastian Cajas Ordonez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Restrepo%2C+D">David Restrepo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paddo%2C+A+R">Atika Rahman Paddo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tsung-Yu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moukheiber%2C+L">Lama Moukheiber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moukheiber%2C+M">Mira Moukheiber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moukheiber%2C+S">Sulaiman Moukheiber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Purkayastha%2C+S">Saptarshi Purkayastha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuo%2C+P">Po-Chih Kuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Celi%2C+L+A">Leo Anthony Celi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Dengue fever presents a substantial challenge in developing countries where
sanitation infrastructure is inadequate. The absence of comprehensive
healthcare systems exacerbates the severity of dengue infections, potentially
leading to life-threatening circumstances. Rapid response to dengue outbreaks
is also challenging due to limited information exchange and integration. While
timely dengue outbreak forecasts have the potential to prevent such outbreaks,
the majority of dengue prediction studies have predominantly relied on data
that impose significant burdens on individual countries for collection. In this
study, our aim is to improve health equity in resource-constrained countries by
exploring the effectiveness of high-resolution satellite imagery as a
nontraditional and readily accessible data source. By leveraging the wealth of
publicly available and easily obtainable satellite imagery, we present a
scalable satellite extraction framework based on Sentinel Hub, a cloud-based
computing platform. Furthermore, we introduce DengueNet, an innovative
architecture that combines Vision Transformer, Radiomics, and Long Short-term
Memory to extract and integrate spatiotemporal features from satellite images.
This enables dengue predictions on an epi-week basis. To evaluate the
effectiveness of our proposed method, we conducted experiments on five
municipalities in Colombia. We utilized a dataset comprising 780
high-resolution Sentinel-2 satellite images for training and evaluation. The
performance of DengueNet was assessed using the mean absolute error (MAE)
metric. Across the five municipalities, DengueNet achieved an average MAE of
43.92. Our findings strongly support the efficacy of satellite imagery as a
valuable resource for dengue prediction, particularly in informing public
health policies within countries where manually collected data is scarce and
dengue virus prevalence is severe.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11115 title=Abstract>arXiv:2401.11115</a> [<a href=https://arxiv.org/pdf/2401.11115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+N+M">Nhat M. Hoang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+K">Kehong Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+C">Chuan Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mi%2C+M+B">Michael Bi Mi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the 38th Association for the Advancement of Artificial Intelligence (AAAI) Conference on Artificial Intelligence, Main Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Controllable generation of 3D human motions becomes an important topic as the
world embraces digital transformation. Existing works, though making promising
progress with the advent of diffusion models, heavily rely on meticulously
captured and annotated (e.g., text) high-quality motion corpus, a
resource-intensive endeavor in the real world. This motivates our proposed
MotionMix, a simple yet effective weakly-supervised diffusion model that
leverages both noisy and unannotated motion sequences. Specifically, we
separate the denoising objectives of a diffusion model into two stages:
obtaining conditional rough motion approximations in the initial <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-60 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.19em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-61><span class=mi id=MathJax-Span-62 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-63 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=msubsup id=MathJax-Span-64 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-65 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.813em><span class=mo id=MathJax-Span-66 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> steps
by learning the noisy annotated motions, followed by the unconditional
refinement of these preliminary motions during the last <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><nobr><span class=math id=MathJax-Span-67 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-68><span class=msubsup id=MathJax-Span-69><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-70 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.813em><span class=mo id=MathJax-Span-71 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> steps using
unannotated motions. Notably, though learning from two sources of imperfect
data, our model does not compromise motion generation quality compared to fully
supervised approaches that access gold data. Extensive experiments on several
benchmarks demonstrate that our MotionMix, as a versatile framework,
consistently achieves state-of-the-art performances on text-to-motion,
action-to-motion, and music-to-dance tasks.
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11116 title=Abstract>arXiv:2401.11116</a> [<a href=https://arxiv.org/pdf/2401.11116 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11116 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Promotion of Scientific Publications on ArXiv and X Is on the Rise and Impacts Citations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagchi%2C+C">Chhandak Bagchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malmi%2C+E">Eric Malmi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grabowicz%2C+P">Przemyslaw Grabowicz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>In the evolving landscape of scientific publishing, it is important to
understand the drivers of high-impact research, to equip scientists with
actionable strategies to enhance the reach of their work, and to understand
trends in the use modern scientific publishing tools to inform their further
development. Here, based on a large dataset of computer science publications,
we study trends in the use of early preprint publications and revisions on
ArXiv and the use of X (formerly Twitter) for promotion of such papers in the
last 10 years. We find that early submission to ArXiv and promotion on X have
soared in recent years. Estimating the effect that the use of each of these
modern affordances has on the number of citations of scientific publications,
we find that in the first 5 years from an initial publication peer-reviewed
conference papers submitted early to ArXiv gain on average <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><nobr><span class=math id=MathJax-Span-72 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-73><span class=mn id=MathJax-Span-74 style=font-family:MathJax_Main>21.1</span><span class=mo id=MathJax-Span-75 style=font-family:MathJax_Main;padding-left:0.234em>±</span><span class=mn id=MathJax-Span-76 style=font-family:MathJax_Main;padding-left:0.234em>17.4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> more
citations, revised on ArXiv gain <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-77 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-78><span class=mn id=MathJax-Span-79 style=font-family:MathJax_Main>18.4</span><span class=mo id=MathJax-Span-80 style=font-family:MathJax_Main;padding-left:0.234em>±</span><span class=mn id=MathJax-Span-81 style=font-family:MathJax_Main;padding-left:0.234em>17.6</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> more citations, and promoted
on X gain <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-82 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.48em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-83><span class=mn id=MathJax-Span-84 style=font-family:MathJax_Main>44.4</span><span class=mo id=MathJax-Span-85 style=font-family:MathJax_Main;padding-left:0.234em>±</span><span class=mn id=MathJax-Span-86 style=font-family:MathJax_Main;padding-left:0.234em>8</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> more citations. Our results show that promoting one's
work on ArXiv or X has a large impact on the number of citations, as well as
the number of influential citations computed by Semantic Scholar, and thereby
on the career of researchers. We discuss the far-reaching implications of these
findings for future scientific publishing systems and measures of scientific
impact.
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11118 title=Abstract>arXiv:2401.11118</a> [<a href=https://arxiv.org/pdf/2401.11118 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11118 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meta Reinforcement Learning for Strategic IoT Deployments Coverage in Disaster-Response UAV Swarms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhuheir%2C+M">Marwan Dhuheir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erbad%2C+A">Aiman Erbad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Fuqaha%2C+A">Ala Al-Fuqaha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted paper at GlobeCom Conference, 2023- Kuala Lumpor - Malayisa
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>In the past decade, Unmanned Aerial Vehicles (UAVs) have grabbed the
attention of researchers in academia and industry for their potential use in
critical emergency applications, such as providing wireless services to ground
users and collecting data from areas affected by disasters, due to their
advantages in terms of maneuverability and movement flexibility. The UAVs'
limited resources, energy budget, and strict mission completion time have posed
challenges in adopting UAVs for these applications. Our system model considers
a UAV swarm that navigates an area collecting data from ground IoT devices
focusing on providing better service for strategic locations and allowing UAVs
to join and leave the swarm (e.g., for recharging) in a dynamic way. In this
work, we introduce an optimization model with the aim of minimizing the total
energy consumption and provide the optimal path planning of UAVs under the
constraints of minimum completion time and transmit power. The formulated
optimization is NP-hard making it not applicable for real-time decision making.
Therefore, we introduce a light-weight meta-reinforcement learning solution
that can also cope with sudden changes in the environment through fast
convergence. We conduct extensive simulations and compare our approach to three
state-of-the-art learning models. Our simulation results prove that our
introduced approach is better than the three state-of-the-art algorithms in
providing coverage to strategic locations with fast convergence.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11120 title=Abstract>arXiv:2401.11120</a> [<a href=https://arxiv.org/pdf/2401.11120 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11120 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oniani%2C+D">David Oniani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xizhi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Visweswaran%2C+S">Shyam Visweswaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapoor%2C+S">Sumit Kapoor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kooragayalu%2C+S">Shravan Kooragayalu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polanska%2C+K">Katelyn Polanska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Background Large Language Models (LLMs), enhanced with Clinical Practice
Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS).
However, methods for incorporating CPGs into LLMs are not well studied. Methods
We develop three distinct methods for incorporating CPGs into LLMs: Binary
Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and
Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of
the proposed methods, we create a set of synthetic patient descriptions and
conduct both automatic and human evaluation of the responses generated by four
LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was
used as the baseline method. We focus on CDS for COVID-19 outpatient treatment
as the case study. Results All four LLMs exhibit improved performance when
enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP
and PAGC in automatic evaluation. All of the proposed methods demonstrated high
performance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate
superior performance, as compared to plain LLMs with ZSP, in providing accurate
recommendations for COVID-19 outpatient treatment, which also highlights the
potential for broader applications beyond the case study.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11122 title=Abstract>arXiv:2401.11122</a> [<a href=https://arxiv.org/pdf/2401.11122 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11122 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spatial Structure Constraints for Weakly Supervised Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yazhou Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xingguo Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zechao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+L">Liqiang Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted by IEEE Transactions on Image Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The image-level label has prevailed in weakly supervised semantic
segmentation tasks due to its easy availability. Since image-level labels can
only indicate the existence or absence of specific categories of objects,
visualization-based techniques have been widely adopted to provide object
location clues. Considering class activation maps (CAMs) can only locate the
most discriminative part of objects, recent approaches usually adopt an
expansion strategy to enlarge the activation area for more integral object
localization. However, without proper constraints, the expanded activation will
easily intrude into the background region. In this paper, we propose spatial
structure constraints (SSC) for weakly supervised semantic segmentation to
alleviate the unwanted object over-activation of attention expansion.
Specifically, we propose a CAM-driven reconstruction module to directly
reconstruct the input image from deep CAM features, which constrains the
diffusion of last-layer object attention by preserving the coarse spatial
structure of the image content. Moreover, we propose an activation
self-modulation module to refine CAMs with finer spatial structure details by
enhancing regional consistency. Without external saliency models to provide
background clues, our approach achieves 72.7\% and 47.0\% mIoU on the PASCAL
VOC 2012 and COCO datasets, respectively, demonstrating the superiority of our
proposed approach.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11123 title=Abstract>arXiv:2401.11123</a> [<a href=https://arxiv.org/pdf/2401.11123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uncertainty-aware Bridge based Mobile-Former Network for Event-based Pattern Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Haoxiang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+C">Chengguo Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yabin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Short Paper. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2306.05239>arXiv:2306.05239</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The mainstream human activity recognition (HAR) algorithms are developed
based on RGB cameras, which are easily influenced by low-quality images (e.g.,
low illumination, motion blur). Meanwhile, the privacy protection issue caused
by ultra-high definition (HD) RGB cameras aroused more and more people's
attention. Inspired by the success of event cameras which perform better on
high dynamic range, no motion blur, and low energy consumption, we propose to
recognize human actions based on the event stream. We propose a lightweight
uncertainty-aware information propagation based Mobile-Former network for
efficient pattern recognition, which aggregates the MobileNet and Transformer
network effectively. Specifically, we first embed the event images using a stem
network into feature representations, then, feed them into uncertainty-aware
Mobile-Former blocks for local and global feature learning and fusion. Finally,
the features from MobileNet and Transformer branches are concatenated for
pattern recognition. Extensive experiments on multiple event-based recognition
datasets fully validated the effectiveness of our model. The source code of
this work will be released at
https://github.com/Event-AHU/Uncertainty_aware_MobileFormer.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11124 title=Abstract>arXiv:2401.11124</a> [<a href=https://arxiv.org/pdf/2401.11124 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11124 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinodinos%2C+D">Dimitrios Sinodinos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Armanfard%2C+N">Narges Armanfard</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Multitask learning (MTL) has gained prominence for its ability to jointly
predict multiple tasks, achieving better per-task performance while using fewer
per-task model parameters than single-task learning. More recently,
decoder-focused architectures have considerably improved multitask performance
by refining task predictions using the features of other related tasks.
However, most of these refinement methods fail to simultaneously capture local
and global task-specific representations, as well as cross-task patterns in a
parameter-efficient manner. In this paper, we introduce the Efficient Multitask
Affinity Learning Network (EMA-Net), which is a lightweight framework that
enhances the task refinement capabilities of multitask networks. EMA-Net
adeptly captures local, global, and cross-task interactions using our novel
Cross-Task Affinity Learning (CTAL) module. The key innovation of CTAL lies in
its ability to manipulate task affinity matrices in a manner that is optimally
suited to apply parameter-efficient grouped convolutions without worrying about
information loss. Our results show that we achieve state-of-the-art MTL
performance for CNN-based decoder-focused models while using substantially
fewer model parameters. Our code is publicly available at
https://github.com/Armanfard-Lab/EMA-Net.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11126 title=Abstract>arXiv:2401.11126</a> [<a href=https://arxiv.org/pdf/2401.11126 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11126 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive Attackers for Security Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hangsheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiqiang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jinsong Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Ensemble defenses, are widely employed in various security-related
applications to enhance model performance and robustness. The widespread
adoption of these techniques also raises many questions: Are general ensembles
defenses guaranteed to be more robust than individuals? Will stronger adaptive
attacks defeat existing ensemble defense strategies as the cybersecurity arms
race progresses? Can ensemble defenses achieve adversarial robustness to
different types of attacks simultaneously and resist the continually adjusted
adaptive attacks? Unfortunately, these critical questions remain unresolved as
there are no platforms for comprehensive evaluation of ensemble adversarial
attacks and defenses in the cybersecurity domain. In this paper, we propose a
general Cybersecurity Adversarial Robustness Evaluation (CARE) platform aiming
to bridge this gap.
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11127 title=Abstract>arXiv:2401.11127</a> [<a href=https://arxiv.org/pdf/2401.11127 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11127 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Bit Complexity of Dynamic Algebraic Formulas and their Determinants
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anand%2C+E">Emile Anand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghadiri%2C+M">Mehrdad Ghadiri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Daniel Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 1 Figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>Many iterative algorithms in optimization, computational geometry, computer
algebra, and other areas of computer science require repeated computation of
some algebraic expression whose input changes slightly from one iteration to
the next. Although efficient data structures have been proposed for maintaining
the solution of such algebraic expressions under low-rank updates, most of
these results are only analyzed under exact arithmetic (real-RAM model and
finite fields) which may not accurately reflect the complexity guarantees of
real computers. In this paper, we analyze the stability and bit complexity of
such data structures for expressions that involve the inversion,
multiplication, addition, and subtraction of matrices under the word-RAM model.
We show that the bit complexity only increases linearly in the number of matrix
operations in the expression. In addition, we consider the bit complexity of
maintaining the determinant of a matrix expression. We show that the required
bit complexity depends on the logarithm of the condition number of matrices
instead of the logarithm of their determinant. We also discuss rank maintenance
and its connections to determinant maintenance. Our results have wide
applications ranging from computational geometry (e.g., computing the volume of
a polytope) to optimization (e.g., solving linear programs using the simplex
algorithm).
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11130 title=Abstract>arXiv:2401.11130</a> [<a href=https://arxiv.org/pdf/2401.11130 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11130 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11130 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawakami%2C+Y">Yuta Kawakami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuroki%2C+M">Manabu Kuroki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+J">Jin Tian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>There has been considerable recent interest in estimating heterogeneous
causal effects. In this paper, we introduce conditional average partial causal
effects (CAPCE) to reveal the heterogeneity of causal effects with continuous
treatment. We provide conditions for identifying CAPCE in an instrumental
variable setting. We develop three families of CAPCE estimators: sieve,
parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze
their statistical properties. We illustrate the proposed CAPCE estimators on
synthetic and real-world data.
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11131 title=Abstract>arXiv:2401.11131</a> [<a href=https://arxiv.org/pdf/2401.11131 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11131 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards a Non-Ideal Methodological Framework for Responsible ML
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mothilal%2C+R+K">Ramaravind Kommiya Mothilal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guha%2C+S">Shion Guha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+S+I">Syed Ishtiaque Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, single-column, preprint for conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Though ML practitioners increasingly employ various Responsible ML (RML)
strategies, their methodological approach in practice is still unclear. In
particular, the constraints, assumptions, and choices of practitioners with
technical duties -- such as developers, engineers, and data scientists -- are
often implicit, subtle, and under-scrutinized in HCI and related fields. We
interviewed 22 technically oriented ML practitioners across seven domains to
understand the characteristics of their methodological approaches to RML
through the lens of ideal and non-ideal theorizing of fairness. We find that
practitioners' methodological approaches fall along a spectrum of idealization.
While they structured their approaches through ideal theorizing, such as by
abstracting RML workflow from the inquiry of applicability of ML, they did not
pay deliberate attention and systematically documented their non-ideal
approaches, such as diagnosing imperfect conditions. We end our paper with a
discussion of a new methodological approach, inspired by elements of non-ideal
theory, to structure technical practitioners' RML process and facilitate
collaboration with other stakeholders.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11132 title=Abstract>arXiv:2401.11132</a> [<a href=https://arxiv.org/pdf/2401.11132 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11132 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConceptThread: Visualizing Threaded Concepts in MOOC Videos
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhiguang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+L">Li Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+L">Lihong Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yigang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 10 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Massive Open Online Courses (MOOCs) platforms are becoming increasingly
popular in recent years. Online learners need to watch the whole course video
on MOOC platforms to learn the underlying new knowledge, which is often tedious
and time-consuming due to the lack of a quick overview of the covered knowledge
and their structures. In this paper, we propose ConceptThread, a visual
analytics approach to effectively show the concepts and the relations among
them to facilitate effective online learning. Specifically, given that the
majority of MOOC videos contain slides, we first leverage video processing and
speech analysis techniques, including shot recognition, speech recognition and
topic modeling, to extract core knowledge concepts and construct the
hierarchical and temporal relations among them. Then, by using a metaphor of
thread, we present a novel visualization to intuitively display the concepts
based on video sequential flow, and enable learners to perform interactive
visual exploration of concepts. We conducted a quantitative study, two case
studies, and a user study to extensively evaluate ConceptThread. The results
demonstrate the effectiveness and usability of ConceptThread in providing
online learners with a quick understanding of the knowledge content of MOOC
videos.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11135 title=Abstract>arXiv:2401.11135</a> [<a href=https://arxiv.org/pdf/2401.11135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> COVID-19 as Reflected in University President Bulk Email
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+R">Ruoyan Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C+C">Charles Chuankai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jin Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Haiyi Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konstan%2C+J+A">Joseph A. Konstan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>E-mail ``Messages From the President'' to university students, staff, and
faculty have long been used to keep campus communities aware of the latest
policies, events, and news. But during the COVID-19 pandemic, as universities
quickly closed facilities, sent students home, and canceled travel, these
messages took on even greater importance. We report on a content analysis of
bulk emails from different universities' presidents to their students and
employees before and in three stages of the pandemic. We find that these
messages change as universities move towards and through closure. During the
pandemic, 1) presidential bulk emails tend to be more informative, positive,
clearer than before; 2) they tend to use more personal and collective language;
3) university presidents tend to mention more local political leaders and fewer
other university leaders. Our results can inform research on digital crisis
communication and may be useful for researchers interested in automatically
identifying crisis situations from communication streams.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11140 title=Abstract>arXiv:2401.11140</a> [<a href=https://arxiv.org/pdf/2401.11140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yuantao Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+P">Ping Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Few-shot object detection(FSOD) aims to design methods to adapt object
detectors efficiently with only few annotated samples. Fine-tuning has been
shown to be an effective and practical approach. However, previous works often
take the classical base-novel two stage fine-tuning procedure but ignore the
implicit stability-plasticity contradiction among different modules.
Specifically, the random re-initialized classifiers need more plasticity to
adapt to novel samples. The other modules inheriting pre-trained weights demand
more stability to reserve their class-agnostic knowledge. Regular fine-tuning
which couples the optimization of these two parts hurts the model
generalization in FSOD scenarios. In this paper, we find that this problem is
prominent in the end-to-end object detector Sparse R-CNN for its
multi-classifier cascaded architecture. We propose to mitigate this
contradiction by a new three-stage fine-tuning procedure by introducing an
addtional plasticity classifier fine-tuning(PCF) stage. We further design the
multi-source ensemble(ME) technique to enhance the generalization of the model
in the final fine-tuning stage. Extensive experiments verify that our method is
effective in regularizing Sparse R-CNN, outperforming previous methods in the
FSOD benchmark.
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11141 title=Abstract>arXiv:2401.11141</a> [<a href=https://arxiv.org/pdf/2401.11141 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11141 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wideband Beamforming for RIS Assisted Near-Field Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Ji Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jian Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yixuan Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+W">Wenwu Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>A near-field wideband beamforming scheme is investigated for reconfigurable
intelligent surface (RIS) assisted multiple-input multiple-output (MIMO)
systems, in which a deep learning-based end-to-end (E2E) optimization framework
is proposed to maximize the system spectral efficiency. To deal with the
near-field double beam split effect, the base station is equipped with
frequency-dependent hybrid precoding architecture by introducing sub-connected
true time delay (TTD) units, while two specific RIS architectures, namely true
time delay-based RIS (TTD-RIS) and virtual subarray-based RIS (SA-RIS), are
exploited to realize the frequency-dependent passive beamforming at the RIS.
Furthermore, the efficient E2E beamforming models without explicit channel
state information are proposed, which jointly exploits the uplink channel
training module and the downlink wideband beamforming module. In the proposed
network architecture of the E2E models, the classical communication signal
processing methods, i.e., polarized filtering and sparsity transform, are
leveraged to develop a signal-guided beamforming network. Numerical results
show that the proposed E2E models have superior beamforming performance and
robustness to conventional beamforming benchmarks. Furthermore, the tradeoff
between the beamforming gain and the hardware complexity is investigated for
different frequency-dependent RIS architectures, in which the TTD-RIS can
achieve better spectral efficiency than the SA-RIS while requiring additional
energy consumption and hardware cost.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11143 title=Abstract>arXiv:2401.11143</a> [<a href=https://arxiv.org/pdf/2401.11143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioannides%2C+G">Georgios Ioannides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chadha%2C+A">Aman Chadha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elkins%2C+A">Aaron Elkins</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
</div>
<p class=mathjax>We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a
novel probabilistic attention framework, and the Gaussian Adaptive Transformer
(GAT), designed to enhance information aggregation across multiple modalities,
including Speech, Text and Vision. GAAM integrates learnable mean and variance
into its attention mechanism, implemented in a Multi-Headed framework enabling
it to collectively model any Probability Distribution for dynamic recalibration
of feature significance. This method demonstrates significant improvements,
especially with highly non-stationary data, surpassing the state-of-the-art
attention techniques in model performance (up to approximately +20% in
accuracy) by identifying key elements within the feature space. GAAM's
compatibility with dot-product-based attention models and relatively low number
of parameters showcases its adaptability and potential to boost existing
attention frameworks. Empirically, GAAM exhibits superior adaptability and
efficacy across a diverse range of tasks, including emotion recognition in
speech, image classification, and text classification, thereby establishing its
robustness and versatility in handling multi-modal data. Furthermore, we
introduce the Importance Factor (IF), a new learning-based metric that enhances
the explainability of models trained with GAAM-based methods. Overall, GAAM
represents an advancement towards development of better performing and more
explainable attention models across multiple modalities.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11144 title=Abstract>arXiv:2401.11144</a> [<a href=https://arxiv.org/pdf/2401.11144 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11144 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Open-World Gesture Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+J">Junxiao Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Lange%2C+M">Matthias De Lange</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X+%22">Xuhai "Orson" Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+E">Enmin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+R">Ran Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suda%2C+N">Naveen Suda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lazarewicz%2C+M">Maciej Lazarewicz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kristensson%2C+P+O">Per Ola Kristensson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karlson%2C+A">Amy Karlson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strasnick%2C+E">Evan Strasnick</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Static machine learning methods in gesture recognition assume that training
and test data come from the same underlying distribution. However, in
real-world applications involving gesture recognition on wrist-worn devices,
data distribution may change over time. We formulate this problem of adapting
recognition models to new tasks, where new data patterns emerge, as open-world
gesture recognition (OWGR). We propose leveraging continual learning to make
machine learning models adaptive to new tasks without degrading performance on
previously learned tasks. However, the exploration of parameters for questions
around when and how to train and deploy recognition models requires
time-consuming user studies and is sometimes impractical. To address this
challenge, we propose a design engineering approach that enables offline
analysis on a collected large-scale dataset with various parameters and
compares different continual learning methods. Finally, design guidelines are
provided to enhance the development of an open-world wrist-worn gesture
recognition process.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11145 title=Abstract>arXiv:2401.11145</a> [<a href=https://arxiv.org/pdf/2401.11145 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11145 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Document Set Expansion with Positive-Unlabeled Learning: A Density Estimation-based Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haiyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qiuyi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yuanjie Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+Y">Yushan Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stevenson%2C+M">Mark Stevenson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>Document set expansion aims to identify relevant documents from a large
collection based on a small set of documents that are on a fine-grained topic.
Previous work shows that PU learning is a promising method for this task.
However, some serious issues remain unresolved, i.e. typical challenges that PU
methods suffer such as unknown class prior and imbalanced data, and the need
for transductive experimental settings. In this paper, we propose a novel PU
learning framework based on density estimation, called puDE, that can handle
the above issues. The advantage of puDE is that it neither constrained to the
SCAR assumption and nor require any class prior knowledge. We demonstrate the
effectiveness of the proposed method using a series of real-world datasets and
conclude that our method is a better alternative for the DSE task.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11146 title=Abstract>arXiv:2401.11146</a> [<a href=https://arxiv.org/pdf/2401.11146 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11146 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalized Optimal AMG Convergence Theory for Nonsymmetric and Indefinite Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ali%2C+A">Ahsan Ali</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Brannick%2C+J">James Brannick</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kahl%2C+K">Karsten Kahl</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Krzysik%2C+O+A">Oliver A. Krzysik</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Schroder%2C+J+B">Jacob B. Schroder</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Southworth%2C+B+S">Ben S. Southworth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 2 figures, submitted as a student paper for the 18th Copper Mountain Conference on Iterative Methods
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Algebraic multigrid (AMG) is known to be an effective solver for many sparse
symmetric positive definite (SPD) linear systems. For SPD systems, the
convergence theory of AMG is well-understood in terms of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-87 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-88><span class=mi id=MathJax-Span-89 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-norm but in a
nonsymmetric setting such an energy norm is non-existent. For this reason,
convergence of AMG for nonsymmetric systems of equations remains an open area
of research. Existing nonsymmetric AMG algorithms in this setting mostly rely
on heuristics motivated by SPD convergence theory. In the SPD setting, the
classical form of optimal AMG interpolation provides a useful insight in
determining the two grid convergence rate of the method. In this work, we
discuss a generalization of the optimal AMG convergence theory targeting
nonsymmetric problems by constructing a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-90 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-91><span class=mn id=MathJax-Span-92 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-93 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mn id=MathJax-Span-94 style=font-family:MathJax_Main;padding-left:0.234em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> block symmetric indefinite
system so that the Petrov-Galerkin AMG process for the nonsymmetric matrix <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-95 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-96><span class=mi id=MathJax-Span-97 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
can be recast as a Galerkin AMG process for a symmetric indefinite system. We
show that using this generalization of the optimal interpolation theory, one
can obtain the same identity for the two-grid convergence rate as that derived
in the SPD setting for optimal interpolation. We also provide supporting
numerical results for the convergence result and nonsymmetric
advection-diffusion problems.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11148 title=Abstract>arXiv:2401.11148</a> [<a href=https://arxiv.org/pdf/2401.11148 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11148 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+J">Jingyuan Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yan%2C+L">Longhao Yan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+K">Kaidi Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Connected and automated vehicles (CAVs) have recently gained prominence in
traffic research, thanks to the advancements in communication technology and
autonomous driving. A variety of longitudinal control strategies for CAVs have
been developed to enhance traffic efficiency, stability, and safety in
mixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promising
strategy for mixed-autonomy platoon control since it can tackle complex
scenarios in real-time. However, there are three research gaps for DRL-based
mixed-autonomy platoon control. First, incorporating safety considerations into
DRL typically relies on designing collision avoidance-based reward functions,
which lack collision-free guarantees. Second, current DRL-based-control
approaches for mixed traffic only consider the safety of CAVs, with little
attention paid to the surrounding HDVs. To address the research gaps, we
introduce a differentiable safety layer that converts DRL actions into safe
actions with collision-free guarantees. This process relies on solving a
differentiable quadratic programming problem that incorporates control barrier
function-based (CBF) safety constraints for both CAV and its following HDVs to
achieve system-level safety. Moreover, constructing CBF constraints needs
system dynamics for the following HDVs, and thus we employ an online system
identification module to estimate the car-following dynamics of the surrounding
HDVs. The proposed safe reinforcement learning approach explicitly integrates
system-level safety constraints into the training process and enables our
method to adapt to varying safety-critical scenarios. Simulation results
demonstrate that our proposed method effectively ensures CAV safety and
improves HDV safety in mixed platoon environments while simultaneously
enhancing traffic capacity and string stability.
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11150 title=Abstract>arXiv:2401.11150</a> [<a href=https://arxiv.org/pdf/2401.11150 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11150 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simultaneous Gesture Classification and Localization with an Automatic Gesture Annotation Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+J">Junxiao Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuhai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+R">Ran Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karlson%2C+A">Amy Karlson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strasnick%2C+E">Evan Strasnick</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Training a real-time gesture recognition model heavily relies on annotated
data. However, manual data annotation is costly and demands substantial human
effort. In order to address this challenge, we propose a novel annotation model
that can automatically annotate gesture classes and identify their temporal
ranges. Our ablation study demonstrates that our annotation model design
surpasses the baseline in terms of both gesture classification accuracy (3-4\%
improvement) and localization accuracy (71-75\% improvement). We believe that
this annotation model has immense potential to improve the training of
downstream gesture recognition models using unlabeled datasets.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11155 title=Abstract>arXiv:2401.11155</a> [<a href=https://arxiv.org/pdf/2401.11155 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11155 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning-Based Adaptive Joint Source-Channel Coding using Hypernetworks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+S">Songjie Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+H">Hengtao He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongru Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S">Shenghui Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y+A">Ying-Jun Angela Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Deep learning-based joint source-channel coding (DJSCC) is expected to be a
key technique for {the} next-generation wireless networks. However, the
existing DJSCC schemes still face the challenge of channel adaptability as they
are typically trained under specific channel conditions. In this paper, we
propose a generic framework for channel-adaptive DJSCC by utilizing
hypernetworks. To tailor the hypernetwork-based framework for communication
systems, we propose a memory-efficient hypernetwork parameterization and then
develop a channel-adaptive DJSCC network, named Hyper-AJSCC. Compared with
existing adaptive DJSCC based on the attention mechanism, Hyper-AJSCC
introduces much fewer parameters and can be seamlessly combined with various
existing DJSCC networks without any substantial modifications to their neural
network architecture. Extensive experiments demonstrate the better adaptability
to channel conditions and higher memory efficiency of Hyper-AJSCC compared with
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11156 title=Abstract>arXiv:2401.11156</a> [<a href=https://arxiv.org/pdf/2401.11156 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11156 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalizing Speaker Verification for Spoof Awareness in the Embedding Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xuechen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahidullah%2C+M">Md Sahidullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K+A">Kong Aik Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kinnunen%2C+T">Tomi Kinnunen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>It is now well-known that automatic speaker verification (ASV) systems can be
spoofed using various types of adversaries. The usual approach to counteract
ASV systems against such attacks is to develop a separate spoofing
countermeasure (CM) module to classify speech input either as a bonafide, or a
spoofed utterance. Nevertheless, such a design requires additional computation
and utilization efforts at the authentication stage. An alternative strategy
involves a single monolithic ASV system designed to handle both zero-effort
imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have
the potential to provide stronger protections and more economic computations.
To this end, we propose to generalize the standalone ASV (G-SASV) against
spoofing attacks, where we leverage limited training data from CM to enhance a
simple backend in the embedding space, without the involvement of a separate CM
module during the test (authentication) phase. We propose a novel yet simple
backend classifier based on deep neural networks and conduct the study via
domain adaptation and multi-task integration of spoof embeddings at the
training stage. Experiments are conducted on the ASVspoof 2019 logical access
dataset, where we improve the performance of statistical ASV backends on the
joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and
49.8% in terms of equal error rates, respectively.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11160 title=Abstract>arXiv:2401.11160</a> [<a href=https://arxiv.org/pdf/2401.11160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11160 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Perfect and Distance-Optimal Sum-Rank Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Constructions of infinite families of distance-optimal codes in the Hamming
metric and the sum-rank metric are challenging problems and have attracted many
attentions. In this paper, we give the following three results.
<br>1) If <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-98 style=width:5.038em;display:inline-block><span style=display:inline-block;position:relative;width:4.17em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.11em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-99><span class=mi id=MathJax-Span-100 style=font-family:MathJax_Math-italic>λ</span><span class=texatom id=MathJax-Span-101><span class=mrow id=MathJax-Span-102><span class=mo id=MathJax-Span-103 style=font-family:MathJax_Main>|</span></span></span><span class=msubsup id=MathJax-Span-104><span style=display:inline-block;position:relative;width:1.565em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-105 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=texatom id=MathJax-Span-106><span class=mrow id=MathJax-Span-107><span class=mi id=MathJax-Span-108 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span class=mi id=MathJax-Span-109 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-110 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-111 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-112 style=width:9.031em;display:inline-block><span style=display:inline-block;position:relative;width:7.526em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.639em,1007.53em,3.417em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-113><span class=mi id=MathJax-Span-114 style=font-family:MathJax_Math-italic>λ</span><span class=mo id=MathJax-Span-115 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=msqrt id=MathJax-Span-116 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:5.558em;height:0px><span style=position:absolute;clip:rect(2.723em,1004.52em,4.922em,-999.997em);top:-3.99em;left:0.987em><span class=mrow id=MathJax-Span-117><span class=mfrac id=MathJax-Span-118><span style=display:inline-block;position:relative;width:4.285em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1002.03em,4.343em,-999.997em);top:-4.569em;left:50%;margin-left:-1.039em><span class=mrow id=MathJax-Span-119><span class=mo id=MathJax-Span-120 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-121><span style=display:inline-block;position:relative;width:0.697em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.35em,4.285em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-122 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.408em><span class=mi id=MathJax-Span-123 style=font-size:50%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-124 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-125 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-126 style=font-size:70.7%;font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.128em,1004.11em,4.343em,-999.997em);top:-3.411em;left:50%;margin-left:-2.08em><span class=mrow id=MathJax-Span-127><span class=mn id=MathJax-Span-128 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-129 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-130 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-131 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-132 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=msubsup id=MathJax-Span-133><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.302em,1000.23em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-134 style=font-size:70.7%;font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.292em><span class=mn id=MathJax-Span-135 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-136 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-137 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-138 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mi id=MathJax-Span-139 style=font-size:70.7%;font-family:MathJax_Math-italic>ϵ</span><span class=mo id=MathJax-Span-140 style=font-size:70.7%;font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1004.28em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:4.285em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1004.46em,3.938em,-999.997em);top:-5.09em;left:0.987em><span style=display:inline-block;position:relative;width:4.459em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:3.764em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:0.408em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:0.871em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:1.392em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:1.855em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:2.376em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:2.896em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:3.359em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(2.376em,1001.04em,5.095em,-999.997em);top:-3.932em;left:0em><span style=font-family:MathJax_Size3>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-1.316em;border-left:0px solid;width:0px;height:2.99em"></span></span></nobr></span>, an infinite family of
distance-optimal <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-141 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-142><span class=mi id=MathJax-Span-143 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-ary cyclic sum-rank codes with the block length
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-144 style=width:4.98em;display:inline-block><span style=display:inline-block;position:relative;width:4.112em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.987em,1004.11em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-145><span class=mi id=MathJax-Span-146 style=font-family:MathJax_Math-italic>t</span><span class=mo id=MathJax-Span-147 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mfrac id=MathJax-Span-148 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:2.144em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1001.97em,4.285em,-999.997em);top:-4.569em;left:50%;margin-left:-0.981em><span class=mrow id=MathJax-Span-149><span class=msubsup id=MathJax-Span-150><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.35em,4.285em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-151 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.408em><span class=texatom id=MathJax-Span-152><span class=mrow id=MathJax-Span-153><span class=mi id=MathJax-Span-154 style=font-size:50%;font-family:MathJax_Math-italic>s</span><span class=mi id=MathJax-Span-155 style=font-size:50%;font-family:MathJax_Math-italic>m</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-156 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-157 style=font-size:70.7%;font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-158 style=font-size:70.7%;font-family:MathJax_Math-italic>λ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1002.14em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:2.144em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.878em"></span></span></nobr></span>, the matrix size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-159 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.14em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-160><span class=mi id=MathJax-Span-161 style=font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-162 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mi id=MathJax-Span-163 style=font-family:MathJax_Math-italic;padding-left:0.234em>s</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.767em"></span></span></nobr></span>, the cardinality
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-164 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.113em,1004.81em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-165><span class=msubsup id=MathJax-Span-166><span style=display:inline-block;position:relative;width:4.806em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-167 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=texatom id=MathJax-Span-168><span class=mrow id=MathJax-Span-169><span class=msubsup id=MathJax-Span-170><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-171 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.35em><span class=mn id=MathJax-Span-172 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-173 style=font-size:70.7%;font-family:MathJax_Math-italic>t</span><span class=mo id=MathJax-Span-174 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mi id=MathJax-Span-175 style=font-size:70.7%;font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-176 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-177 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-178 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-179 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-180 style=font-size:70.7%;font-family:MathJax_Main>3</span><span class=mo id=MathJax-Span-181 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> and the minimum sum-rank distance four is constructed.
<br>2) Block length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-182 style=width:3.244em;display:inline-block><span style=display:inline-block;position:relative;width:2.665em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.61em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-183><span class=msubsup id=MathJax-Span-184><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-185 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=mn id=MathJax-Span-186 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-187 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-188 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span> and the matrix size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-189 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-190><span class=mn id=MathJax-Span-191 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-192 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mn id=MathJax-Span-193 style=font-family:MathJax_Main;padding-left:0.234em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> distance-optimal
sum-rank codes with the minimum sum-rank distance four and the Singleton defect
four are constructed. These sum-rank codes are close to the sphere packing
bound , the Singleton-like bound and have much larger block length
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-194 style=width:8.452em;display:inline-block><span style=display:inline-block;position:relative;width:7.005em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1006.95em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-195><span class=msubsup id=MathJax-Span-196><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-197 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=mn id=MathJax-Span-198 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-199 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-200 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-201 style=font-family:MathJax_Main;padding-left:0.292em>&gt;<span style=font-family:MathJax_Main>&gt;</span></span><span class=mi id=MathJax-Span-202 style=font-family:MathJax_Math-italic;padding-left:0.292em>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-203 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-204 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span>.
<br>3) For given positive integers <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-205 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-206><span class=mi id=MathJax-Span-207 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-208 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-209><span class=mi id=MathJax-Span-210 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> satisfying <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-211 style=width:3.417em;display:inline-block><span style=display:inline-block;position:relative;width:2.839em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1002.84em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-212><span class=mi id=MathJax-Span-213 style=font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-214 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mi id=MathJax-Span-215 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>, an infinite
family of perfect sum-rank codes with the matrix size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-216 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.72em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-217><span class=mi id=MathJax-Span-218 style=font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-219 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mi id=MathJax-Span-220 style=font-family:MathJax_Math-italic;padding-left:0.234em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.767em"></span></span></nobr></span>, and the
minimum sum-rank distance three is also constructed.
<br>The construction of perfect sum-rank codes of the matrix size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-221 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.72em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-222><span class=mi id=MathJax-Span-223 style=font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-224 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mi id=MathJax-Span-225 style=font-family:MathJax_Math-italic;padding-left:0.234em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.767em"></span></span></nobr></span>,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-226 style=width:5.674em;display:inline-block><span style=display:inline-block;position:relative;width:4.69em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.69em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-227><span class=mn id=MathJax-Span-228 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-229 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mi id=MathJax-Span-230 style=font-family:MathJax_Math-italic;padding-left:0.292em>m</span><span class=mo id=MathJax-Span-231 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=mi id=MathJax-Span-232 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, answers the open problem proposed by U. Mart\'{\i}nez-Pe\~{n}as in
2019 positively.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11161 title=Abstract>arXiv:2401.11161</a> [<a href=https://arxiv.org/pdf/2401.11161 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11161 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+L">Ling Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+J">Junwen An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Huihui Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Q">Qiyi Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+S">Sen Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Shi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuqun Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>While third-party libraries are extensively reused to enhance productivity
during software development, they can also introduce potential security risks
such as vulnerability propagation. Software composition analysis, proposed to
identify reused TPLs for reducing such risks, has become an essential procedure
within modern DevSecOps. As one of the mainstream SCA techniques,
binary-to-source SCA identifies the third-party source projects contained in
binary files via binary source code matching, which is a major challenge in
reverse engineering since binary and source code exhibit substantial
disparities after compilation. The existing binary-to-source SCA techniques
leverage basic syntactic features that suffer from redundancy and lack
robustness in the large-scale TPL dataset, leading to inevitable false
positives and compromised recall. To mitigate these limitations, we introduce
BinaryAI, a novel binary-to-source SCA technique with two-phase binary source
code matching to capture both syntactic and semantic code features. First,
BinaryAI trains a transformer-based model to produce function-level embeddings
and obtain similar source functions for each binary function accordingly. Then
by applying the link-time locality to facilitate function matching, BinaryAI
detects the reused TPLs based on the ratio of matched source functions. Our
experimental results demonstrate the superior performance of BinaryAI in terms
of binary source code matching and the downstream SCA task. Specifically, our
embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving
22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively.
Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in
TPL detection, increasing the precision from 73.36% to 85.84% and recall from
59.81% to 64.98% compared with the well-recognized commercial SCA product Black
Duck.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11162 title=Abstract>arXiv:2401.11162</a> [<a href=https://arxiv.org/pdf/2401.11162 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11162 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11162 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extending Polaris to Support Transactions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aguilar-Saborit%2C+J">Josep Aguilar-Saborit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramakrishnan%2C+R">Raghu Ramakrishnan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bocksrocker%2C+K">Kevin Bocksrocker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Halverson%2C+A">Alan Halverson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kosinsky%2C+K">Konstantin Kosinsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=O%27Connor%2C+R">Ryan O'Connor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poliakova%2C+N">Nadejda Poliakova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shafiei%2C+M">Moe Shafiei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+T">Taewoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kon-Kim%2C+P">Phil Kon-Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahmud-Ansari%2C+H">Haris Mahmud-Ansari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matuszyk%2C+B">Blazej Matuszyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miles%2C+M">Matt Miles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohanan%2C+S">Sumin Mohanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petculescu%2C+C">Cristian Petculescu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahesh-Madan%2C+I">Ishan Rahesh-Madan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rose-Wirshing%2C+E">Emma Rose-Wirshing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yousefi%2C+E">Elias Yousefi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 12 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>In Polaris, we introduced a cloud-native distributed query processor to
perform analytics at scale. In this paper, we extend the underlying Polaris
distributed computation framework, which can be thought of as a read-only
transaction engine, to execute general transactions (including updates,
deletes, inserts and bulk loads, in addition to queries) for Tier 1 warehousing
workloads in a highly performant and predictable manner. We take advantage of
the immutability of data files in log-structured data stores and build on SQL
Server transaction management to deliver full transactional support with
Snapshot Isolation semantics, including multi-table and multi-statement
transactions. With the enhancements described in this paper, Polaris supports
both query processing and transactions for T-SQL in Microsoft Fabric.
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11166 title=Abstract>arXiv:2401.11166</a> [<a href=https://arxiv.org/pdf/2401.11166 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11166 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11166 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatGPT in the classroom. Exploring its potential and limitations in a Functional Programming course
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovici%2C+D">Dan-Matei Popovici</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Human-Computer Interaction, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>In November 2022, OpenAI has introduced ChatGPT, a chatbot based on
supervised and reinforcement learning. Not only can it answer questions
emulating human-like responses, but it can also generate code from scratch or
complete coding templates provided by the user. ChatGPT can generate unique
responses which render any traditional anti-plagiarism tool useless. Its
release has ignited a heated debate about its usage in academia, especially by
students. We have found, to our surprise, that our students at POLITEHNICA
University of Bucharest (UPB) have been using generative AI tools (ChatGPT and
its predecessors) for solving homework, for at least 6 months. We therefore set
out to explore the capabilities of ChatGPT and assess its value for educational
purposes. We solved all our coding assignments for the semester from our UPB
Functional Programming course. We discovered that, although ChatGPT provides
correct answers in 68% of the cases, only around half of those are legible
solutions which can benefit students in some form. On the other hand, ChatGPT
has a very good ability to perform code review on student programming homework.
Based on these findings, we discuss the pros and cons of ChatGPT in education.
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11167 title=Abstract>arXiv:2401.11167</a> [<a href=https://arxiv.org/pdf/2401.11167 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11167 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coevolving Artistic Images Using OMNIREP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sipper%2C+M">Moshe Sipper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+J+H">Jason H. Moore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Urbanowicz%2C+R+J">Ryan J. Urbanowicz</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. Romero et al. (Eds.), EvoMUSART 2020, LNCS 12103, pp. 165-178,
 2020
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>We have recently developed OMNIREP, a coevolutionary algorithm to discover
both a representation and an interpreter that solve a particular problem of
interest. Herein, we demonstrate that the OMNIREP framework can be successfully
applied within the field of evolutionary art. Specifically, we coevolve
representations that encode image position, alongside interpreters that
transform these positions into one of three pre-defined shapes (chunks,
polygons, or circles) of varying size, shape, and color. We showcase a sampling
of the unique image variations produced by this approach.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11170 title=Abstract>arXiv:2401.11170</a> [<a href=https://arxiv.org/pdf/2401.11170 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11170 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+K">Kuofeng Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yang Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jindong Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torr%2C+P">Philip Torr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhifeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Large vision-language models (VLMs) such as GPT-4 have achieved exceptional
performance across various multi-modal tasks. However, the deployment of VLMs
necessitates substantial energy consumption and computational resources. Once
attackers maliciously induce high energy consumption and latency time
(energy-latency cost) during inference of VLMs, it will exhaust computational
resources. In this paper, we explore this attack surface about availability of
VLMs and aim to induce high energy-latency cost during inference of VLMs. We
find that high energy-latency cost during inference of VLMs can be manipulated
by maximizing the length of generated sequences. To this end, we propose
verbose images, with the goal of crafting an imperceptible perturbation to
induce VLMs to generate long sentences during inference. Concretely, we design
three loss objectives. First, a loss is proposed to delay the occurrence of
end-of-sequence (EOS) token, where EOS token is a signal for VLMs to stop
generating further tokens. Moreover, an uncertainty loss and a token diversity
loss are proposed to increase the uncertainty over each generated token and the
diversity among all tokens of the whole generated sequence, respectively, which
can break output dependency at token-level and sequence-level. Furthermore, a
temporal weight adjustment algorithm is proposed, which can effectively balance
these losses. Extensive experiments demonstrate that our verbose images can
increase the length of generated sequences by 7.87 times and 8.56 times
compared to original images on MS-COCO and ImageNet datasets, which presents
potential challenges for various applications. Our code is available at
https://github.com/KuofengGao/Verbose_Images.
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11174 title=Abstract>arXiv:2401.11174</a> [<a href=https://arxiv.org/pdf/2401.11174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pixel-Wise Recognition for Holistic Surgical Scene Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayobi%2C+N">Nicolás Ayobi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodr%C3%ADguez%2C+S">Santiago Rodríguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez%2C+A">Alejandra Pérez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hern%C3%A1ndez%2C+I">Isabela Hernández</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aparicio%2C+N">Nicolás Aparicio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dessevres%2C+E">Eugénie Dessevres</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pe%C3%B1a%2C+S">Sebastián Peña</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santander%2C+J">Jessica Santander</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caicedo%2C+J+I">Juan Ignacio Caicedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez%2C+N">Nicolás Fernández</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arbel%C3%A1ez%2C+P">Pablo Arbeláez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint submitted to Medical Image Analysis. Official extension of previous $\href{<a href=https://link.springer.com/chapter/10.1007/978-3-031-16449-1_42>this https URL</a>}{\text{MICCAI}}<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-233 style=width:1.996em;display:inline-block><span style=display:inline-block;position:relative;width:1.674em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.031em,1001.67em,2.124em,-999.997em);top:-1.925em;left:0em><span class=mrow id=MathJax-Span-234><span class=mi id=MathJax-Span-235 style=font-family:MathJax_Math-italic>a</span><span class=mi id=MathJax-Span-236 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-237 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.931em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.073em;border-left:0px solid;width:0px;height:1.006em"></span></span></nobr></span>\href{<a href=https://ieeexplore.ieee.org/document/10230819>this https URL</a>}{\text{ISBI}}$ orals
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper presents the Holistic and Multi-Granular Surgical Scene
Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that
models surgical scene understanding as a hierarchy of complementary tasks with
varying levels of granularity. Our approach enables a multi-level comprehension
of surgical activities, encompassing long-term tasks such as surgical phases
and steps recognition and short-term tasks including surgical instrument
segmentation and atomic visual actions detection. To exploit our proposed
benchmark, we introduce the Transformers for Actions, Phases, Steps, and
Instrument Segmentation (TAPIS) model, a general architecture that combines a
global video feature extractor with localized region proposals from an
instrument segmentation model to tackle the multi-granularity of our benchmark.
Through extensive experimentation, we demonstrate the impact of including
segmentation annotations in short-term recognition tasks, highlight the varying
granularity requirements of each task, and establish TAPIS's superiority over
previously proposed baselines and conventional CNN-based models. Additionally,
we validate the robustness of our method across multiple public benchmarks,
confirming the reliability and applicability of our dataset. This work
represents a significant step forward in Endoscopic Vision, offering a novel
and comprehensive framework for future research towards a holistic
understanding of surgical procedures.
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11181 title=Abstract>arXiv:2401.11181</a> [<a href=https://arxiv.org/pdf/2401.11181 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11181 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+C">Cunchen Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Heyang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Liangliang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xusheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+H">Hao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenxi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sa Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Y">Yungang Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+N">Ninghui Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Yizhou Shan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Transformer-based large language model (LLM) inference serving is now the
backbone of many cloud services. LLM inference consists of a prefill phase and
a decode phase. However, existing LLM deployment practices often overlook the
distinct characteristics of these phases, leading to significant interference.
To mitigate interference, our insight is to carefully schedule and group
inference requests based on their characteristics. We realize this idea in
TetriInfer through three pillars. First, it partitions prompts into fixed-size
chunks so that the accelerator always runs close to its computationsaturated
limit. Second, it disaggregates prefill and decode instances so each can run
independently. Finally, it uses a smart two-level scheduling algorithm
augmented with predicted resource usage to avoid decode scheduling hotspots.
Results show that TetriInfer improves time-to-first-token (TTFT), job
completion time (JCT), and inference efficiency in turns of performance per
dollar by a large margin, e.g., it uses 38% less resources all the while
lowering average TTFT and average JCT by 97% and 47%, respectively.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11183 title=Abstract>arXiv:2401.11183</a> [<a href=https://arxiv.org/pdf/2401.11183 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11183 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predictive stability filters for nonlinear dynamical systems affected by disturbances
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Didier%2C+A">Alexandre Didier</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zanelli%2C+A">Andrea Zanelli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wabersich%2C+K+P">Kim P. Wabersich</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to NMPC'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>Predictive safety filters provide a way of projecting potentially unsafe
inputs onto the set of inputs that guarantee recursive state and input
constraint satisfaction. Unsafe inputs, proposed, e.g. by a human or
learning-based controller, can thereby be filtered by leveraging model
predictive control techniques. In this paper, we extend this framework such
that in addition, robust asymptotic stability of the closed-loop system can be
guaranteed by enforcing a decrease of an implicit Lyapunov function which is
constructed using a predicted system trajectory. Differently from previous
results, we show robust asymptotic stability on an extended state consisting of
the system state and a warmstart input sequence and establish robust asymptotic
stability for the augmented dynamics with respect to a predefined disturbance.
The proposed strategy is applied to an automotive lane keeping example in
simulation.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11185 title=Abstract>arXiv:2401.11185</a> [<a href=https://arxiv.org/pdf/2401.11185 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11185 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sung%2C+Y+Y">Yoo Yeon Sung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal%2C+I">Ishani Mondal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Dynamic adversarial question generation, where humans write examples to stump
a model, aims to create examples that are realistic and informative. However,
the advent of large language models (LLMs) has been a double-edged sword for
human authors: more people are interested in seeing and pushing the limits of
these models, but because the models are so much stronger an opponent, they are
harder to defeat. To understand how these models impact adversarial question
writing process, we enrich the writing guidance with LLMs and retrieval models
for the authors to reason why their questions are not adversarial. While
authors could create interesting, challenging adversarial questions, they
sometimes resort to tricks that result in poor questions that are ambiguous,
subjective, or confusing not just to a computer but also to humans. To address
these issues, we propose new metrics and incentives for eliciting good,
challenging questions and present a new dataset of adversarially authored
questions.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11188 title=Abstract>arXiv:2401.11188</a> [<a href=https://arxiv.org/pdf/2401.11188 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11188 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast and Exact Enumeration of Deep Networks Partitions Regions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balestriero%2C+R">Randall Balestriero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=LeCun%2C+Y">Yann LeCun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>One fruitful formulation of Deep Networks (DNs) enabling their theoretical
study and providing practical guidelines to practitioners relies on Piecewise
Affine Splines. In that realm, a DN's input-mapping is expressed as per-region
affine mapping where those regions are implicitly determined by the model's
architecture and form a partition of their input space. That partition -- which
is involved in all the results spanned from this line of research -- has so far
only been computed on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-238 style=width:1.855em;display:inline-block><span style=display:inline-block;position:relative;width:1.508em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.45em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-239><span class=mn id=MathJax-Span-240 style=font-family:MathJax_Main>2</span><span class=texatom id=MathJax-Span-241><span class=mrow id=MathJax-Span-242><span class=mo id=MathJax-Span-243 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-244 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-dimensional slices of the DN's input space or
estimated by random sampling. In this paper, we provide the first parallel
algorithm that does exact enumeration of the DN's partition regions. The
proposed algorithm enables one to finally assess the closeness of the commonly
employed approximations methods, e.g. based on random sampling of the DN input
space. One of our key finding is that if one is only interested in regions with
``large'' volume, then uniform sampling of the space is highly efficient, but
that if one is also interested in discovering the ``small'' regions of the
partition, then uniform sampling is exponentially costly with the DN's input
space dimension. On the other hand, our proposed method has complexity scaling
linearly with input dimension and the number of regions.
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11189 title=Abstract>arXiv:2401.11189</a> [<a href=https://arxiv.org/pdf/2401.11189 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11189 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11189 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Globally exponentially convergent observer for systems evolving on matrix Lie groups
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shanbhag%2C+S">Soham Shanbhag</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+D+E">Dong Eui Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>We propose a globally exponentially convergent observer for the dynamical
system evolving on matrix Lie groups with bounded velocity with unknown bound.
We design the observer in the ambient Euclidean space and show exponential
convergence of the observer to the state of the system. We show the convergence
with an example of a rigid body rotation and translation system on the special
Euclidean group. We compare the proposed observer with an observer present in
the literature.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11191 title=Abstract>arXiv:2401.11191</a> [<a href=https://arxiv.org/pdf/2401.11191 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11191 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11191 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Angular velocity and linear acceleration measurement bias estimators for the rigid body system with global exponential convergence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shanbhag%2C+S">Soham Shanbhag</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+D+E">Dong Eui Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Rigid body systems usually consider measurements of the pose of the body
using onboard cameras/LiDAR systems, that of linear acceleration using an
accelerometer and of angular velocity using an IMU. However, the measurements
of the linear acceleration and angular velocity are usually biased with an
unknown constant or slowly varying bias. We propose a measurement bias
estimator for such systems under assumption of boundedness of angular velocity.
We also provide continuous estimates to the state of the system, i.e. the pose,
linear velocity, and position of the body. These estimates are globally
exponentially convergent to the state of the rigid body system. We propose two
bias estimators designed with the estimate of the pose in the ambient Euclidean
space of the Special Euclidean group and show global exponential convergence of
the proposed observers to the state of the system. The first observer assumes
knowledge of bounds of the angular velocity, while the second observer uses a
Riccati observer to overcome this limitation. We show the convergence with an
example of a rigid body rotation and translation system on the special
Euclidean group. We show that the observer is able to estimate the bias using
data collected from an Intel Realsense camera.
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11194 title=Abstract>arXiv:2401.11194</a> [<a href=https://arxiv.org/pdf/2401.11194 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11194 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mapping the Field of Algorithm Auditing: A Systematic Literature Review Identifying Research Trends, Linguistic and Geographical Disparities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Urman%2C+A">Aleksandra Urman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makhortykh%2C+M">Mykola Makhortykh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hannak%2C+A">Aniko Hannak</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The increasing reliance on complex algorithmic systems by online platforms
has sparked a growing need for algorithm auditing, a research methodology
evaluating these systems' functionality and societal impact. In this paper, we
systematically review algorithm auditing studies and identify trends in their
methodological approaches, the geographic distribution of authors, and the
selection of platforms, languages, geographies, and group-based attributes in
the focus of auditing research. We present evidence of a significant skew of
research focus toward Western contexts, particularly the US, and a
disproportionate reliance on English language data. Additionally, our analysis
indicates a tendency in algorithm auditing studies to focus on a narrow set of
group-based attributes, often operationalized in simplified ways, which might
obscure more nuanced aspects of algorithmic bias and discrimination. By
conducting this review, we aim to provide a clearer understanding of the
current state of the algorithm auditing field and identify gaps that need to be
addressed for a more inclusive and representative research landscape.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11195 title=Abstract>arXiv:2401.11195</a> [<a href=https://arxiv.org/pdf/2401.11195 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11195 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Triple-Refined Hybrid-Field Beam Training for mmWave Extremely Large-Scale MIMO
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kangjian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+C">Chenhao Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Wireless Communications, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper investigates beam training for extremely large-scale
multiple-input multiple-output systems. By considering both the near field and
far field, a triple-refined hybrid-field beam training scheme is proposed,
where high-accuracy estimates of channel parameters are obtained through three
steps of progressive beam refinement. First, the hybrid-field beam gain
(HFBG)-based first refinement method is developed. Based on the analysis of the
HFBG, the first-refinement codebook is designed and the beam training is
performed accordingly to narrow down the potential region of the channel path.
Then, the maximum likelihood (ML)-based and principle of stationary phase
(PSP)-based second refinement methods are developed. By exploiting the
measurements of the beam training, the ML is used to estimate the channel
parameters. To avoid the high computational complexity of ML, closed-form
estimates of the channel parameters are derived according to the PSP. Moreover,
the Gaussian approximation (GA)-based third refinement method is developed. The
hybrid-field neighboring search is first performed to identify the potential
region of the main lobe of the channel steering vector. Afterwards, by applying
the GA, a least-squares estimator is developed to obtain the high-accuracy
channel parameter estimation. Simulation results verify the effectiveness of
the proposed scheme.
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11196 title=Abstract>arXiv:2401.11196</a> [<a href=https://arxiv.org/pdf/2401.11196 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11196 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11196 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine learning based state observer for discrete time systems evolving on Lie groups
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shanbhag%2C+S">Soham Shanbhag</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+D+E">Dong Eui Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, a machine learning based observer for systems evolving on
manifolds is designed such that the state of the observer is restricted to the
Lie group on which the system evolves. Conventional techniques involving
machine learning based observers on systems evolving on Lie groups involve
designing charts for the Lie group, training a machine learning based observer
for each chart, and switching between the trained models based on the state of
the system. We propose a novel deep learning based technique whose predictions
are restricted to a measure 0 subset of Euclidean space without using charts.
Using this network, we design an observer ensuring that the state of the
observer is restricted to the Lie group, and predicting the state using only
one trained algorithm. The deep learning network predicts an ``error term'' on
the Lie algebra of the Lie group, uses the map from the Lie algebra to the
group, and uses the group action and the present state to estimate the state at
the next epoch. This model being purely data driven does not require the model
of the system. The proposed algorithm provides a novel framework for
constraining the output of machine learning networks to a measure 0 subset of a
Euclidean space without chart specific training and without requiring
switching. We show the validity of this method using Monte Carlo simulations
performed of the rigid body rotation and translation system.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11197 title=Abstract>arXiv:2401.11197</a> [<a href=https://arxiv.org/pdf/2401.11197 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11197 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Introducing TOAST: Safe Asynchronous Mixed-Choice For Timed Interactions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pears%2C+J">Jonah Pears</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bocchi%2C+L">Laura Bocchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murgia%2C+M">Maurizio Murgia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=King%2C+A">Andy King</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Mixed-choice has long been barred from models of asynchronous communication
since it compromises the decidability of key properties of communicating
finite-state machines. Session types inherit this restriction, which precludes
them from fully modelling timeouts -- a core property of web and cloud
services. To address this deficiency, we present (binary) Timeout Asynchronous
Session Types ({TOAST}) as an extension to (binary) asynchronous timed session
types, that permits mixed-choice. {TOAST} deploys timing constraints to
regulate the use of mixed-choice so as to preserve communication safety. We
provide a new behavioural semantics for {TOAST} which guarantees progress in
the presence of mixed-choice. Building upon {TOAST}, we provide a calculus
featuring process timers which is capable of modelling timeouts using a
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-245 style=width:8.22em;display:inline-block><span style=display:inline-block;position:relative;width:6.832em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1006.77em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-246><span class=texatom id=MathJax-Span-247><span class=mrow id=MathJax-Span-248><span class=mi id=MathJax-Span-249 style=font-family:MathJax_Typewriter>r</span><span class=mi id=MathJax-Span-250 style=font-family:MathJax_Typewriter>e</span><span class=mi id=MathJax-Span-251 style=font-family:MathJax_Typewriter>c</span><span class=mi id=MathJax-Span-252 style=font-family:MathJax_Typewriter>e</span><span class=mi id=MathJax-Span-253 style=font-family:MathJax_Typewriter>i</span><span class=mi id=MathJax-Span-254 style=font-family:MathJax_Typewriter>v</span><span class=mi id=MathJax-Span-255 style=font-family:MathJax_Typewriter>e</span><span class=mtext id=MathJax-Span-256 style=font-family:MathJax_Typewriter>-</span><span class=mi id=MathJax-Span-257 style=font-family:MathJax_Typewriter>a</span><span class=mi id=MathJax-Span-258 style=font-family:MathJax_Typewriter>f</span><span class=mi id=MathJax-Span-259 style=font-family:MathJax_Typewriter>t</span><span class=mi id=MathJax-Span-260 style=font-family:MathJax_Typewriter>e</span><span class=mi id=MathJax-Span-261 style=font-family:MathJax_Typewriter>r</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> pattern, much like Erlang, and capture the
correspondence with TOAST specifications via a type system for which we prove
subject reduction.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11198 title=Abstract>arXiv:2401.11198</a> [<a href=https://arxiv.org/pdf/2401.11198 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11198 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Deep Learning Approach for Selective Relevance Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Datta%2C+S">Suchana Datta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganguly%2C+D">Debasis Ganguly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=MacAvaney%2C+S">Sean MacAvaney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greene%2C+D">Derek Greene</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness
over a sufficiently large number of queries. However, PRF often introduces a
drift into the original information need, thus hurting the retrieval
effectiveness of several queries. While a selective application of PRF can
potentially alleviate this issue, previous approaches have largely relied on
unsupervised or feature-based learning to determine whether a query should be
expanded. In contrast, we revisit the problem of selective PRF from a deep
learning perspective, presenting a model that is entirely data-driven and
trained in an end-to-end manner. The proposed model leverages a
transformer-based bi-encoder architecture. Additionally, to further improve
retrieval effectiveness with this selective PRF approach, we make use of the
model's confidence estimates to combine the information from the original and
expanded queries. In our experiments, we apply this selective feedback on a
number of different combinations of ranking and feedback models, and show that
our proposed approach consistently improves retrieval effectiveness for both
sparse and dense ranking models, with the feedback models being either sparse,
dense or generative.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11199 title=Abstract>arXiv:2401.11199</a> [<a href=https://arxiv.org/pdf/2401.11199 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11199 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11199 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Projected Belief Networks With Discriminative Alignment for Acoustic Event Classification: Rivaling State of the Art CNNs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baggenstoss%2C+P+M">Paul M. Baggenstoss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilkinghoff%2C+K">Kevin Wilkinghoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Govaers%2C+F">Felix Govaers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurth%2C+F">Frank Kurth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 Pages. Submitted to IEEE-TNNLS
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>The projected belief network (PBN) is a generative stochastic network with
tractable likelihood function based on a feed-forward neural network (FFNN).
The generative function operates by "backing up" through the FFNN. The PBN is
two networks in one, a FFNN that operates in the forward direction, and a
generative network that operates in the backward direction. Both networks
co-exist based on the same parameter set, have their own cost functions, and
can be separately or jointly trained. The PBN therefore has the potential to
possess the best qualities of both discriminative and generative classifiers.
To realize this potential, a separate PBN is trained on each class, maximizing
the generative likelihood function for the given class, while minimizing the
discriminative cost for the FFNN against "all other classes". This technique,
called discriminative alignment (PBN-DA), aligns the contours of the likelihood
function to the decision boundaries and attains vastly improved classification
performance, rivaling that of state of the art discriminative networks. The
method may be further improved using a hidden Markov model (HMM) as a component
of the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of
PBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification
experiments are provided. The first experiment uses air-acoustic events, and
the second uses underwater acoustic data consisting of marine mammal calls. In
both experiments, PBN-DA-HMM attains comparable or better performance as a
state of the art CNN, and attain a factor of two error reduction when combined
with the CNN.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11200 title=Abstract>arXiv:2401.11200</a> [<a href=https://arxiv.org/pdf/2401.11200 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11200 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11200 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transversally exponentially stable Euclidean space extension technique for discrete time systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shanbhag%2C+S">Soham Shanbhag</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chang%2C+D+E">Dong Eui Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>We propose a modification technique for discrete time systems for
exponentially fast convergence to compact sets. The extension technique allows
us to use tools defined on Euclidean spaces to systems evolving on manifolds by
modifying the dynamics of the system such that the manifold is an attractor
set. We show the stability properties of this technique using the simulation of
the rigid body rotation system on the unit sphere <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-262 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.16em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-263><span class=msubsup id=MathJax-Span-264><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-265 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-266 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. We also show the
improvement afforded due to this technique on a Luenberger like observer
designed for the rigid body rotation system on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-267 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.16em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-268><span class=msubsup id=MathJax-Span-269><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-270 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mn id=MathJax-Span-271 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11201 title=Abstract>arXiv:2401.11201</a> [<a href=https://arxiv.org/pdf/2401.11201 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11201 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cau%2C+F+M">F. M. Cau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tintarev%2C+N">N. Tintarev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 3 figures, ECIR2024 (46th European Conference on Information Retrieval - IR4Good track)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Opinionated users often seek information that aligns with their preexisting
beliefs while dismissing contradictory evidence due to confirmation bias. This
conduct hinders their ability to consider alternative stances when searching
the web. Despite this, few studies have analyzed how the diversification of
search results on disputed topics influences the search behavior of highly
opinionated users. To this end, we present a preregistered user study (n = 257)
investigating whether different levels (low and high) of bias metrics and
search results presentation (with or without AI-predicted stances labels) can
affect the stance diversity consumption and search behavior of opinionated
users on three debated topics (i.e., atheism, intellectual property rights, and
school uniforms). Our results show that exposing participants to
(counter-attitudinally) biased search results increases their consumption of
attitude-opposing content, but we also found that bias was associated with a
trend toward overall fewer interactions within the search page. We also found
that 19% of users interacted with queries and search pages but did not select
any search results. When we removed these participants in a post-hoc analysis,
we found that stance labels increased the diversity of stances consumed by
users, particularly when the search results were biased. Our findings highlight
the need for future research to explore distinct search scenario settings to
gain insight into opinionated users' behavior.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11202 title=Abstract>arXiv:2401.11202</a> [<a href=https://arxiv.org/pdf/2401.11202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PartIR: Composing SPMD Partitioning Strategies for Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alabed%2C+S">Sami Alabed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chrzaszcz%2C+B">Bart Chrzaszcz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franco%2C+J">Juliana Franco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grewe%2C+D">Dominik Grewe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maclaurin%2C+D">Dougal Maclaurin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molloy%2C+J">James Molloy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natan%2C+T">Tom Natan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Norman%2C+T">Tamara Norman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+X">Xiaoyue Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paszke%2C+A">Adam Paszke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rink%2C+N+A">Norman A. Rink</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaarschmidt%2C+M">Michael Schaarschmidt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sitdikov%2C+T">Timur Sitdikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swietlik%2C+A">Agnieszka Swietlik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vytiniotis%2C+D">Dimitrios Vytiniotis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wee%2C+J">Joel Wee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Programming Languages (cs.PL)
</div>
<p class=mathjax>Training of modern large neural networks (NN) requires a combination of
parallelization strategies encompassing data, model, or optimizer sharding.
When strategies increase in complexity, it becomes necessary for partitioning
tools to be 1) expressive, allowing the composition of simpler strategies, and
2) predictable to estimate performance analytically. We present PartIR, our
design for a NN partitioning system. PartIR is focused on an incremental
approach to rewriting and is hardware-and-runtime agnostic. We present a simple
but powerful API for composing sharding strategies and a simulator to validate
them. The process is driven by high-level programmer-issued partitioning
tactics, which can be both manual and automatic. Importantly, the tactics are
specified separately from the model code, making them easy to change. We
evaluate PartIR on several different models to demonstrate its predictability,
expressibility, and ability to reach peak performance..
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11203 title=Abstract>arXiv:2401.11203</a> [<a href=https://arxiv.org/pdf/2401.11203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Hussieny%2C+H">Haitham El-Hussieny</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Soft growing robots, are a type of robots that are designed to move and adapt
to their environment in a similar way to how plants grow and move with
potential applications where they could be used to navigate through tight
spaces, dangerous terrain, and hard-to-reach areas. This research explores the
application of deep reinforcement Q-learning algorithm for facilitating the
navigation of the soft growing robots in cluttered environments. The proposed
algorithm utilizes the flexibility of the soft robot to adapt and incorporate
the interaction between the robot and the environment into the decision-making
process. Results from simulations show that the proposed algorithm improves the
soft robot's ability to navigate effectively and efficiently in confined
spaces. This study presents a promising approach to addressing the challenges
faced by growing robots in particular and soft robots general in planning
obstacle-aware paths in real-world scenarios.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11204 title=Abstract>arXiv:2401.11204</a> [<a href=https://arxiv.org/pdf/2401.11204 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11204 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Category Unification of 3D Single Object Tracking on Point Clouds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+J">Jiahao Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Z">Zhiwei He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+X">Xudong Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xueyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chae%2C+D">Dong-Kyu Chae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+F">Fei Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR2024 (poster)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Category-specific models are provenly valuable methods in 3D single object
tracking (SOT) regardless of Siamese or motion-centric paradigms. However, such
over-specialized model designs incur redundant parameters, thus limiting the
broader applicability of 3D SOT task. This paper first introduces unified
models that can simultaneously track objects across all categories using a
single network with shared model parameters. Specifically, we propose to
explicitly encode distinct attributes associated to different object
categories, enabling the model to adapt to cross-category data. We find that
the attribute variances of point cloud objects primarily occur from the varying
size and shape (e.g., large and square vehicles v.s. small and slender humans).
Based on this observation, we design a novel point set representation learning
network inheriting transformer architecture, termed AdaFormer, which adaptively
encodes the dynamically varying shape and size information from cross-category
data in a unified manner. We further incorporate the size and shape prior
derived from the known template targets into the model's inputs and learning
objective, facilitating the learning of unified representation. Equipped with
such designs, we construct two category-unified models SiamCUT and
MoCUT.Extensive experiments demonstrate that SiamCUT and MoCUT exhibit strong
generalization and training stability. Furthermore, our category-unified models
outperform the category-specific counterparts by a significant margin (e.g., on
KITTI dataset, 12% and 3% performance gains on the Siamese and motion
paradigms). Our code will be available.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11205 title=Abstract>arXiv:2401.11205</a> [<a href=https://arxiv.org/pdf/2401.11205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jintao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chengzhi Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+S">Shiqi Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 9 figures. This paper has been submitted to IEEE journal for possible publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Considering the appealing distribution gains of distributed antenna systems
(DAS) and passive gains of reconfigurable intelligent surface (RIS), a flexible
reconfigurable architecture called reconfigurable distributed antenna and
reflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as two
special cases and maintains the advantages of distributed antennas while
reducing the hardware cost by replacing some active antennas with low-cost
passive reflecting surfaces. In this paper, we present a RDARS-aided uplink
multi-user communication system and investigate the system transmission
reliability with the newly proposed architecture. Specifically, in addition to
the distribution gain and the reflection gain provided by the connection and
reflection modes, respectively, we also consider the dynamic mode switching of
each element which introduces an additional degree of freedom (DoF) and thus
results in a selection gain. As such, we aim to minimize the total sum
mean-square-error (MSE) of all data streams by jointly optimizing the receive
beamforming matrix, the reflection phase shifts and the channel-aware placement
of elements in the connection mode. To tackle this nonconvex problem with
intractable binary and cardinality constraints, we propose an inexact block
coordinate descent (BCD) based penalty dual decomposition (PDD) algorithm with
the guaranteed convergence. Since the PDD algorithm usually suffers from high
computational complexity, a low-complexity greedy-search-based alternating
optimization (AO) algorithm is developed to yield a semi-closed-form solution
with acceptable performance. Numerical results demonstrate the superiority of
the proposed architecture compared to the conventional fully passive RIS or
DAS. Furthermore, some insights about the practical implementation of RDARS are
provided.
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11206 title=Abstract>arXiv:2401.11206</a> [<a href=https://arxiv.org/pdf/2401.11206 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11206 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Linyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+C">Chenkun Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinghao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+K">Ke Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+B">Botian Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>With the rapid development of large language models (LLMs), they are not only
used as general-purpose AI assistants but are also customized through further
fine-tuning to meet the requirements of different applications. A pivotal
factor in the success of current LLMs is the alignment process. Current
alignment methods, such as supervised fine-tuning (SFT) and reinforcement
learning from human feedback (RLHF), focus on training-time alignment and are
often complex and cumbersome to implement. Therefore, we develop
\textbf{InferAligner}, a novel inference-time alignment method that utilizes
cross-model guidance for harmlessness alignment. InferAligner utilizes safety
steering vectors extracted from safety-aligned model to modify the activations
of the target model when responding to harmful inputs, thereby guiding the
target model to provide harmless responses. Experimental results show that our
method can be very effectively applied to domain-specific models in finance,
medicine, and mathematics, as well as to multimodal large language models
(MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate
(ASR) of both harmful instructions and jailbreak attacks, while maintaining
almost unchanged performance in downstream tasks.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11207 title=Abstract>arXiv:2401.11207</a> [<a href=https://arxiv.org/pdf/2401.11207 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11207 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11207 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unfair TOS: An Automated Approach using Customized BERT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akash%2C+B+S">Bathini Sai Akash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kupireddy%2C+A">Akshara Kupireddy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murthy%2C+L+B">Lalita Bhanu Murthy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Terms of Service (ToS) form an integral part of any agreement as it defines
the legal relationship between a service provider and an end-user. Not only do
they establish and delineate reciprocal rights and responsibilities, but they
also provide users with information on essential aspects of contracts that
pertain to the use of digital spaces. These aspects include a wide range of
topics, including limitation of liability, data protection, etc. Users tend to
accept the ToS without going through it before using any application or
service. Such ignorance puts them in a potentially weaker situation in case any
action is required. Existing methodologies for the detection or classification
of unfair clauses are however obsolete and show modest performance. In this
research paper, we present SOTA(State of The Art) results on unfair clause
detection from ToS documents based on unprecedented Fine-tuning BERT in
integration with SVC(Support Vector Classifier). The study shows proficient
performance with a macro F1-score of 0.922 at unfair clause detection, and
superior performance is also shown in the classification of unfair clauses by
each tag. Further, a comparative analysis is performed by answering research
questions on the Transformer models utilized. In order to further research and
experimentation the code and results are made available on
https://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11212 title=Abstract>arXiv:2401.11212</a> [<a href=https://arxiv.org/pdf/2401.11212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Programming Distributed Collective Processes in the eXchange Calculus
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Audrito%2C+G">Giorgio Audrito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casadei%2C+R">Roberto Casadei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damiani%2C+F">Ferruccio Damiani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torta%2C+G">Gianluca Torta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viroli%2C+M">Mirko Viroli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Programming Languages (cs.PL)
</div>
<p class=mathjax>Recent trends like the Internet of Things (IoT) suggest a vision of dense and
multi-scale deployments of computing devices in nearly all kinds of
environments. A prominent engineering challenge revolves around programming the
collective adaptive behaviour of such computational ecosystems. This requires
abstractions able to capture concepts like ensembles (dynamic groups of
cooperating devices) and collective tasks (joint activities carried out by
ensembles). In this work, we consider collections of devices interacting with
neighbours and that execute in nearly-synchronised sense-compute-interact
rounds, where the computation is given by a single program mapping sensing
values and incoming messages to output and outcoming messages. To support
programming whole computational collectives, we propose the abstraction of a
distributed collective process, which can be used to define at once the
ensemble formation logic and its collective task. We formalise the abstraction
in the eXchange Calculus (XC), a core functional language based on neighbouring
values (maps from neighbours to values) where state and interaction is handled
through a single primitive, exchange, and provide a corresponding
implementation in the FCPP language. Then, we exercise distributed collective
processes using two case studies: multi-hop message propagation and distributed
monitoring of spatial properties. Finally, we discuss the features of the
abstraction and its suitability for different kinds of distributed computing
applications.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11214 title=Abstract>arXiv:2401.11214</a> [<a href=https://arxiv.org/pdf/2401.11214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D Receiver for Molecular Communications in Internet of Organoids
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shaojie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akan%2C+O+B">Ozgur B. Akan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Organoids have garnered attention due to their effectiveness in modeling the
3D structure of organ interactions. However, the communication engineering
perspective has received relatively little attention. One way to achieve
organoids communication is molecular communication (MC). Molecular
communication is a bio-inspired communication paradigm that uses molecules as
information carriers. It is considered one of the most promising methods for
enabling the Internet of Nano-Things (IoNT) and nanonetworks. BioFETs are
commonly used to implement practical MC receivers. However, most previous
analyses have focused on a planar device, neglecting considerations like the
threshold voltage and its potential 3D structure. This paper introduces the
first FinFET-based MC receiver that covers both the top and side gates with
receptors. Both binding noise and flicker noise are considered in the analysis.
The performance, in terms of signal-to-noise ratio (SNR) and symbol error
probability (SEP), is compared with that of the 2D receiver.
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11215 title=Abstract>arXiv:2401.11215</a> [<a href=https://arxiv.org/pdf/2401.11215 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11215 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Selecting Walk Schemes for Database Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lubarsky%2C+Y+L">Yuval Lev Lubarsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C3%B6nshoff%2C+J">Jan Tönshoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grohe%2C+M">Martin Grohe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kimelfeld%2C+B">Benny Kimelfeld</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by CIKM 2023, 10 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> CIKM 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Databases (cs.DB)
</div>
<p class=mathjax>Machinery for data analysis often requires a numeric representation of the
input. Towards that, a common practice is to embed components of structured
data into a high-dimensional vector space. We study the embedding of the tuples
of a relational database, where existing techniques are often based on
optimization tasks over a collection of random walks from the database. The
focus of this paper is on the recent FoRWaRD algorithm that is designed for
dynamic databases, where walks are sampled by following foreign keys between
tuples. Importantly, different walks have different schemas, or "walk schemes",
that are derived by listing the relations and attributes along the walk. Also
importantly, different walk schemes describe relationships of different natures
in the database. We show that by focusing on a few informative walk schemes, we
can obtain tuple embedding significantly faster, while retaining the quality.
We define the problem of scheme selection for tuple embedding, devise several
approaches and strategies for scheme selection, and conduct a thorough
empirical study of the performance over a collection of downstream tasks. Our
results confirm that with effective strategies for scheme selection, we can
obtain high-quality embeddings considerably (e.g., three times) faster,
preserve the extensibility to newly inserted tuples, and even achieve an
increase in the precision of some tasks.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11217 title=Abstract>arXiv:2401.11217</a> [<a href=https://arxiv.org/pdf/2401.11217 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11217 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11217 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koksal%2C+E+S">Ece S. Koksal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aydin%2C+E">Erdal Aydin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)
</div>
<p class=mathjax>Constructing first principles models is a challenging task for nonlinear and
complex systems such as a wastewater treatment unit. In recent years,
data-driven models are widely used to overcome the complexity. However, they
often suffer from issues such as missing, low quality or noisy data. Transfer
learning is a solution for this issue where knowledge from another task is
transferred to target one to increase the prediction performance. In this work,
the objective is increasing the prediction performance of an industrial
wastewater treatment plant by transferring the knowledge of (i) an open-source
simulation model that captures the underlying physics of the process, albeit
with dissimilarities to the target plant, (ii) another industrial plant
characterized by noisy and limited data but located in the same refinery, and
(iii) the model in (ii) and making the objective function of the training
problem physics informed where the physics information derived from the
open-source model in (ii). The results have shown that test and validation
performance are improved up to 27% and 59%, respectively.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11218 title=Abstract>arXiv:2401.11218</a> [<a href=https://arxiv.org/pdf/2401.11218 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11218 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> End-to-End Argument Mining over Varying Rhetorical Structures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chistova%2C+E">Elena Chistova</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Findings of the Association for Computational Linguistics: ACL
 2023, 3376-3391
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Rhetorical Structure Theory implies no single discourse interpretation of a
text, and the limitations of RST parsers further exacerbate inconsistent
parsing of similar structures. Therefore, it is important to take into account
that the same argumentative structure can be found in semantically similar
texts with varying rhetorical structures. In this work, the differences between
paraphrases within the same argument scheme are evaluated from a rhetorical
perspective. The study proposes a deep dependency parsing model to assess the
connection between rhetorical and argument structures. The model utilizes
rhetorical relations; RST structures of paraphrases serve as training data
augmentations. The method allows for end-to-end argumentation analysis using a
rhetorical tree instead of a word sequence. It is evaluated on the bilingual
Microtexts corpus, and the first results on fully-fledged argument parsing for
the Russian version of the corpus are reported. The results suggest that
argument mining can benefit from multiple variants of discourse structure.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11219 title=Abstract>arXiv:2401.11219</a> [<a href=https://arxiv.org/pdf/2401.11219 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11219 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11219 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Information Leakage Performance of Secure Finite Blocklength Transmissions over Rayleigh Fading Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mamaghani%2C+M+T">Milad Tatar Mamaghani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiangyun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+N">Nan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swindlehurst%2C+A+L">A. Lee Swindlehurst</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures. Accepted for presentation at the 2024 IEEE International Conference on Communications (CT Symposium), 9 - 13 June 2024, Denver, CO United States. Note: An extended version of this work is available as <a href=https://arxiv.org/abs/2308.13184>arXiv:2308.13184</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper presents a secrecy performance study of a wiretap communication
system with finite blocklength (FBL) transmissions over Rayleigh fading
channels, based on the definition of an average information leakage (AIL)
metric. We evaluate the exact and closed-form approximate AIL performance,
assuming that only statistical channel state information (CSI) of the
eavesdropping link is available. Then, we reveal an inherent statistical
relationship between the AIL metric in the FBL regime and the commonly-used
secrecy outage probability in conventional infinite blocklength communications.
Aiming to improve the secure communication performance of the considered
system, we formulate a blocklength optimization problem and solve it via a
low-complexity approach. Next, we present numerical results to verify our
analytical findings and provide various important insights into the impacts of
system parameters on the AIL. Specifically, our results indicate that i)
compromising a small amount of AIL can lead to significant reliability
improvements, and ii) the AIL experiences a secrecy floor in the high
signal-to-noise ratio regime.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11225 title=Abstract>arXiv:2401.11225</a> [<a href=https://arxiv.org/pdf/2401.11225 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11225 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11225 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Protecting Personalized Trajectory with Differential Privacy under Temporal Correlations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+M">Mingge Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Haopeng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+M">Minghui Min</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yulu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shiyin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongliang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhu Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offer
users numerous conveniences. However, the extensive use of LBSs raises concerns
about the privacy of users' trajectories, as adversaries can exploit temporal
correlations between different locations to extract personal information.
Additionally, users have varying privacy requirements depending on the time and
location. To address these issues, this paper proposes a personalized
trajectory privacy protection mechanism (PTPPM). This mechanism first uses the
temporal correlation between trajectory locations to determine the possible
location set for each time instant. We identify a protection location set (PLS)
for each location by employing the Hilbert curve-based minimum distance search
algorithm. This approach incorporates the complementary features of
geo-indistinguishability and distortion privacy. We put forth a novel
Permute-and-Flip mechanism for location perturbation, which maps its initial
application in data publishing privacy protection to a location perturbation
mechanism. This mechanism generates fake locations with smaller perturbation
distances while improving the balance between privacy and quality of service
(QoS). Simulation results show that our mechanism outperforms the benchmark by
providing enhanced privacy protection while meeting user's QoS requirements.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11228 title=Abstract>arXiv:2401.11228</a> [<a href=https://arxiv.org/pdf/2401.11228 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11228 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unifying Visual and Vision-Language Tracking via Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yinchao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yuyang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenfei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianzhu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinpeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+M">Mengxue Kang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Single object tracking aims to locate the target object in a video sequence
according to the state specified by different modal references, including the
initial bounding box (BBOX), natural language (NL), or both (NL+BBOX). Due to
the gap between different modalities, most existing trackers are designed for
single or partial of these reference settings and overspecialize on the
specific modality. Differently, we present a unified tracker called UVLTrack,
which can simultaneously handle all three reference settings (BBOX, NL,
NL+BBOX) with the same parameters. The proposed UVLTrack enjoys several merits.
First, we design a modality-unified feature extractor for joint visual and
language feature learning and propose a multi-modal contrastive loss to align
the visual and language features into a unified semantic space. Second, a
modality-adaptive box head is proposed, which makes full use of the target
reference to mine ever-changing scenario features dynamically from video
contexts and distinguish the target in a contrastive way, enabling robust
performance in different reference settings. Extensive experimental results
demonstrate that UVLTrack achieves promising performance on seven visual
tracking datasets, three vision-language tracking datasets, and three visual
grounding datasets. Codes and models will be open-sourced at
https://github.com/OpenSpaceAI/UVLTrack.
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11231 title=Abstract>arXiv:2401.11231</a> [<a href=https://arxiv.org/pdf/2401.11231 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11231 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Two-Insertion/Deletion/Substitution Correcting Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pi%2C+Y">Yuhang Pi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhifang Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In recent years, the emergence of DNA storage systems has led to a widespread
focus on the research of codes correcting insertions, deletions, and classic
substitutions. During the initial investigation, Levenshtein discovered the VT
codes are precisely capable of correcting single insertion/deletion and then
extended the VT construction to single-insertion/deletion/substitution
(<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-272 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-273><span class=mn id=MathJax-Span-274 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-ins/del/sub) correcting codes. Inspired by this, we generalize the recent
findings of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-275 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-276><span class=mn id=MathJax-Span-277 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-del <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-278 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-279><span class=mn id=MathJax-Span-280 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-sub correcting codes with redundancy <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-281 style=width:7.758em;display:inline-block><span style=display:inline-block;position:relative;width:6.427em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.31em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-282><span class=mn id=MathJax-Span-283 style=font-family:MathJax_Main>6</span><span class=msubsup id=MathJax-Span-284 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-285 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.276em><span class=texatom id=MathJax-Span-286><span class=mrow id=MathJax-Span-287><span class=mn id=MathJax-Span-288 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-289></span><span class=mi id=MathJax-Span-290 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-291 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-292 style=font-family:MathJax_Math-italic;padding-left:0.234em>O</span><span class=mo id=MathJax-Span-293 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-294 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-295 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
to more general <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-296 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-297><span class=mn id=MathJax-Span-298 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-ins/del/sub correcting codes without increasing the
redundancy. Our key technique is to apply higher-order VT syndromes to distinct
objects and accomplish a systematic classification of all error patterns.
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11232 title=Abstract>arXiv:2401.11232</a> [<a href=https://arxiv.org/pdf/2401.11232 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11232 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11232 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative consumption for low and high trust requiring business models: from fare sharing to supporting the elderly and people with disability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xusen Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kroenung%2C+J">Julia Kroenung</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Electronic Business, pp.1-20 (2019)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>This paper offers an overview of collaborative consumption (CC), the related
business models (BM), the value added (VA) from the consumer's perspective and
the role of trust. CC is expanding but it is unclear what opportunities it
offers and what the challenges will be. This research evaluates the current CC
BMs and identifies 13 ways they add value from the consumer's perspective. This
research further explores whether CC BMs fall into two categories in terms of
what the consumer values. In the first category, the CC BMs require a low level
of trust while in the second category of CC BMs a higher level of trust is
necessary. It was found that 13 VA by CC BMs could be grouped into personal
interest, communal interest and trust building. It is important for
organisations to acknowledge how their CC BM relates to these dimensions.
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11235 title=Abstract>arXiv:2401.11235</a> [<a href=https://arxiv.org/pdf/2401.11235 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11235 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+S">Shibo He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shizhong Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by IEEE ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Time series anomaly detection (TSAD) plays a vital role in various domains
such as healthcare, networks, and industry. Considering labels are crucial for
detection but difficult to obtain, we turn to TSAD with inexact supervision:
only series-level labels are provided during the training phase, while
point-level anomalies are predicted during the testing phase. Previous works
follow a traditional multi-instance learning (MIL) approach, which focuses on
encouraging high anomaly scores at individual time steps. However, time series
anomalies are not only limited to individual point anomalies, they can also be
collective anomalies, typically exhibiting abnormal patterns over subsequences.
To address the challenge of collective anomalies, in this paper, we propose a
tree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to
divide the entire series into multiple nodes, where nodes at different levels
represent subsequences with different lengths. Then, the subsequence features
are extracted to determine the presence of collective anomalies. Finally, we
calculate point-level anomaly scores by aggregating features from nodes at
different levels. Experiments conducted on seven public datasets and eight
baselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-
score compared to previous state-of-the-art methods. The code is available at
https://github.com/fly-orange/TreeMIL.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11236 title=Abstract>arXiv:2401.11236</a> [<a href=https://arxiv.org/pdf/2401.11236 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11236 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Cell-Free Massive MIMO for High Capacity with Simple Implementation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 IEEE International Conference on Communications (ICC-2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Cell-free massive multi-input multi-output (MIMO) has recently gained much
attention for its potential in shaping the landscape of sixth-generation (6G)
wireless systems. This paper proposes a hierarchical network architecture
tailored for cell-free massive MIMO, seamlessly integrating co-located and
distributed antennas. A central base station (CBS), equipped with an antenna
array, positions itself near the center of the coverage area, complemented by
distributed access points spanning the periphery. The proposed architecture
remarkably outperforms conventional cell-free networks, demonstrating superior
sum throughput while maintaining a comparable worst-case per-user spectral
efficiency. Meanwhile, the implementation cost associated with the fronthaul
network is substantially diminished.
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11237 title=Abstract>arXiv:2401.11237</a> [<a href=https://arxiv.org/pdf/2401.11237 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11237 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Closing the Gap between TD Learning and Supervised Learning -- A Generalisation Point of View
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghugare%2C+R">Raj Ghugare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geist%2C+M">Matthieu Geist</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berseth%2C+G">Glen Berseth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eysenbach%2C+B">Benjamin Eysenbach</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024, Project code: <a href=https://github.com/RajGhugare19/stitching-is-combinatorial-generalisation>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Some reinforcement learning (RL) algorithms can stitch pieces of experience
to solve a task never seen before during training. This oft-sought property is
one of the few ways in which RL methods based on dynamic-programming differ
from RL methods based on supervised-learning (SL). Yet, certain RL methods
based on off-the-shelf SL algorithms achieve excellent results without an
explicit mechanism for stitching; it remains unclear whether those methods
forgo this important stitching property. This paper studies this question for
the problems of achieving a target goal state and achieving a target return
value. Our main result is to show that the stitching property corresponds to a
form of combinatorial generalization: after training on a distribution of
(state, goal) pairs, one would like to evaluate on (state, goal) pairs not seen
together in the training data. Our analysis shows that this sort of
generalization is different from i.i.d. generalization. This connection between
stitching and generalisation reveals why we should not expect SL-based RL
methods to perform stitching, even in the limit of large datasets and models.
Based on this analysis, we construct new datasets to explicitly test for this
property, revealing that SL-based methods lack this stitching property and
hence fail to perform combinatorial generalization. Nonetheless, the connection
between stitching and combinatorial generalisation also suggests a simple
remedy for improving generalisation in SL: data augmentation. We propose a
temporal data augmentation and demonstrate that adding it to SL-based methods
enables them to successfully complete tasks not seen together during training.
On a high level, this connection illustrates the importance of combinatorial
generalization for data efficiency in time-series data beyond tasks beyond RL,
like audio, video, or text.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11238 title=Abstract>arXiv:2401.11238</a> [<a href=https://arxiv.org/pdf/2401.11238 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11238 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11238 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can global, extended and repeated ransomware attacks overcome the users status quo bias and cause a switch of system
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xusen Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayawickrama%2C+U">Uchitha Jayawickrama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corsi%2C+S">Simone Corsi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Journal of Information Systems in the Service Sector (2022)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Ransomware attack effectiveness has increased causing far reaching
consequences that are not fully understood. The ability to disrupt core
services, the global reach, extended duration, and the repetition has increased
their ability to harm organizations. One aspect that needs to be understood
better is the effect on the user. The user in the current environment is
exposed to new technologies that might be adopted, but there are also habits of
using existing systems. The habits have developed over time with trust
increasing in the organization in contact directly and the institutions
supporting it. This research explores whether the global, extended, and
repeated RW attacks reduce the trust and inertia sufficiently to change
long-held habits in using information systems. The model tested measures the
effect of the RW attack on the e-commerce status quo to evaluate if it is
significant enough to overcome the users resistance to change.
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11239 title=Abstract>arXiv:2401.11239</a> [<a href=https://arxiv.org/pdf/2401.11239 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11239 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes Shading and Wrinkles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+Y">Yanlong Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Han Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+J">Jiaxu Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yi Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Image-based virtual try-on systems,which fit new garments onto human
portraits,are gaining research attention.An ideal pipeline should preserve the
static features of clothes(like textures and logos)while also generating
dynamic elements(e.g.shadows,folds)that adapt to the model's pose and
environment.Previous works fail specifically in generating dynamic features,as
they preserve the warped in-shop clothes trivially with predicted an alpha mask
by composition.To break the dilemma of over-preserving and textures losses,we
propose a novel diffusion-based Product-level virtual try-on pipeline,\ie
PLTON, which can preserve the fine details of logos and embroideries while
producing realistic clothes shading and wrinkles.The main insights are in three
folds:1)Adaptive Dynamic Rendering:We take a pre-trained diffusion model as a
generative prior and tame it with image features,training a dynamic extractor
from scratch to generate dynamic tokens that preserve high-fidelity semantic
information. Due to the strong generative power of the diffusion prior,we can
generate realistic clothes shadows and wrinkles.2)Static Characteristics
Transformation: High-frequency Map(HF-Map)is our fundamental insight for static
representation.PLTON first warps in-shop clothes to the target model pose by a
traditional warping network,and uses a high-pass filter to extract an HF-Map
for preserving static cloth features.The HF-Map is used to generate modulation
maps through our static extractor,which are injected into a fixed U-net to
synthesize the final result.To enhance retention,a Two-stage Blended Denoising
method is proposed to guide the diffusion process for correct spatial layout
and color.PLTON is finetuned only with our collected small-size try-on
dataset.Extensive quantitative and qualitative experiments on 1024 768 datasets
demonstrate the superiority of our framework in mimicking real clothes
dynamics.
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11240 title=Abstract>arXiv:2401.11240</a> [<a href=https://arxiv.org/pdf/2401.11240 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11240 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CaraServe: CPU-Assisted and Rank-Aware LoRA Serving for Generative LLM Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Suyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Hanfeng Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tianyuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+M">Minchen Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weng%2C+Q">Qizhen Weng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xusheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Yizhou Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+B">Binhang Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Pre-trained large language models (LLMs) often need specialization for
domain-specific tasks. Low-Rank Adaptation (LoRA) is a popular approach that
adapts a base model to multiple tasks by adding lightweight trainable adapters.
In this paper, we present CaraServe, a system that efficiently serves many LoRA
adapters derived from a common base model. CaraServe maintains the base model
on GPUs and dynamically loads activated LoRA adapters from main memory. As GPU
loading results in a cold-start that substantially delays token generation,
CaraServe employs a CPU-assisted approach. It early starts the activated
adapters on CPUs for prefilling as they are being loaded onto GPUs; after
loading completes, it then switches to the GPUs for generative LoRA inference.
CaraServe develops a highly optimized synchronization mechanism to efficiently
coordinate LoRA computation on the CPU and GPU. Moreover, CaraServe employs a
rank-aware scheduling algorithm to optimally schedule heterogeneous LoRA
requests for maximum service-level objective (SLO) attainment. We have
implemented CaraServe and evaluated it against state-of-the-art LoRA serving
systems. Our results demonstrate that CaraServe can speed up the average
request serving latency by up to 1.4<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-299 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-300><span class=mo id=MathJax-Span-301 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and achieve an SLO attainment of
up to 99%.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11243 title=Abstract>arXiv:2401.11243</a> [<a href=https://arxiv.org/pdf/2401.11243 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11243 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11243 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise Relevance Propagation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ranjan%2C+N">Navin Ranjan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Savakis%2C+A">Andreas Savakis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Vision transformers (ViTs) have demonstrated remarkable performance across
various visual tasks. However, ViT models suffer from substantial computational
and memory requirements, making it challenging to deploy them on
resource-constrained platforms. Quantization is a popular approach for reducing
model size, but most studies mainly focus on equal bit-width quantization for
the entire network, resulting in sub-optimal solutions. While there are few
works on mixed precision quantization (MPQ) for ViTs, they typically rely on
search space-based methods or employ mixed precision arbitrarily. In this
paper, we introduce LRP-QViT, an explainability-based method for assigning
mixed-precision bit allocations to different layers based on their importance
during classification. Specifically, to measure the contribution score of each
layer in predicting the target class, we employ the Layer-wise Relevance
Propagation (LRP) method. LRP assigns local relevance at the output layer and
propagates it through all layers, distributing the relevance until it reaches
the input layers. These relevance scores serve as indicators for computing the
layer contribution score. Additionally, we have introduced a clipped
channel-wise quantization aimed at eliminating outliers from post-LayerNorm
activations to alleviate severe inter-channel variations. To validate and
assess our approach, we employ LRP-QViT across ViT, DeiT, and Swin transformer
models on various datasets. Our experimental findings demonstrate that both our
fixed-bit and mixed-bit post-training quantization methods surpass existing
models in the context of 4-bit and 6-bit quantization.
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11246 title=Abstract>arXiv:2401.11246</a> [<a href=https://arxiv.org/pdf/2401.11246 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11246 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11246 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+B">Bongsu Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jundong Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+T">Tae-Rim Yun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+C">Chang-Eop Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 4 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>We propose a natural language prompt-based retrieval augmented generation
(Prompt-RAG), a novel approach to enhance the performance of generative large
language models (LLMs) in niche domains. Conventional RAG methods mostly
require vector embeddings, yet the suitability of generic LLM-based embedding
representations for specialized domains remains uncertain. To explore and
exemplify this point, we compared vector embeddings from Korean Medicine (KM)
and Conventional Medicine (CM) documents, finding that KM document embeddings
correlated more with token overlaps and less with human-assessed document
relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from
conventional RAG models, operates without the need for embedding vectors. Its
performance was assessed through a Question-Answering (QA) chatbot application,
where responses were evaluated for relevance, readability, and informativeness.
The results showed that Prompt-RAG outperformed existing models, including
ChatGPT and conventional vector embedding-based RAGs, in terms of relevance and
informativeness. Despite challenges like content structuring and response
latency, the advancements in LLMs are expected to encourage the use of
Prompt-RAG, making it a promising tool for other domains in need of RAG
methods.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11247 title=Abstract>arXiv:2401.11247</a> [<a href=https://arxiv.org/pdf/2401.11247 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11247 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Applying stiff integrators for ODEs and DDEs to problems with distributed delays
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Guglielmi%2C+N">Nicola Guglielmi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hairer%2C+E">Ernst Hairer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>There exist excellent codes for an efficient numerical treatment of stiff and
differential-algebraic problems. Let us mention {\sc Radau5} which is based on
the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-302 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-303><span class=mn id=MathJax-Span-304 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-stage Radau IIA collocation method, and its extension to problems with
discrete delays {\sc Radar5}. The aim of the present work is to present a
technique that permits a direct application of these codes to problems having a
right-hand side with an additional distributed delay term (which is a special
case of an integro-differential equation). Models with distributed delays are
of increasing importance in pharmacodynamics and pharmacokinetics for the study
of the interaction between drugs and the body.
<br>The main idea is to approximate the distribution kernel of the integral term
by a sum of exponential functions or by a quasi-polynomial expansion, and then
to transform the distributed (integral) delay term into a set of ordinary
differential equations. This set is typically stiff and, for some distribution
kernels (e.g., Pareto distribution), it contains discrete delay terms with
constant delay. The original equations augmented by this set of ordinary
differential equations can have a very large dimension, and a careful treatment
of the solution of the arising linear systems is necessary.
<br>The use of the codes {\sc Radau5} and {\sc Radar5} is illustrated at three
examples (two test equations and one problem taken from pharmacodynamics). The
driver programs for these examples are publicly available from the homepages of
the authors.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11248 title=Abstract>arXiv:2401.11248</a> [<a href=https://arxiv.org/pdf/2401.11248 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11248 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+G">Guangyuan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xing Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zijia Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Working in progress. Our code will be available at <a href=https://github.com/ma787639046/bowdpr>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Masked auto-encoder pre-training has emerged as a prevalent technique for
initializing and enhancing dense retrieval systems. It generally utilizes
additional Transformer decoder blocks to provide sustainable supervision
signals and compress contextual information into dense representations.
However, the underlying reasons for the effectiveness of such a pre-training
technique remain unclear. The usage of additional Transformer-based decoders
also incurs significant computational costs. In this study, we aim to shed
light on this issue by revealing that masked auto-encoder (MAE) pre-training
with enhanced decoding significantly improves the term coverage of input tokens
in dense representations, compared to vanilla BERT checkpoints. Building upon
this observation, we propose a modification to the traditional MAE by replacing
the decoder of a masked auto-encoder with a completely simplified Bag-of-Word
prediction task. This modification enables the efficient compression of lexical
signals into dense representations through unsupervised pre-training.
Remarkably, our proposed method achieves state-of-the-art retrieval performance
on several large-scale retrieval benchmarks without requiring any additional
parameters, which provides a 67% training speed-up compared to standard masked
auto-encoder pre-training with enhanced decoding.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11249 title=Abstract>arXiv:2401.11249</a> [<a href=https://arxiv.org/pdf/2401.11249 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11249 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11249 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawalek%2C+P">Peter Kawalek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azadegan%2C+A">Aida Azadegan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Journal of Internet Commerce (2021)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Trust and privacy have emerged as significant concerns in online
transactions. Sharing information on health is especially sensitive but it is
necessary for purchasing and utilizing health insurance. Evidence shows that
consumers are increasingly comfortable with technology in place of humans, but
the expanding use of AI potentially changes this. This research explores
whether trust and privacy concern are barriers to the adoption of AI in health
insurance. Two scenarios are compared: The first scenario has limited AI that
is not in the interface and its presence is not explicitly revealed to the
consumer. In the second scenario there is an AI interface and AI evaluation,
and this is explicitly revealed to the consumer. The two scenarios were modeled
and compared using SEM PLS-MGA. The findings show that trust is significantly
lower in the second scenario where AI is visible. Privacy concerns are higher
with AI but the difference is not statistically significant within the model.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11250 title=Abstract>arXiv:2401.11250</a> [<a href=https://arxiv.org/pdf/2401.11250 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11250 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Turali%2C+M+Y">Mehmet Y. Turali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lorasdagi%2C+M+E">Mehmet E. Lorasdagi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koc%2C+A+T">Ali T. Koc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozat%2C+S+S">Suleyman S. Kozat</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)
</div>
<p class=mathjax>We study the problem of feature selection in general machine learning (ML)
context, which is one of the most critical subjects in the field. Although,
there exist many feature selection methods, however, these methods face
challenges such as scalability, managing high-dimensional data, dealing with
correlated features, adapting to variable feature importance, and integrating
domain knowledge. To this end, we introduce the ``Adaptive Feature Selection
with Binary Masking" (AFS-BM) which remedies these problems. AFS-BM achieves
this by joint optimization for simultaneous feature selection and model
training. In particular, we do the joint optimization and binary masking to
continuously adapt the set of features and model parameters during the training
process. This approach leads to significant improvements in model accuracy and
a reduction in computational requirements. We provide an extensive set of
experiments where we compare AFS-BM with the established feature selection
methods using well-known datasets from real-life competitions. Our results show
that AFS-BM makes significant improvement in terms of accuracy and requires
significantly less computational complexity. This is due to AFS-BM's ability to
dynamically adjust to the changing importance of features during the training
process, which an important contribution to the field. We openly share our code
for the replicability of our results and to facilitate further research.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11252 title=Abstract>arXiv:2401.11252</a> [<a href=https://arxiv.org/pdf/2401.11252 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11252 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+S">Suhan Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yuan Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Ting Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+F">Fenglong Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by SDM 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The widespread adoption of Electronic Health Record (EHR) systems in
healthcare institutes has generated vast amounts of medical data, offering
significant opportunities for improving healthcare services through deep
learning techniques. However, the complex and diverse modalities and feature
structures in real-world EHR data pose great challenges for deep learning model
design. To address the multi-modality challenge in EHR data, current approaches
primarily rely on hand-crafted model architectures based on intuition and
empirical experiences, leading to sub-optimal model architectures and limited
performance. Therefore, to automate the process of model design for mining EHR
data, we propose a novel neural architecture search (NAS) framework named
AutoFM, which can automatically search for the optimal model architectures for
encoding diverse input modalities and fusion strategies. We conduct thorough
experiments on real-world multi-modal EHR data and prediction tasks, and the
results demonstrate that our framework not only achieves significant
performance improvement over existing state-of-the-art methods but also
discovers meaningful network architectures effectively.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11254 title=Abstract>arXiv:2401.11254</a> [<a href=https://arxiv.org/pdf/2401.11254 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11254 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cima%2C+L">Lorenzo Cima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larios%2C+A+T">Amaury Trujillo Larios</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Avvenuti%2C+M">Marco Avvenuti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cresci%2C+S">Stefano Cresci</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>In the current landscape of online abuses and harms, effective content
moderation is necessary to cultivate safe and inclusive online spaces. Yet, the
effectiveness of many moderation interventions is still unclear. Here, we
assess the effectiveness of The Great Ban, a massive deplatforming operation
that affected nearly 2,000 communities on Reddit. By analyzing 16M comments
posted by 17K users during 14 months, we provide nuanced results on the
effects, both desired and otherwise, of the ban. Among our main findings is
that 15.6% of the affected users left Reddit and that those who remained
reduced their toxicity by 6.6% on average. The ban also caused 5% users to
increase their toxicity by more than 70% of their pre-ban level. However, these
resentful users likely had limited impact on Reddit due to low activity and
little support by peers. Overall, our multifaceted results provide new insights
into the efficacy of deplatforming. Our findings can inform the development of
future moderation interventions and the policing of online platforms.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11255 title=Abstract>arXiv:2401.11255</a> [<a href=https://arxiv.org/pdf/2401.11255 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11255 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visualization Generation with Large Language Models: An Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guozheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aodeng%2C+G">Gerile Aodeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Shunyuan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+C">Chuangxin Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C+H">Chi Harold Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Analysts frequently need to create visualizations in the data analysis
process to obtain and communicate insights. To reduce the burden of creating
visualizations, previous research has developed various approaches for analysts
to create visualizations from natural language queries. Recent studies have
demonstrated the capabilities of large language models in natural language
understanding and code generation tasks. The capabilities imply the potential
of using large language models to generate visualization specifications from
natural language queries. In this paper, we evaluate the capability of a large
language model to generate visualization specifications on the task of natural
language to visualization (NL2VIS). More specifically, we have opted for
GPT-3.5 and Vega-Lite to represent large language models and visualization
specifications, respectively. The evaluation is conducted on the nvBench
dataset. In the evaluation, we utilize both zero-shot and few-shot prompt
strategies. The results demonstrate that GPT-3.5 surpasses previous NL2VIS
approaches. Additionally, the performance of few-shot prompts is higher than
that of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS,
such as misunderstanding the data attributes and grammar errors in generated
specifications. We also summarized several directions, such as correcting the
ground truth and reducing the ambiguities in natural language queries, to
improve the NL2VIS benchmark.
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11257 title=Abstract>arXiv:2401.11257</a> [<a href=https://arxiv.org/pdf/2401.11257 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11257 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Measuring Policy Distance for Multi-Agent Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+T">Tianyi Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pu%2C+Z">Zhiqiang Pu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ai%2C+X">Xiaolin Ai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+T">Tenghai Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+J">Jianqiang Yi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Diversity plays a crucial role in improving the performance of multi-agent
reinforcement learning (MARL). Currently, many diversity-based methods have
been developed to overcome the drawbacks of excessive parameter sharing in
traditional MARL. However, there remains a lack of a general metric to quantify
policy differences among agents. Such a metric would not only facilitate the
evaluation of the diversity evolution in multi-agent systems, but also provide
guidance for the design of diversity-based MARL algorithms. In this paper, we
propose the multi-agent policy distance (MAPD), a general tool for measuring
policy differences in MARL. By learning the conditional representations of
agents' decisions, MAPD can computes the policy distance between any pair of
agents. Furthermore, we extend MAPD to a customizable version, which can
quantify differences among agent policies on specified aspects. Based on the
online deployment of MAPD, we design a multi-agent dynamic parameter sharing
(MADPS) algorithm as an example of the MAPD's applications. Extensive
experiments demonstrate that our method is effective in measuring differences
in agent policies and specific behavioral tendencies. Moreover, in comparison
to other methods of parameter sharing, MADPS exhibits superior performance.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11261 title=Abstract>arXiv:2401.11261</a> [<a href=https://arxiv.org/pdf/2401.11261 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11261 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion Model Conditioning on Gaussian Mixture Model and Negative Gaussian Mixture Gradient
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+W">Weiguo Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+D">Deng Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+J">Jinqiao Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+J">Jirong Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+G">Gangnan Yuan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Diffusion models (DMs) are a type of generative model that has a huge impact
on image synthesis and beyond. They achieve state-of-the-art generation results
in various generative tasks. A great diversity of conditioning inputs, such as
text or bounding boxes, are accessible to control the generation. In this work,
we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as
feature conditioning to guide the denoising process. Based on set theory, we
provide a comprehensive theoretical analysis that shows that conditional latent
distribution based on features and classes is significantly different, so that
conditional latent distribution on features produces fewer defect generations
than conditioning on classes. Two diffusion models conditioned on the Gaussian
mixture model are trained separately for comparison. Experiments support our
findings. A novel gradient function called the negative Gaussian mixture
gradient (NGMG) is proposed and applied in diffusion model training with an
additional classifier. Training stability has improved. We also theoretically
prove that NGMG shares the same benefit as the Earth Mover distance
(Wasserstein) as a more sensible cost function when learning distributions
supported by low-dimensional manifolds.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11266 title=Abstract>arXiv:2401.11266</a> [<a href=https://arxiv.org/pdf/2401.11266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lower bounds for set-blocked clauses proofs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yolcu%2C+E">Emre Yolcu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2211.12456>arXiv:2211.12456</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)
</div>
<p class=mathjax>We study propositional proof systems with inference rules that formalize
restricted versions of the ability to make assumptions that hold without loss
of generality, commonly used informally to shorten proofs. Each system we study
is built on resolution. They are called BC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-305 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-306><span class=msubsup id=MathJax-Span-307><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-308><span class=mrow id=MathJax-Span-309></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-310 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, RAT<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-311 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-312><span class=msubsup id=MathJax-Span-313><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-314><span class=mrow id=MathJax-Span-315></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-316 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, SBC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-317 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-318><span class=msubsup id=MathJax-Span-319><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-320><span class=mrow id=MathJax-Span-321></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-322 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, and
GER<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-323 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-324><span class=msubsup id=MathJax-Span-325><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-326><span class=mrow id=MathJax-Span-327></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-328 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, denoting respectively blocked clauses, resolution asymmetric
tautologies, set-blocked clauses, and generalized extended resolution - all
"without new variables." They may be viewed as weak versions of extended
resolution (ER) since they are defined by first generalizing the extension rule
and then taking away the ability to introduce new variables. Except for
SBC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-329 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-330><span class=msubsup id=MathJax-Span-331><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-332><span class=mrow id=MathJax-Span-333></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-334 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, they are known to be strictly between resolution and extended
resolution.
<br>Several separations between these systems were proved earlier by exploiting
the fact that they effectively simulate ER. We answer the questions left open:
We prove exponential lower bounds for SBC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-335 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-336><span class=msubsup id=MathJax-Span-337><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-338><span class=mrow id=MathJax-Span-339></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-340 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> proofs of a binary encoding of
the pigeonhole principle, which separates ER from SBC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><nobr><span class=math id=MathJax-Span-341 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-342><span class=msubsup id=MathJax-Span-343><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-344><span class=mrow id=MathJax-Span-345></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-346 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Using this new
separation, we prove that both RAT<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-347 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-348><span class=msubsup id=MathJax-Span-349><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-350><span class=mrow id=MathJax-Span-351></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-352 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and GER<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-353 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-354><span class=msubsup id=MathJax-Span-355><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-356><span class=mrow id=MathJax-Span-357></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-358 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> are exponentially
separated from SBC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-359 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.061em,1000.64em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-360><span class=msubsup id=MathJax-Span-361><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-362><span class=mrow id=MathJax-Span-363></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mo id=MathJax-Span-364 style=font-size:70.7%;font-family:MathJax_Main>−</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. This completes the picture of their relative
strengths.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11268 title=Abstract>arXiv:2401.11268</a> [<a href=https://arxiv.org/pdf/2401.11268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Javadi%2C+G">Golara Javadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuksel%2C+K+A">Kamer Ali Yuksel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yunsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+T+C">Thiago Castro Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Al-Badrashiny%2C+M">Mohamed Al-Badrashiny</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>In the realm of automatic speech recognition (ASR), the quest for models that
not only perform with high accuracy but also offer transparency in their
decision-making processes is crucial. The potential of quality estimation (QE)
metrics is introduced and evaluated as a novel tool to enhance explainable
artificial intelligence (XAI) in ASR systems. Through experiments and analyses,
the capabilities of the NoRefER (No Reference Error Rate) metric are explored
in identifying word-level errors to aid post-editors in refining ASR
hypotheses. The investigation also extends to the utility of NoRefER in the
corpus-building process, demonstrating its effectiveness in augmenting datasets
with insightful annotations. The diagnostic aspects of NoRefER are examined,
revealing its ability to provide valuable insights into model behaviors and
decision patterns. This has proven beneficial for prioritizing hypotheses in
post-editing workflows and fine-tuning ASR models. The findings suggest that
NoRefER is not merely a tool for error detection but also a comprehensive
framework for enhancing ASR systems' transparency, efficiency, and
effectiveness. To ensure the reproducibility of the results, all source codes
of this study are made publicly available.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11271 title=Abstract>arXiv:2401.11271</a> [<a href=https://arxiv.org/pdf/2401.11271 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11271 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lixu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shichao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xinyu Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Anomaly detection in time-series data is crucial for identifying faults,
failures, threats, and outliers across a range of applications. Recently, deep
learning techniques have been applied to this topic, but they often struggle in
real-world scenarios that are complex and highly dynamic, e.g., the normal data
may consist of multiple distributions, and various types of anomalies may
differ from the normal data to different degrees. In this work, to tackle these
challenges, we propose Distribution-Augmented Contrastive Reconstruction
(DACR). DACR generates extra data disjoint from the normal data distribution to
compress the normal data's representation space, and enhances the feature
extractor through contrastive learning to better capture the intrinsic
semantics from time-series data. Furthermore, DACR employs an attention
mechanism to model the semantic dependencies among multivariate time-series
features, thereby achieving more robust reconstruction for anomaly detection.
Extensive experiments conducted on nine benchmark datasets in various anomaly
detection scenarios demonstrate the effectiveness of DACR in achieving new
state-of-the-art time-series anomaly detection.
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11274 title=Abstract>arXiv:2401.11274</a> [<a href=https://arxiv.org/pdf/2401.11274 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11274 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11274 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unambiguous parity-query complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavinsky%2C+D">Dmytro Gavinsky</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>We give a lower bound of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-365 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.84em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-366><span class=mi id=MathJax-Span-367 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-368 style=font-family:MathJax_Main>(</span><span class=msqrt id=MathJax-Span-369><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-370><span class=mi id=MathJax-Span-371 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.64em,3.938em,-999.997em);top:-4.395em;left:0.813em><span style=display:inline-block;position:relative;width:0.639em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-3.932em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-372 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span> on the unambiguous randomised
parity-query complexity of the approximate majority problem -- that is, on the
lowest randomised parity-query complexity of any function over <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-373 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.95em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-374><span class=mo id=MathJax-Span-375 style=font-family:MathJax_Main>{</span><span class=mn id=MathJax-Span-376 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-377 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-378 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=msubsup id=MathJax-Span-379><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.41em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-380 style=font-family:MathJax_Main>}</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.524em><span class=mi id=MathJax-Span-381 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
whose value is "0" if the Hamming weight of the input is at most n/3, is "1" if
the weight is at least 2n/3, and may be arbitrary otherwise.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11281 title=Abstract>arXiv:2401.11281</a> [<a href=https://arxiv.org/pdf/2401.11281 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11281 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sources of Underproduction in Open Source Software
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Champion%2C+K">Kaylea Champion</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hill%2C+B+M">Benjamin Mako Hill</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Because open source software relies on individuals who select their own
tasks, it is often underproduced -- a term used by software engineering
researchers to describe when a piece of software's relative quality is lower
than its relative importance. We examine the social and technical factors
associated with underproduction through a comparison of software packaged by
the Debian GNU/Linux community. We test a series of hypotheses developed from a
reading of prior research in software engineering. Although we find that
software age and programming language age offer a partial explanation for
variation in underproduction, we were surprised to find that the association
between underproduction and package age is weaker at high levels of programming
language age. With respect to maintenance efforts, we find that additional
resources are not always tied to better outcomes. In particular, having higher
numbers of contributors is associated with higher underproduction risk. Also,
contrary to our expectations, maintainer turnover and maintenance by a declared
team are not associated with lower rates of underproduction. Finally, we find
that the people working on bugs in underproduced packages tend to be those who
are more central to the community's collaboration network structure, although
contributors' betweenness centrality (often associated with brokerage in social
networks) is not associated with underproduction.
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11282 title=Abstract>arXiv:2401.11282</a> [<a href=https://arxiv.org/pdf/2401.11282 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11282 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Juris Hartmanis taught me about Reductions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Immerman%2C+N">Neil Immerman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>I was a student of Juris Hartmanis at Cornell in the late 1970's. He believed
that there was great potential in studying restricted reductions. I describe
here some of his influences on me and, in particular, how his insights
concerning reductions helped me to prove that nondeterministic space is closed
under complementation.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11284 title=Abstract>arXiv:2401.11284</a> [<a href=https://arxiv.org/pdf/2401.11284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazemi%2C+M">Mostafa Kazemi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rezaei%2C+M">Mahdi Rezaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azarmi%2C+M">Mohsen Azarmi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>As automated driving technology advances, the role of the driver to resume
control of the vehicle in conditionally automated vehicles becomes increasingly
critical. In the SAE Level 3 or partly automated vehicles, the driver needs to
be available and ready to intervene when necessary. This makes it essential to
evaluate their readiness accurately. This article presents a comprehensive
analysis of driver readiness assessment by combining head pose features and
eye-tracking data. The study explores the effectiveness of predictive models in
evaluating driver readiness, addressing the challenges of dataset limitations
and limited ground truth labels. Machine learning techniques, including LSTM
architectures, are utilised to model driver readiness based on the
Spatio-temporal status of the driver's head pose and eye gaze. The experiments
in this article revealed that a Bidirectional LSTM architecture, combining both
feature sets, achieves a mean absolute error of 0.363 on the DMD dataset,
demonstrating superior performance in assessing driver readiness. The modular
architecture of the proposed model also allows the integration of additional
driver-specific features, such as steering wheel activity, enhancing its
adaptability and real-world applicability.
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11286 title=Abstract>arXiv:2401.11286</a> [<a href=https://arxiv.org/pdf/2401.11286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data repairing and resolution enhancement using data-driven modal decomposition and deep learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hetherington%2C+A">A. Hetherington</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serfaty%2C+D">D. Serfaty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corrochano%2C+A">A. Corrochano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soria%2C+J">J. Soria</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clainche%2C+S+L">S. Le Clainche</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Fluid Dynamics (physics.flu-dyn)
</div>
<p class=mathjax>This paper introduces a new series of methods which combine modal
decomposition algorithms, such as singular value decomposition and high-order
singular value decomposition, and deep learning architectures to repair,
enhance, and increase the quality and precision of numerical and experimental
data. A combination of two- and three-dimensional, numerical and experimental
dasasets are used to demonstrate the reconstruction capacity of the presented
methods, showing that these methods can be used to reconstruct any type of
dataset, showing outstanding results when applied to highly complex data, which
is noisy. The combination of benefits of these techniques results in a series
of data-driven methods which are capable of repairing and/or enhancing the
resolution of a dataset by identifying the underlying physics that define the
data, which is incomplete or under-resolved, filtering any existing noise.
These methods and the Python codes are included in the first release of
ModelFLOWs-app.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11287 title=Abstract>arXiv:2401.11287</a> [<a href=https://arxiv.org/pdf/2401.11287 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11287 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On-The-Fly Algorithm for Reachability in Parametric Timed Games (Extended Version)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dahlsen-Jensen%2C+M+B">Mikael Bisgaard Dahlsen-Jensen</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fievet%2C+B">Baptiste Fievet</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petrucci%2C+L">Laure Petrucci</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+de+Pol%2C+J">Jaco van de Pol</a> (1) ((1) Aarhus University, Aarhus, Denmark, (2) Université Sorbonne Paris Nord CNRS, Villetaneuse, France)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
<p class=mathjax>Parametric Timed Games (PTG) are an extension of the model of Timed Automata.
They allow for the verification and synthesis of real-time systems, reactive to
their environmeand depending on adjustable parameters. Given a PTG and a
reachability objective, we synthesize the values of the parameters such that
the game is winning for the controller. We adapt and implement the On-The-Fly
algorithm for parameter synthesis for PTG. Several pruning heuristics are
introduced, to improve termination and speed of the algorithm. We evaluate the
feasibility of parameter synthesis for PTG on two large case studies. Finally,
we investigate the correctness guarantee of the algorithm: though the problem
is undecidable, our semi-algorithm produces all correct parameter valuations
``in the limit''.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11288 title=Abstract>arXiv:2401.11288</a> [<a href=https://arxiv.org/pdf/2401.11288 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11288 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Long-Term Fair Decision Making through Deep Generative Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yaowei Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yongkai Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lu Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>This paper studies long-term fair machine learning which aims to mitigate
group disparity over the long term in sequential decision-making systems. To
define long-term fairness, we leverage the temporal causal graph and use the
1-Wasserstein distance between the interventional distributions of different
demographic groups at a sufficiently large time step as the quantitative
metric. Then, we propose a three-phase learning framework where the decision
model is trained on high-fidelity data generated by a deep generative model. We
formulate the optimization problem as a performative risk minimization and
adopt the repeated gradient descent algorithm for learning. The empirical
evaluation shows the efficacy of the proposed method using both synthetic and
semi-synthetic datasets.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11290 title=Abstract>arXiv:2401.11290</a> [<a href=https://arxiv.org/pdf/2401.11290 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11290 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Dependent Variables in Reactive Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akshay%2C+S">S. Akshay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basa%2C+E">Eliyahu Basa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakraborty%2C+S">Supratik Chakraborty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fried%2C+D">Dror Fried</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Full version of conference paper published in TACAS'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)
</div>
<p class=mathjax>Given a Linear Temporal Logic (LTL) formula over input and output variables,
reactive synthesis requires us to design a deterministic Mealy machine that
gives the values of outputs at every time step for every sequence of inputs,
such that the LTL formula is satisfied. In this paper, we investigate the
notion of dependent variables in the context of reactive synthesis. Inspired by
successful pre-processing steps in Boolean functional synthesis, we define
dependent variables as output variables that are uniquely assigned, given an
assignment, to all other variables and the history so far. We describe an
automata-based approach for finding a set of dependent variables. Using this,
we show that dependent variables are surprisingly common in reactive synthesis
benchmarks. Next, we develop a novel synthesis framework that exploits
dependent variables to construct an overall synthesis solution. By implementing
this framework using the widely used library Spot, we show that reactive
synthesis using dependent variables can solve some problems beyond the reach of
several existing techniques. Further, among benchmarks with dependent
variables, if the number of non-dependent variables is low (at most 3 in our
experiments), our method is able outperform all state-of-the-art tools for
synthesis.
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11295 title=Abstract>arXiv:2401.11295</a> [<a href=https://arxiv.org/pdf/2401.11295 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11295 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An exact solution to the Fourier Transform of band-limited periodic functions with nonequispaced data and application to non-periodic functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Perrin%2C+G">Guy Perrin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 3 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Computational Physics 474, 111806 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>The need to Fourier transform data sets with irregular sampling is shared by
various domains of science. This is the case for example in astronomy or
sismology. Iterative methods have been developed that allow to reach
approximate solutions. Here an exact solution to the problem for band-limited
periodic signals is presented. The exact spectrum can be deduced from the
spectrum of the non-equispaced data through the inversion of a Toeplitz matrix.
The result applies to data of any dimension. This method also provides an
excellent approximation for non-periodic band-limit signals. The method allows
to reach very high dynamic ranges (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-382 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.8em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-383><span class=msubsup id=MathJax-Span-384><span style=display:inline-block;position:relative;width:1.797em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.99em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-385 style=font-family:MathJax_Main>10</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.987em><span class=texatom id=MathJax-Span-386><span class=mrow id=MathJax-Span-387><span class=mn id=MathJax-Span-388 style=font-size:70.7%;font-family:MathJax_Main>13</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> with double-float precision) which
depend on the regularity of the samples.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11305 title=Abstract>arXiv:2401.11305</a> [<a href=https://arxiv.org/pdf/2401.11305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Progress in Privacy Protection: A Review of Privacy Preserving Techniques in Recommender Systems, Edge Computing, and Cloud Computing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bashir%2C+S+R">Syed Raza Bashir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raza%2C+S">Shaina Raza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Misic%2C+V">Vojislav Misic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>As digital technology evolves, the increasing use of connected devices brings
both challenges and opportunities in the areas of mobile crowdsourcing, edge
computing, and recommender systems. This survey focuses on these dynamic
fields, emphasizing the critical need for privacy protection in our
increasingly data-oriented world. It explores the latest trends in these
interconnected areas, with a special emphasis on privacy and data security. Our
method involves an in-depth analysis of various academic works, which helps us
to gain a comprehensive understanding of these sectors and their shifting focus
towards privacy concerns. We present new insights and marks a significant
advancement in addressing privacy issues within these technologies. The survey
is a valuable resource for researchers, industry practitioners, and policy
makers, offering an extensive overview of these fields and their related
privacy challenges, catering to a wide audience in the modern digital era.
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11311 title=Abstract>arXiv:2401.11311</a> [<a href=https://arxiv.org/pdf/2401.11311 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11311 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bensaid%2C+R">Reda Bensaid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gripon%2C+V">Vincent Gripon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leduc-Primeau%2C+F">François Leduc-Primeau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mauch%2C+L">Lukas Mauch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hacene%2C+G+B">Ghouthi Boukli Hacene</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardinaux%2C+F">Fabien Cardinaux</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In recent years, the rapid evolution of computer vision has seen the
emergence of various vision foundation models, each tailored to specific data
types and tasks. While large language models often share a common pretext task,
the diversity in vision foundation models arises from their varying training
objectives. In this study, we delve into the quest for identifying the most
effective vision foundation models for few-shot semantic segmentation, a
critical task in computer vision. Specifically, we conduct a comprehensive
comparative analysis of four prominent foundation models: DINO V2, Segment
Anything, CLIP, Masked AutoEncoders, and a straightforward ResNet50 pre-trained
on the COCO dataset. Our investigation focuses on their adaptability to new
semantic segmentation tasks, leveraging only a limited number of segmented
images. Our experimental findings reveal that DINO V2 consistently outperforms
the other considered foundation models across a diverse range of datasets and
adaptation methods. This outcome underscores DINO V2's superior capability to
adapt to semantic segmentation tasks compared to its counterparts. Furthermore,
our observations indicate that various adapter methods exhibit similar
performance, emphasizing the paramount importance of selecting a robust feature
extractor over the intricacies of the adaptation technique itself. This insight
sheds light on the critical role of feature extraction in the context of
few-shot semantic segmentation. This research not only contributes valuable
insights into the comparative performance of vision foundation models in the
realm of few-shot semantic segmentation but also highlights the significance of
a robust feature extractor in this domain.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11313 title=Abstract>arXiv:2401.11313</a> [<a href=https://arxiv.org/pdf/2401.11313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weakly-Supervised Semantic Segmentation of Circular-Scan, Synthetic-Aperture-Sonar Imagery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sledge%2C+I+J">Isaac J. Sledge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Byrne%2C+D+M">Dominic M. Byrne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=King%2C+J+L">Jonathan L. King</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ostertag%2C+S+H">Steven H. Ostertag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woods%2C+D+L">Denton L. Woods</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prater%2C+J+L">James L. Prater</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kennedy%2C+J+L">Jermaine L. Kennedy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marston%2C+T+M">Timothy M. Marston</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Principe%2C+J+C">Jose C. Principe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the IEEE Journal of Oceanic Engineering
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>We propose a weakly-supervised framework for the semantic segmentation of
circular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our
framework is trained in a supervised manner, on image-level labels, to uncover
a set of semi-sparse, spatially-discriminative regions in each image. The
classification uncertainty of each region is then evaluated. Those areas with
the lowest uncertainties are then chosen to be weakly labeled segmentation
seeds, at the pixel level, for the second part of the framework. Each of the
seed extents are progressively resized according to an unsupervised,
information-theoretic loss with structured-prediction regularizers. This
reshaping process uses multi-scale, adaptively-weighted features to delineate
class-specific transitions in local image content. Content-addressable memories
are inserted at various parts of our framework so that it can leverage features
from previously seen images to improve segmentation performance for related
images.
<br>We evaluate our weakly-supervised framework using real-world CSAS imagery
that contains over ten seafloor classes and ten target classes. We show that
our framework performs comparably to nine fully-supervised deep networks. Our
framework also outperforms eleven of the best weakly-supervised deep networks.
We achieve state-of-the-art performance when pre-training on natural imagery.
The average absolute performance gap to the next-best weakly-supervised network
is well over ten percent for both natural imagery and sonar imagery. This gap
is found to be statistically significant.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11314 title=Abstract>arXiv:2401.11314</a> [<a href=https://arxiv.org/pdf/2401.11314 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11314 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazemitabaar%2C+M">Majeed Kazemitabaar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+R">Runlong Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henley%2C+A+Z">Austin Z. Henley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denny%2C+P">Paul Denny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Craig%2C+M">Michelle Craig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossman%2C+T">Tovi Grossman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in the Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, in Honolulu, USA. The paper includes 17 pages, 8 figures, 2 tables, along with a 2-page appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Timely, personalized feedback is essential for students learning programming,
especially as class sizes expand. LLM-based tools like ChatGPT offer instant
support, but reveal direct answers with code, which may hinder deep conceptual
engagement. We developed CodeAid, an LLM-based programming assistant delivering
helpful, technically correct responses, without revealing code solutions. For
example, CodeAid can answer conceptual questions, generate pseudo-code with
line-by-line explanations, and annotate student's incorrect code with fix
suggestions. We deployed CodeAid in a programming class of 700 students for a
12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed,
further enriched by weekly surveys, and 22 student interviews. We then
interviewed eight programming educators to gain further insights on CodeAid.
Findings revealed students primarily used CodeAid for conceptual understanding
and debugging, although a minority tried to obtain direct code. Educators
appreciated CodeAid's educational approach, and expressed concerns about
occasional incorrect feedback and students defaulting to ChatGPT.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11316 title=Abstract>arXiv:2401.11316</a> [<a href=https://arxiv.org/pdf/2401.11316 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11316 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benedek%2C+N">Nadav Benedek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>With the proliferation of large pre-trained language models (PLMs),
fine-tuning all model parameters becomes increasingly inefficient, particularly
when dealing with numerous downstream tasks that entail substantial training
and storage costs. Several approaches aimed at achieving parameter-efficient
fine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA)
stands out as an archetypal method, incorporating trainable rank decomposition
matrices into each target module. Nevertheless, LoRA does not consider the
varying importance of each layer. To address these challenges, we introduce
PRILoRA, which linearly allocates a different rank for each layer, in an
increasing manner, and performs pruning throughout the training process,
considering both the temporary magnitude of weights and the accumulated
statistics of the input to any given layer. We validate the effectiveness of
PRILoRA through extensive experiments on eight GLUE benchmarks, setting a new
state of the art.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11317 title=Abstract>arXiv:2401.11317</a> [<a href=https://arxiv.org/pdf/2401.11317 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11317 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+J">Jie Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Ya-Fang Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">He Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ACM CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Community management is critical for community stakeholders to
collaboratively build and maintain the community with socio-technical support.
Existing work mainly focuses on the community members and the platform; little
work explores the developers who mediate the relationship between the platform
and community members and build the tools to support their community
management. In this study, we focus on third-party developers (TPDs) for the
live streaming platform Twitch and explore their tool development practices. In
a mixed method with in-depth qualitative analysis, we found that TPDs maintain
complex relationships with different stakeholders (streamers, viewers,
platform, professional developers), and the multi-layered policy restricts
their agency regarding idea innovation and tool development. We argue that HCI
research should redirect the attention from tool users to tool developers
regarding community management and propose close collaboration with the
platform and professional developers and streamlining the development process
with unified took kits and policy documentation.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11323 title=Abstract>arXiv:2401.11323</a> [<a href=https://arxiv.org/pdf/2401.11323 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11323 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analyzing Task-Encoding Tokens in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yu Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Heyan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piano%2C+C+S">Cesare Spinoso-Di Piano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rondeau%2C+M">Marc-Antoine Rondeau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Sanxing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+J+C+K">Jackie Chi Kit Cheung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In-context learning (ICL) has become an effective solution for few-shot
learning in natural language processing. Past work has found that, during this
process, representations of the last prompt token are utilized to store task
reasoning procedures, thereby explaining the working mechanism of in-context
learning. In this paper, we seek to locate and analyze other task-encoding
tokens whose representations store task reasoning procedures. Supported by
experiments that ablate the representations of different token types, we find
that template and stopword tokens are the most prone to be task-encoding
tokens. In addition, we demonstrate experimentally that lexical cues,
repetition, and text formats are the main distinguishing characteristics of
these tokens. Our work provides additional insights into how large language
models (LLMs) leverage task reasoning procedures in ICL and suggests that
future work may involve using task-encoding tokens to improve the computational
efficiency of LLMs at inference time and their ability to handle long
sequences.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11324 title=Abstract>arXiv:2401.11324</a> [<a href=https://arxiv.org/pdf/2401.11324 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11324 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=V.%2C+K">Karthik V.</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+S">Saim Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+S">Somesh Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simhadri%2C+H+V">Harsha Vardhan Simhadri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vedurada%2C+J">Jyothi Vedurada</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms
routinely employed in information retrieval, pattern recognition, data mining,
image processing, and beyond. Recent works have established that graph-based
ANNS algorithms are practically more efficient than the other methods proposed
in the literature, on large datasets. The growing volume and dimensionality of
data necessitates designing scalable techniques for ANNS. To this end, the
prior art has explored parallelizing graph-based ANNS on GPU leveraging its
high computational power and energy efficiency. The current state-of-the-art
GPU-based ANNS algorithms either (i) require both the index-graph and the data
to reside entirely in the GPU memory, or (ii) they partition the data into
small independent shards, each of which can fit in GPU memory, and perform the
search on these shards on the GPU. While the first approach fails to handle
large datasets due to the limited memory available on the GPU, the latter
delivers poor performance on large datasets due to high data traffic over the
low-bandwidth PCIe bus. In this paper, we introduce BANG, a first-of-its-kind
GPU-based ANNS method which works efficiently on billion-scale datasets that
cannot entirely fit in the GPU memory. BANG stands out by harnessing compressed
data on the GPU to perform distance computations while maintaining the graph on
the CPU. BANG incorporates high-optimized GPU kernels and proceeds in stages
that run concurrently on the GPU and CPU, taking advantage of their
architectural specificities. We evaluate BANG using a single NVIDIA Ampere A100
GPU on ten popular ANN benchmark datasets. BANG outperforms the
state-of-the-art in the majority of the cases. Notably, on the billion-size
datasets, we are significantly faster than our competitors, achieving
throughputs 40x-200x more than the competing methods for a high recall of 0.9.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11325 title=Abstract>arXiv:2401.11325</a> [<a href=https://arxiv.org/pdf/2401.11325 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11325 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hyde%2C+G">Gregory Hyde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santos%2C+E">Eugene Santos Jr</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Many Reinforcement Learning algorithms assume a Markov reward function to
guarantee optimality. However, not all reward functions are known to be Markov.
In this paper, we propose a framework for mapping non-Markov reward functions
into equivalent Markov ones by learning a Reward Machine - a specialized reward
automaton. Unlike the general practice of learning Reward Machines, we do not
require a set of high-level propositional symbols from which to learn. Rather,
we learn \emph{hidden triggers} directly from data that encode them. We
demonstrate the importance of learning Reward Machines versus their
Deterministic Finite-State Automata counterparts, for this task, given their
ability to model reward dependencies in a single automaton. We formalize this
distinction in our learning objective. Our mapping process is constructed as an
Integer Linear Programming problem. We prove that our mappings provide
consistent expectations for the underlying process. We empirically validate our
approach by learning black-box non-Markov Reward functions in the Officeworld
Domain. Additionally, we demonstrate the effectiveness of learning dependencies
between rewards in a new domain, Breakfastworld.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11326 title=Abstract>arXiv:2401.11326</a> [<a href=https://arxiv.org/pdf/2401.11326 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11326 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11326 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating Cybersecurity Training: A Comprehensive Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qawasmeh%2C+S+A">Saif Al-Dean Qawasmeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlQahtani%2C+A+A+S">Ali Abdullah S. AlQahtani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+M+K">Muhammad Khurram Khan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>In the dynamic realm of cybersecurity, awareness training is crucial for
strengthening defenses against cyber threats. This survey examines a spectrum
of cybersecurity awareness training methods, analyzing traditional,
technology-based, and innovative strategies. It evaluates the principles,
efficacy, and constraints of each method, presenting a comparative analysis
that highlights their pros and cons. The study also investigates emerging
trends like artificial intelligence and extended reality, discussing their
prospective influence on the future of cybersecurity training. Additionally, it
addresses implementation challenges and proposes solutions, drawing on insights
from real-world case studies. The goal is to bolster the understanding of
cybersecurity awareness training's current landscape, offering valuable
perspectives for both practitioners and scholars.
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11328 title=Abstract>arXiv:2401.11328</a> [<a href=https://arxiv.org/pdf/2401.11328 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11328 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Hierarchical Decision-Based Maintenance for a Complex Modular System Driven by the { MoMA} Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gamiz%2C+M+L">M.L. Gamiz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Montoro-Cazorla%2C+D">D. Montoro-Cazorla</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Segovia-Garcia%2C+M+C">M.C. Segovia-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 43 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Methodology (stat.ME)
</div>
<p class=mathjax>This paper presents a maintenance policy for a modular system formed by K
independent modules (n-subsystems) subjected to environmental conditions
(shocks). For the modeling of this complex system, the use of the
Matrix-Analytical Method (MAM) is proposed under a layered approach according
to its hierarchical structure. Thus, the operational state of the system (top
layer) depends on the states of the modules (middle layer), which in turn
depend on the states of their components (bottom layer). This allows a detailed
description of the system operation to plan maintenance actions appropriately
and optimally. We propose a hierarchical decision-based maintenance strategy
with periodic inspections as follows: at the time of the inspection, the
condition of the system is first evaluated. If intervention is necessary, the
modules are then checked to make individual decisions based on their states,
and so on. Replacement or repair will be carried out as appropriate. An
optimization problem is formulated as a function of the length of the
inspection period and the intervention cost incurred over the useful life of
the system. Our method shows the advantages, providing compact and
implementable expressions. The model is illustrated on a submarine Electrical
Control Unit (ECU).
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11330 title=Abstract>arXiv:2401.11330</a> [<a href=https://arxiv.org/pdf/2401.11330 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11330 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Source Detection in Networks using the Stationary Distribution of a Markov Chain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabato%2C+Y">Yael Sabato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azaria%2C+A">Amos Azaria</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hazon%2C+N">Noam Hazon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Nowadays, the diffusion of information through social networks is a powerful
phenomenon. One common way to model diffusions in social networks is the
Independent Cascade (IC) model. Given a set of infected nodes according to the
IC model, a natural problem is the source detection problem, in which the goal
is to identify the unique node that has started the diffusion. Maximum
Likelihood Estimation (MLE) is a common approach for tackling the source
detection problem, but it is computationally hard.
<br>In this work, we propose an efficient method for the source detection problem
under the MLE approach, which is based on computing the stationary distribution
of a Markov chain. Using simulations, we demonstrate the effectiveness of our
method compared to other state-of-the-art methods from the literature, both on
random and real-world networks.
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11335 title=Abstract>arXiv:2401.11335</a> [<a href=https://arxiv.org/pdf/2401.11335 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11335 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11335 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deception and Manipulation in Generative AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tarsney%2C+C">Christian Tarsney</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Large language models now possess human-level linguistic abilities in many
contexts. This raises the concern that they can be used to deceive and
manipulate on unprecedented scales, for instance spreading political
misinformation on social media. In future, agentic AI systems might also
deceive and manipulate humans for their own ends. In this paper, first, I argue
that AI-generated content should be subject to stricter standards against
deception and manipulation than we ordinarily apply to humans. Second, I offer
new characterizations of AI deception and manipulation meant to support such
standards, according to which a statement is deceptive (manipulative) if it
leads human addressees away from the beliefs (choices) they would endorse under
``semi-ideal'' conditions. Third, I propose two measures to guard against AI
deception and manipulation, inspired by this characterization: "extreme
transparency" requirements for AI-generated content and defensive systems that,
among other things, annotate AI-generated statements with contextualizing
information. Finally, I consider to what extent these measures can protect
against deceptive behavior in future, agentic AIs, and argue that non-agentic
defensive systems can provide an important layer of defense even against more
powerful agentic systems.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11337 title=Abstract>arXiv:2401.11337</a> [<a href=https://arxiv.org/pdf/2401.11337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompting Large Vision-Language Models for Compositional Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ossowski%2C+T">Timothy Ossowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+M">Ming Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Junjie Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Vision-language models such as CLIP have shown impressive capabilities in
encoding texts and images into aligned embeddings, enabling the retrieval of
multimodal data in a shared embedding space. However, these embedding-based
models still face challenges in effectively matching images and texts with
similar visio-linguistic compositionality, as evidenced by their performance on
the recent Winoground dataset. In this paper, we argue that this limitation
stems from two factors: the use of single vector representations for complex
multimodal data, and the absence of step-by-step reasoning in these
embedding-based methods. To address this issue, we make an exploratory step
using a novel generative method that prompts large vision-language models
(e.g., GPT-4) to depict images and perform compositional reasoning. Our method
outperforms other embedding-based methods on the Winoground dataset, and
obtains further improvement of up to 10% accuracy when enhanced with the
optimal description.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11347 title=Abstract>arXiv:2401.11347</a> [<a href=https://arxiv.org/pdf/2401.11347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Are Your Epochs Too Epic? Batch Free Can Be Harmful
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Daewoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+T">Trevor Brown</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+A">Ajay Singh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Full version of the paper accepted in PPoPP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Epoch based memory reclamation (EBR) is one of the most popular techniques
for reclaiming memory in lock-free and optimistic locking data structures, due
to its ease of use and good performance in practice. However, EBR is known to
be sensitive to thread delays, which can result in performance degradation.
Moreover, the exact mechanism for this performance degradation is not well
understood. This paper illustrates this performance degradation in a popular
data structure benchmark, and does a deep dive to uncover its root cause-a
subtle interaction between EBR and state of the art memory allocators. In
essence, modern allocators attempt to reduce the overhead of freeing by
maintaining bounded thread caches of objects for local reuse, actually freeing
them (a very high latency operation) only when thread caches become too large.
EBR immediately bypasses these mechanisms whenever a particularly large batch
of objects is freed, substantially increasing overheads and latencies. Beyond
EBR, many memory reclamation algorithms, and data structures, that reclaim
objects in large batches suffer similar deleterious interactions with popular
allocators. We propose a simple algorithmic fix for such algorithms to amortize
the freeing of large object batches over time, and apply this technique to ten
existing memory reclamation algorithms, observing performance improvements for
nine out of ten, and over 50% improvement for six out of ten in experiments on
a high performance lock-free ABtree. We also present an extremely simple token
passing variant of EBR and show that, with our fix, it performs 1.5-2.6x faster
than the fastest known memory reclamation algorithm, and 1.2-1.5x faster than
not reclaiming at all, on a 192 thread four socket Intel system.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11353 title=Abstract>arXiv:2401.11353</a> [<a href=https://arxiv.org/pdf/2401.11353 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11353 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributionally Robust Policy Evaluation under General Covariate Shift in Contextual Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yihong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+Y">Yisong Yue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+A">Anqi Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We introduce a distributionally robust approach that enhances the reliability
of offline policy evaluation in contextual bandits under general covariate
shifts. Our method aims to deliver robust policy evaluation results in the
presence of discrepancies in both context and policy distribution between
logging and target data. Central to our methodology is the application of
robust regression, a distributionally robust technique tailored here to improve
the estimation of conditional reward distribution from logging data. Utilizing
the reward model obtained from robust regression, we develop a comprehensive
suite of policy value estimators, by integrating our reward model into
established evaluation frameworks, namely direct methods and doubly robust
methods. Through theoretical analysis, we further establish that the proposed
policy value estimators offer a finite sample upper bound for the bias,
providing a clear advantage over traditional methods, especially when the shift
is large. Finally, we designed an extensive range of policy evaluation
scenarios, covering diverse magnitudes of shifts and a spectrum of logging and
target policies. Our empirical results indicate that our approach significantly
outperforms baseline methods, most notably in 90% of the cases under the policy
shift-only settings and 72% of the scenarios under the general covariate shift
settings.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11356 title=Abstract>arXiv:2401.11356</a> [<a href=https://arxiv.org/pdf/2401.11356 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11356 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zixun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Lexical Substitution discovers appropriate substitutes for a given target
word in a context sentence. However, the task fails to consider substitutes
that are of equal or higher proficiency than the target, an aspect that could
be beneficial for language learners looking to improve their writing. To bridge
this gap, we propose a new task, language proficiency-oriented lexical
substitution. We also introduce ProLex, a novel benchmark designed to assess
systems' ability to generate not only appropriate substitutes but also
substitutes that demonstrate better language proficiency. Besides the
benchmark, we propose models that can automatically perform the new task. We
show that our best model, a Llama2-13B model fine-tuned with task-specific
synthetic data, outperforms ChatGPT by an average of 3.2% in F-score and
achieves comparable results with GPT-4 on ProLex.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11358 title=Abstract>arXiv:2401.11358</a> [<a href=https://arxiv.org/pdf/2401.11358 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11358 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for Autonomous Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamal%2C+M">Mahedi Kamal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fariha%2C+T">Tasnim Fariha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zinia%2C+A+K">Afrina Kabir Zinia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Syed%2C+M+A">Md. Abu Syed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+F+H">Fahim Hasan Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+M+M">Md. Mahbubur Rahman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent breakthroughs in artificial intelligence offer tremendous promise for
the development of self-driving applications. Deep Neural Networks, in
particular, are being utilized to support the operation of semi-autonomous cars
through object identification and semantic segmentation. To assess the
inadequacy of the current dataset in the context of autonomous and
semi-autonomous cars, we created a new dataset named ANNA. This study discusses
a custom-built dataset that includes some unidentified vehicles in the
perspective of Bangladesh, which are not included in the existing dataset. A
dataset validity check was performed by evaluating models using the
Intersection Over Union (IOU) metric. The results demonstrated that the model
trained on our custom dataset was more precise and efficient than the models
trained on the KITTI or COCO dataset concerning Bangladeshi traffic. The
research presented in this paper also emphasizes the importance of developing
accurate and efficient object detection algorithms for the advancement of
autonomous vehicles.
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11360 title=Abstract>arXiv:2401.11360</a> [<a href=https://arxiv.org/pdf/2401.11360 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11360 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11360 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruochi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Haoran Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Huaping Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuqian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kewei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yifan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yifan Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiahui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+F">Fengfeng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xin Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 5 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM)
</div>
<p class=mathjax>Recent advances in protein language models have catalyzed significant
progress in peptide sequence representation. Despite extensive exploration in
this field, pre-trained models tailored for peptide-specific needs remain
largely unaddressed due to the difficulty in capturing the complex and
sometimes unstable structures of peptides. This study introduces a novel
multi-view contrastive learning framework PepHarmony for the sequence-based
peptide encoding task. PepHarmony innovatively combines both sequence- and
structure-level information into a sequence-level encoding module through
contrastive learning. We carefully select datasets from the Protein Data Bank
(PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences
and structures. The experimental data highlights PepHarmony's exceptional
capability in capturing the intricate relationship between peptide sequences
and structures compared with the baseline and fine-tuned models. The robustness
of our model is confirmed through extensive ablation studies, which emphasize
the crucial roles of contrastive loss and strategic data sorting in enhancing
predictive performance. The proposed PepHarmony framework serves as a notable
contribution to peptide representations, and offers valuable insights for
future applications in peptide drug discovery and peptide engineering. We have
made all the source code utilized in this study publicly accessible via GitHub
at https://github.com/zhangruochi/PepHarmony or
<a href=http://www.healthinformaticslab.org/supp/>this http URL</a>
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11361 title=Abstract>arXiv:2401.11361</a> [<a href=https://arxiv.org/pdf/2401.11361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11361 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revolutionizing API Documentation through Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naghshzan%2C+A">AmirHossein Naghshzan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ratte%2C+S">Sylvie Ratte</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2308.09070>arXiv:2308.09070</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>This study tackles the challenges associated with interpreting Application
Programming Interface (API) documentation, an integral aspect of software
development. Official API documentation, while essential, can be lengthy and
challenging to navigate, prompting developers to seek unofficial sources such
as Stack Overflow. Leveraging the vast user-generated content on Stack
Overflow, including code snippets and discussions, we employ BERTopic and
extractive summarization to automatically generate concise and informative API
summaries. These summaries encompass key insights like general usage, common
developer issues, and potential solutions, sourced from the wealth of knowledge
on Stack Overflow. Software developers evaluate these summaries for
performance, coherence, and interoperability, providing valuable feedback on
the practicality of our approach.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11364 title=Abstract>arXiv:2401.11364</a> [<a href=https://arxiv.org/pdf/2401.11364 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11364 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11364 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Folding Custom Gates with Verifier Input
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vark%2C+A">Aard Vark</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y+X">Yan X Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>In the context of interactive proofs, a "folding scheme" (popularized by
Nova) is a way to combine multiple instances of a constraint system into a
single instance, so the validity of the multiple instances can statistically be
reduced to the validity of a single one. We show how Nova folding can be
generalized to ``custom'' gates and extra rounds of verifier randomness. As an
application of this extension, we present Origami, the first (to our knowledge)
known example of a folding scheme for lookups.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11365 title=Abstract>arXiv:2401.11365</a> [<a href=https://arxiv.org/pdf/2401.11365 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11365 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Confidence Preservation Property in Knowledge Distillation Abstractions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vengertsev%2C+D">Dmitry Vengertsev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sherman%2C+E">Elena Sherman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Social media platforms prevent malicious activities by detecting harmful
content of posts and comments. To that end, they employ large-scale deep neural
network language models for sentiment analysis and content understanding. Some
models, like BERT, are complex, and have numerous parameters, which makes them
expensive to operate and maintain. To overcome these deficiencies, industry
experts employ a knowledge distillation compression technique, where a
distilled model is trained to reproduce the classification behavior of the
original model. The distillation processes terminates when the distillation
loss function reaches the stopping criteria. This function is mainly designed
to ensure that the original and the distilled models exhibit alike
classification behaviors. However, besides classification accuracy, there are
additional properties of the original model that the distilled model should
preserve to be considered as an appropriate abstraction. In this work, we
explore whether distilled TinyBERT models preserve confidence values of the
original BERT models, and investigate how this confidence preservation property
could guide tuning hyperparameters of the distillation process.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11366 title=Abstract>arXiv:2401.11366</a> [<a href=https://arxiv.org/pdf/2401.11366 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11366 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11366 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Multivocal Literature Review on the Benefits and Limitations of Automated Machine Learning Tools
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azevedo%2C+K">Kelly Azevedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quaranta%2C+L">Luigi Quaranta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calefato%2C+F">Fabio Calefato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalinowski%2C+M">Marcos Kalinowski</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Context. Advancements in Machine Learning (ML) are revolutionizing every
application domain, driving unprecedented transformations and fostering
innovation. However, despite these advances, several organizations are
experiencing friction in the adoption of ML-based technologies, mainly due to
the shortage of ML professionals. In this context, Automated Machine Learning
(AutoML) techniques have been presented as a promising solution to democratize
ML adoption. Objective. We aim to provide an overview of the evidence on the
benefits and limitations of using AutoML tools. Method. We conducted a
multivocal literature review, which allowed us to identify 54 sources from the
academic literature and 108 sources from the grey literature reporting on
AutoML benefits and limitations. We extracted reported benefits and limitations
from the papers and applied thematic analysis. Results. We identified 18
benefits and 25 limitations. Concerning the benefits, we highlight that AutoML
tools can help streamline the core steps of ML workflows, namely data
preparation, feature engineering, model construction, and hyperparameter
tuning, with concrete benefits on model performance, efficiency, and
scalability. In addition, AutoML empowers both novice and experienced data
scientists, promoting ML accessibility. On the other hand, we highlight several
limitations that may represent obstacles to the widespread adoption of AutoML.
For instance, AutoML tools may introduce barriers to transparency and
interoperability, exhibit limited flexibility for complex scenarios, and offer
inconsistent coverage of the ML workflow. Conclusions. The effectiveness of
AutoML in facilitating the adoption of machine learning by users may vary
depending on the tool and the context in which it is used. As of today, AutoML
tools are used to increase human expertise rather than replace it, and, as
such, they require skilled users.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11370 title=Abstract>arXiv:2401.11370</a> [<a href=https://arxiv.org/pdf/2401.11370 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11370 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11370 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cabrera%2C+C">Christian Cabrera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paleyes%2C+A">Andrei Paleyes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lawrence%2C+N+D">Neil D. Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at The 1st International Workshop New Trends in Software Architecture (SATrends) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
</div>
<p class=mathjax>Software systems impact society at different levels as they pervasively solve
real-world problems. Modern software systems are often so sophisticated that
their complexity exceeds the limits of human comprehension. These systems must
respond to changing goals, dynamic data, unexpected failures, and security
threats, among other variable factors in real-world environments. Systems'
complexity challenges their interpretability and requires autonomous responses
to dynamic changes. Two main research areas explore autonomous systems'
responses: evolutionary computing and autonomic computing. Evolutionary
computing focuses on software improvement based on iterative modifications to
the source code. Autonomic computing focuses on optimising systems' performance
by changing their structure, behaviour, or environment variables. Approaches
from both areas rely on feedback loops that accumulate knowledge from the
system interactions to inform autonomous decision-making. However, this
knowledge is often limited, constraining the systems' interpretability and
adaptability. This paper proposes a new concept for interpretable and adaptable
software systems: self-sustaining software systems (S4). S4 builds knowledge
loops between all available knowledge sources that define modern software
systems to improve their interpretability and adaptability. This paper
introduces and discusses the S4 concept.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11371 title=Abstract>arXiv:2401.11371</a> [<a href=https://arxiv.org/pdf/2401.11371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling Considerations for Developing Deep Space Autonomous Spacecraft and Simulators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agia%2C+C">Christopher Agia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vila%2C+G+C">Guillem Casadesus Vila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bandyopadhyay%2C+S">Saptarshi Bandyopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bayard%2C+D+S">David S. Bayard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+K">Kar-Ming Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+C+H">Charles H. Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+E">Eric Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aenishanslin%2C+I">Ian Aenishanslin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ardito%2C+S">Steven Ardito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fesq%2C+L">Lorraine Fesq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pavone%2C+M">Marco Pavone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nesnas%2C+I+A+D">Issa A. D. Nesnas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://sites.google.com/stanford.edu/spacecraft-models.>this https URL</a> 20 pages, 8 figures. Accepted to the IEEE Conference on Aerospace (AeroConf) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>To extend the limited scope of autonomy used in prior missions for operation
in distant and complex environments, there is a need to further develop and
mature autonomy that jointly reasons over multiple subsystems, which we term
system-level autonomy. System-level autonomy establishes situational awareness
that resolves conflicting information across subsystems, which may necessitate
the refinement and interconnection of the underlying spacecraft and environment
onboard models. However, with a limited understanding of the assumptions and
tradeoffs of modeling to arbitrary extents, designing onboard models to support
system-level capabilities presents a significant challenge.
<br>In this paper, we provide a detailed analysis of the increasing levels of
model fidelity for several key spacecraft subsystems, with the goal of
informing future spacecraft functional- and system-level autonomy algorithms
and the physics-based simulators on which they are validated. We do not argue
for the adoption of a particular fidelity class of models but, instead,
highlight the potential tradeoffs and opportunities associated with the use of
models for onboard autonomy and in physics-based simulators at various fidelity
levels. We ground our analysis in the context of deep space exploration of
small bodies, an emerging frontier for autonomous spacecraft operation in
space, where the choice of models employed onboard the spacecraft may determine
mission success. We conduct our experiments in the Multi-Spacecraft Concept and
Autonomy Tool (MuSCAT), a software suite for developing spacecraft autonomy
algorithms.
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11372 title=Abstract>arXiv:2401.11372</a> [<a href=https://arxiv.org/pdf/2401.11372 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11372 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Back-stepping Experience Replay with Application to Model-free Reinforcement Learning for a Soft Snake Robot
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+X">Xinda Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhaojian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+X">Xiaobo Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the IEEE for possible publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we propose a novel technique, Back-stepping Experience Replay
(BER), that is compatible with arbitrary off-policy reinforcement learning (RL)
algorithms. BER aims to enhance learning efficiency in systems with approximate
reversibility, reducing the need for complex reward shaping. The method
constructs reversed trajectories using back-stepping transitions to reach
random or fixed targets. Interpretable as a bi-directional approach, BER
addresses inaccuracies in back-stepping transitions through a distillation of
the replay experience during learning. Given the intricate nature of soft
robots and their complex interactions with environments, we present an
application of BER in a model-free RL approach for the locomotion and
navigation of a soft snake robot, which is capable of serpentine motion enabled
by anisotropic friction between the body and ground. In addition, a dynamic
simulator is developed to assess the effectiveness and efficiency of the BER
algorithm, in which the robot demonstrates successful learning (reaching a 100%
success rate) and adeptly reaches random targets, achieving an average speed
48% faster than that of the best baseline approach.
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11373 title=Abstract>arXiv:2401.11373</a> [<a href=https://arxiv.org/pdf/2401.11373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kassem%2C+A+M">Aly M. Kassem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saad%2C+S">Sherif Saad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 - Main conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Adversarial attacks against NLP Deep Learning models are a significant
concern. In particular, adversarial samples exploit the model's sensitivity to
small input changes. While these changes appear insignificant on the semantics
of the input sample, they result in significant decay in model performance. In
this paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to
automatically learn a policy to generate challenging samples that most likely
improve the model's performance. TPRL leverages FLAN T5, a language model, as a
generator and employs a self learned policy using a proximal policy gradient to
generate the adversarial examples automatically. TPRL's reward is based on the
confusion induced in the classifier, preserving the original text meaning
through a Mutual Implication score. We demonstrate and evaluate TPRL's
effectiveness in discovering natural adversarial attacks and improving model
performance through extensive experiments on four diverse NLP classification
tasks via Automatic and Human evaluation. TPRL outperforms strong baselines,
exhibits generalizability across classifiers and datasets, and combines the
strengths of language modeling and reinforcement learning to generate diverse
and influential adversarial examples.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11374 title=Abstract>arXiv:2401.11374</a> [<a href=https://arxiv.org/pdf/2401.11374 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11374 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Language Models as Hierarchy Encoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zhangdie Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Interpreting hierarchical structures latent in language is a key limitation
of current language models (LMs). While previous research has implicitly
leveraged these hierarchies to enhance LMs, approaches for their explicit
encoding are yet to be explored. To address this, we introduce a novel approach
to re-train transformer encoder-based LMs as Hierarchy Transformer encoders
(HiTs), harnessing the expansive nature of hyperbolic space. Our method
situates the output embedding space of pre-trained LMs within a Poincar\'e ball
with a curvature that adapts to the embedding dimension, followed by
re-training on hyperbolic cluster and centripetal losses. These losses are
designed to effectively cluster related entities (input as texts) and organise
them hierarchically. We evaluate HiTs against pre-trained and fine-tuned LMs,
focusing on their capabilities in simulating transitive inference, predicting
subsumptions, and transferring knowledge across hierarchies. The results
demonstrate that HiTs consistently outperform both pre-trained and fine-tuned
LMs in these tasks, underscoring the effectiveness and transferability of our
re-trained hierarchy encoders.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11378 title=Abstract>arXiv:2401.11378</a> [<a href=https://arxiv.org/pdf/2401.11378 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11378 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Agent Generative Adversarial Interactive Self-Imitation Learning for AUV Formation Control and Obstacle Avoidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Z">Zheng Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianhao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+D">Dong Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guangliang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8pages,10figures,Published to RA-L
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Multiple autonomous underwater vehicles (multi-AUV) can cooperatively
accomplish tasks that a single AUV cannot complete. Recently, multi-agent
reinforcement learning has been introduced to control of multi-AUV. However,
designing efficient reward functions for various tasks of multi-AUV control is
difficult or even impractical. Multi-agent generative adversarial imitation
learning (MAGAIL) allows multi-AUV to learn from expert demonstration instead
of pre-defined reward functions, but suffers from the deficiency of requiring
optimal demonstrations and not surpassing provided expert demonstrations. This
paper builds upon the MAGAIL algorithm by proposing multi-agent generative
adversarial interactive self-imitation learning (MAGAISIL), which can
facilitate AUVs to learn policies by gradually replacing the provided
sub-optimal demonstrations with self-generated good trajectories selected by a
human trainer. Our experimental results in a multi-AUV formation control and
obstacle avoidance task on the Gazebo platform with AUV simulator of our lab
show that AUVs trained via MAGAISIL can surpass the provided sub-optimal expert
demonstrations and reach a performance close to or even better than MAGAIL with
optimal demonstrations. Further results indicate that AUVs' policies trained
via MAGAISIL can adapt to complex and different tasks as well as MAGAIL
learning from optimal demonstrations.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11380 title=Abstract>arXiv:2401.11380</a> [<a href=https://arxiv.org/pdf/2401.11380 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11380 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+M">Mao Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiyue Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yue Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yanxun Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Methodology (stat.ME); Machine Learning (stat.ML)
</div>
<p class=mathjax>Model-based offline reinforcement learning methods (RL) have achieved
state-of-the-art performance in many decision-making problems thanks to their
sample efficiency and generalizability. Despite these advancements, existing
model-based offline RL approaches either focus on theoretical studies without
developing practical algorithms or rely on a restricted parametric policy
space, thus not fully leveraging the advantages of an unrestricted policy space
inherent to model-based methods. To address this limitation, we develop MoMA, a
model-based mirror ascent algorithm with general function approximations under
partial coverage of offline data. MoMA distinguishes itself from existing
literature by employing an unrestricted policy class. In each iteration, MoMA
conservatively estimates the value function by a minimization procedure within
a confidence set of transition models in the policy evaluation step, then
updates the policy with general function approximations instead of
commonly-used parametric policy classes in the policy improvement step. Under
some mild assumptions, we establish theoretical guarantees of MoMA by proving
an upper bound on the suboptimality of the returned policy. We also provide a
practically implementable, approximate version of the algorithm. The
effectiveness of MoMA is demonstrated via numerical studies.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11382 title=Abstract>arXiv:2401.11382</a> [<a href=https://arxiv.org/pdf/2401.11382 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11382 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using Large Language Model for End-to-End Chinese ASR and NER
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jiawei Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yanqing Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+M">Mengxin Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiaofeng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+X">Xiaosong Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+C">Chang Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+M">Miaomiao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Mapping speech tokens to the same feature space as text tokens has become the
paradigm for the integration of speech modality into decoder-only large
language models (LLMs). An alternative approach is to use an encoder-decoder
architecture that incorporates speech features through cross-attention. This
approach, however, has received less attention in the literature. In this work,
we connect the Whisper encoder with ChatGLM3 and provide in-depth comparisons
of these two approaches using Chinese automatic speech recognition (ASR) and
name entity recognition (NER) tasks. We evaluate them not only by conventional
metrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NER
errors. Our experiments reveal that encoder-decoder architecture outperforms
decoder-only architecture with a short context, while decoder-only architecture
benefits from a long context as it fully exploits all layers of the LLM. By
using LLM, we significantly reduced the entity omission errors and improved the
entity ASR accuracy compared to the Conformer baseline. Additionally, we
obtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER test
set by using chain-of-thought (CoT) NER which first infers long-form ASR
transcriptions and then predicts NER labels.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11389 title=Abstract>arXiv:2401.11389</a> [<a href=https://arxiv.org/pdf/2401.11389 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11389 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MedLM: Exploring Language Models for Medical Question Answering Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yagnik%2C+N">Niraj Yagnik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jhaveri%2C+J">Jay Jhaveri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+V">Vivek Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pila%2C+G">Gabriel Pila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ben%2C+A">Asma Ben</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>In the face of rapidly expanding online medical literature, automated systems
for aggregating and summarizing information are becoming increasingly crucial
for healthcare professionals and patients. Large Language Models (LLMs), with
their advanced generative capabilities, have shown promise in various NLP
tasks, and their potential in the healthcare domain, particularly for
Closed-Book Generative QnA, is significant. However, the performance of these
models in domain-specific tasks such as medical Q&amp;A remains largely unexplored.
This study aims to fill this gap by comparing the performance of general and
medical-specific distilled LMs for medical Q&amp;A. We aim to evaluate the
effectiveness of fine-tuning domain-specific LMs and compare the performance of
different families of Language Models. The study will address critical
questions about these models' reliability, comparative performance, and
effectiveness in the context of medical Q&amp;A. The findings will provide valuable
insights into the suitability of different LMs for specific applications in the
medical domain.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11390 title=Abstract>arXiv:2401.11390</a> [<a href=https://arxiv.org/pdf/2401.11390 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11390 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11390 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Transformation of Repairing Reed-Solomon Codes from Rack-Aware Storage Model to Homogeneous Storage Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yumeng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+H">Han Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 2 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we address the node repair problem of Reed-Solomon (RS) coded
distributed storage systems. Specifically, to overcome the challenges of
multiple-node failures of RS codes under the rack-aware storage model, we
employ good polynomials to guide the placement of the conventional RS codes
into racks and then propose a novel repair framework for the resultant
rack-aware RS codes, which can transform its repair to that under the
homogeneous storage model. As applications of our repair framework, firstly we
present the repair scheme of multiple-node failures for some existing
constructions, which can only repair a single-node failure before. Secondly, we
deduce several new constructions of rack-aware RS codes supporting the repair
of multiple-node failures.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11391 title=Abstract>arXiv:2401.11391</a> [<a href=https://arxiv.org/pdf/2401.11391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interactive AI with Retrieval-Augmented Generation for Next Generation Networking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruichen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+H">Hongyang Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yinqiu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S">Sumei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+X">Xuemin Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>With the advance of artificial intelligence (AI), the emergence of Google
Gemini and OpenAI Q* marks the direction towards artificial general
intelligence (AGI). To implement AGI, the concept of interactive AI (IAI) has
been introduced, which can interactively understand and respond not only to
human user input but also to dynamic system and network conditions. In this
article, we explore an integration and enhancement of IAI in networking. We
first comprehensively review recent developments and future perspectives of AI
and then introduce the technology and components of IAI. We then explore the
integration of IAI into the next-generation networks, focusing on how implicit
and explicit interactions can enhance network functionality, improve user
experience, and promote efficient network management. Subsequently, we propose
an IAI-enabled network management and optimization framework, which consists of
environment, perception, action, and brain units. We also design the pluggable
large language model (LLM) module and retrieval augmented generation (RAG)
module to build the knowledge base and contextual memory for decision-making in
the brain unit. We demonstrate the effectiveness of the framework through case
studies. Finally, we discuss potential research directions for IAI-based
networks.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11394 title=Abstract>arXiv:2401.11394</a> [<a href=https://arxiv.org/pdf/2401.11394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Generative Explainers using Counterfactual Inference: A Case Study on the Morpho-MNIST Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taylor-Melanson%2C+W">Will Taylor-Melanson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadeghi%2C+Z">Zahra Sadeghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matwin%2C+S">Stan Matwin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In this paper, we propose leveraging causal generative learning as an
interpretable tool for explaining image classifiers. Specifically, we present a
generative counterfactual inference approach to study the influence of visual
features (i.e., pixels) as well as causal factors through generative learning.
To this end, we first uncover the most influential pixels on a classifier's
decision by varying the value of a causal attribute via counterfactual
inference and computing both Shapely and contrastive explanations for
counterfactual images with these different attribute values. We then establish
a Monte-Carlo mechanism using the generator of a causal generative model in
order to adapt Shapley explainers to produce feature importances for the
human-interpretable attributes of a causal dataset in the case where a
classifier has been trained exclusively on the images of the dataset. Finally,
we present optimization methods for creating counterfactual explanations of
classifiers by means of counterfactual inference, proposing straightforward
approaches for both differentiable and arbitrary classifiers. We exploit the
Morpho-MNIST causal dataset as a case study for exploring our proposed methods
for generating counterfacutl explantions. We employ visual explanation methods
from OmnixAI open source toolkit to compare them with our proposed methods. By
employing quantitative metrics to measure the interpretability of
counterfactual explanations, we find that our proposed methods of
counterfactual explanation offer more interpretable explanations compared to
those generated from OmnixAI. This finding suggests that our methods are
well-suited for generating highly interpretable counterfactual explanations on
causal datasets.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11395 title=Abstract>arXiv:2401.11395</a> [<a href=https://arxiv.org/pdf/2401.11395 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11395 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Q">Qingdong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+J">Jinlong Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhengkai Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+K">Kai Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+X">Xiaozhong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yunsheng Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>3D open-vocabulary scene understanding aims to recognize arbitrary novel
categories beyond the base label space. However, existing works not only fail
to fully utilize all the available modal information in the 3D domain but also
lack sufficient granularity in representing the features of each modality. In
this paper, we propose a unified multimodal 3D open-vocabulary scene
understanding network, namely UniM-OV3D, which aligns point clouds with image,
language and depth. To better integrate global and local features of the point
clouds, we design a hierarchical point cloud feature extraction module that
learns comprehensive fine-grained feature representations. Further, to
facilitate the learning of coarse-to-fine point-semantic representations from
captions, we propose the utilization of hierarchical 3D caption pairs,
capitalizing on geometric constraints across various viewpoints of 3D scenes.
Extensive experimental results demonstrate the effectiveness and superiority of
our method in open-vocabulary semantic and instance segmentation, which
achieves state-of-the-art performance on both indoor and outdoor benchmarks
such as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available at
https://github.com/hithqd/UniM-OV3D.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11396 title=Abstract>arXiv:2401.11396</a> [<a href=https://arxiv.org/pdf/2401.11396 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11396 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual Imitation Learning with Calibrated Contrastive Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunke Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+L">Linwei Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yutian Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chang Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Adversarial Imitation Learning (AIL) allows the agent to reproduce expert
behavior with low-dimensional states and actions. However, challenges arise in
handling visual states due to their less distinguishable representation
compared to low-dimensional proprioceptive features. While existing methods
resort to adopt complex network architectures or separate the process of
learning representation and decision-making, they overlook valuable intra-agent
information within demonstrations. To address this problem, this paper proposes
a simple and effective solution by incorporating calibrated contrastive
representative learning into visual AIL framework. Specifically, we present an
image encoder in visual AIL, utilizing a combination of unsupervised and
supervised contrastive learning to extract valuable features from visual
states. Based on the fact that the improved agent often produces demonstrations
of varying quality, we propose to calibrate the contrastive loss by treating
each agent demonstrations as a mixed sample. The incorporation of contrastive
learning can be jointly optimized with the AIL framework, without modifying the
architecture or incurring significant computational costs. Experimental results
on DMControl Suite demonstrate our proposed method is sample efficient and can
outperform other compared methods from different aspects.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11398 title=Abstract>arXiv:2401.11398</a> [<a href=https://arxiv.org/pdf/2401.11398 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11398 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11398 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pinsky%2C+M+A">Mark A. Pinsky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Differential Geometry (math.DG)
</div>
<p class=mathjax>This paper develops a new approach to the assessment of the
boundedness/stability of some vector nonlinear systems with delays and variable
coefficients. The approach rests on the development of scalar counterparts to
the original vector systems. We show that the solutions to these scalar
auxiliary nonlinear equations with delay and variable coefficients bound from
the above the norms of solutions to the original equations with the matched
history functions. This prompts the assessment of the boundedness/stability
traits of the vector systems through the abridged evaluation of the dynamics of
their scalar counterparts. The latter task is achieved in effortless
simulations or through the application of simplified analytical inferences.
Consequently, we convey some novel boundedness/ stability criteria and estimate
the radiuses of the balls imbedded in the boundedness/stability regions.
Lastly, we authenticate our inferences in representative simulations that also
measure their accuracy.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11401 title=Abstract>arXiv:2401.11401</a> [<a href=https://arxiv.org/pdf/2401.11401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLMRA: Multi-modal Large Language Model based Restoration Assistant
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+X">Xiaoyu Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuan Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+B">Bin Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenming Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-modal Large Language Models (MLLMs) have a significant impact on
various tasks, due to their extensive knowledge and powerful perception and
generation capabilities. However, it still remains an open research problem on
applying MLLMs to low-level vision tasks. In this paper, we present a simple
MLLM-based Image Restoration framework to address this gap, namely Multi-modal
Large Language Model based Restoration Assistant (LLMRA). We exploit the
impressive capabilities of MLLMs to obtain the degradation information for
universal image restoration. By employing a pretrained multi-modal large
language model and a vision language model, we generate text descriptions and
encode them as context embedding with degradation information for the degraded
image. Through the proposed Context Enhance Module (CEM) and Degradation
Context based Transformer Network (DC-former), we integrate these context
embedding into the restoration network, contributing to more accurate and
adjustable image restoration. Based on the dialogue with the users, our method
leverages image degradation priors from MLLMs, providing low-level attributes
descriptions of the input low-quality images and the restored high-quality
images simultaneously. Extensive experiments demonstrate the superior
performance of our LLMRA in universal image restoration tasks.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11402 title=Abstract>arXiv:2401.11402</a> [<a href=https://arxiv.org/pdf/2401.11402 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11402 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling clustering algorithms to detect clusters of varying densities through scale-invariant data preprocessing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aryal%2C+S">Sunil Aryal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wells%2C+J+R">Jonathan R. Wells</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baniya%2C+A+A">Arbind Agrahari Baniya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santosh%2C+K">KC Santosh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>In this paper, we show that preprocessing data using a variant of rank
transformation called 'Average Rank over an Ensemble of Sub-samples (ARES)'
makes clustering algorithms robust to data representation and enable them to
detect varying density clusters. Our empirical results, obtained using three
most widely used clustering algorithms-namely KMeans, DBSCAN, and DP (Density
Peak)-across a wide range of real-world datasets, show that clustering after
ARES transformation produces better and more consistent results.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11403 title=Abstract>arXiv:2401.11403</a> [<a href=https://arxiv.org/pdf/2401.11403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+H">Haoqiang Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haochun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yanrui Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Biomolecules (q-bio.BM)
</div>
<p class=mathjax>Deep learning is now widely used in drug discovery, providing significant
acceleration and cost reduction. As the most fundamental building block,
molecular representation is essential for predicting molecular properties to
enable various downstream applications. Most existing methods attempt to
incorporate more information to learn better representations. However, not all
features are equally important for a specific task. Ignoring this would
potentially compromise the training efficiency and predictive accuracy. To
address this issue, we propose a novel approach, which treats language models
as an agent and molecular pretraining models as a knowledge base. The agent
accentuates task-relevant features in the molecular representation by
understanding the natural language description of the task, just as a tailor
customizes clothes for clients. Thus, we call this approach MolTailor.
Evaluations demonstrate MolTailor's superior performance over baselines,
validating the efficacy of enhancing relevance for molecular representation
learning. This illustrates the potential of language model guided optimization
to better exploit and unleash the capabilities of existing powerful molecular
representation methods. Our codes and appendix are available at
https://github.com/SCIR-HI/MolTailor.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11404 title=Abstract>arXiv:2401.11404</a> [<a href=https://arxiv.org/pdf/2401.11404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PlasmoData.jl -- A Julia Framework for Modeling and Analyzing Complex Data as Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cole%2C+D+L">David L Cole</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zavala%2C+V+M">Victor M Zavala</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 62 pages, 18 figures, 8 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Datasets encountered in scientific and engineering applications appear in
complex formats (e.g., images, multivariate time series, molecules, video, text
strings, networks). Graph theory provides a unifying framework to model such
datasets and enables the use of powerful tools that can help analyze,
visualize, and extract value from data. In this work, we present PlasmoData.jl,
an open-source, Julia framework that uses concepts of graph theory to
facilitate the modeling and analysis of complex datasets. The core of our
framework is a general data modeling abstraction, which we call a DataGraph. We
show how the abstraction and software implementation can be used to represent
diverse data objects as graphs and to enable the use of tools from topology,
graph theory, and machine learning (e.g., graph neural networks) to conduct a
variety of tasks. We illustrate the versatility of the framework by using real
datasets: i) an image classification problem using topological data analysis to
extract features from the graph model to train machine learning models; ii) a
disease outbreak problem where we model multivariate time series as graphs to
detect abnormal events; and iii) a technology pathway analysis problem where we
highlight how we can use graphs to navigate connectivity. Our discussion also
highlights how PlasmoData.jl leverages native Julia capabilities to enable
compact syntax, scalable computations, and interfaces with diverse packages.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11406 title=Abstract>arXiv:2401.11406</a> [<a href=https://arxiv.org/pdf/2401.11406 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11406 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K">Kiyoon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gowda%2C+S+N">Shreyank N Gowda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eustratiadis%2C+P">Panagiotis Eustratiadis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniou%2C+A">Antreas Antoniou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fisher%2C+R+B">Robert B Fisher</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Despite recent advances in video action recognition achieving strong
performance on existing benchmarks, these models often lack robustness when
faced with natural distribution shifts between training and test data. We
propose two novel evaluation methods to assess model resilience to such
distribution disparity. One method uses two different datasets collected from
different sources and uses one for training and validation, and the other for
testing. More precisely, we created dataset splits of HMDB-51 or UCF-101 for
training, and Kinetics-400 for testing, using the subset of the classes that
are overlapping in both train and test datasets. The other proposed method
extracts the feature mean of each class from the target evaluation dataset's
training data (i.e. class prototype) and estimates test video prediction as a
cosine similarity score between each sample to the class prototypes of each
target class. This procedure does not alter model weights using the target
dataset and it does not require aligning overlapping classes of two different
datasets, thus is a very efficient method to test the model robustness to
distribution shifts without prior knowledge of the target distribution. We
address the robustness problem by adversarial augmentation training -
generating augmented views of videos that are "hard" for the classification
model by applying gradient ascent on the augmentation parameters - as well as
"curriculum" scheduling the strength of the video augmentations. We
experimentally demonstrate the superior performance of the proposed adversarial
augmentation approach over baselines across three state-of-the-art action
recognition models - TSM, Video Swin Transformer, and Uniformer. The presented
work provides critical insight into model robustness to distribution shifts and
presents effective techniques to enhance video action recognition performance
in a real-world deployment.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11408 title=Abstract>arXiv:2401.11408</a> [<a href=https://arxiv.org/pdf/2401.11408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction Tasks Oriented to the Finance Field
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+C">Congqing He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+Y">Yuquan Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuzhong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+J">Jianhong Yin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> CCKS 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Event extraction lies at the cores of investment analysis and asset
management in the financial field, and thus has received much attention. The
2019 China conference on knowledge graph and semantic computing (CCKS)
challenge sets up a evaluation competition for event entity extraction task
oriented to the finance field. In this task, we mainly focus on how to extract
the event entity accurately, and recall all the corresponding event entity
effectively. In this paper, we propose a novel model, Sequence Enhanced BERT
Networks (SEBERTNets for short), which can inherit the advantages of the
BERT,and while capturing sequence semantic information. In addition, motivated
by recommendation system, we propose Hybrid Sequence Enhanced BERT Networks
(HSEBERTNets for short), which uses a multi-channel recall method to recall all
the corresponding event entity. The experimental results show that, the F1
score of SEBERTNets is 0.905 in the first stage, and the F1 score of
HSEBERTNets is 0.934 in the first stage, which demonstarate the effectiveness
of our methods.
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11409 title=Abstract>arXiv:2401.11409</a> [<a href=https://arxiv.org/pdf/2401.11409 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11409 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel Optimization Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xingdi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yu Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kai Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Utilization of inter-base station cooperation for information processing has
shown great potential in enhancing the overall quality of communication
services (QoS) in wireless communication networks. Nevertheless, such
cooperations require the knowledge of channel state information (CSI) at base
stations (BSs), which is assumed to be perfectly known. However, CSI errors are
inevitable in practice which necessitates beamforming techniques that can
achieve robust performance in the presence of channel estimation errors.
Existing approaches relax the robust beamforming design problems into
semidefinite programming (SDP), which can only achieve a solution that is far
from being optimal. To this end, this paper views robust beamforming design
problems from a bilevel optimization perspective. In particular, we focus on
maximizing the worst-case weighted sum-rate (WSR) in the downlink multi-cell
multi-user multiple-input single-output (MISO) system considering bounded CSI
errors. We first reformulate this problem into a bilevel optimization problem
and then develop an efficient algorithm based on the cutting plane method. A
distributed optimization algorithm has also been developed to facilitate the
parallel processing in practical settings. Numerical results are provided to
confirm the effectiveness of the proposed algorithm in terms of performance and
complexity, particularly in the presence of CSI uncertainties.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11410 title=Abstract>arXiv:2401.11410</a> [<a href=https://arxiv.org/pdf/2401.11410 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11410 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zubair%2C+M">Md Zubair</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salim%2C+M+S">Md. Shahidul Salim</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+M+M">Mehrab Mustafy Rahman</a> (3), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basher%2C+M+J+I">Mohammad Jahid Ibna Basher</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Imran%2C+S">Shahin Imran</a> (4), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarker%2C+I+H">Iqbal H. Sarker</a> (5) ((1) Chittagong University of Engineering &amp; Technology, Chittagong, Bangladesh, (2) Khulna University of Engineering &amp; Technology, Khulna, Bangladesh, (3) Islamic University of Technology, Gazipur, Bangladesh, (4) Khulna Agricultural University, Khulna, Bangladesh, (5) Edith Cowan University, Perth, Australia.)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 14 figures and 12 tables. Submitted to Engineering Application of Artificial Intelligence (Elsevier)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Bangladesh is predominantly an agricultural country, where the agrarian
sector plays an essential role in accelerating economic growth and enabling the
food security of the people. The performance of this sector has an overwhelming
impact on the primary macroeconomic objectives like food security, employment
generation, poverty alleviation, human resources development, and other
economic and social forces. Although Bangladesh's labor-intensive agriculture
has achieved steady increases in food grain production, it often suffered from
unfavorable weather conditions such as heavy rainfall, low temperature, and
drought. Consequently, these factors hinder the production of food
substantially, putting the country's overall food security in danger. In order
to have a profitable, sustainable, and farmer-friendly agricultural practice,
this paper proposes a context-based crop recommendation system powered by a
weather forecast model. With extensive evaluation, the multivariate Stacked
Bi-LSTM Network is employed as the weather forecasting model. The proposed
weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for
any given location in Bangladesh with higher accuracy. These predictions guide
our system to assist the farmers in making feasible decisions about planting,
irrigation, harvesting, and so on. Additionally, our full-fledged system is
capable of alerting the farmers about extreme weather conditions so that
preventive measures can be undertaken to protect the crops. Finally, the system
is also adept at making knowledge-based crop suggestions for the flood and
drought-prone regions of Bangladesh.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11411 title=Abstract>arXiv:2401.11411</a> [<a href=https://arxiv.org/pdf/2401.11411 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11411 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The degree of ill-posedness for some composition governed by the Cesaro operator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Deng%2C+Y">Yu Deng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fischer%2C+H">Hans-Jürgen Fischer</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hofmann%2C+B">Bernd Hofmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 2 figures, submitted to conference proceedings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)
</div>
<p class=mathjax>In this article, we consider the singular value asymptotics of compositions
of compact linear operators mapping in the real Hilbert space of quadratically
integrable functions over the unit interval. Specifically, the composition is
given by the compact simple integration operator followed by the non-compact
Ces`aro operator possessing a non-closed range. We show that the degree of
ill-posedness of that composition is two, which means that the Ces`aro operator
increases the degree of illposedness by the amount of one compared to the
simple integration operator.
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11414 title=Abstract>arXiv:2401.11414</a> [<a href=https://arxiv.org/pdf/2401.11414 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11414 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> S<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-389 style=width:0.512em;display:inline-block><span style=display:inline-block;position:relative;width:0.419em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.049em,1000.42em,1.16em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-390><span class=msubsup id=MathJax-Span-391><span style=display:inline-block;position:relative;width:0.419em;height:0px><span style=position:absolute;clip:rect(3.845em,1000em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mi id=MathJax-Span-392></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.35em;left:0em><span class=mn id=MathJax-Span-393 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:1.114em"></span></span></nobr></span>M-Net: Joint Learning of Semantic Segmentation and Stereo Matching for Autonomous Driving
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yi Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chuang-Wei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+F">Fisher Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qijun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted to IEEE Trans. on Intelligent Vehicles (T-IV)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)
</div>
<p class=mathjax>Semantic segmentation and stereo matching are two essential components of 3D
environmental perception systems for autonomous driving. Nevertheless,
conventional approaches often address these two problems independently,
employing separate models for each task. This approach poses practical
limitations in real-world scenarios, particularly when computational resources
are scarce or real-time performance is imperative. Hence, in this article, we
introduce S<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-394 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.41em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-395><span class=msubsup id=MathJax-Span-396><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-397></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mn id=MathJax-Span-398 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>M-Net, a novel joint learning framework developed to perform
semantic segmentation and stereo matching simultaneously. Specifically,
S<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-399 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.41em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-400><span class=msubsup id=MathJax-Span-401><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-402></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=mn id=MathJax-Span-403 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>M-Net shares the features extracted from RGB images between both tasks,
resulting in an improved overall scene understanding capability. This feature
sharing process is realized using a feature fusion adaption (FFA) module, which
effectively transforms the shared features into semantic space and subsequently
fuses them with the encoded disparity features. The entire joint learning
framework is trained by minimizing a novel semantic consistency-guided (SCG)
loss, which places emphasis on the structural consistency in both tasks.
Extensive experimental results conducted on the vKITTI2 and KITTI datasets
demonstrate the effectiveness of our proposed joint learning framework and its
superior performance compared to other state-of-the-art single-task networks.
Our project webpage is accessible at mias.group/S3M-Net.
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11415 title=Abstract>arXiv:2401.11415</a> [<a href=https://arxiv.org/pdf/2401.11415 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11415 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 11 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Link prediction can help rectify inaccuracies in community detection stemming
from unaccounted-for or overlooked links within networks. Many existing works
use a baseline approach, which incurs unnecessary computational costs due to
its high time complexity. Further, many studies focus on smaller graphs, which
can lead to misleading conclusions. The report introduces two parallel
approaches, called IHub and LHub, which predict links using neighborhood-based
similarity measures on large graphs. LHub is a heuristic approach, which
additionally disregards large hubs - based on the idea that low-degree nodes
contribute significant similarity among neighbors. On a server equipped with
dual 16-core Intel Xeon Gold 6226R processors, LHub is on average 563x faster
than IHub, especially on web graphs and social networks, while having similar
prediction accuracy. Notably, LHub achieves a link prediction rate of 38.1M
edges/s and improves performance at a rate of 1.6x for every doubling of
threads.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11418 title=Abstract>arXiv:2401.11418</a> [<a href=https://arxiv.org/pdf/2401.11418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Double-Bounded Optimal Transport for Advanced Clustering and Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+L">Liangliang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhaoqi Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J">Junchi Yan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)
</div>
<p class=mathjax>Optimal transport (OT) is attracting increasing attention in machine
learning. It aims to transport a source distribution to a target one at minimal
cost. In its vanilla form, the source and target distributions are
predetermined, which contracts to the real-world case involving undetermined
targets. In this paper, we propose Doubly Bounded Optimal Transport (DB-OT),
which assumes that the target distribution is restricted within two boundaries
instead of a fixed one, thus giving more freedom for the transport to find
solutions. Based on the entropic regularization of DB-OT, three scaling-based
algorithms are devised for calculating the optimal solution. We also show that
our DB-OT is helpful for barycenter-based clustering, which can avoid the
excessive concentration of samples in a single cluster. Then we further develop
DB-OT techniques for long-tailed classification which is an emerging and open
problem. We first propose a connection between OT and classification, that is,
in the classification task, training involves optimizing the Inverse OT to
learn the representations, while testing involves optimizing the OT for
predictions. With this OT perspective, we first apply DB-OT to improve the
loss, and the Balanced Softmax is shown as a special case. Then we apply DB-OT
for inference in the testing process. Even with vanilla Softmax trained
features, our extensive experimental results show that our method can achieve
good results with our improved inference scheme in the testing stage.
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11419 title=Abstract>arXiv:2401.11419</a> [<a href=https://arxiv.org/pdf/2401.11419 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11419 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint UAV Deployment and Resource Allocation in THz-Assisted MEC-Enabled Integrated Space-Air-Ground Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tun%2C+Y+K">Yan Kyaw Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%A1n%2C+G">György Dán</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+Y+M">Yu Min Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 36 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Multi-access edge computing (MEC)-enabled integrated space-air-ground (SAG)
networks have drawn much attention recently, as they can provide communication
and computing services to wireless devices in areas that lack terrestrial base
stations (TBSs). Leveraging the ample bandwidth in the terahertz (THz)
spectrum, in this paper, we propose MEC-enabled integrated SAG networks with
collaboration among unmanned aerial vehicles (UAVs). We then formulate the
problem of minimizing the energy consumption of devices and UAVs in the
proposed MEC-enabled integrated SAG networks by optimizing tasks offloading
decisions, THz sub-bands assignment, transmit power control, and UAVs
deployment. The formulated problem is a mixed-integer nonlinear programming
(MILP) problem with a non-convex structure, which is challenging to solve. We
thus propose a block coordinate descent (BCD) approach to decompose the problem
into four sub-problems: 1) device task offloading decision problem, 2) THz
sub-band assignment and power control problem, 3) UAV deployment problem, and
4) UAV task offloading decision problem. We then propose to use a matching
game, concave-convex procedure (CCP) method, successive convex approximation
(SCA), and block successive upper-bound minimization (BSUM) approaches for
solving the individual subproblems. Finally, extensive simulations are
performed to demonstrate the effectiveness of our proposed algorithm.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11420 title=Abstract>arXiv:2401.11420</a> [<a href=https://arxiv.org/pdf/2401.11420 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11420 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Embedded Hyperspectral Band Selection with Adaptive Optimization for Image Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmer%2C+Y">Yaniv Zimmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glickman%2C+O">Oren Glickman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Hyperspectral band selection plays a pivotal role in remote sensing and image
analysis, aiming to identify the most informative spectral bands while
minimizing computational overhead. In this paper, we introduce a pioneering
approach for hyperspectral band selection that offers an embedded solution,
making it well-suited for resource-constrained or real-time applications. Our
proposed method, embedded Hyperspectral Band Selection (EHBS), excels in
selecting the best bands without the need for prior processing, seamlessly
integrating with the downstream task model. This is achieved through the
adaptation of the Stochastic Gates (STG) algorithm, originally designed for
feature selection, for hyperspectral band selection in the context of image
semantic segmentation and the integration of a dynamic optimizer, DoG, which
removes the need for the required tuning the learning rate. To assess the
performance of our method, we introduce a novel metric for evaluating band
selection methods across different target numbers of selected bands quantified
by the Area Under the Curve (AUC). We conduct experiments on two distinct
semantic-segmentation hyperspectral benchmark datasets, demonstrating its
superiority in terms of its resulting accuracy and its ease of use compared to
many common and state-of-the-art methods. Furthermore, our contributions extend
beyond the realm of hyperspectral band selection. The adaptability of our
approach to other tasks, especially those involving grouped features, opens up
promising avenues for broader applications within the realm of deep learning,
such as feature selection for feature groups. The demonstrated success on the
tested datasets and the potential for application to a variety of tasks
underscore the value of our method as a substantial addition to the field of
computer vision.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11421 title=Abstract>arXiv:2401.11421</a> [<a href=https://arxiv.org/pdf/2401.11421 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11421 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11421 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing the vision-language foundation model with key semantic knowledge-emphasized report refinement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Cheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Weijian Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiarun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shanshan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, vision-language representation learning has made remarkable
advancements in building up medical foundation models, holding immense
potential for transforming the landscape of clinical research and medical care.
The underlying hypothesis is that the rich knowledge embedded in radiology
reports can effectively assist and guide the learning process, reducing the
need for additional labels. However, these reports tend to be complex and
sometimes even consist of redundant descriptions that make the representation
learning too challenging to capture the key semantic information. This paper
develops a novel iterative vision-language representation learning framework by
proposing a key semantic knowledge-emphasized report refinement method.
Particularly, raw radiology reports are refined to highlight the key
information according to a constructed clinical dictionary and two
model-optimized knowledge-enhancement metrics. The iterative framework is
designed to progressively learn, starting from gaining a general understanding
of the patient's condition based on raw reports and gradually refines and
extracts critical information essential to the fine-grained analysis tasks. The
effectiveness of the proposed framework is validated on various downstream
medical image analysis tasks, including disease classification,
region-of-interest segmentation, and phrase grounding. Our framework surpasses
seven state-of-the-art methods in both fine-tuning and zero-shot settings,
demonstrating its encouraging potential for different clinical applications.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11425 title=Abstract>arXiv:2401.11425</a> [<a href=https://arxiv.org/pdf/2401.11425 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11425 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Grayscale Image Colorization with GAN and CycleGAN in Different Image Domain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+C">Chen Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+Y">Yunchen Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+Y">Yichen Mo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Automatic colorization of grayscale image has been a challenging task.
Previous research have applied supervised methods in conquering this problem [
1]. In this paper, we reproduces a GAN-based coloring model, and experiments
one of its variant. We also proposed a CycleGAN based model and experiments
those methods on various datasets. The result shows that the proposed CycleGAN
model does well in human-face coloring and comic coloring, but lack the ability
to diverse colorization.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11429 title=Abstract>arXiv:2401.11429</a> [<a href=https://arxiv.org/pdf/2401.11429 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11429 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11429 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Downlink and Uplink Optimization for RIS-Aided FDD MIMO Communication Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+G">Gyoseung Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hyeongtaek Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Donghwan Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung%2C+J">Jaehoon Chung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swindlehurst%2C+A+L">A. Lee. Swindlehurst</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Junil Choi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE Transactions on Wireless Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper investigates reconfigurable intelligent surface (RIS)-aided
frequency division duplexing (FDD) communication systems. Since the downlink
and uplink signals are simultaneously transmitted in FDD, the phase shifts at
the RIS should be designed to support both transmissions. Considering a
single-user multiple-input multiple-output system, we formulate a weighted
sum-rate maximization problem to jointly maximize the downlink and uplink
system performance. To tackle the non-convex optimization problem, we adopt an
alternating optimization (AO) algorithm, in which two phase shift optimization
techniques are developed to handle the unit-modulus constraints induced by the
reflection coefficients at the RIS. The first technique exploits the manifold
optimization-based algorithm, while the second uses a lower-complexity AO
approach. Numerical results verify that the proposed techniques rapidly
converge to local optima and significantly improve the overall system
performance compared to existing benchmark schemes.
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11430 title=Abstract>arXiv:2401.11430</a> [<a href=https://arxiv.org/pdf/2401.11430 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11430 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Diffusion Time-steps for Unsupervised Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+Z">Zhongqi Yue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiankun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qianru Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+L">Lei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+E+I">Eric I-Chao Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Representation learning is all about discovering the hidden modular
attributes that generate the data faithfully. We explore the potential of
Denoising Diffusion Probabilistic Model (DM) in unsupervised learning of the
modular attributes. We build a theoretical framework that connects the
diffusion time-steps and the hidden attributes, which serves as an effective
inductive bias for unsupervised learning. Specifically, the forward diffusion
process incrementally adds Gaussian noise to samples at each time-step, which
essentially collapses different samples into similar ones by losing attributes,
e.g., fine-grained attributes such as texture are lost with less noise added
(i.e., early time-steps), while coarse-grained ones such as shape are lost by
adding more noise (i.e., late time-steps). To disentangle the modular
attributes, at each time-step t, we learn a t-specific feature to compensate
for the newly lost attribute, and the set of all 1,...,t-specific features,
corresponding to the cumulative set of lost attributes, are trained to make up
for the reconstruction error of a pre-trained DM at time-step t. On CelebA,
FFHQ, and Bedroom datasets, the learned feature significantly improves
attribute classification and enables faithful counterfactual generation, e.g.,
interpolating only one specified attribute between two images, validating the
disentanglement quality. Codes are in https://github.com/yue-zhongqi/diti.
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11431 title=Abstract>arXiv:2401.11431</a> [<a href=https://arxiv.org/pdf/2401.11431 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11431 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Majority or Minority: Data Imbalance Learning Method for Named Entity Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nemoto%2C+S">Sota Nemoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kitada%2C+S">Shunsuke Kitada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iyatomi%2C+H">Hitoshi Iyatomi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Data imbalance presents a significant challenge in various machine learning
(ML) tasks, particularly named entity recognition (NER) within natural language
processing (NLP). NER exhibits a data imbalance with a long-tail distribution,
featuring numerous minority classes (i.e., entity classes) and a single
majority class (i.e., O-class). The imbalance leads to the misclassifications
of the entity classes as the O-class. To tackle the imbalance, we propose a
simple and effective learning method, named majority or minority (MoM)
learning. MoM learning incorporates the loss computed only for samples whose
ground truth is the majority class (i.e., the O-class) into the loss of the
conventional ML model. Evaluation experiments on four NER datasets (Japanese
and English) showed that MoM learning improves prediction performance of the
minority classes, without sacrificing the performance of the majority class and
is more effective than widely known and state-of-the-art methods. We also
evaluated MoM learning using frameworks as sequential labeling and machine
reading comprehension, which are commonly used in NER. Furthermore, MoM
learning has achieved consistent performance improvements regardless of
language, model, or framework.
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11432 title=Abstract>arXiv:2401.11432</a> [<a href=https://arxiv.org/pdf/2401.11432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bimanual Deformable Bag Manipulation Using a Structure-of-Interest Based Latent Dynamics Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+P">Peng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+P">Pai Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+J">Jiaming Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenxi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chenguang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+J">Jia Pan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>The manipulation of deformable objects by robotic systems presents a
significant challenge due to their complex and infinite-dimensional
configuration spaces. This paper introduces a novel approach to Deformable
Object Manipulation (DOM) by emphasizing the identification and manipulation of
Structures of Interest (SOIs) in deformable fabric bags. We propose a bimanual
manipulation framework that leverages a Graph Neural Network (GNN)-based latent
dynamics model to succinctly represent and predict the behavior of these SOIs.
Our approach involves constructing a graph representation from partial point
cloud data of the object and learning the latent dynamics model that
effectively captures the essential deformations of the fabric bag within a
reduced computational space. By integrating this latent dynamics model with
Model Predictive Control (MPC), we empower robotic manipulators to perform
precise and stable manipulation tasks focused on the SOIs. We have validated
our framework through various empirical experiments demonstrating its efficacy
in bimanual manipulation of fabric bags. Our contributions not only address the
complexities inherent in DOM but also provide new perspectives and
methodologies for enhancing robotic interactions with deformable objects by
concentrating on their critical structural elements. Experimental videos can be
obtained from https://sites.google.com/view/bagbot.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11433 title=Abstract>arXiv:2401.11433</a> [<a href=https://arxiv.org/pdf/2401.11433 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11433 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11433 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error-Correcting Codes on Projective Bundles over Deligne-Lusztig varieties
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Portela%2C+D+C">Daniel Camazón Portela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramos%2C+J+A+L">Juan Antonio López Ramos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Mathematics 2023, 11(14), 3079;
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG)
</div>
<p class=mathjax>The aim of this article is to give lower bounds on the parameters of
algebraic geometric error-correcting codes constructed from projective bundles
over Deligne--Lusztig surfaces. The methods based on an intensive use of the
intersection theory allow us to extend the codes previously constructed from
higher-dimensional varieties, as well as those coming from curves. General
bounds are obtained for the case of projective bundles of rank <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-404 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-405><span class=mn id=MathJax-Span-406 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> over
standard Deligne-Lusztig surfaces, and some explicit examples coming from
surfaces of type <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-407 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-408><span class=msubsup id=MathJax-Span-409><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-410 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-411><span class=mrow id=MathJax-Span-412><span class=mn id=MathJax-Span-413 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-414 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.57em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-415><span class=msubsup id=MathJax-Span-416><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-417><span class=mrow id=MathJax-Span-418></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0em><span class=texatom id=MathJax-Span-419><span class=mrow id=MathJax-Span-420><span class=mn id=MathJax-Span-421 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-422><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-423 style=font-family:MathJax_Math-italic>A</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=texatom id=MathJax-Span-424><span class=mrow id=MathJax-Span-425><span class=mn id=MathJax-Span-426 style=font-size:70.7%;font-family:MathJax_Main>4</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> are given.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11436 title=Abstract>arXiv:2401.11436</a> [<a href=https://arxiv.org/pdf/2401.11436 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11436 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Geometric Prior Guided Feature Representation Learning for Long-Tailed Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yanbiao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Shuyuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Puhua Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work was accepted by the IJCV
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Real-world data are long-tailed, the lack of tail samples leads to a
significant limitation in the generalization ability of the model. Although
numerous approaches of class re-balancing perform well for moderate class
imbalance problems, additional knowledge needs to be introduced to help the
tail class recover the underlying true distribution when the observed
distribution from a few tail samples does not represent its true distribution
properly, thus allowing the model to learn valuable information outside the
observed domain. In this work, we propose to leverage the geometric information
of the feature distribution of the well-represented head class to guide the
model to learn the underlying distribution of the tail class. Specifically, we
first systematically define the geometry of the feature distribution and the
similarity measures between the geometries, and discover four phenomena
regarding the relationship between the geometries of different feature
distributions. Then, based on four phenomena, feature uncertainty
representation is proposed to perturb the tail features by utilizing the
geometry of the head class feature distribution. It aims to make the perturbed
features cover the underlying distribution of the tail class as much as
possible, thus improving the model's generalization performance in the test
domain. Finally, we design a three-stage training scheme enabling feature
uncertainty modeling to be successfully applied. Experiments on
CIFAR-10/100-LT, ImageNet-LT, and iNaturalist2018 show that our proposed
approach outperforms other similar methods on most metrics. In addition, the
experimental phenomena we discovered are able to provide new perspectives and
theoretical foundations for subsequent studies.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11437 title=Abstract>arXiv:2401.11437</a> [<a href=https://arxiv.org/pdf/2401.11437 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11437 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Ge Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hongyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roth%2C+D">Dominik Roth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thilges%2C+S">Serge Thilges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Otto%2C+F">Fabian Otto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lioutikov%2C+R">Rudolf Lioutikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Codebase, see: <a href=https://github.com/BruceGeLi/TCE_RL>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Current advancements in reinforcement learning (RL) have predominantly
focused on learning step-based policies that generate actions for each
perceived state. While these methods efficiently leverage step information from
environmental interaction, they often ignore the temporal correlation between
actions, resulting in inefficient exploration and unsmooth trajectories that
are challenging to implement on real hardware. Episodic RL (ERL) seeks to
overcome these challenges by exploring in parameters space that capture the
correlation of actions. However, these approaches typically compromise data
efficiency, as they treat trajectories as opaque \emph{black boxes}. In this
work, we introduce a novel ERL algorithm, Temporally-Correlated Episodic RL
(TCE), which effectively utilizes step information in episodic policy updates,
opening the 'black box' in existing ERL methods while retaining the smooth and
consistent exploration in parameter space. TCE synergistically combines the
advantages of step-based and episodic RL, achieving comparable performance to
recent ERL methods while maintaining data efficiency akin to state-of-the-art
(SoTA) step-based RL.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11439 title=Abstract>arXiv:2401.11439</a> [<a href=https://arxiv.org/pdf/2401.11439 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11439 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> General Flow as Foundation Affordance for Scalable Robot Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+C">Chengbo Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+C">Chuan Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yang Gao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>We address the challenge of acquiring real-world manipulation skills with a
scalable framework.Inspired by the success of large-scale auto-regressive
prediction in Large Language Models (LLMs), we hold the belief that identifying
an appropriate prediction target capable of leveraging large-scale datasets is
crucial for achieving efficient and universal learning. Therefore, we propose
to utilize flow, which represents the future trajectories of 3D points on
objects of interest, as an ideal prediction target in robot learning. To
exploit scalable data resources, we turn our attention to cross-embodiment
datasets. We develop, for the first time, a language-conditioned prediction
model directly from large-scale RGBD human video datasets. Our predicted flow
offers actionable geometric and physics guidance, thus facilitating stable
zero-shot skill transfer in real-world scenarios.We deploy our method with a
policy based on closed-loop flow prediction. Remarkably, without any additional
training, our method achieves an impressive 81% success rate in human-to-robot
skill transfer, covering 18 tasks in 6 scenes. Our framework features the
following benefits: (1) scalability: leveraging cross-embodiment data
resources; (2) universality: multiple object categories, including rigid,
articulated, and soft bodies; (3) stable skill transfer: providing actionable
guidance with a small inference domain-gap. These lead to a new pathway towards
scalable general robot learning. Data, code, and model weights will be made
publicly available.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11441 title=Abstract>arXiv:2401.11441</a> [<a href=https://arxiv.org/pdf/2401.11441 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11441 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On-Device Recommender Systems: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+L">Liang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Wei Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Ruiqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+J">Jing Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+X">Xin Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chengqi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Recommender systems have been widely deployed in various real-world
applications to help users identify content of interest from massive amounts of
information. Traditional recommender systems work by collecting user-item
interaction data in a cloud-based data center and training a centralized model
to perform the recommendation service. However, such cloud-based recommender
systems (CloudRSs) inevitably suffer from excessive resource consumption,
response latency, as well as privacy and security risks concerning both data
and models. Recently, driven by the advances in storage, communication, and
computation capabilities of edge devices, there has been a shift of focus from
CloudRSs to on-device recommender systems (DeviceRSs), which leverage the
capabilities of edge devices to minimize centralized data storage requirements,
reduce the response latency caused by communication overheads, and enhance user
privacy and security by localizing data processing and model training. Despite
the rapid rise of DeviceRSs, there is a clear absence of timely literature
reviews that systematically introduce, categorize and contrast these methods.
To bridge this gap, we aim to provide a comprehensive survey of DeviceRSs,
covering three main aspects: (1) the deployment and inference of DeviceRSs (2)
the training and update of DeviceRSs (3) the security and privacy of DeviceRSs.
Furthermore, we provide a fine-grained and systematic taxonomy of the methods
involved in each aspect, followed by a discussion regarding challenges and
future research directions. This is the first comprehensive survey on DeviceRSs
that covers a spectrum of tasks to fit various needs. We believe this survey
will help readers effectively grasp the current research status in this field,
equip them with relevant technical foundations, and stimulate new research
ideas for developing DeviceRSs.
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11445 title=Abstract>arXiv:2401.11445</a> [<a href=https://arxiv.org/pdf/2401.11445 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11445 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Non-Robocentric Dynamic Landing of Quadrotor UAVs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+L">Li-Yu Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Boyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+C">Chih-Yung Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+C">Ching-Wei Chang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In this work, we propose a dynamic landing solution without the need for
onboard exteroceptive sensors and an expensive computation unit, where all
localization and control modules are carried out on the ground in a
non-inertial frame. Our system starts with a relative state estimator of the
aerial robot from the perspective of the landing platform, where the state
tracking of the UAV is done through a set of onboard LED markers and an
on-ground camera; the state is expressed geometrically on manifold, and is
returned by Iterated Extended Kalman filter (IEKF) algorithm. Subsequently, a
motion planning module is developed to guide the landing process, formulating
it as a minimum jerk trajectory by applying the differential flatness property.
Considering visibility and dynamic constraints, the problem is solved using
quadratic programming, and the final motion primitive is expressed through
piecewise polynomials. Through a series of experiments, the applicability of
this approach is validated by successfully landing 18 cm x 18 cm quadrotor on a
43 cm x 43 cm platform, exhibiting performance comparable to conventional
methods. Finally, we provide comprehensive hardware and software details to the
research community for future reference.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11447 title=Abstract>arXiv:2401.11447</a> [<a href=https://arxiv.org/pdf/2401.11447 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11447 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+L">Li Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiong Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wenxin%2C+F">Fan Wenxin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kai%2C+W">Wang Kai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qingqing%2C+Y">Yu Qingqing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liping%2C+S">Si Liping</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=der+Smagt+Patrick%2C+v">van der Smagt Patrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jun%2C+T">Tang Jun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nutan%2C+C">Chen Nutan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal
treatment of allergic rhinitis. How to enhance the adherence of patients to
maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in
the management of AIT. This study aims to leverage novel machine learning
models to precisely predict the risk of non-adherence of patients and related
systematic symptom scores, to provide a novel approach in the management of
long-term AIT.
<br>Methods: The research develops and analyzes two models, Sequential Latent
Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on
scoring and adherence prediction capabilities.
<br>Results: Excluding the biased samples at the first time step, the predictive
adherence accuracy of the SLAC models is from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-427 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-428><span class=mn id=MathJax-Span-429 style=font-family:MathJax_Main>60</span><span class=mspace id=MathJax-Span-430 style=height:0em;vertical-align:0em;width:0.177em;display:inline-block;overflow:hidden></span><span class=mi id=MathJax-Span-431 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-432 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-433><span class=mn id=MathJax-Span-434 style=font-family:MathJax_Main>72</span><span class=mi id=MathJax-Span-435 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, and for LSTM
models, it is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-436 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-437><span class=mn id=MathJax-Span-438 style=font-family:MathJax_Main>66</span><span class=mspace id=MathJax-Span-439 style=height:0em;vertical-align:0em;width:0.177em;display:inline-block;overflow:hidden></span><span class=mi id=MathJax-Span-440 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-441 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-442><span class=mn id=MathJax-Span-443 style=font-family:MathJax_Main>84</span><span class=mspace id=MathJax-Span-444 style=height:0em;vertical-align:0em;width:0.177em;display:inline-block;overflow:hidden></span><span class=mi id=MathJax-Span-445 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, varying according to the time steps. The
range of Root Mean Square Error (RMSE) for SLAC models is between <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-446 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.74em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-447><span class=mn id=MathJax-Span-448 style=font-family:MathJax_Main>0.93</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-449 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.74em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-450><span class=mn id=MathJax-Span-451 style=font-family:MathJax_Main>2.22</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, while for LSTM models it is between <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-452 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.74em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-453><span class=mn id=MathJax-Span-454 style=font-family:MathJax_Main>1.09</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-455 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.8em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-456><span class=mn id=MathJax-Span-457 style=font-family:MathJax_Main>1.77</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. Notably, these
RMSEs are significantly lower than the random prediction error of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-458 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.74em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-459><span class=mn id=MathJax-Span-460 style=font-family:MathJax_Main>4.55</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
<br>Conclusion: We creatively apply sequential models in the long-term management
of SCIT with promising accuracy in the prediction of SCIT nonadherence in
Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence
prediction, SLAC excels in score prediction for patients undergoing SCIT for
AR. The state-action-based SLAC adds flexibility, presenting a novel and
effective approach for managing long-term AIT.
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11448 title=Abstract>arXiv:2401.11448</a> [<a href=https://arxiv.org/pdf/2401.11448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Betweenness Clustering for Semi-Supervised Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jichang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guanbin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 9 figures, published to IEEE TIP
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Image Processing, vol. 32, pp. 5580-5594,
 October 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Compared to unsupervised domain adaptation, semi-supervised domain adaptation
(SSDA) aims to significantly improve the classification performance and
generalization capability of the model by leveraging the presence of a small
amount of labeled data from the target domain. Several SSDA approaches have
been developed to enable semantic-aligned feature confusion between labeled (or
pseudo labeled) samples across domains; nevertheless, owing to the scarcity of
semantic label information of the target domain, they were arduous to fully
realize their potential. In this study, we propose a novel SSDA approach named
Graph-based Adaptive Betweenness Clustering (G-ABC) for achieving categorical
domain alignment, which enables cross-domain semantic alignment by mandating
semantic transfer from labeled data of both the source and target domains to
unlabeled target samples. In particular, a heterogeneous graph is initially
constructed to reflect the pairwise relationships between labeled samples from
both domains and unlabeled ones of the target domain. Then, to degrade the
noisy connectivity in the graph, connectivity refinement is conducted by
introducing two strategies, namely Confidence Uncertainty based Node Removal
and Prediction Dissimilarity based Edge Pruning. Once the graph has been
refined, Adaptive Betweenness Clustering is introduced to facilitate semantic
transfer by using across-domain betweenness clustering and within-domain
betweenness clustering, thereby propagating semantic label information from
labeled samples across domains to unlabeled target data. Extensive experiments
on three standard benchmark datasets, namely DomainNet, Office-Home, and
Office-31, indicated that our method outperforms previous state-of-the-art SSDA
approaches, demonstrating the superiority of the proposed G-ABC algorithm.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11452 title=Abstract>arXiv:2401.11452</a> [<a href=https://arxiv.org/pdf/2401.11452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Reliable and Factual Response Generation: Detecting Unanswerable Questions in Information-Seeking Conversations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%81ajewska%2C+W">Weronika Łajewska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balog%2C+K">Krisztian Balog</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the author's version of the work. The definitive version is published in: Proceedings of the 46th European Conference on Information Retrieval} (ECIR '24), March 24--28, 2024, Glasgow, Scotland
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Generative AI models face the challenge of hallucinations that can undermine
users' trust in such systems. We approach the problem of conversational
information seeking as a two-step process, where relevant passages in a corpus
are identified first and then summarized into a final system response. This way
we can automatically assess if the answer to the user's question is present in
the corpus. Specifically, our proposed method employs a sentence-level
classifier to detect if the answer is present, then aggregates these
predictions on the passage level, and eventually across the top-ranked passages
to arrive at a final answerability estimate. For training and evaluation, we
develop a dataset based on the TREC CAsT benchmark that includes answerability
labels on the sentence, passage, and ranking levels. We demonstrate that our
proposed method represents a strong baseline and outperforms a state-of-the-art
LLM on the answerability prediction task.
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11453 title=Abstract>arXiv:2401.11453</a> [<a href=https://arxiv.org/pdf/2401.11453 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11453 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inter-Domain Mixup for Semi-Supervised Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jichang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guanbin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Publisted to Elsevier PR2024, available at <a href=https://www.sciencedirect.com/science/article/pii/S0031320323007203?via%3Dihub>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Semi-supervised domain adaptation (SSDA) aims to bridge source and target
domain distributions, with a small number of target labels available, achieving
better classification performance than unsupervised domain adaptation (UDA).
However, existing SSDA work fails to make full use of label information from
both source and target domains for feature alignment across domains, resulting
in label mismatch in the label space during model testing. This paper presents
a novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE),
to tackle this issue. Firstly, we introduce a cross-domain feature alignment
strategy, Inter-domain Mixup, that incorporates label information into model
adaptation. Specifically, we employ sample-level and manifold-level data mixing
to generate compatible training samples. These newly established samples,
combined with reliable and actual label information, display diversity and
compatibility across domains, while such extra supervision thus facilitates
cross-domain feature alignment and mitigates label mismatch. Additionally, we
utilize Neighborhood Expansion to leverage high-confidence pseudo-labeled
samples in the target domain, diversifying the label information of the target
domain and thereby further increasing the performance of the adaptation model.
Accordingly, the proposed approach outperforms existing state-of-the-art
methods, achieving significant accuracy improvements on popular SSDA
benchmarks, including DomainNet, Office-Home, and Office-31.
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11455 title=Abstract>arXiv:2401.11455</a> [<a href=https://arxiv.org/pdf/2401.11455 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11455 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Study on the Sorting Performance for Reactor Monte Carlo Neutron Transport on Apple Unified Memory GPUs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Changyuan Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>In simulation of nuclear reactor physics using the Monte Carlo neutron
transport method on GPUs, the sorting of particles play a significant role in
execution performance. Traditionally, CPUs and GPUs are separated devices
connected with low data transfer rate and high data transfer latency. Emerging
computing chips tend to integrate CPUs and GPUs. One example is the Apple
silicon chips with unified memory. Such a unified memory chips has opened doors
for new strategies of collaboration between CPUs and GPUs for Monte Carlo
neutron transport. Sorting particle on CPU and transport on GPU is an example
of such new strategy, which has been suffering the high CPU-GPU data transfer
latency on the traditional devices with separated CPU and GPU. The finding is
that for the Apple M2 max chip, sorting on CPU leads to better performance than
sorting on GPU for the ExaSMR whole core benchmark problems, while for the
HTR-10 high temperature gas reactor fuel pebble problem, sorting on GPU is more
efficient. The features of partially sorted particle order have been identified
to contribute to the higher performance with CPU sort than GPU for the ExaSMR
problem. The in-house code using both CPUs and GPUs achieves 7.5 times power
efficiency that of OpenMC on CPUs for ExaSMR whole core and 50 times for HTR-10
fuel pebble benchmark problems.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11458 title=Abstract>arXiv:2401.11458</a> [<a href=https://arxiv.org/pdf/2401.11458 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11458 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Songyang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Q">Qiming Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+W">Wei Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+S">Shihan Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J">Junjie Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Rui Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yicheng Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+H">Hang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The success of AI assistants based on Language Models (LLMs) hinges on
Reinforcement Learning from Human Feedback (RLHF) to comprehend and align with
user intentions. However, traditional alignment algorithms, such as PPO, are
hampered by complex annotation and training requirements. This reliance limits
the applicability of RLHF and hinders the development of professional
assistants tailored to diverse human preferences. In this work, we introduce
\textit{Linear Alignment}, a novel algorithm that aligns language models with
human preferences in one single inference step, eliminating the reliance on
data annotation and model training. Linear alignment incorporates a new
parameterization for policy optimization under divergence constraints, which
enables the extraction of optimal policy in a closed-form manner and
facilitates the direct estimation of the aligned response. Extensive
experiments on both general and personalized preference datasets demonstrate
that linear alignment significantly enhances the performance and efficiency of
LLM alignment across diverse scenarios. Our code and dataset will be published
on \url{https://github.com/Wizardcoast/Linear_Alignment.git}.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11459 title=Abstract>arXiv:2401.11459</a> [<a href=https://arxiv.org/pdf/2401.11459 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11459 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cong%2C+R">Rongqing Cong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+W">Wenyang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingxuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+B">Bangning Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zebin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuchao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+R">Ru Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Bonan Yan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> for associated source codes, see <a href=https://bonany.cc/attentionleg>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs) with Transformer architectures have become
phenomenal in natural language processing, multimodal generative artificial
intelligence, and agent-oriented artificial intelligence. The self-attention
module is the most dominating sub-structure inside Transformer-based LLMs.
Computation using general-purpose graphics processing units (GPUs) inflicts
reckless demand for I/O bandwidth for transferring intermediate calculation
results between memories and processing units. To tackle this challenge, this
work develops a fully customized vanilla self-attention accelerator,
AttentionLego, as the basic building block for constructing spatially
expandable LLM processors. AttentionLego provides basic implementation with
fully-customized digital logic incorporating Processing-In-Memory (PIM)
technology. It is based on PIM-based matrix-vector multiplication and look-up
table-based Softmax design. The open-source code is available online:
https://bonany.cc/attentionleg.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11462 title=Abstract>arXiv:2401.11462</a> [<a href=https://arxiv.org/pdf/2401.11462 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11462 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11462 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Frost Prediction Using Machine Learning Methods in Fars Province
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barooni%2C+M">Milad Barooni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziarati%2C+K">Koorush Ziarati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barooni%2C+A">Ali Barooni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accpeted by 28th International Computer Conference, Computer Society of Iran (CSICC)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>One of the common hazards and issues in meteorology and agriculture is the
problem of frost, chilling or freezing. This event occurs when the minimum
ambient temperature falls below a certain value. This phenomenon causes a lot
of damage to the country, especially Fars province. Solving this problem
requires that, in addition to predicting the minimum temperature, we can
provide enough time to implement the necessary measures. Empirical methods have
been provided by the Food and Agriculture Organization (FAO), which can predict
the minimum temperature, but not in time. In addition to this, we can use
machine learning methods to model the minimum temperature. In this study, we
have used three methods Gated Recurrent Unit (GRU), Temporal Convolutional
Network (TCN) as deep learning methods, and Gradient Boosting (XGBoost). A
customized loss function designed for methods based on deep learning, which can
be effective in reducing prediction errors. With methods based on deep learning
models, not only do we observe a reduction in RMSE error compared to empirical
methods but also have more time to predict minimum temperature. Thus, we can
model the minimum temperature for the next 24 hours by having the current 24
hours. With the gradient boosting model (XGBoost) we can keep the prediction
time as deep learning and RMSE error reduced. Finally, we experimentally
concluded that machine learning methods work better than empirical methods and
XGBoost model can have better performance in this problem among other
implemented.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11463 title=Abstract>arXiv:2401.11463</a> [<a href=https://arxiv.org/pdf/2401.11463 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11463 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11463 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Estimating the Usefulness of Clarifying Questions and Answers for Conversational Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sekuli%C4%87%2C+I">Ivan Sekulić</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%81ajewska%2C+W">Weronika Łajewska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balog%2C+K">Krisztian Balog</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crestani%2C+F">Fabio Crestani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the author's version of the work. The definitive version is published in: Proceedings of the 46th European Conference on Information Retrieval (ECIR '24), March 24-28, 2024, Glasgow, Scotland
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>While the body of research directed towards constructing and generating
clarifying questions in mixed-initiative conversational search systems is vast,
research aimed at processing and comprehending users' answers to such questions
is scarce. To this end, we present a simple yet effective method for processing
answers to clarifying questions, moving away from previous work that simply
appends answers to the original query and thus potentially degrades retrieval
performance. Specifically, we propose a classifier for assessing usefulness of
the prompted clarifying question and an answer given by the user. Useful
questions or answers are further appended to the conversation history and
passed to a transformer-based query rewriting module. Results demonstrate
significant improvements over strong non-mixed-initiative baselines.
Furthermore, the proposed approach mitigates the performance drops when non
useful questions and answers are utilized.
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11467 title=Abstract>arXiv:2401.11467</a> [<a href=https://arxiv.org/pdf/2401.11467 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11467 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Over-Reasoning and Redundant Calculation of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang%2C+C">Cheng-Han Chiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 main conference paper. Camera-ready version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models (LLMs) can solve problems step-by-step. While this
chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if
LLMs \textit{know} when to use CoT and whether those CoT are always necessary
to answer the question. This paper shows that LLMs tend to generate redundant
calculations and reasoning on a manually constructed math QA dataset,
GSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answered
without any calculations, but LLMs, including Llama-2 models and Claude-2, tend
to generate lengthy and unnecessary calculations to answer the questions. We
also conduct experiments to explain why LLMs generate redundant calculations
and reasonings. GSM8K-Zero is publicly available at
https://github.com/d223302/Over-Reasoning-of-LLMs and
https://huggingface.co/datasets/dcml0714/GSM8K-Zero.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11469 title=Abstract>arXiv:2401.11469</a> [<a href=https://arxiv.org/pdf/2401.11469 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11469 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Ning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chuanfei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+J">Jie Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhiqiang Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yu Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Transformer-based models are becoming deeper and larger recently. For better
scalability, an underlying training solution in industry is to split billions
of parameters (tensors) into many tasks and then run them across homogeneous
accelerators (e.g., GPUs). However, such dedicated compute cluster is
prohibitively expensive in academia and moderate companies. An economic
replacement is to aggregate existing heterogeneous devices and share resources
among multi-tenants. Nevertheless, static hardware configurations and dynamic
resource contention definitely cause straggling tasks, which heavily slows down
the overall training efficiency. Existing works feature contributions mainly
tailored for traditional data parallelism. They cannot work well for the new
tensor parallelism due to strict communication and correctness constraints.
<br>In this paper we first present ZERO-resizing, a novel dynamic workload
balancing technique without any data migration. We tune workloads in real-time
by temporarily resizing matrices involved in core tensor-related computations.
We particularly design data imputation and priority selection policies to
respectively satisfy consistency constraint required by normal training and
reduce the accuracy loss. We also give a lightweight data migration technique
without loss of accuracy, to cope with heavy heterogeneity. Our final
SEMI-migration solution is built on top of these two techniques and can
adaptively distinguish their respective balancing missions, to achieve an
overall success in efficiency and accuracy. Extensive experiments on the
representative Colossal-AI platform validate the effectiveness of our
proposals.
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11470 title=Abstract>arXiv:2401.11470</a> [<a href=https://arxiv.org/pdf/2401.11470 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11470 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Missing Modality in Multimodal Egocentric Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramazanova%2C+M">Merey Ramazanova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pardo%2C+A">Alejandro Pardo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alwassel%2C+H">Humam Alwassel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multimodal video understanding is crucial for analyzing egocentric videos,
where integrating multiple sensory signals significantly enhances action
recognition and moment localization. However, practical applications often
grapple with incomplete modalities due to factors like privacy concerns,
efficiency demands, or hardware malfunctions. Addressing this, our study delves
into the impact of missing modalities on egocentric action recognition,
particularly within transformer-based models. We introduce a novel concept
-Missing Modality Token (MMT)-to maintain performance even when modalities are
absent, a strategy that proves effective in the Ego4D, Epic-Kitchens, and
Epic-Sounds datasets. Our method mitigates the performance loss, reducing it
from its original <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-461 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.84em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-462><span class=mo id=MathJax-Span-463 style=font-family:MathJax_Main>∼</span><span class=mn id=MathJax-Span-464 style=font-family:MathJax_Main;padding-left:0.292em>30</span><span class=mi id=MathJax-Span-465 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> drop to only <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-466 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.84em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-467><span class=mo id=MathJax-Span-468 style=font-family:MathJax_Main>∼</span><span class=mn id=MathJax-Span-469 style=font-family:MathJax_Main;padding-left:0.292em>10</span><span class=mi id=MathJax-Span-470 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> when half of the test
set is modal-incomplete. Through extensive experimentation, we demonstrate the
adaptability of MMT to different training scenarios and its superiority in
handling missing modalities compared to current methods. Our research
contributes a comprehensive analysis and an innovative approach, opening
avenues for more resilient multimodal systems in real-world settings.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11471 title=Abstract>arXiv:2401.11471</a> [<a href=https://arxiv.org/pdf/2401.11471 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11471 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LR-CNN: Lightweight Row-centric Convolutional Neural Network Training for Memory Reduction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hangyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Ning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chuanfei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+J">Jie Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhiqiang Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yu Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+G">Ge Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In the last decade, Convolutional Neural Network with a multi-layer
architecture has advanced rapidly. However, training its complex network is
very space-consuming, since a lot of intermediate data are preserved across
layers, especially when processing high-dimension inputs with a big batch size.
That poses great challenges to the limited memory capacity of current
accelerators (e.g., GPUs). Existing efforts mitigate such bottleneck by
external auxiliary solutions with additional hardware costs, and internal
modifications with potential accuracy penalty. Differently, our analysis
reveals that computations intra- and inter-layers exhibit the spatial-temporal
weak dependency and even complete independency features. That inspires us to
break the traditional layer-by-layer (column) dataflow rule. Now operations are
novelly re-organized into rows throughout all convolution layers. This
lightweight design allows a majority of intermediate data to be removed without
any loss of accuracy. We particularly study the weak dependency between two
consecutive rows. For the resulting skewed memory consumption, we give two
solutions with different favorite scenarios. Evaluations on two representative
networks confirm the effectiveness. We also validate that our middle dataflow
optimization can be smoothly embraced by existing works for better memory
reduction.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11472 title=Abstract>arXiv:2401.11472</a> [<a href=https://arxiv.org/pdf/2401.11472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Abstract Weighted Based Gradual Semantics in Argumentation Theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Libman%2C+A">Assaf Libman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oren%2C+N">Nir Oren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+B">Bruno Yun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Weighted gradual semantics provide an acceptability degree to each argument
representing the strength of the argument, computed based on factors including
background evidence for the argument, and taking into account interactions
between this argument and others. We introduce four important problems linking
gradual semantics and acceptability degrees. First, we reexamine the inverse
problem, seeking to identify the argument weights of the argumentation
framework which lead to a specific final acceptability degree. Second, we ask
whether the function mapping between argument weights and acceptability degrees
is injective or a homeomorphism onto its image. Third, we ask whether argument
weights can be found when preferences, rather than acceptability degrees for
arguments are considered. Fourth, we consider the topology of the space of
valid acceptability degrees, asking whether gaps exist in this space. While
different gradual semantics have been proposed in the literature, in this
paper, we identify a large family of weighted gradual semantics, called
abstract weighted based gradual semantics. These generalise many of the
existing semantics while maintaining desirable properties such as convergence
to a unique fixed point. We also show that a sub-family of the weighted gradual
semantics, called abstract weighted (Lp,lambda,mu,A)-based gradual semantics
and which include well-known semantics, solve all four of the aforementioned
problems.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11478 title=Abstract>arXiv:2401.11478</a> [<a href=https://arxiv.org/pdf/2401.11478 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11478 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+J">Jiarui Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weiwen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+R">Ruiming Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>A vast amount of user behavior data is constantly accumulating on today's
large recommendation platforms, recording users' various interests and tastes.
Preserving knowledge from the old data while new data continually arrives is a
vital problem for recommender systems. Existing approaches generally seek to
save the knowledge implicitly in the model parameters. However, such a
parameter-centric approach lacks scalability and flexibility -- the capacity is
hard to scale, and the knowledge is inflexible to utilize. Hence, in this work,
we propose a framework that turns massive user behavior data to retrievable
knowledge (D2K). It is a data-centric approach that is model-agnostic and easy
to scale up. Different from only storing unary knowledge such as the user-side
or item-side information, D2K propose to store ternary knowledge for
recommendation, which is determined by the complete recommendation factors --
user, item, and context. The knowledge retrieved by target samples can be
directly used to enhance the performance of any recommendation algorithms.
Specifically, we introduce a Transformer-based knowledge encoder to transform
the old data into knowledge with the user-item-context cross features. A
personalized knowledge adaptation unit is devised to effectively exploit the
information from the knowledge base by adapting the retrieved knowledge to the
target samples. Extensive experiments on two public datasets show that D2K
significantly outperforms existing baselines and is compatible with a major
collection of recommendation algorithms.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11483 title=Abstract>arXiv:2401.11483</a> [<a href=https://arxiv.org/pdf/2401.11483 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11483 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed Traffic Signal Control of Interconnected Intersections: A Two-Lane Traffic Network Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ru%2C+X">Xinfeng Ru</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xia%2C+W">Weiguo Xia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bai%2C+T">Ting Bai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> journal paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Adaptation and Self-Organizing Systems (nlin.AO)
</div>
<p class=mathjax>Practical and accurate traffic models play an important role in capturing
real traffic dynamics and then in achieving effective control performance. This
paper studies traffic signal control in a traffic network with multiple
interconnected intersections, where the target is to balance the vehicle
density on each lane by controlling the green times of each phase at every
intersection. Different from traditional road-based modeling schemes, a
two-lane intersection model is first proposed to model the flow propagation in
a more accurate way. A distributed model predictive control (MPC) method is
then presented to assign the green times. To enable the real-time feasibility
of the proposed approach, the alternating direction method of multipliers
(ADMM) is incorporated with the distributed MPC scheme for solving the problem.
Finally, the simulation studies performed in VISSIM for a six-intersection
traffic network in Dalian, China, show the effectiveness and characteristics of
the proposed method.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11485 title=Abstract>arXiv:2401.11485</a> [<a href=https://arxiv.org/pdf/2401.11485 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11485 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ColorVideoVDP: A visual difference predictor for image, video and display distortions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mantiuk%2C+R+K">Rafal K. Mantiuk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hanji%2C+P">Param Hanji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ashraf%2C+M">Maliha Ashraf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asano%2C+Y">Yuta Asano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chapiro%2C+A">Alexandre Chapiro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>ColorVideoVDP is a video and image quality metric that models spatial and
temporal aspects of vision, for both luminance and color. The metric is built
on novel psychophysical models of chromatic spatiotemporal contrast sensitivity
and cross-channel contrast masking. It accounts for the viewing conditions,
geometric, and photometric characteristics of the display. It was trained to
predict common video streaming distortions (e.g. video compression, rescaling,
and transmission errors), and also 8 new distortion types related to AR/VR
displays (e.g. light source and waveguide non-uniformities). To address the
latter application, we collected our novel XR-Display-Artifact-Video quality
dataset (XR-DAVID), comprised of 336 distorted videos. Extensive testing on
XR-DAVID, as well as several datasets from the literature, indicate a
significant gain in prediction performance compared to existing metrics.
ColorVideoVDP opens the doors to many novel applications which require the
joint automated spatiotemporal assessment of luminance and color distortions,
including video streaming, display specification and design, visual comparison
of results, and perceptually-guided quality optimization.
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11487 title=Abstract>arXiv:2401.11487</a> [<a href=https://arxiv.org/pdf/2401.11487 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11487 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Better Inclusivity: A Diverse Tweet Corpus of English Varieties
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pham%2C+N">Nhi Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pham%2C+L">Lachlan Pham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meyers%2C+A+L">Adam L. Meyers</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages (including limitations, references and appendices), 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The prevalence of social media presents a growing opportunity to collect and
analyse examples of English varieties. Whilst usage of these varieties was -
and, in many cases, still is - used only in spoken contexts or hard-to-access
private messages, social media sites like Twitter provide a platform for users
to communicate informally in a scrapeable format. Notably, Indian English
(Hinglish), Singaporean English (Singlish), and African-American English (AAE)
can be commonly found online. These varieties pose a challenge to existing
natural language processing (NLP) tools as they often differ orthographically
and syntactically from standard English for which the majority of these tools
are built. NLP models trained on standard English texts produced biased
outcomes for users of underrepresented varieties. Some research has aimed to
overcome the inherent biases caused by unrepresentative data through techniques
like data augmentation or adjusting training models.
<br>We aim to address the issue of bias at its root - the data itself. We curate
a dataset of tweets from countries with high proportions of underserved English
variety speakers, and propose an annotation framework of six categorical
classifications along a pseudo-spectrum that measures the degree of standard
English and that thereby indirectly aims to surface the manifestations of
English varieties in these tweets. Following best annotation practices, our
growing corpus features 170,800 tweets taken from 7 countries, labeled by
annotators who are from those countries and can communicate in
regionally-dominant varieties of English. Our corpus highlights the accuracy
discrepancies in pre-trained language identifiers between western English and
non-western (i.e., less standard) English varieties. We hope to contribute to
the growing literature identifying and reducing the implicit demographic
discrepancies in NLP.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11488 title=Abstract>arXiv:2401.11488</a> [<a href=https://arxiv.org/pdf/2401.11488 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11488 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=F%C3%B6rster%2C+N">Nikolas Förster</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kirchg%C3%A4ssner%2C+W">Wilhelm Kirchgässner</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Piepenbrock%2C+T">Till Piepenbrock</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schweins%2C+O">Oliver Schweins</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wallscheid%2C+O">Oliver Wallscheid</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Competition submission version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph)
</div>
<p class=mathjax>The MagNet Challenge 2023 calls upon competitors to develop data-driven
models for the material-specific, waveform-agnostic estimation of steady-state
power losses in toroidal ferrite cores. The following HARDCORE (H-field and
power loss estimation for Arbitrary waveforms with Residual, Dilated
convolutional neural networks in ferrite COREs) approach shows that a residual
convolutional neural network with physics-informed extensions can serve this
task efficiently when trained on observational data beforehand. One key
solution element is an intermediate model layer which first reconstructs the bh
curve and then estimates the power losses based on the curve's area rendering
the proposed topology physically interpretable. In addition, emphasis was
placed on expert-based feature engineering and information-rich inputs in order
to enable a lean model architecture. A model is trained from scratch for each
material, while the topology remains the same. A Pareto-style trade-off between
model size and estimation accuracy is demonstrated, which yields an optimum at
as low as 1755 parameters and down to below 8\,\% for the 95-th percentile of
the relative error for the worst-case material with sufficient samples.
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11489 title=Abstract>arXiv:2401.11489</a> [<a href=https://arxiv.org/pdf/2401.11489 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11489 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11489 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MapChange: Enhancing Semantic Change Detection with Temporal-Invariant Historical Maps Based on Deep Triplet Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yinhe Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+S">Sunan Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Zhuo Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+S">Shiqi Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yanfei Zhong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Semantic Change Detection (SCD) is recognized as both a crucial and
challenging task in the field of image analysis. Traditional methods for SCD
have predominantly relied on the comparison of image pairs. However, this
approach is significantly hindered by substantial imaging differences, which
arise due to variations in shooting times, atmospheric conditions, and angles.
Such discrepancies lead to two primary issues: the under-detection of minor yet
significant changes, and the generation of false alarms due to temporal
variances. These factors often result in unchanged objects appearing markedly
different in multi-temporal images. In response to these challenges, the
MapChange framework has been developed. This framework introduces a novel
paradigm that synergizes temporal-invariant historical map data with
contemporary high-resolution images. By employing this combination, the
temporal variance inherent in conventional image pair comparisons is
effectively mitigated. The efficacy of the MapChange framework has been
empirically validated through comprehensive testing on two public datasets.
These tests have demonstrated the framework's marked superiority over existing
state-of-the-art SCD methods.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11490 title=Abstract>arXiv:2401.11490</a> [<a href=https://arxiv.org/pdf/2401.11490 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11490 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reliable Low-Delay Routing In Space with Routing-Oblivious LEO Satellites
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vissicchio%2C+S">Stefano Vissicchio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Handley%2C+M">Mark Handley</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Large networks of Low Earth Orbit (LEO) satellites are being built using
inter-satellite lasers. These networks promise to offer low-latency wide-area
connectivity, but reliably routing such traffic is difficult, as satellites are
very resource-constrained and paths change constantly.
<br>We present STARGLIDER, a new routing system where path computation is
delegated to ground stations, while satellites are routing-oblivious and
exchange no information at runtime. Yet, STARGLIDER satellites effectively
support reliability primitives: they fast reroute packets over near-optimal
paths when links fail, and validate that packets sent by potentially malicious
ground stations follow reasonable paths.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11491 title=Abstract>arXiv:2401.11491</a> [<a href=https://arxiv.org/pdf/2401.11491 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11491 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11491 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BA-LINS: A Frame-to-Frame Bundle Adjustment for LiDAR-Inertial Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+H">Hailiang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tisheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liqiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=yuan%2C+M">Man yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+X">Xiaoji Niu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Bundle Adjustment (BA) has been proven to improve the accuracy of the LiDAR
mapping. However, the BA method has not been properly employed in a
dead-reckoning navigation system. In this paper, we present a frame-to-frame
(F2F) BA for LiDAR-inertial navigation, named BA-LINS. Based on the direct F2F
point-cloud association, the same-plane points are associated among the LiDAR
keyframes. Hence, the plane-point BA measurement can be constructed using the
same-plane points. The LiDAR BA measurements and the inertial measurement unit
(IMU)-preintegration measurements are tightly integrated under the framework of
factor graph optimization. An effective adaptive covariance estimation
algorithm for LiDAR BA measurements is proposed to further improve the accuracy
of BA-LINS. We conduct exhaustive real-world experiments on public and private
datasets to examine the proposed BA-LINS. The results demonstrate that BA-LINS
yields superior accuracy to state-of-the-art methods. Compared to the baseline
system FF-LINS, the absolute translation accuracy and state-estimation
efficiency of BA-LINS are improved by 29.5% and 28.7%, respectively, on the
private dataset. Besides, the ablation experiment results exhibit that the
proposed adaptive covariance estimation algorithm can notably improve the
accuracy and robustness of BA-LINS.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11492 title=Abstract>arXiv:2401.11492</a> [<a href=https://arxiv.org/pdf/2401.11492 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11492 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Edge-Enabled Real-time Railway Track Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chenglin%2C+C">Chen Chenglin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fei%2C+W">Wang Fei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+Y">Yang Min</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yong%2C+Q">Qin Yong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+B">Bai Yun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Accurate and rapid railway track segmentation can assist automatic train
driving and is a key step in early warning to fixed or moving obstacles on the
railway track. However, certain existing algorithms tailored for track
segmentation often struggle to meet the requirements of real-time and
efficiency on resource-constrained edge devices. Considering this challenge, we
propose an edge-enabled real-time railway track segmentation algorithm, which
is optimized to be suitable for edge applications by optimizing the network
structure and quantizing the model after training. Initially, Ghost convolution
is introduced to reduce the complexity of the backbone, thereby achieving the
extraction of key information of the interested region at a lower cost. To
further reduce the model complexity and calculation, a new lightweight
detection head is proposed to achieve the best balance between accuracy and
efficiency. Subsequently, we introduce quantization techniques to map the
model's floating-point weights and activation values into lower bit-width
fixed-point representations, reducing computational demands and memory
footprint, ultimately accelerating the model's inference. Finally, we draw
inspiration from GPU parallel programming principles to expedite the
pre-processing and post-processing stages of the algorithm by doing parallel
processing. The approach is evaluated with public and challenging dataset
RailSem19 and tested on Jetson Nano. Experimental results demonstrate that our
enhanced algorithm achieves an accuracy level of 83.3% while achieving a
real-time inference rate of 25 frames per second when the input size is
480x480, thereby effectively meeting the requirements for real-time and
high-efficiency operation.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11496 title=Abstract>arXiv:2401.11496</a> [<a href=https://arxiv.org/pdf/2401.11496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11496 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On a Group Under Which Symmetric Reed-Muller Codes are Invariant
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toplu%2C+S+K">Sibel Kurt Toplu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arikan%2C+T">Talha Arikan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aydo%C4%9FDu%2C+P">Pinar AydoğDu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yayla%2C+O">OğUz Yayla</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The Reed-Muller codes are a family of error-correcting codes that have been
widely studied in coding theory. In 2020, Wei Yan and Sian-Jheng Lin introduced
a variant of Reed-Muller codes so called symmetric Reed-Muller codes. We
investigate linear maps of the automorphism group of symmetric Reed-Muller
codes and show that the set of these linear maps forms a subgroup of the
general linear group, which is the automorphism group of punctured Reed-Muller
codes. We provide a method to determine all the automorphisms in this subgroup
explicitly for some special cases.
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11499 title=Abstract>arXiv:2401.11499</a> [<a href=https://arxiv.org/pdf/2401.11499 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11499 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Supervised Bird's Eye View Motion Prediction with Cross-Modality Signals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+S">Shaoheng Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zuhong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mingyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chenxin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yiqi Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Siheng Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Learning the dense bird's eye view (BEV) motion flow in a self-supervised
manner is an emerging research for robotics and autonomous driving. Current
self-supervised methods mainly rely on point correspondences between point
clouds, which may introduce the problems of fake flow and inconsistency,
hindering the model's ability to learn accurate and realistic motion. In this
paper, we introduce a novel cross-modality self-supervised training framework
that effectively addresses these issues by leveraging multi-modality data to
obtain supervision signals. We design three innovative supervision signals to
preserve the inherent properties of scene motion, including the masked Chamfer
distance loss, the piecewise rigidity loss, and the temporal consistency loss.
Through extensive experiments, we demonstrate that our proposed self-supervised
framework outperforms all previous self-supervision methods for the motion
prediction task.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11500 title=Abstract>arXiv:2401.11500</a> [<a href=https://arxiv.org/pdf/2401.11500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yanhong Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Ceng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+C">Chenlong Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+Z">Zebing Mao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper presents an innovative approach to integrating Large Language
Models (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for
precise color synthesis in automation systems. We propose a novel framework
that employs fine-tuned LLMs to interpret natural language commands and convert
them into specific operational instructions for EHD pump control. This approach
aims to enhance user interaction with complex hardware systems, making it more
intuitive and efficient. The methodology involves four key steps: fine-tuning
the language model with a dataset of color specifications and corresponding
Arduino code, developing a natural language processing interface, translating
user inputs into executable Arduino code, and controlling EHD pumps for
accurate color mixing. Conceptual experiment results, based on theoretical
assumptions, indicate a high potential for accurate color synthesis, efficient
language model interpretation, and reliable EHD pump operation. This research
extends the application of LLMs beyond text-based tasks, demonstrating their
potential in industrial automation and control systems. While highlighting the
limitations and the need for real-world testing, this study opens new avenues
for AI applications in physical system control and sets a foundation for future
advancements in AI-driven automation technologies.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11504 title=Abstract>arXiv:2401.11504</a> [<a href=https://arxiv.org/pdf/2401.11504 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11504 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Y. Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+D">D. Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+D">D. Cai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Long text generation, such as novel writing or discourse-level translation
with extremely long contexts, presents significant challenges to current
language models. Existing methods mainly focus on extending the model's context
window through strategies like length extrapolation. However, these approaches
demand substantial hardware resources during the training and/or inference
phases. Our proposed method, Temp-Lora, introduces an alternative concept.
Instead of relying on the KV cache to store all context information, Temp-Lora
embeds this information directly into the model's parameters. In the process of
long text generation, we use a temporary Lora module, progressively trained
with text generated previously. This approach not only efficiently preserves
contextual knowledge but also prevents any permanent alteration to the model's
parameters given that the module is discarded post-generation. Extensive
experiments on the PG19 language modeling benchmark and the GuoFeng
discourse-level translation benchmark validate the effectiveness of Temp-Lora.
Our results show that: 1) Temp-Lora substantially enhances generation quality
for long texts, as indicated by a 13.2% decrease in perplexity on a subset of
PG19, and a 29.6% decrease in perplexity along with a 53.2% increase in BLEU
score on GuoFeng, 2) Temp-Lora is compatible with and enhances most existing
long text generation methods, and 3) Temp-Lora can greatly reduce computational
costs by shortening the context window. While ensuring a slight improvement in
generation quality (a decrease of 3.8% in PPL), it enables a reduction of 70.5%
in the FLOPs required for inference and a 51.5% decrease in latency.
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11505 title=Abstract>arXiv:2401.11505</a> [<a href=https://arxiv.org/pdf/2401.11505 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11505 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jawook Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+H">Han-Cheol Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jiho Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+K">Kihyun You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+E+K">Eun Kyoung Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roh%2C+B">Byungseok Roh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>Free-text radiology reports present a rich data source for various medical
tasks, but effectively labeling these texts remains challenging. Traditional
rule-based labeling methods fall short of capturing the nuances of diverse
free-text patterns. Moreover, models using expert-annotated data are limited by
data scarcity and pre-defined classes, impacting their performance, flexibility
and scalability. To address these issues, our study offers three main
contributions: 1) We demonstrate the potential of GPT as an adept labeler using
carefully designed prompts. 2) Utilizing only the data labeled by GPT, we
trained a BERT-based labeler, CheX-GPT, which operates faster and more
efficiently than its GPT counterpart. 3) To benchmark labeler performance, we
introduced a publicly available expert-annotated test set, MIMIC-500,
comprising 500 cases from the MIMIC validation set. Our findings demonstrate
that CheX-GPT not only excels in labeling accuracy over existing models, but
also showcases superior efficiency, flexibility, and scalability, supported by
our introduction of the MIMIC-500 dataset for robust benchmarking. Code and
models are available at https://github.com/kakaobrain/CheXGPT.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11506 title=Abstract>arXiv:2401.11506</a> [<a href=https://arxiv.org/pdf/2401.11506 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11506 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11506 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Recommendation Diversity by Re-ranking with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carraro%2C+D">Diego Carraro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bridge%2C+D">Derek Bridge</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>It has long been recognized that it is not enough for a Recommender System
(RS) to provide recommendations based only on their relevance to users. Among
many other criteria, the set of recommendations may need to be diverse in order
to handle uncertainty and offer a meaningful choice. The literature reports
many ways of measuring diversity and ways of improving the diversity of a set
of recommendations, most notably by re-ranking and selecting from a larger set
of candidate recommendations. Driven by promising insights from the literature
on how to incorporate versatile Large Language Models (LLMs) into the RS
pipeline, in this paper, we show how LLMs can be used for diversity re-ranking.
<br>We begin with an informal study that verifies that LLMs can be used for
re-ranking tasks and do have some understanding of the concept of diversity.
Then, we design a more rigorous methodology where LLMs are prompted to generate
a diverse ranking from a candidate ranking using various prompt templates with
different re-ranking instructions in a zero-shot fashion. We conduct
comprehensive experiments testing state-of-the-art conversational LLMs from the
GPT and Llama families. We compare their re-ranking capabilities with random
re-ranking and various traditional re-ranking methods from the literature (MMR,
xQuAD and RxQuAD). We find that LLM-based re-ranking outperforms random
re-ranking across all the metrics that we use but does not perform as well as
the traditional re-ranking methods. We gain insight into prompt design for this
task (e.g.\ on the whole, it is better to prompt for diversity rather than a
balance of diversity and relevance). Given that no special knowledge
engineering is needed, we conclude that LLM-based re-ranking is a promising
approach, and we highlight directions for future research. We open-source the
code of our experiments for reproducibility.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11509 title=Abstract>arXiv:2401.11509</a> [<a href=https://arxiv.org/pdf/2401.11509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simple Domain Adaptation for Sparse Retrievers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vast%2C+M">Mathias Vast</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zong%2C+Y">Yuxuan Zong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Cooten%2C+B">Basile Van Cooten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piwowarski%2C+B">Benjamin Piwowarski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soulier%2C+L">Laure Soulier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ECIR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>In Information Retrieval, and more generally in Natural Language Processing,
adapting models to specific domains is conducted through fine-tuning. Despite
the successes achieved by this method and its versatility, the need for
human-curated and labeled data makes it impractical to transfer to new tasks,
domains, and/or languages when training data doesn't exist. Using the model
without training (zero-shot) is another option that however suffers an
effectiveness cost, especially in the case of first-stage retrievers. Numerous
research directions have emerged to tackle these issues, most of them in the
context of adapting to a task or a language. However, the literature is scarcer
for domain (or topic) adaptation. In this paper, we address this issue of
cross-topic discrepancy for a sparse first-stage retriever by transposing a
method initially designed for language adaptation. By leveraging pre-training
on the target data to learn domain-specific knowledge, this technique
alleviates the need for annotated data and expands the scope of domain
adaptation. Despite their relatively good generalization ability, we show that
even sparse retrievers can benefit from our simple domain adaptation method.
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11511 title=Abstract>arXiv:2401.11511</a> [<a href=https://arxiv.org/pdf/2401.11511 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11511 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MobileARLoc: On-device Robust Absolute Localisation for Pervasive Markerless Mobile AR
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Changkun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yukun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Braud%2C+T">Tristan Braud</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication at the 3rd edition of the Pervasive and Resource-Constrained AI (PerConAI) workshop (co-located with PerCom 2024). arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2308.05394>arXiv:2308.05394</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent years have seen significant improvement in absolute camera pose
estimation, paving the way for pervasive markerless Augmented Reality (AR).
However, accurate absolute pose estimation techniques are computation- and
storage-heavy, requiring computation offloading. As such, AR systems rely on
visual-inertial odometry (VIO) to track the device's relative pose between
requests to the server. However, VIO suffers from drift, requiring frequent
absolute repositioning. This paper introduces MobileARLoc, a new framework for
on-device large-scale markerless mobile AR that combines an absolute pose
regressor (APR) with a local VIO tracking system. Absolute pose regressors
(APRs) provide fast on-device pose estimation at the cost of reduced accuracy.
To address APR accuracy and reduce VIO drift, MobileARLoc creates a feedback
loop where VIO pose estimations refine the APR predictions. The VIO system
identifies reliable predictions of APR, which are then used to compensate for
the VIO drift. We comprehensively evaluate MobileARLoc through dataset
simulations. MobileARLoc halves the error compared to the underlying APR and
achieve fast (80\,ms) on-device inference speed.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11512 title=Abstract>arXiv:2401.11512</a> [<a href=https://arxiv.org/pdf/2401.11512 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11512 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Information-Theoretic State Variable Selection for Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Westphal%2C+C">Charles Westphal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hailes%2C+S">Stephen Hailes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)
</div>
<p class=mathjax>Identifying the most suitable variables to represent the state is a
fundamental challenge in Reinforcement Learning (RL). These variables must
efficiently capture the information necessary for making optimal decisions. In
order to address this problem, in this paper, we introduce the Transfer Entropy
Redundancy Criterion (TERC), an information-theoretic criterion, which
determines if there is \textit{entropy transferred} from state variables to
actions during training. We define an algorithm based on TERC that provably
excludes variables from the state that have no effect on the final performance
of the agent, resulting in more sample efficient learning. Experimental results
show that this speed-up is present across three different algorithm classes
(represented by tabular Q-learning, Actor-Critic, and Proximal Policy
Optimization (PPO)) in a variety of environments. Furthermore, to highlight the
differences between the proposed methodology and the current state-of-the-art
feature selection approaches, we present a series of controlled experiments on
synthetic data, before generalizing to real-world decision-making tasks. We
also introduce a representation of the problem that compactly captures the
transfer of information from state variables to actions as Bayesian networks.
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11519 title=Abstract>arXiv:2401.11519</a> [<a href=https://arxiv.org/pdf/2401.11519 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11519 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CaBuAr: California Burned Areas dataset for delineation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cambrin%2C+D+R">Daniele Rege Cambrin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colomba%2C+L">Luca Colomba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garza%2C+P">Paolo Garza</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the IEEE Geoscience and Remote Sensing Magazine
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Forest wildfires represent one of the catastrophic events that, over the last
decades, caused huge environmental and humanitarian damages. In addition to a
significant amount of carbon dioxide emission, they are a source of risk to
society in both short-term (e.g., temporary city evacuation due to fire) and
long-term (e.g., higher risks of landslides) cases. Consequently, the
availability of tools to support local authorities in automatically identifying
burned areas plays an important role in the continuous monitoring requirement
to alleviate the aftereffects of such catastrophic events. The great
availability of satellite acquisitions coupled with computer vision techniques
represents an important step in developing such tools. This paper introduces a
novel open dataset that tackles the burned area delineation problem, a binary
segmentation problem applied to satellite imagery. The presented resource
consists of pre- and post-fire Sentinel-2 L2A acquisitions of California forest
fires that took place starting in 2015. Raster annotations were generated from
the data released by California's Department of Forestry and Fire Protection.
Moreover, in conjunction with the dataset, we release three different baselines
based on spectral indexes analyses, SegFormer, and U-Net models.
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11520 title=Abstract>arXiv:2401.11520</a> [<a href=https://arxiv.org/pdf/2401.11520 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11520 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11520 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is it a Real CD Mismatch in Interdomain Routing?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Letong%2C+S">Sun Letong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xingang%2C+S">Shi Xingang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fengyan%2C+H">Han Fengyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yin Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhiliang%2C+W">Wang Zhiliang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhang Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>In inter-domain routing, a packet is not always forwarded along the
Autonomous System (AS) level path determined by the BGP routing protocol. This
is often called control-plane and data-plane (CD) mismatch, which allows for
flexible traffic control, but also leads to operation and security issues. We
systematically analyze this phenomenon with path pairs collected from 128 pairs
of vantage points over more than 5 years, and use multiple IP-to-AS mapping
methods to compare CD paths. What is interesting is that, working at such a
large scale in turn helps us design a novel method to fairly evaluate the
accuracy of various existing mapping methods, and further develop a new mapping
method, i.e., LearnToCorrect, that can correct more than 70\% mapping errors of
the state-of-the-art one. Then we devise to identify real mismatches with
LearnToCorrect, and estimate that the real-mismatch ratio in the wild is
typically less than 6\%. At last, we use our proposed methods to detect routing
security issues, which are previously difficult to accurately find out.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11524 title=Abstract>arXiv:2401.11524</a> [<a href=https://arxiv.org/pdf/2401.11524 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11524 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Controlling the Misinformation Diffusion in Social Media by the Effect of Different Classes of Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yalabadi%2C+A+K">Ali Khodabandeh Yalabadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazdani-Jahromi%2C+M">Mehdi Yazdani-Jahromi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdidizaji%2C+S">Sina Abdidizaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garibay%2C+I">Ivan Garibay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garibay%2C+O+O">Ozlem Ozmen Garibay</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at The Computational Social Science Society of the Americas (CSS) - 2023, Annual Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>The rapid and widespread dissemination of misinformation through social
networks is a growing concern in today's digital age. This study focused on
modeling fake news diffusion, discovering the spreading dynamics, and designing
control strategies. A common approach for modeling the misinformation dynamics
is SIR-based models. Our approach is an extension of a model called 'SBFC'
which is a SIR-based model. This model has three states, Susceptible, Believer,
and Fact-Checker. The dynamics and transition between states are based on
neighbors' beliefs, hoax credibility, spreading rate, probability of verifying
the news, and probability of forgetting the current state. Our contribution is
to push this model to real social networks by considering different classes of
agents with their characteristics. We proposed two main strategies for
confronting misinformation diffusion. First, we can educate a minor class, like
scholars or influencers, to improve their ability to verify the news or
remember their state longer. The second strategy is adding fact-checker bots to
the network to spread the facts and influence their neighbors' states. Our
result shows that both of these approaches can effectively control the
misinformation spread.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11529 title=Abstract>arXiv:2401.11529</a> [<a href=https://arxiv.org/pdf/2401.11529 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11529 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computational predictions of weld structural integrity in hydrogen transport pipelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandal%2C+T+K">T. K. Mandal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parker%2C+J">J. Parker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gagliano%2C+M">M. Gagliano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Pa%C3%B1eda%2C+E">E. Martínez-Pañeda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci); Applied Physics (physics.app-ph); Chemical Physics (physics.chem-ph)
</div>
<p class=mathjax>We combine welding process modelling with deformation-diffusion-fracture
(embrittlement) simulations to predict failures in hydrogen transport
pipelines. The focus is on the structural integrity of seam welds, as these are
often the locations most susceptible to damage in gas transport infrastructure.
Finite element analyses are conducted to showcase the ability of the model to
predict cracking in pipeline steels exposed to hydrogen-containing
environments. The validated model is then employed to quantify critical H<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-471 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.466em,1000.41em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-472><span class=msubsup id=MathJax-Span-473><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-474></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=mn id=MathJax-Span-475 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
fracture pressures. The coupled, phase field-based simulations conducted
provide insight into the role of existing defects, microstructural
heterogeneity, and residual stresses. We find that under a combination of
deleterious yet realistic conditions, the critical pressure at which fracture
takes place can be as low as 15 MPa. These results bring new mechanistic
insight into the viability of using the existing natural gas pipeline network
to transport hydrogen, and the computational framework presented enables
mapping the conditions under which this can be achieved safely.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11531 title=Abstract>arXiv:2401.11531</a> [<a href=https://arxiv.org/pdf/2401.11531 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11531 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tempo: Confidentiality Preservation in Cloud-Based Neural Network Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Rongwu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Z">Zhixuan Fang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Cloud deep learning platforms provide cost-effective deep neural network
(DNN) training for customers who lack computation resources. However, cloud
systems are often untrustworthy and vulnerable to attackers, leading to growing
concerns about model privacy. Recently, researchers have sought to protect data
privacy in deep learning by leveraging CPU trusted execution environments
(TEEs), which minimize the use of cryptography, but existing works failed to
simultaneously utilize the computational resources of GPUs to assist in
training and prevent model leakage. This paper presents Tempo, the first
cloud-based deep learning system that cooperates with TEE and distributed GPUs
for efficient DNN training with model confidentiality preserved. To tackle the
challenge of preserving privacy while offloading linear algebraic operations
from TEE to GPUs for efficient batch computation, we introduce a customized
permutation-based obfuscation algorithm to blind both inputs and model
parameters. An optimization mechanism that reduces encryption operations is
proposed for faster weight updates during backpropagation to speed up training.
We implement Tempo and evaluate it with both training and inference for two
prevalent DNNs. Empirical results indicate that Tempo outperforms baselines and
offers sufficient privacy protection.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11533 title=Abstract>arXiv:2401.11533</a> [<a href=https://arxiv.org/pdf/2401.11533 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11533 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pulse Width Modulation Method Applied to Nonlinear Model Predictive Control on an Under-actuated Small Satellite
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kondo%2C+K">Kota Kondo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yoshimura%2C+Y">Yasuhiro Yoshimura</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nagasaki%2C+S">Shiji Nagasaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hanada%2C+T">Toshiya Hanada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 10 figures. In AIAA Scitech 2021 Forum
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Among various satellite actuators, magnetic torquers have been widely
equipped for stabilization and attitude control of small satellites. Although
magnetorquers are generally used with other actuators, such as momentum wheels,
this paper explores a control method where only a magnetic actuation is
available. We applied a nonlinear optimal control method, Nonlinear Model
Predictive Control (NMPC), to small satellites, employing the generalized
minimal residual (GMRES) method, which generates continuous control inputs.
Onboard magnetic actuation systems often find it challenging to produce smooth
magnetic moments as a control input; hence, we employ the Pulse Width
Modulation (PWM) method, which discretizes a control input and reduces the
burden on actuators. In our case, the PWM approach discretizes control torques
generated by the NMPC scheme. This study's main contributions are investigating
the NMPC and the GMRES method applied to small spacecraft and presenting the
PWM control system's feasibility.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11535 title=Abstract>arXiv:2401.11535</a> [<a href=https://arxiv.org/pdf/2401.11535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lingting Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhenchao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+G">Guying Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lequan Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress. 10 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Surgical 3D reconstruction is a critical area of research in robotic surgery,
with recent works adopting variants of dynamic radiance fields to achieve
success in 3D reconstruction of deformable tissues from single-viewpoint
videos. However, these methods often suffer from time-consuming optimization or
inferior quality, limiting their adoption in downstream tasks. Inspired by 3D
Gaussian Splatting, a recent trending 3D representation, we present EndoGS,
applying Gaussian Splatting for deformable endoscopic tissue reconstruction.
Specifically, our approach incorporates deformation fields to handle dynamic
scenes, depth-guided supervision to optimize 3D targets with a single
viewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As a
result, EndoGS reconstructs and renders high-quality deformable endoscopic
tissues from a single-viewpoint video, estimated depth maps, and labeled tool
masks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS
achieves superior rendering quality. Code is available at
https://github.com/HKU-MedAI/EndoGS.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11536 title=Abstract>arXiv:2401.11536</a> [<a href=https://arxiv.org/pdf/2401.11536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nonlinear Model Predictive Detumbling of Small Satellites with a Single-axis Magnetorquer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kondo%2C+K">Kota Kondo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yoshimura%2C+Y">Yasuhiro Yoshimura</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bando%2C+M">Mai Bando</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nagasaki%2C+S">Shuji Nagasaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hanada%2C+T">Toshiya Hanada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 6 figures. Journal of Guidance, Control, and Dynamics (2021)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Various actuators are used in spacecraft to achieve attitude stabilization,
including thrusters, momentum wheels, and control moment gyros. Small
satellites, however, have stringent size, weight, and cost constraints, which
makes many actuator choices prohibitive. Consequently, magnetic torquers have
commonly been applied to spacecraft to attenuate angular rates. Approaches for
dealing with under-actuation due to magnetic control torque's dependency on the
magnetic field and required high magnetic flux densities have been previously
considered. Generally speaking, control of a satellite that becomes
under-actuated as a result of on-board failures has been a recurrent theme in
the literature. Methods for controlling spacecraft with fewer actuators than
degrees of freedom are increasingly in demand due to the increased number of
small satellite launches. Magnetic torquers have been extensively investigated
for momentum management of spacecraft with momentum wheels and for nutation
damping of spin satellites, momentum-biased, and dual-spin satellites.
Nonetheless, severely under-actuated small spacecraft that carry only a
single-axis magnetic torquer have not been previously treated. This note
considers the detumbling of a small spacecraft using only a single-axis
magnetic torquer. Even with a three-axis magnetic torquer, the spacecraft is
under-actuated, while, in the case of only a single axis magnetic torquer, the
problem is considerably more demanding. Our note examines the feasibility of
spacecraft attitude control with a single-axis magnetic torquer and possible
control methods that can be used.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11538 title=Abstract>arXiv:2401.11538</a> [<a href=https://arxiv.org/pdf/2401.11538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11538 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Maintenance cost assessment for heterogeneous multi-component systems incorporating perfect inspections and waiting time to maintenance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bautista%2C+L">Lucía Bautista</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castro%2C+I+T">Inma T. Castro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landesa%2C+L">Luis Landesa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Probability (math.PR)
</div>
<p class=mathjax>Most existing research about complex systems maintenance assumes they consist
of the same type of components. However, systems can be assembled with
heterogeneous components (for example degrading and non-degrading components)
that require different maintenance actions. Since industrial systems become
more and more complex, more research about the maintenance of systems with
heterogeneous components is needed. For this reason, in this paper, a system
consisting of two groups of components: degrading and non-degrading components
is analyzed. The main novelty of this paper is the evaluation of a maintenance
policy at system-level coordinating condition-based maintenance for the
degrading components, delay time to the maintenance and an inspection strategy
for this heterogeneous system. To that end, an analytic cost model is built
using the semi-regenerative processes theory. Furthermore, a safety constraint
related to the reliability of the degrading components is imposed. To find the
optimal maintenance strategy, meta-heuristic algorithms are used.
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11539 title=Abstract>arXiv:2401.11539</a> [<a href=https://arxiv.org/pdf/2401.11539 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11539 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11539 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model Predictive Approach for Detumbling an Underactuated Satellite
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kondo%2C+K">Kota Kondo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yoshimura%2C+Y">Yasuhiro Yoshimura</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bando%2C+M">Mai Bando</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nagasaki%2C+S">Shuji Nagasaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hanada%2C+T">Toshiya Hanada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 4 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> AIAA Scitech 2020 Forum
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This research proposes an innovative approach to detumble satellites'
triple-axis angular velocities with only one single-axis magnetic torquer.
Since magnetic torque is generated perpendicularly to magnetorquers, no
intended control torque along the magnetorquer can be produced, which makes
systems underactuated. Our paper introduces a control method using Model
Predictive Control (MPC) and compares it with B-dot control algorithm. By
applying these control laws to Kyushu University Light Curve Inversion (Q-Li)
Demonstration Satellite in numerical simulations, we describe the applicability
of these control laws to underactuated systems.
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11541 title=Abstract>arXiv:2401.11541</a> [<a href=https://arxiv.org/pdf/2401.11541 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11541 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-View Neural 3D Reconstruction of Micro-/Nanostructures with Atomic Force Microscopy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuo Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+M">Mao Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yijin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+B">Bing-Feng Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+H">Hujun Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuan-Liu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guofeng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Materials Science (cond-mat.mtrl-sci)
</div>
<p class=mathjax>Atomic Force Microscopy (AFM) is a widely employed tool for micro-/nanoscale
topographic imaging. However, conventional AFM scanning struggles to
reconstruct complex 3D micro-/nanostructures precisely due to limitations such
as incomplete sample topography capturing and tip-sample convolution artifacts.
Here, we propose a multi-view neural-network-based framework with AFM
(MVN-AFM), which accurately reconstructs surface models of intricate
micro-/nanostructures. Unlike previous works, MVN-AFM does not depend on any
specially shaped probes or costly modifications to the AFM system. To achieve
this, MVN-AFM uniquely employs an iterative method to align multi-view data and
eliminate AFM artifacts simultaneously. Furthermore, we pioneer the application
of neural implicit surface reconstruction in nanotechnology and achieve
markedly improved results. Extensive experiments show that MVN-AFM effectively
eliminates artifacts present in raw AFM images and reconstructs various
micro-/nanostructures including complex geometrical microstructures printed via
Two-photon Lithography and nanoparticles such as PMMA nanospheres and ZIF-67
nanocrystals. This work presents a cost-effective tool for micro-/nanoscale 3D
analysis.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11542 title=Abstract>arXiv:2401.11542</a> [<a href=https://arxiv.org/pdf/2401.11542 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11542 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nigel -- Mechatronic Design and Robust Sim2Real Control of an Over-Actuated Autonomous Vehicle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samak%2C+C+V">Chinmay Vilas Samak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samak%2C+T+V">Tanmay Vilas Samak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Velni%2C+J+M">Javad Mohammadpour Velni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krovi%2C+V+N">Venkat Narayan Krovi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Simulation to reality (sim2real) transfer from a dynamics and controls
perspective usually involves re-tuning or adapting the designed algorithms to
suit real-world operating conditions, which often violates the performance
guarantees established originally. This work presents a generalizable framework
for achieving reliable sim2real transfer of autonomy-oriented control systems
using multi-model multi-objective robust optimal control synthesis, which lends
well to uncertainty handling and disturbance rejection with theoretical
guarantees. Particularly, this work is centered around an actuation-redundant
scaled autonomous vehicle called Nigel, with independent all-wheel drive and
independent all-wheel steering architecture, whose enhanced configuration space
bodes well for robust control applications. To this end, we present a
systematic study on the complete mechatronic design, dynamics modeling,
parameter identification, and robust stabilizing as well as steady-state
tracking control of Nigel using the proposed framework, with experimental
validation.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11543 title=Abstract>arXiv:2401.11543</a> [<a href=https://arxiv.org/pdf/2401.11543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Robust Are Energy-Based Models Trained With Equilibrium Propagation?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansingh%2C+S">Siddharth Mansingh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kucer%2C+M">Michal Kucer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kenyon%2C+G">Garrett Kenyon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moore%2C+J">Juston Moore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teti%2C+M">Michael Teti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Deep neural networks (DNNs) are easily fooled by adversarial perturbations
that are imperceptible to humans. Adversarial training, a process where
adversarial examples are added to the training set, is the current
state-of-the-art defense against adversarial attacks, but it lowers the model's
accuracy on clean inputs, is computationally expensive, and offers less
robustness to natural noise. In contrast, energy-based models (EBMs), which
were designed for efficient implementation in neuromorphic hardware and
physical systems, incorporate feedback connections from each layer to the
previous layer, yielding a recurrent, deep-attractor architecture which we
hypothesize should make them naturally robust. Our work is the first to explore
the robustness of EBMs to both natural corruptions and adversarial attacks,
which we do using the CIFAR-10 and CIFAR-100 datasets. We demonstrate that EBMs
are more robust than transformers and display comparable robustness to
adversarially-trained DNNs on gradient-based (white-box) attacks, query-based
(black-box) attacks, and natural perturbations without sacrificing clean
accuracy, and without the need for adversarial training or additional training
techniques.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11544 title=Abstract>arXiv:2401.11544</a> [<a href=https://arxiv.org/pdf/2401.11544 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11544 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Prompts for Rehearsal-free Continual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+Y">Yukun Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+H">Hantao Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lu Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+L">Liansheng Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to TPAMI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Continual learning endeavors to equip the model with the capability to
integrate current task knowledge while mitigating the forgetting of past task
knowledge. Inspired by prompt tuning, prompt-based methods maintain a frozen
backbone and train with slight learnable prompts to minimize the catastrophic
forgetting that arises due to updating a large number of backbone parameters.
Nonetheless, these learnable prompts tend to concentrate on the discriminatory
knowledge of the current task while ignoring past task knowledge, leading to
that learnable prompts still suffering from catastrophic forgetting. This paper
introduces a novel rehearsal-free paradigm for continual learning termed
Hierarchical Prompts (H-Prompts), comprising three categories of prompts --
class prompt, task prompt, and general prompt. To effectively depict the
knowledge of past classes, class prompt leverages Bayesian Distribution
Alignment to model the distribution of classes in each task. To reduce the
forgetting of past task knowledge, task prompt employs Cross-task Knowledge
Excavation to amalgamate the knowledge encapsulated in the learned class
prompts of past tasks and current task knowledge. Furthermore, general prompt
utilizes Generalized Knowledge Exploration to deduce highly generalized
knowledge in a self-supervised manner. Evaluations on two benchmarks
substantiate the efficacy of the proposed H-Prompts, exemplified by an average
accuracy of 87.8% in Split CIFAR-100 and 70.6% in Split ImageNet-R.
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11547 title=Abstract>arXiv:2401.11547</a> [<a href=https://arxiv.org/pdf/2401.11547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Understanding the Security Risks of Decentralized Exchanges by Uncovering Unfair Trades in the Wild
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yibo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+W">Wanning Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yuzhe Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">XiaoFeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kai Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>DEX, or decentralized exchange, is a prominent class of decentralized finance
(DeFi) applications on blockchains, attracting a total locked value worth tens
of billions of USD today.
<br>This paper presents the first large-scale empirical study that uncovers
unfair trades on popular DEX services on Ethereum and Binance Smart Chain
(BSC). By joining and analyzing 60 million transactions, we find 671,400 unfair
trades on all six measured DEXes, including Uniswap, Balancer, and Curve. Out
of these unfair trades, we attribute 55,000 instances, with high confidence, to
token thefts that cause a value loss of more than 3.88 million USD.
Furthermore, the measurement study uncovers previously unknown causes of
extractable value and real-world adaptive strategies to these causes. Finally,
we propose countermeasures to redesign secure DEX protocols and to harden
deployed services against the discovered security risks.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11553 title=Abstract>arXiv:2401.11553</a> [<a href=https://arxiv.org/pdf/2401.11553 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11553 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11553 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Taxi dispatching strategies with compensations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Billhardt%2C+H">Holger Billhardt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez%2C+A">Alberto Fernández</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ossowski%2C+S">Sascha Ossowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palanca%2C+J">Javier Palanca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bajo%2C+J">Javier Bajo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Expert Systems with Applications, Volume 122 (2019)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Urban mobility efficiency is of utmost importance in big cities. Taxi
vehicles are key elements in daily traffic activity. The advance of ICT and
geo-positioning systems has given rise to new opportunities for improving the
efficiency of taxi fleets in terms of waiting times of passengers, cost and
time for drivers, traffic density, CO2 emissions, etc., by using more informed,
intelligent dispatching. Still, the explicit spatial and temporal components,
as well as the scale and, in particular, the dynamicity of the problem of
pairing passengers and taxis in big towns, render traditional approaches for
solving standard assignment problem useless for this purpose, and call for
intelligent approximation strategies based on domain-specific heuristics.
Furthermore, taxi drivers are often autonomous actors and may not agree to
participate in assignments that, though globally efficient, may not be
sufficently beneficial for them individually. This paper presents a new
heuristic algorithm for taxi assignment to customers that considers taxi
reassignments if this may lead to globally better solutions. In addition, as
such new assignments may reduce the expected revenues of individual drivers, we
propose an economic compensation scheme to make individually rational drivers
agree to proposed modifications in their assigned clients. We carried out a set
of experiments, where several commonly used assignment strategies are compared
to three different instantiations of our heuristic algorithm. The results
indicate that our proposal has the potential to reduce customer waiting times
in fleets of autonomous taxis, while being also beneficial from an economic
point of view.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11563 title=Abstract>arXiv:2401.11563</a> [<a href=https://arxiv.org/pdf/2401.11563 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11563 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed Multi-Task Learning for Stochastic Bandits with Context Distribution and Stage-wise Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiabin Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moothedath%2C+S">Shana Moothedath</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>We present the problem of conservative distributed multi-task learning in
stochastic linear contextual bandits with heterogeneous agents. This extends
conservative linear bandits to a distributed setting where M agents tackle
different but related tasks while adhering to stage-wise performance
constraints. The exact context is unknown, and only a context distribution is
available to the agents as in many practical applications that involve a
prediction mechanism to infer context, such as stock market prediction and
weather forecast. We propose a distributed upper confidence bound (UCB)
algorithm, DiSC-UCB. Our algorithm constructs a pruned action set during each
round to ensure the constraints are met. Additionally, it includes synchronized
sharing of estimates among agents via a central server using well-structured
synchronization steps. We prove the regret and communication bounds on the
algorithm. We extend the problem to a setting where the agents are unaware of
the baseline reward. For this setting, we provide a modified algorithm,
DiSC-UCB2, and we show that the modified algorithm achieves the same regret and
communication bounds. We empirically validated the performance of our algorithm
on synthetic data and real-world Movielens-100K data.
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11565 title=Abstract>arXiv:2401.11565</a> [<a href=https://arxiv.org/pdf/2401.11565 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11565 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jose%2C+S+T">Sharu Theresa Jose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moothedath%2C+S">Shana Moothedath</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>We explore a stochastic contextual linear bandit problem where the agent
observes a noisy, corrupted version of the true context through a noise channel
with an unknown noise parameter. Our objective is to design an action policy
that can approximate" that of an oracle, which has access to the reward model,
the channel parameter, and the predictive distribution of the true context from
the observed noisy context. In a Bayesian framework, we introduce a Thompson
sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting
an information-theoretic analysis, we demonstrate the Bayesian regret of our
algorithm concerning the oracle's action policy. We also extend this problem to
a scenario where the agent observes the true context with some delay after
receiving the reward and show that delayed true contexts lead to lower Bayesian
regret. Finally, we empirically demonstrate the performance of the proposed
algorithms against baselines.
</p>
</div>
</dd>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11580 title=Abstract>arXiv:2401.11580</a> [<a href=https://arxiv.org/pdf/2401.11580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Age of Gossip in Random and Bipartite Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=maranzatto%2C+T">Thomas maranzatto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>In this paper we study gossip networks where a source observing a process
sends updates to an underlying graph. Nodes in the graph communicate to their
neighbors by randomly sending updates. Our interest is studying the version age
of information (vAoI) metric over various classes of networks. It is known that
the version age of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-476 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.33em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-477><span class=msubsup id=MathJax-Span-478><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-479 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-480 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> is logarithmic, and the version age of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-481 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.229em,1001.33em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-482><span class=munderover id=MathJax-Span-483><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.33em,4.343em,-999.997em);top:-3.99em;left:0em><span class=msubsup id=MathJax-Span-484><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-485 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-486 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1001.33em,3.764em,-999.997em);top:-4.511em;left:0.003em><span class=mo id=MathJax-Span-487><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;top:-3.99em;left:-0.055em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:1.045em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.119em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.292em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.524em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.697em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.871em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> is linear. We study the question `how does the vAoI evolve as
we interpolate between <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-488 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.33em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-489><span class=msubsup id=MathJax-Span-490><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-491 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-492 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-493 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.229em,1001.33em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-494><span class=munderover id=MathJax-Span-495><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.33em,4.343em,-999.997em);top:-3.99em;left:0em><span class=msubsup id=MathJax-Span-496><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-497 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-498 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1001.33em,3.764em,-999.997em);top:-4.511em;left:0.003em><span class=mo id=MathJax-Span-499><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;top:-3.99em;left:-0.055em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:1.045em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.119em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.292em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.524em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.697em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.99em;left:0.871em><span style=font-size:70.7%;font-family:MathJax_Main>¯</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>' by studying Erd\H{o}s-Reyni
random graphs, random <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-500 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-501><span class=mi id=MathJax-Span-502 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-regular graphs, and bipartite networks. Our main
results are proving the existence of a threshold in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-503 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.01em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-504><span class=mi id=MathJax-Span-505 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-506 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-507 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-508 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-509 style=font-family:MathJax_Math-italic;padding-left:0.177em>p</span><span class=mo id=MathJax-Span-510 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> from rational to
logarithmic average version age, and showing <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-511 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.01em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-512><span class=mi id=MathJax-Span-513 style=font-family:MathJax_Math-italic>G</span><span class=mo id=MathJax-Span-514 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-515 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-516 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-517 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-518 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> almost surely has
logarithmic version age for constant <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-519 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-520><span class=mi id=MathJax-Span-521 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We also characterize the version age
of complete bipartite graphs <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-522 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1002.14em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-523><span class=msubsup id=MathJax-Span-524><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-525 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=texatom id=MathJax-Span-526><span class=mrow id=MathJax-Span-527><span class=mi id=MathJax-Span-528 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span><span class=mo id=MathJax-Span-529 style=font-size:70.7%;font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-530 style=font-size:70.7%;font-family:MathJax_Math-italic>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, when we let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-531 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-532><span class=mi id=MathJax-Span-533 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> vary from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-534 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-535><span class=mi id=MathJax-Span-536 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-537 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-538 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-539 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> to
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-540 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-541><span class=mi id=MathJax-Span-542 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-543 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-544 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-545 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11582 title=Abstract>arXiv:2401.11582</a> [<a href=https://arxiv.org/pdf/2401.11582 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11582 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Thermal Image Calibration and Correction using Unpaired Cycle-Consistent Adversarial Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajoli%2C+H">Hossein Rajoli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Afshin%2C+P">Pouya Afshin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Afghah%2C+F">Fatemeh Afghah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted at the Asilomar 2023 Conference and will be published
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Unmanned aerial vehicles (UAVs) offer a flexible and cost-effective solution
for wildfire monitoring. However, their widespread deployment during wildfires
has been hindered by a lack of operational guidelines and concerns about
potential interference with aircraft systems. Consequently, the progress in
developing deep-learning models for wildfire detection and characterization
using aerial images is constrained by the limited availability, size, and
quality of existing datasets. This paper introduces a solution aimed at
enhancing the quality of current aerial wildfire datasets to align with
advancements in camera technology. The proposed approach offers a solution to
create a comprehensive, standardized large-scale image dataset. This paper
presents a pipeline based on CycleGAN to enhance wildfire datasets and a novel
fusion method that integrates paired RGB images as attribute conditioning in
the generators of both directions, improving the accuracy of the generated
images.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11590 title=Abstract>arXiv:2401.11590</a> [<a href=https://arxiv.org/pdf/2401.11590 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11590 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11590 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Small Even Covers, Locally Decodable Codes and Restricted Subgraphs of Edge-Colored Kikuchi Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsieh%2C+J">Jun-Ting Hsieh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kothari%2C+P+K">Pravesh K. Kothari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohanty%2C+S">Sidhanth Mohanty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Correia%2C+D+M">David Munhá Correia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sudakov%2C+B">Benny Sudakov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>Given a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-546 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-547><span class=mi id=MathJax-Span-548 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-uniform hypergraph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><nobr><span class=math id=MathJax-Span-549 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-550><span class=mi id=MathJax-Span-551 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-552 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-553><span class=mi id=MathJax-Span-554 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> vertices, an even cover in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-555 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-556><span class=mi id=MathJax-Span-557 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a
collection of hyperedges that touch each vertex an even number of times. Even
covers are a generalization of cycles in graphs and are equivalent to linearly
dependent subsets of a system of linear equations modulo <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-558 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-559><span class=mn id=MathJax-Span-560 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. As a result, they
arise naturally in the context of well-studied questions in coding theory and
refuting unsatisfiable <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-561 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-562><span class=mi id=MathJax-Span-563 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-SAT formulas. Analogous to the irregular Moore bound
of Alon, Hoory, and Linial (2002), in 2008, Feige conjectured an extremal
trade-off between the number of hyperedges and the length of the smallest even
cover in a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-564 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-565><span class=mi id=MathJax-Span-566 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-uniform hypergraph. This conjecture was recently settled up to a
multiplicative logarithmic factor in the number of hyperedges (Guruswami,
Kothari, and 1Manohar 2022 and Hsieh, Kothari, and Mohanty 2023). These works
introduce the new technique that relates hypergraph even covers to cycles in
the associated \emph{Kikuchi} graphs. Their analysis of these Kikuchi graphs,
especially for odd <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-567 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-568><span class=mi id=MathJax-Span-569 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, is rather involved and relies on matrix concentration
inequalities.
<br>In this work, we give a simple and purely combinatorial argument that
recovers the best-known bound for Feige's conjecture for even <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-570 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-571><span class=mi id=MathJax-Span-572 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We also
introduce a novel variant of a Kikuchi graph which together with this argument
improves the logarithmic factor in the best-known bounds for odd <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-573 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-574><span class=mi id=MathJax-Span-575 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. As an
application of our ideas, we also give a purely combinatorial proof of the
improved lower bounds (Alrabiah, Guruswami, Kothari and Manohar, 2023) on
3-query binary linear locally decodable codes.
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11592 title=Abstract>arXiv:2401.11592</a> [<a href=https://arxiv.org/pdf/2401.11592 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11592 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differential Privacy in Hierarchical Federated Learning: A Formal Analysis and Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+F+P">Frank Po-Chen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brinton%2C+C">Christopher Brinton</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>While federated learning (FL) eliminates the transmission of raw data over a
network, it is still vulnerable to privacy breaches from the communicated model
parameters. In this work, we formalize Differentially Private Hierarchical
Federated Learning (DP-HFL), a DP-enhanced FL methodology that seeks to improve
the privacy-utility tradeoff inherent in FL. Building upon recent proposals for
Hierarchical Differential Privacy (HDP), one of the key concepts of DP-HFL is
adapting DP noise injection at different layers of an established FL hierarchy
-- edge devices, edge servers, and cloud servers -- according to the trust
models within particular subnetworks. We conduct a comprehensive analysis of
the convergence behavior of DP-HFL, revealing conditions on parameter tuning
under which the model training process converges sublinearly to a stationarity
gap, with this gap depending on the network hierarchy, trust model, and target
privacy level. Subsequent numerical evaluations demonstrate that DP-HFL obtains
substantial improvements in convergence speed over baselines for different
privacy budgets, and validate the impact of network configuration on training.
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11596 title=Abstract>arXiv:2401.11596</a> [<a href=https://arxiv.org/pdf/2401.11596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Maximize Gains From Trade in Small Markets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babaioff%2C+M">Moshe Babaioff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frey%2C+A">Amitai Frey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nisan%2C+N">Noam Nisan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>We study the problem of designing a two-sided market (double auction) to
maximize the gains from trade (social welfare) under the constraints of
(dominant-strategy) incentive compatibility and budget-balance. Our goal is to
do so for an unknown distribution from which we are given a polynomial number
of samples. Our first result is a general impossibility for the case of
correlated distributions of values even between just one seller and two buyers,
in contrast to the case of one seller and one buyer (bilateral trade) where
this is possible. Our second result is an efficient learning algorithm for one
seller and two buyers in the case of independent distributions which is based
on a novel algorithm for computing optimal mechanisms for finitely supported
and explicitly given independent distributions. Both results rely heavily on
characterizations of (dominant-strategy) incentive compatible mechanisms that
are strongly budget-balanced.
</p>
</div>
</dd>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11598 title=Abstract>arXiv:2401.11598</a> [<a href=https://arxiv.org/pdf/2401.11598 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11598 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TetraLoss: Improving the Robustness of Face Recognition against Morphing Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ibsen%2C+M">Mathias Ibsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonz%C3%A1lez-Soler%2C+L+J">Lázaro J. González-Soler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the IEEE International Conference on Automatic Face &amp; Gesture Recognition 2024 (FG'24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Face recognition systems are widely deployed in high-security applications
such as for biometric verification at border controls. Despite their high
accuracy on pristine data, it is well-known that digital manipulations, such as
face morphing, pose a security threat to face recognition systems. Malicious
actors can exploit the facilities offered by the identity document issuance
process to obtain identity documents containing morphed images. Thus, subjects
who contributed to the creation of the morphed image can with high probability
use the identity document to bypass automated face recognition systems. In
recent years, no-reference (i.e., single image) and differential morphing
attack detectors have been proposed to tackle this risk. These systems are
typically evaluated in isolation from the face recognition system that they
have to operate jointly with and do not consider the face recognition process.
Contrary to most existing works, we present a novel method for adapting deep
learning-based face recognition systems to be more robust against face morphing
attacks. To this end, we introduce TetraLoss, a novel loss function that learns
to separate morphed face images from its contributing subjects in the embedding
space while still preserving high biometric verification performance. In a
comprehensive evaluation, we show that the proposed method can significantly
enhance the original system while also significantly outperforming other tested
baseline methods.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11599 title=Abstract>arXiv:2401.11599</a> [<a href=https://arxiv.org/pdf/2401.11599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11599 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reducing Usefulness of Stolen Credentials in SSO Contexts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hays%2C+S">Sam Hays</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandborn%2C+M">Michael Sandborn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=White%2C+D+J">Dr. Jules White</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Approximately 61% of cyber attacks involve adversaries in possession of valid
credentials. Attackers acquire credentials through various means, including
phishing, dark web data drops, password reuse, etc. Multi-factor authentication
(MFA) helps to thwart attacks that use valid credentials, but attackers still
commonly breach systems by tricking users into accepting MFA step up requests
through techniques, such as ``MFA Bombing'', where multiple requests are sent
to a user until they accept one. Currently, there are several solutions to this
problem, each with varying levels of security and increasing invasiveness on
user devices. This paper proposes a token-based enrollment architecture that is
less invasive to user devices than mobile device management, but still offers
strong protection against use of stolen credentials and MFA attacks.
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11600 title=Abstract>arXiv:2401.11600</a> [<a href=https://arxiv.org/pdf/2401.11600 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11600 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Understanding the Generalization Benefits of Late Learning Rate Decay
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yinuo Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Why do neural networks trained with large learning rates for a longer time
often lead to better generalization? In this paper, we delve into this question
by examining the relation between training and testing loss in neural networks.
Through visualization of these losses, we note that the training trajectory
with a large learning rate navigates through the minima manifold of the
training loss, finally nearing the neighborhood of the testing loss minimum.
Motivated by these findings, we introduce a nonlinear model whose loss
landscapes mirror those observed for real neural networks. Upon investigating
the training process using SGD on our model, we demonstrate that an extended
phase with a large learning rate steers our model towards the minimum norm
solution of the training loss, which may achieve near-optimal generalization,
thereby affirming the empirically observed benefits of late learning rate
decay.
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11601 title=Abstract>arXiv:2401.11601</a> [<a href=https://arxiv.org/pdf/2401.11601 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11601 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Evaluation Measures for Evaluating Social Biases in Masked Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Many evaluation measures are used to evaluate social biases in masked
language models (MLMs). However, we find that these previously proposed
evaluation measures are lacking robustness in scenarios with limited datasets.
This is because these measures are obtained by comparing the
pseudo-log-likelihood (PLL) scores of the stereotypical and anti-stereotypical
samples using an indicator function. The disadvantage is the limited mining of
the PLL score sets without capturing its distributional information. In this
paper, we represent a PLL score set as a Gaussian distribution and use Kullback
Leibler (KL) divergence and Jensen Shannon (JS) divergence to construct
evaluation measures for the distributions of stereotypical and
anti-stereotypical PLL scores. Experimental results on the publicly available
datasets StereoSet (SS) and CrowS-Pairs (CP) show that our proposed measures
are significantly more robust and interpretable than those proposed previously.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11605 title=Abstract>arXiv:2401.11605</a> [<a href=https://arxiv.org/pdf/2401.11605 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11605 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crowson%2C+K">Katherine Crowson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baumann%2C+S+A">Stefan Andreas Baumann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Birch%2C+A">Alex Birch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abraham%2C+T+M">Tanishq Mathew Abraham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan%2C+D+Z">Daniel Z. Kaplan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shippole%2C+E">Enrico Shippole</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 13 figures, project page and code available at <a href=https://crowsonkb.github.io/hourglass-diffusion-transformers/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>We present the Hourglass Diffusion Transformer (HDiT), an image generative
model that exhibits linear scaling with pixel count, supporting training at
high-resolution (e.g. <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-99-Frame tabindex=0><nobr><span class=math id=MathJax-Span-576 style=width:6.369em;display:inline-block><span style=display:inline-block;position:relative;width:5.269em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.21em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-577><span class=mn id=MathJax-Span-578 style=font-family:MathJax_Main>1024</span><span class=mo id=MathJax-Span-579 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mn id=MathJax-Span-580 style=font-family:MathJax_Main;padding-left:0.234em>1024</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>) directly in pixel-space. Building on
the Transformer architecture, which is known to scale to billions of
parameters, it bridges the gap between the efficiency of convolutional U-Nets
and the scalability of Transformers. HDiT trains successfully without typical
high-resolution training techniques such as multiscale architectures, latent
autoencoders or self-conditioning. We demonstrate that HDiT performs
competitively with existing models on ImageNet <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-100-Frame tabindex=0><nobr><span class=math id=MathJax-Span-581 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.91em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-582><span class=msubsup id=MathJax-Span-583><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.45em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-584 style=font-family:MathJax_Main>256</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:1.508em><span class=mn id=MathJax-Span-585 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, and sets a new
state-of-the-art for diffusion models on FFHQ-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-101-Frame tabindex=0><nobr><span class=math id=MathJax-Span-586 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1002.43em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-587><span class=msubsup id=MathJax-Span-588><span style=display:inline-block;position:relative;width:2.433em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.97em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-589 style=font-family:MathJax_Main>1024</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:2.028em><span class=mn id=MathJax-Span-590 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11608 title=Abstract>arXiv:2401.11608</a> [<a href=https://arxiv.org/pdf/2401.11608 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11608 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-102-Frame tabindex=0><nobr><span class=math id=MathJax-Span-591 style=width:3.799em;display:inline-block><span style=display:inline-block;position:relative;width:3.15em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.206em,1003.1em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-592><span class=texatom id=MathJax-Span-593><span class=mrow id=MathJax-Span-594><span class=mtext id=MathJax-Span-595 style=font-family:MathJax_Typewriter>immrax</span></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.836em"></span></span></nobr></span>: A Parallelizable and Differentiable Toolbox for Interval Analysis and Mixed Monotone Reachability in JAX
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Harapanahalli%2C+A">Akash Harapanahalli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jafarpour%2C+S">Saber Jafarpour</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Coogan%2C+S">Samuel Coogan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
</div>
<p class=mathjax>We present an implementation of interval analysis and mixed monotone interval
reachability analysis as function transforms in Python, fully composable with
the computational framework JAX. The resulting toolbox inherits several key
features from JAX, including computational efficiency through Just-In-Time
Compilation, GPU acceleration for quick parallelized computations, and
Automatic Differentiability. We demonstrate the toolbox's performance on
several case studies, including a reachability problem on a vehicle model
controlled by a neural network, and a robust closed-loop optimal control
problem for a swinging pendulum.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11609 title=Abstract>arXiv:2401.11609</a> [<a href=https://arxiv.org/pdf/2401.11609 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11609 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Edits for Counterfactual Explanations: A Unified GNN Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaidos%2C+N">Nikolaos Chaidos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dimitriou%2C+A">Angeliki Dimitriou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lymperaiou%2C+M">Maria Lymperaiou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stamou%2C+G">Giorgos Stamou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Counterfactuals have been established as a popular explainability technique
which leverages a set of minimal edits to alter the prediction of a classifier.
When considering conceptual counterfactuals, the edits requested should
correspond to salient concepts present in the input data. At the same time,
conceptual distances are defined by knowledge graphs, ensuring the optimality
of conceptual edits. In this work, we extend previous endeavors on conceptual
counterfactuals by introducing \textit{graph edits as counterfactual
explanations}: should we represent input data as graphs, which is the shortest
graph edit path that results in an alternative classification label as provided
by a black-box classifier?
</p>
</div>
</dd>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11611 title=Abstract>arXiv:2401.11611</a> [<a href=https://arxiv.org/pdf/2401.11611 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11611 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+X">Xihaier Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yihui Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nadiga%2C+B">Balu Nadiga</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages,21 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Reliably reconstructing physical fields from sparse sensor data is a
challenge that frequently arises in many scientific domains. In practice, the
process generating the data often is not understood to sufficient accuracy.
Therefore, there is a growing interest in using the deep neural network route
to address the problem. This work presents a novel approach that learns a
continuous representation of the physical field using implicit neural
representations (INRs). Specifically, after factorizing spatiotemporal
variability into spatial and temporal components using the separation of
variables technique, the method learns relevant basis functions from sparsely
sampled irregular data points to develop a continuous representation of the
data. In experimental evaluations, the proposed model outperforms recent INR
methods, offering superior reconstruction quality on simulation data from a
state-of-the-art climate model and a second dataset that comprises ultra-high
resolution satellite-based sea surface temperature fields.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11614 title=Abstract>arXiv:2401.11614</a> [<a href=https://arxiv.org/pdf/2401.11614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lightweight Self-Driven Deformable Organ Animations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kenwright%2C+B">Benjamnin Kenwright</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinmai%2C+K">Kanida Sinmai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
<p class=mathjax>The subject of simulating internal organs is a valuable and important topic
of research to multiple fields from medical analysis to education and training.
This paper presents a solution that utilizes a graphical technique in
combination with a Stochastic method for tuning an active physics-based model.
We generate responsive interactive organ animations with regional properties
(i.e., areas of the model oscillating with different harmonic frequencies) to
reproduce and capture real-world characteristics. Our method builds upon
biological and physical discoveries to procedurally generate internally
controlled rhythmic motions but also enable the solution to be interactive and
adaptive. We briefly review deformation models for medical simulations and
investigate the impediments to combining 'computergraphics' representations
with biomechanical models. Finally, we present a lightweight solution that is
scalable and able to procedurally generate large organ animations. In
particular, simplified geometric representations of deformable structures that
use periodic coupled forces to drive themselves.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11616 title=Abstract>arXiv:2401.11616</a> [<a href=https://arxiv.org/pdf/2401.11616 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11616 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11616 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boundary element method for the Dirichlet problem for Laplace's equation on a disk
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Morales%2C+M+M">Misael M. Morales</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pomeranz%2C+S">Shirley Pomeranz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>The Boundary Element Method (BEM) is implemented using piecewise linear
elements to solve the two-dimensional Dirichlet problem for Laplace's equation
posed on a disk. A benefit of the BEM as opposed to many other numerical
solution techniques is that discretization only occurs on the boundary, i.e.,
the complete domain does not need to be discretized. This provides an advantage
in terms of time and cost. The algorithm's performance is illustrated through
sample test problems with known solutions. A comparison between the exact
solution and the BEM numerical solution is done, and error analysis is
performed on the results.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11617 title=Abstract>arXiv:2401.11617</a> [<a href=https://arxiv.org/pdf/2401.11617 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11617 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on African Computer Vision Datasets, Topics and Researchers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omotayo%2C+A">Abdul-Hakeem Omotayo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mbilinyi%2C+A">Ashery Mbilinyi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ismaila%2C+L">Lukman Ismaila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Turki%2C+H">Houcemeddine Turki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdien%2C+M">Mahmoud Abdien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gamal%2C+K">Karim Gamal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tondji%2C+I">Idriss Tondji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pimi%2C+Y">Yvan Pimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Etori%2C+N+A">Naome A. Etori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matar%2C+M+M">Marwa M. Matar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Broni-Bediako%2C+C">Clifford Broni-Bediako</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oppong%2C+A">Abigail Oppong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gamal%2C+M">Mai Gamal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ehab%2C+E">Eman Ehab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dovonon%2C+G">Gbetondji Dovonon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akinjobi%2C+Z">Zainab Akinjobi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ajisafe%2C+D">Daniel Ajisafe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adegboro%2C+O+G">Oluwabukola G. Adegboro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siam%2C+M">Mennatullah Siam</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review, Community Work of Ro'ya Grassroots, <a href=https://ro-ya-cv4africa.github.io/homepage/>this https URL</a> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.06773>arXiv:2305.06773</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Computer vision encompasses a range of tasks such as object detection,
semantic segmentation, and 3D reconstruction. Despite its relevance to African
communities, research in this field within Africa represents only 0.06% of
top-tier publications over the past decade. This study undertakes a thorough
analysis of 63,000 Scopus-indexed computer vision publications from Africa,
spanning from 2012 to 2022. The aim is to provide a survey of African computer
vision topics, datasets and researchers. A key aspect of our study is the
identification and categorization of African Computer Vision datasets using
large language models that automatically parse abstracts of these publications.
We also provide a compilation of unofficial African Computer Vision datasets
distributed through challenges or data hosting platforms, and provide a full
taxonomy of dataset categories. Our survey also pinpoints computer vision
topics trends specific to different African regions, indicating their unique
focus areas. Additionally, we carried out an extensive survey to capture the
views of African researchers on the current state of computer vision research
in the continent and the structural barriers they believe need urgent
attention. In conclusion, this study catalogs and categorizes Computer Vision
datasets and topics contributed or initiated by African institutions and
identifies barriers to publishing in top-tier Computer Vision venues. This
survey underscores the importance of encouraging African researchers and
institutions in advancing computer vision research in the continent. It also
stresses on the need for research topics to be more aligned with the needs of
African communities.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11618 title=Abstract>arXiv:2401.11618</a> [<a href=https://arxiv.org/pdf/2401.11618 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11618 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient local linearity regularization to overcome catastrophic overfitting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rocamora%2C+E+A">Elias Abad Rocamora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fanghui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chrysos%2C+G+G">Grigorios G. Chrysos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olmos%2C+P+M">Pablo M. Olmos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cevher%2C+V">Volkan Cevher</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)
</div>
<p class=mathjax>Catastrophic overfitting (CO) in single-step adversarial training (AT)
results in abrupt drops in the adversarial test accuracy (even down to 0%). For
models trained with multi-step AT, it has been observed that the loss function
behaves locally linearly with respect to the input, this is however lost in
single-step AT. To address CO in single-step AT, several methods have been
proposed to enforce local linearity of the loss via regularization. However,
these regularization terms considerably slow down training due to Double
Backpropagation. Instead, in this work, we introduce a regularization term,
called ELLE, to mitigate CO effectively and efficiently in classical AT
evaluations, as well as some more difficult regimes, e.g., large adversarial
perturbations and long training schedules. Our regularization term can be
theoretically linked to curvature of the loss function and is computationally
cheaper than previous methods by avoiding Double Backpropagation. Our thorough
experimental validation demonstrates that our work does not suffer from CO,
even in challenging settings where previous works suffer from it. We also
notice that adapting our regularization parameter during training (ELLE-A)
greatly improves the performance, specially in large <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-103-Frame tabindex=0><nobr><span class=math id=MathJax-Span-596 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-597><span class=mi id=MathJax-Span-598 style=font-family:MathJax_Math-italic>ϵ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> setups. Our
implementation is available in https://github.com/LIONS-EPFL/ELLE .
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11620 title=Abstract>arXiv:2401.11620</a> [<a href=https://arxiv.org/pdf/2401.11620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Real-Time Systems Optimization with Black-box Constraints and Hybrid Variables
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Sen Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+D">Dong Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+S">Shao-Yu Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Deng%2C+X">Xuanliang Deng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sifat%2C+A+H">Ashrarul H. Sifat</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+C">Changhee Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Williams%2C+R">Ryan Williams</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zeng%2C+H">Haibo Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Workshop on OPtimization for Embedded and ReAl-time systems (OPERA 2023) co-located with the 44th IEEE Real-Time Systems Symposium (RTSS)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>When optimizing real-time systems, designers often face a challenging problem
where the schedulability constraints are non-convex, non-continuous, or lack an
analytical form to understand their properties. Although the optimization
framework NORTH proposed in previous work is general (it works with arbitrary
schedulability analysis) and scalable, it can only handle problems with
continuous variables, which limits its application. In this paper, we extend
the applications of the framework NORTH to problems with a hybrid of continuous
and discrete variables. This is achieved in a coordinate-descent method, where
the continuous and discrete variables are optimized separately during
iterations. The new framework, NORTH+, improves around 20% solution quality
than NORTH in experiments.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11622 title=Abstract>arXiv:2401.11622</a> [<a href=https://arxiv.org/pdf/2401.11622 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11622 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Markov-Chain Polytope with Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golin%2C+M+J">Mordecai J. Golin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patupat%2C+A+J+L">Albert John Lalim Patupat</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper addresses the problem of finding a minimum-cost <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-104-Frame tabindex=0><nobr><span class=math id=MathJax-Span-599 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-600><span class=mi id=MathJax-Span-601 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-state Markov
chain <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-105-Frame tabindex=0><nobr><span class=math id=MathJax-Span-602 style=width:7.584em;display:inline-block><span style=display:inline-block;position:relative;width:6.311em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.2em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-603><span class=mo id=MathJax-Span-604 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-605><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-606 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mn id=MathJax-Span-607 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-608 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-609 style=font-family:MathJax_Main;padding-left:0.177em>…</span><span class=mo id=MathJax-Span-610 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=msubsup id=MathJax-Span-611 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:2.202em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-612 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=texatom id=MathJax-Span-613><span class=mrow id=MathJax-Span-614><span class=mi id=MathJax-Span-615 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-616 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-617 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-618 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> in a large set of chains. The chains studied have
a reward associated with each state. The cost of a chain is its "gain", i.e.,
its average reward under its stationary distribution.
<br>Specifically, for each <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-106-Frame tabindex=0><nobr><span class=math id=MathJax-Span-619 style=width:8.799em;display:inline-block><span style=display:inline-block;position:relative;width:7.295em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1007.24em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-620><span class=mi id=MathJax-Span-621 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-622 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-623 style=font-family:MathJax_Main;padding-left:0.292em>0</span><span class=mo id=MathJax-Span-624 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-625 style=font-family:MathJax_Main;padding-left:0.177em>…</span><span class=mo id=MathJax-Span-626 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-627 style=font-family:MathJax_Math-italic;padding-left:0.177em>m</span><span class=mo id=MathJax-Span-628 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-629 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> there is a known set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-107-Frame tabindex=0><nobr><span class=math id=MathJax-Span-630 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-631><span class=msubsup id=MathJax-Span-632><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-633><span class=mrow id=MathJax-Span-634><span class=texatom id=MathJax-Span-635><span class=mrow id=MathJax-Span-636><span class=mi id=MathJax-Span-637 style=font-family:MathJax_AMS>S</span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-638 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>
of type-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-108-Frame tabindex=0><nobr><span class=math id=MathJax-Span-639 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-640><span class=mi id=MathJax-Span-641 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> states. A permissible Markov chain contains exactly one state of
each type; the problem is to find a minimum-cost permissible chain.
<br>The original motivation was to find a cheapest binary AIFV-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-109-Frame tabindex=0><nobr><span class=math id=MathJax-Span-642 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-643><span class=mi id=MathJax-Span-644 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> lossless code
on a source alphabet of size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-110-Frame tabindex=0><nobr><span class=math id=MathJax-Span-645 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-646><span class=mi id=MathJax-Span-647 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. Such a code is an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-111-Frame tabindex=0><nobr><span class=math id=MathJax-Span-648 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-649><span class=mi id=MathJax-Span-650 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-tuple of trees, in
which each tree can be viewed as a Markov Chain state. This formulation was
then used to address other problems in lossless compression. The known solution
techniques for finding minimum-cost Markov chains were iterative and ran in
exponential time.
<br>This paper shows how to map every possible type-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-112-Frame tabindex=0><nobr><span class=math id=MathJax-Span-651 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-652><span class=mi id=MathJax-Span-653 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> state into a type-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-113-Frame tabindex=0><nobr><span class=math id=MathJax-Span-654 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-655><span class=mi id=MathJax-Span-656 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
hyperplane and then define a "Markov Chain Polytope" as the lower envelope of
all such hyperplanes. Finding a minimum-cost Markov chain can then be shown to
be equivalent to finding a "highest" point on this polytope.
<br>The local optimization procedures used in the previous iterative algorithms
are shown to be separation oracles for this polytope. Since these were often
polynomial time, an application of the Ellipsoid method immediately leads to
polynomial time algorithms for these problems.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11624 title=Abstract>arXiv:2401.11624</a> [<a href=https://arxiv.org/pdf/2401.11624 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11624 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> In-context Learning with Retrieved Demonstrations for Language Models: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+a">an Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasupat%2C+P">Panupong Pasupat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazemi%2C+M">Mehran Kazemi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Language models, especially pre-trained large language models, have showcased
remarkable abilities as few-shot in-context learners (ICL), adept at adapting
to new tasks with just a few demonstrations in the input context. However, the
model's ability to perform ICL is sensitive to the choice of the few-shot
demonstrations. Instead of using a fixed set of demonstrations, one recent
development is to retrieve demonstrations tailored to each input query. The
implementation of demonstration retrieval is relatively straightforward,
leveraging existing databases and retrieval systems. This not only improves the
efficiency and scalability of the learning process but also has been shown to
reduce biases inherent in manual example selection. In light of the encouraging
results and growing research in ICL with retrieved demonstrations, we conduct
an extensive review of studies in this area. In this survey, we discuss and
compare different design choices for retrieval models, retrieval training
procedures, and inference algorithms.
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11626 title=Abstract>arXiv:2401.11626</a> [<a href=https://arxiv.org/pdf/2401.11626 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11626 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Freely Long-Thinking Transformer (FraiLT)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabak%2C+A">Akbay Tabak</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Freely Long-Thinking Transformer (FraiLT) is an improved transformer model
designed to enhance processing capabilities without scaling up size. It
utilizes a recursive approach, iterating over a subset of layers multiple
times, and introduces iteration encodings to maintain awareness across these
cycles. Iteration encoding allows FraiLT to achieve the interpretive depth of
larger models in a compact form. When evaluated on a synthetic story dataset,
FraiLT outperformed larger models, showcasing its ability to deliver
high-quality performance while reducing memory demands. This model represents a
step forward towards more efficient and accessible language models.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11627 title=Abstract>arXiv:2401.11627</a> [<a href=https://arxiv.org/pdf/2401.11627 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11627 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tight Verification of Probabilistic Robustness in Bayesian Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batten%2C+B">Ben Batten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hosseini%2C+M">Mehran Hosseini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lomuscio%2C+A">Alessio Lomuscio</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>We introduce two algorithms for computing tight guarantees on the
probabilistic robustness of Bayesian Neural Networks (BNNs). Computing
robustness guarantees for BNNs is a significantly more challenging task than
verifying the robustness of standard Neural Networks (NNs) because it requires
searching the parameters' space for safe weights. Moreover, tight and complete
approaches for the verification of standard NNs, such as those based on
Mixed-Integer Linear Programming (MILP), cannot be directly used for the
verification of BNNs because of the polynomial terms resulting from the
consecutive multiplication of variables encoding the weights. Our algorithms
efficiently and effectively search the parameters' space for safe weights by
using iterative expansion and the network's gradient and can be used with any
verification algorithm of choice for BNNs. In addition to proving that our
algorithms compute tighter bounds than the SoA, we also evaluate our algorithms
against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that
our algorithms compute bounds up to 40% tighter than the SoA.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11628 title=Abstract>arXiv:2401.11628</a> [<a href=https://arxiv.org/pdf/2401.11628 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11628 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11628 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wei Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kelly%2C+R+M">Ryan M. Kelly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rogerson%2C+M+J">Melissa J. Rogerson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Waycott%2C+J">Jenny Waycott</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Recent innovations in digital technology offer significant opportunities for
older adults to engage in meaningful activities. To investigate older adults'
perceptions of using existing and emerging technologies for meaningful
activities, we conducted three participatory design workshops and follow-up
interviews with adults aged over 65. The workshops encompassed discussions on
existing technologies for meaningful activities, demonstrations of emerging
technologies such as VR, AR, and AI, and design activities including
prototyping and storyboarding. Our findings show that while participants had
diverse interpretations of meaningful activities, they sought to use
technologies to support continuity in the pursuit of these activities.
Specifically, participants highlighted the importance of safe aging at home,
which provides a pathway for meaningful activities in later life. We further
discuss participants' discerning attitudes when assessing the use of different
technologies for meaningful activities and several values and attributes they
desire when envisioning future technologies, including simplicity, positivity,
proactivity, and integration.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11629 title=Abstract>arXiv:2401.11629</a> [<a href=https://arxiv.org/pdf/2401.11629 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11629 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11629 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Jump off the Bandwagon? Characterizing Bandwagon Fans' Future Loyalty in Online NBA Fan Communities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yichen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+Q">Qin Lv</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE SocialCom 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Online user dynamics has been actively studied in recent years and bandwagon
behavior is one of the most representative topics which can provide valuable
insights for user identity change. Many previous studies have characterized
bandwagon users and leveraged such characteristics to tackle practical problems
such as community loyalty prediction. However, very few of them have
investigated bandwagon dynamics from a long-term perspective. In this work, we
focus on characterizing and predicting long-term bandwagon user behaviors in
the context of online fan loyalty. Using a dataset collected from NBA-related
discussion forums on Reddit, we trace the long-term loyalty status of bandwagon
fans to capture their latent behavioral characteristics and then propose a
computational model to predict their next sport season loyalty status with
their home teams. Our analyses reveal that bandwagoning for most fans is a
temporary switch and most of them will be back in the long term. In addition,
online fans with different loyalty levels to their home teams have demonstrated
different behaviors in various aspects, such as activity level, language usage
and reply network properties. We then propose a model based on such behavioral
characteristics to predict their next-season loyalty status. Its promising
performance demonstrates the effectiveness of our behavior characterization.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11630 title=Abstract>arXiv:2401.11630</a> [<a href=https://arxiv.org/pdf/2401.11630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reframing Offline Reinforcement Learning as a Regression Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koirala%2C+P">Prajwal Koirala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fleming%2C+C">Cody Fleming</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>The study proposes the reformulation of offline reinforcement learning as a
regression problem that can be solved with decision trees. Aiming to predict
actions based on input states, return-to-go (RTG), and timestep information, we
observe that with gradient-boosted trees, the agent training and inference are
very fast, the former taking less than a minute. Despite the simplification
inherent in this reformulated problem, our agent demonstrates performance that
is at least on par with established methods. This assertion is validated by
testing it across standard datasets associated with D4RL Gym-MuJoCo tasks. We
further discuss the agent's ability to generalize by testing it on two extreme
cases, how it learns to model the return distributions effectively even with
highly skewed expert datasets, and how it exhibits robust performance in
scenarios with sparse/delayed rewards.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11631 title=Abstract>arXiv:2401.11631</a> [<a href=https://arxiv.org/pdf/2401.11631 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11631 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text-to-Image Cross-Modal Generation: A Systematic Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%BBelaszczyk%2C+M">Maciej Żelaszczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%C5%84dziuk%2C+J">Jacek Mańdziuk</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>We review research on generating visual data from text from the angle of
"cross-modal generation." This point of view allows us to draw parallels
between various methods geared towards working on input text and producing
visual output, without limiting the analysis to narrow sub-areas. It also
results in the identification of common templates in the field, which are then
compared and contrasted both within pools of similar methods and across lines
of research. We provide a breakdown of text-to-image generation into various
flavors of image-from-text methods, video-from-text methods, image editing,
self-supervised and graph-based approaches. In this discussion, we focus on
research papers published at 8 leading machine learning conferences in the
years 2016-2022, also incorporating a number of relevant papers not matching
the outlined search criteria. The conducted review suggests a significant
increase in the number of papers published in the area and highlights research
gaps and potential lines of investigation. To our knowledge, this is the first
review to systematically look at text-to-image generation from the perspective
of "cross-modal generation."
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11632 title=Abstract>arXiv:2401.11632</a> [<a href=https://arxiv.org/pdf/2401.11632 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11632 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Are We Optimizing For? A Human-centric Evaluation Of Deep Learning-based Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+R">Ruixuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akella%2C+A">Avinash Akella</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xinyi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+R">Ruoyan Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konstan%2C+J+A">Joseph A. Konstan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)
</div>
<p class=mathjax>Deep learning-based (DL) models in recommender systems (RecSys) have gained
significant recognition for their remarkable accuracy in predicting user
preferences. However, their performance often lacks a comprehensive evaluation
from a human-centric perspective, which encompasses various dimensions beyond
simple interest matching. In this work, we have developed a robust
human-centric evaluation framework that incorporates seven diverse metrics to
assess the quality of recommendations generated by five recent open-sourced DL
models. Our evaluation datasets consist of both offline benchmark data and
personalized online recommendation feedback collected from 445 real users. We
find that (1) different DL models have different pros and cons in the
multi-dimensional metrics that we test with; (2) users generally want a
combination of accuracy with at least one another human values in the
recommendation; (3) the degree of combination of different values needs to be
carefully experimented to user preferred level.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11633 title=Abstract>arXiv:2401.11633</a> [<a href=https://arxiv.org/pdf/2401.11633 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11633 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to Vision Encoders with Multimodal Loss
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shipard%2C+J">Jordan Shipard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wiliem%2C+A">Arnold Wiliem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thanh%2C+K+N">Kien Nguyen Thanh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+W">Wei Xiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fookes%2C+C">Clinton Fookes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The fusion of vision and language has brought about a transformative shift in
computer vision through the emergence of Vision-Language Models (VLMs).
However, the resource-intensive nature of existing VLMs poses a significant
challenge. We need an accessible method for developing the next generation of
VLMs. To address this issue, we propose Zoom-shot, a novel method for
transferring the zero-shot capabilities of CLIP to any pre-trained vision
encoder. We do this by exploiting the multimodal information (i.e. text and
image) present in the CLIP latent space through the use of specifically
designed multimodal loss functions. These loss functions are (1)
cycle-consistency loss and (2) our novel prompt-guided knowledge distillation
loss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP's
zero-shot classification, to capture the interactions between text and image
features. With our multimodal losses, we train a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-114-Frame tabindex=0><nobr><span class=math id=MathJax-Span-657 style=width:8.915em;display:inline-block><span style=display:inline-block;position:relative;width:7.41em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1007.41em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-658><span class=texatom id=MathJax-Span-659><span class=mrow id=MathJax-Span-660><span class=mtext id=MathJax-Span-661 style=font-family:MathJax_Main-bold>linear mapping</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>
between the CLIP latent space and the latent space of a pre-trained vision
encoder, for only a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-115-Frame tabindex=0><nobr><span class=math id=MathJax-Span-662 style=width:7.179em;display:inline-block><span style=display:inline-block;position:relative;width:5.964em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.96em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-663><span class=texatom id=MathJax-Span-664><span class=mrow id=MathJax-Span-665><span class=mtext id=MathJax-Span-666 style=font-family:MathJax_Main-bold>single epoch</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>. Furthermore, Zoom-shot is entirely
unsupervised and is trained using <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-116-Frame tabindex=0><nobr><span class=math id=MathJax-Span-667 style=width:5.385em;display:inline-block><span style=display:inline-block;position:relative;width:4.459em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.4em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-668><span class=texatom id=MathJax-Span-669><span class=mrow id=MathJax-Span-670><span class=mtext id=MathJax-Span-671 style=font-family:MathJax_Main-bold>unpaired</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> data. We test the
zero-shot capabilities of a range of vision encoders augmented as new VLMs, on
coarse and fine-grained classification datasets, outperforming the previous
state-of-the-art in this problem domain. In our ablations, we find Zoom-shot
allows for a trade-off between data and compute during training; and our
state-of-the-art results can be obtained by reducing training from 20% to 1% of
the ImageNet training data with 20 epochs. All code and models are available on
GitHub.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11634 title=Abstract>arXiv:2401.11634</a> [<a href=https://arxiv.org/pdf/2401.11634 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11634 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MR.CAP: Multi-Robot Joint Control and Planning for Object Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaafar%2C+H+A">Hussein Ali Jaafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kao%2C+C">Cheng-Hao Kao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeedi%2C+S">Sajad Saeedi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> H. A. Jaafar, C. -H. Kao and S. Saeedi, "MR.CAP: Multi-Robot Joint Control and Planning for Object Transport," in IEEE Control Systems Letters, doi: 10.1109/LCSYS.2024.3349989
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>With the recent influx in demand for multi-robot systems throughout industry
and academia, there is an increasing need for faster, robust, and generalizable
path planning algorithms. Similarly, given the inherent connection between
control algorithms and multi-robot path planners, there is in turn an increased
demand for fast, efficient, and robust controllers. We propose a scalable joint
path planning and control algorithm for multi-robot systems with constrained
behaviours based on factor graph optimization. We demonstrate our algorithm on
a series of hardware and simulated experiments. Our algorithm is consistently
able to recover from disturbances and avoid obstacles while outperforming
state-of-the-art methods in optimization time, path deviation, and inter-robot
errors. See the code and supplementary video for experiments.
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11641 title=Abstract>arXiv:2401.11641</a> [<a href=https://arxiv.org/pdf/2401.11641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revolutionizing Finance with LLMs: An Overview of Applications and Insights
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Huaqin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zihao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yiwei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+T">Tianze Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+P">Peng Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shaochen Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+H">Haixing Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mai%2C+G">Gengchen Mai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Ninghao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianming Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In recent years, Large Language Models (LLMs) like ChatGPT have seen
considerable advancements and have been applied in diverse fields. Built on the
Transformer architecture, these models are trained on extensive datasets,
enabling them to understand and generate human language effectively. In the
financial domain, the deployment of LLMs is gaining momentum. These models are
being utilized for automating financial report generation, forecasting market
trends, analyzing investor sentiment, and offering personalized financial
advice. Leveraging their natural language processing capabilities, LLMs can
distill key insights from vast financial data, aiding institutions in making
informed investment choices and enhancing both operational efficiency and
customer satisfaction. In this study, we provide a comprehensive overview of
the emerging integration of LLMs into various financial tasks. Additionally, we
conducted holistic tests on multiple financial tasks through the combination of
natural language instructions. Our findings show that GPT-4 effectively follow
prompt instructions across various financial tasks. This survey and evaluation
of LLMs in the financial domain aim to deepen the understanding of LLMs'
current role in finance for both financial practitioners and LLM researchers,
identify new research and application prospects, and highlight how these
technologies can be leveraged to solve practical challenges in the finance
industry.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11642 title=Abstract>arXiv:2401.11642</a> [<a href=https://arxiv.org/pdf/2401.11642 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11642 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SyzRetrospector: A Large-Scale Retrospective Study of Syzbot
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bursey%2C+J">Joseph Bursey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sani%2C+A+A">Ardalan Amiri Sani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Z">Zhiyun Qian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Operating Systems (cs.OS)
</div>
<p class=mathjax>Over the past 6 years, Syzbot has fuzzed the Linux kernel day and night to
report over 5570 bugs, of which 4604 have been patched [11]. While this is
impressive, we have found the average time to find a bug is over 405 days.
Moreover, we have found that current metrics commonly used, such as
time-to-find and number of bugs found, are inaccurate in evaluating Syzbot
since bugs often spend the majority of their lives hidden from the fuzzer. In
this paper, we set out to better understand and quantify Syzbot's performance
and improvement in finding bugs. Our tool, SyzRetrospector, takes a different
approach to evaluating Syzbot by finding the earliest that Syzbot was capable
of finding a bug, and why that bug was revealed. We use SyzRetrospector on a
large scale to analyze 559 bugs and find that bugs are hidden for an average of
331.17 days before Syzbot is even able to find them. We further present
findings on the behaviors of revealing factors, how some bugs are harder to
reveal than others, the trends in delays over the past 6 years, and how bug
location relates to delays. We also provide key takeaways for improving
Syzbot's delays.
</p>
</div>
</dd>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11644 title=Abstract>arXiv:2401.11644</a> [<a href=https://arxiv.org/pdf/2401.11644 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11644 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Friends Across Time: Multi-Scale Action Segmentation Transformer for Surgical Phase Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bokai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+J">Jiayuan Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+B">Bin Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Biskup%2C+D">Dean Biskup</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petculescu%2C+S">Svetlana Petculescu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chapman%2C+A">Angela Chapman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Automatic surgical phase recognition is a core technology for modern
operating rooms and online surgical video assessment platforms. Current
state-of-the-art methods use both spatial and temporal information to tackle
the surgical phase recognition task. Building on this idea, we propose the
Multi-Scale Action Segmentation Transformer (MS-AST) for offline surgical phase
recognition and the Multi-Scale Action Segmentation Causal Transformer
(MS-ASCT) for online surgical phase recognition. We use ResNet50 or
EfficientNetV2-M for spatial feature extraction. Our MS-AST and MS-ASCT can
model temporal information at different scales with multi-scale temporal
self-attention and multi-scale temporal cross-attention, which enhances the
capture of temporal relationships between frames and segments. We demonstrate
that our method can achieve 95.26% and 96.15% accuracy on the Cholec80 dataset
for online and offline surgical phase recognition, respectively, which achieves
new state-of-the-art results. Our method can also achieve state-of-the-art
results on non-medical datasets in the video action segmentation domain.
</p>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11647 title=Abstract>arXiv:2401.11647</a> [<a href=https://arxiv.org/pdf/2401.11647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huy%2C+L+Q">Le Quang Huy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+M+N+H">Minh N. H. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Many recent studies integrate federated learning (FL) with self-supervised
learning (SSL) to take advantage of raw training data distributed across edge
devices. However, edge devices often struggle with high computation and
communication costs imposed by SSL and FL algorithms. To tackle this hindrance,
we propose LW-FedSSL, a layer-wise federated self-supervised learning approach
that allows edge devices to incrementally train one layer of the model at a
time. LW-FedSSL comprises server-side calibration and representation alignment
mechanisms to maintain comparable performance with end-to-end FedSSL while
significantly lowering clients' resource requirements. The server-side
calibration mechanism takes advantage of the resource-rich server in an FL
environment to assist in global model training. Meanwhile, the representation
alignment mechanism encourages closeness between representations of FL local
models and those of the global model. Our experiments show that LW-FedSSL has a
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-117-Frame tabindex=0><nobr><span class=math id=MathJax-Span-672 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1001.91em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-673><span class=mn id=MathJax-Span-674 style=font-family:MathJax_Main>3.3</span><span class=mo id=MathJax-Span-675 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> lower memory requirement and a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-118-Frame tabindex=0><nobr><span class=math id=MathJax-Span-676 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.91em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-677><span class=mn id=MathJax-Span-678 style=font-family:MathJax_Main>3.2</span><span class=mo id=MathJax-Span-679 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> cheaper communication
cost than its end-to-end counterpart. We also explore a progressive training
strategy called Prog-FedSSL that outperforms end-to-end training with a similar
memory requirement and a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-119-Frame tabindex=0><nobr><span class=math id=MathJax-Span-680 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.91em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-681><span class=mn id=MathJax-Span-682 style=font-family:MathJax_Main>1.8</span><span class=mo id=MathJax-Span-683 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> cheaper communication cost.
</p>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11648 title=Abstract>arXiv:2401.11648</a> [<a href=https://arxiv.org/pdf/2401.11648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koo%2C+H">Heejoon Koo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024 (The 18th Conference of the European Chapter of the Association for Computational Linguistics)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Predicting next visit diagnosis using Electronic Health Records (EHR) is an
essential task in healthcare, critical for devising proactive future plans for
both healthcare providers and patients. Nonetheless, many preceding studies
have not sufficiently addressed the heterogeneous and hierarchical
characteristics inherent in EHR data, inevitably leading to sub-optimal
performance. To this end, we propose NECHO, a novel medical code-centric
multimodal contrastive EHR learning framework with hierarchical regularisation.
First, we integrate multifaceted information encompassing medical codes,
demographics, and clinical notes using a tailored network design and a pair of
bimodal contrastive losses, all of which pivot around a medical code
representation. We also regularise modality-specific encoders using a parental
level information in medical ontology to learn hierarchical structure of EHR
data. A series of experiments on MIMIC-III data demonstrates effectiveness of
our approach.
</p>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11649 title=Abstract>arXiv:2401.11649</a> [<a href=https://arxiv.org/pdf/2401.11649 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11649 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+J">Jiazheng Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+B">Boyuan Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+J">Jianbiao Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+X">Xingxing Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+G">Guang Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingdong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yong Liu</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, the rise of large-scale vision-language pretrained models like
CLIP, coupled with the technology of Parameter-Efficient FineTuning (PEFT), has
captured substantial attraction in video action recognition. Nevertheless,
prevailing approaches tend to prioritize strong supervised performance at the
expense of compromising the models' generalization capabilities during
transfer. In this paper, we introduce a novel Multimodal, Multi-task CLIP
adapting framework named \name to address these challenges, preserving both
high supervised performance and robust transferability. Firstly, to enhance the
individual modality architectures, we introduce multimodal adapters to both the
visual and text branches. Specifically, we design a novel visual TED-Adapter,
that performs global Temporal Enhancement and local temporal Difference
modeling to improve the temporal representation capabilities of the visual
encoder. Moreover, we adopt text encoder adapters to strengthen the learning of
semantic label information. Secondly, we design a multi-task decoder with a
rich set of supervisory signals to adeptly satisfy the need for strong
supervised performance and generalization within a multimodal framework.
Experimental results validate the efficacy of our approach, demonstrating
exceptional performance in supervised learning while maintaining strong
generalization in zero-shot scenarios.
</p>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11650 title=Abstract>arXiv:2401.11650</a> [<a href=https://arxiv.org/pdf/2401.11650 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11650 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PointGL: A Simple Global-Local Framework for Efficient Point Cloud Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+T">Tingfa Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Efficient analysis of point clouds holds paramount significance in real-world
3D applications. Currently, prevailing point-based models adhere to the
PointNet++ methodology, which involves embedding and abstracting point features
within a sequence of spatially overlapping local point sets, resulting in
noticeable computational redundancy. Drawing inspiration from the streamlined
paradigm of pixel embedding followed by regional pooling in Convolutional
Neural Networks (CNNs), we introduce a novel, uncomplicated yet potent
architecture known as PointGL, crafted to facilitate efficient point cloud
analysis. PointGL employs a hierarchical process of feature acquisition through
two recursive steps. First, the Global Point Embedding leverages
straightforward residual Multilayer Perceptrons (MLPs) to effectuate feature
embedding for each individual point. Second, the novel Local Graph Pooling
technique characterizes point-to-point relationships and abstracts regional
representations through succinct local graphs. The harmonious fusion of
one-time point embedding and parameter-free graph pooling contributes to
PointGL's defining attributes of minimized model complexity and heightened
efficiency. Our PointGL attains state-of-the-art accuracy on the ScanObjectNN
dataset while exhibiting a runtime that is more than 5 times faster and
utilizing only approximately 4% of the FLOPs and 30% of the parameters compared
to the recent PointMLP model. The code for PointGL is available at
https://github.com/Roywangj/PointGL.
</p>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11652 title=Abstract>arXiv:2401.11652</a> [<a href=https://arxiv.org/pdf/2401.11652 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11652 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+M+N+H">Minh N.H. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S+T">Seong Tae Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thai%2C+M+T">My T. Thai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in Neural Networks
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Federated learning (FL) has emerged as a promising approach to
collaboratively train machine learning models across multiple edge devices
while preserving privacy. The success of FL hinges on the efficiency of
participating models and their ability to handle the unique challenges of
distributed learning. While several variants of Vision Transformer (ViT) have
shown great potential as alternatives to modern convolutional neural networks
(CNNs) for centralized training, the unprecedented size and higher
computational demands hinder their deployment on resource-constrained edge
devices, challenging their widespread application in FL. Since client devices
in FL typically have limited computing resources and communication bandwidth,
models intended for such devices must strike a balance between model size,
computational efficiency, and the ability to adapt to the diverse and non-IID
data distributions encountered in FL. To address these challenges, we propose
OnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks
with limited training data and resources. Our models incorporate image-specific
inductive biases through the LCT tokenizer by leveraging efficient depthwise
separable convolutions in residual linear bottleneck blocks to extract local
features, while the multi-head self-attention (MHSA) mechanism in the LCT
encoder implicitly facilitates capturing global representations of images.
Extensive experiments on benchmark image datasets indicate that our models
outperform existing lightweight vision models while having fewer parameters and
lower computational demands, making them suitable for FL scenarios with data
heterogeneity and communication bottlenecks.
</p>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11654 title=Abstract>arXiv:2401.11654</a> [<a href=https://arxiv.org/pdf/2401.11654 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11654 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ActionHub: A Large-scale Action Video Description Dataset for Zero-shot Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiaming Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+J">Junwei Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+K">Kun-Yu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jinrui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Zero-shot action recognition (ZSAR) aims to learn an alignment model between
videos and class descriptions of seen actions that is transferable to unseen
actions. The text queries (class descriptions) used in existing ZSAR works,
however, are often short action names that fail to capture the rich semantics
in the videos, leading to misalignment. With the intuition that video content
descriptions (e.g., video captions) can provide rich contextual information of
visual concepts in videos, we propose to utilize human annotated video
descriptions to enrich the semantics of the class descriptions of each action.
However, all existing action video description datasets are limited in terms of
the number of actions, the semantics of video descriptions, etc. To this end,
we collect a large-scale action video descriptions dataset named ActionHub,
which covers a total of 1,211 common actions and provides 3.6 million action
video descriptions. With the proposed ActionHub dataset, we further propose a
novel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, which
consists of a Dual Cross-modality Alignment module and a Cross-action
Invariance Mining module. Specifically, the Dual Cross-modality Alignment
module utilizes both action labels and video descriptions from ActionHub to
obtain rich class semantic features for feature alignment. The Cross-action
Invariance Mining module exploits a cycle-reconstruction process between the
class semantic feature spaces of seen actions and unseen actions, aiming to
guide the model to learn cross-action invariant representations. Extensive
experimental results demonstrate that our CoCo framework significantly
outperforms the state-of-the-art on three popular ZSAR benchmarks (i.e.,
Kinetics-ZSAR, UCF101 and HMDB51) under two different learning protocols in
ZSAR. We will release our code, models, and the proposed ActionHub dataset.
</p>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11656 title=Abstract>arXiv:2401.11656</a> [<a href=https://arxiv.org/pdf/2401.11656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Agent-Based Modeling of C. Difficile Spread in Hospitals: Assessing Contribution of High-Touch vs. Low-Touch Surfaces and Inoculations' Containment Impact
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdidizaji%2C+S">Sina Abdidizaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yalabadi%2C+A+K">Ali Khodabandeh Yalabadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazdani-Jahromi%2C+M">Mehdi Yazdani-Jahromi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garibay%2C+O+O">Ozlem Ozmen Garibay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garibay%2C+I">Ivan Garibay</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted and presented at the Computational Social Science Society of the Americas Conference (CSS 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>Health issues and pandemics remain paramount concerns in the contemporary
era. Clostridioides Difficile Infection (CDI) stands out as a critical
healthcare-associated infection with global implications. Effectively
understanding the mechanisms of infection dissemination within healthcare units
and hospitals is imperative to implement targeted containment measures. In this
study, we address the limitations of prior research by Sulyok et al., where
they delineated two distinct categories of surfaces as high-touch and low-touch
fomites, and subsequently evaluated the viral spread contribution of each
surface utilizing mathematical modeling and Ordinary Differential Equations
(ODE). Acknowledging the indispensable role of spatial features and
heterogeneity in the modeling of hospital and healthcare settings, we employ
agent-based modeling to capture new insights. By incorporating spatial
considerations and heterogeneous patients, we explore the impact of high-touch
and low-touch surfaces on contamination transmission between patients.
Furthermore, the study encompasses a comprehensive assessment of various
cleaning protocols, with differing intervals and detergent cleaning efficacies,
in order to identify the most optimal cleaning strategy and the most important
factor amidst the array of alternatives. Our results indicate that, among
various factors, the frequency of cleaning intervals is the most critical
element for controlling the spread of CDI in a hospital environment.
</p>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11658 title=Abstract>arXiv:2401.11658</a> [<a href=https://arxiv.org/pdf/2401.11658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Randomized Runge-Kutta Method for time-irregular delay differential equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Difonzo%2C+F+V">Fabio V. Difonzo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Przyby%C5%82owicz%2C+P">Paweł Przybyłowicz</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wu%2C+Y">Yue Wu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xie%2C+X">Xinheng Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2204.02016>arXiv:2204.02016</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Probability (math.PR)
</div>
<p class=mathjax>In this paper we investigate the existence, uniqueness and approximation of
solutions of delay differential equations (DDEs) with the right-hand side
functions <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-120-Frame tabindex=0><nobr><span class=math id=MathJax-Span-684 style=width:6.716em;display:inline-block><span style=display:inline-block;position:relative;width:5.558em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.44em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-685><span class=mi id=MathJax-Span-686 style=font-family:MathJax_Math-italic>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-687 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-688 style=font-family:MathJax_Math-italic;padding-left:0.292em>f<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-689 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-690 style=font-family:MathJax_Math-italic>t</span><span class=mo id=MathJax-Span-691 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-692 style=font-family:MathJax_Math-italic;padding-left:0.177em>x</span><span class=mo id=MathJax-Span-693 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-694 style=font-family:MathJax_Math-italic;padding-left:0.177em>z<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-695 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> that are Lipschitz continuous with respect to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-121-Frame tabindex=0><nobr><span class=math id=MathJax-Span-696 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-697><span class=mi id=MathJax-Span-698 style=font-family:MathJax_Math-italic>x</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> but
only H\"older continuous with respect to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-122-Frame tabindex=0><nobr><span class=math id=MathJax-Span-699 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.97em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-700><span class=mo id=MathJax-Span-701 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-702 style=font-family:MathJax_Math-italic>t</span><span class=mo id=MathJax-Span-703 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-704 style=font-family:MathJax_Math-italic;padding-left:0.177em>z<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-705 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. We give a construction of the
randomized two-stage Runge-Kutta scheme for DDEs and investigate its upper
error bound in the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-123-Frame tabindex=0><nobr><span class=math id=MathJax-Span-706 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.49em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-707><span class=msubsup id=MathJax-Span-708><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-709 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-710 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-711 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-712 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-713 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-norm for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-124-Frame tabindex=0><nobr><span class=math id=MathJax-Span-714 style=width:6.195em;display:inline-block><span style=display:inline-block;position:relative;width:5.153em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-715><span class=mi id=MathJax-Span-716 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-717 style=font-family:MathJax_Main;padding-left:0.292em>∈</span><span class=mo id=MathJax-Span-718 style=font-family:MathJax_Main;padding-left:0.292em>[</span><span class=mn id=MathJax-Span-719 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-720 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-721 style=font-family:MathJax_Main;padding-left:0.177em>+</span><span class=mi id=MathJax-Span-722 style=font-family:MathJax_Main>∞</span><span class=mo id=MathJax-Span-723 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. Finally, we
report on results of numerical experiments.
</p>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11660 title=Abstract>arXiv:2401.11660</a> [<a href=https://arxiv.org/pdf/2401.11660 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11660 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differentiable Tree Search in Latent State Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mittal%2C+D">Dixant Mittal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+W+S">Wee Sun Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In decision-making problems with limited training data, policy functions
approximated using deep neural networks often exhibit suboptimal performance.
An alternative approach involves learning a world model from the limited data
and determining actions through online search. However, the performance is
adversely affected by compounding errors arising from inaccuracies in the
learnt world model. While methods like TreeQN have attempted to address these
inaccuracies by incorporating algorithmic structural biases into their
architectures, the biases they introduce are often weak and insufficient for
complex decision-making tasks. In this work, we introduce Differentiable Tree
Search (DTS), a novel neural network architecture that significantly
strengthens the inductive bias by embedding the algorithmic structure of a
best-first online search algorithm. DTS employs a learnt world model to conduct
a fully differentiable online search in latent state space. The world model is
jointly optimised with the search algorithm, enabling the learning of a robust
world model and mitigating the effect of model inaccuracies. We address
potential Q-function discontinuities arising from naive incorporation of
best-first search by adopting a stochastic tree expansion policy, formulating
search tree expansion as a decision-making task, and introducing an effective
variance reduction technique for the gradient computation. We evaluate DTS in
an offline-RL setting with a limited training data scenario on Procgen games
and grid navigation task, and demonstrate that DTS outperforms popular
model-free and model-based baselines.
</p>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11663 title=Abstract>arXiv:2401.11663</a> [<a href=https://arxiv.org/pdf/2401.11663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> "I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.": A Study of Blind TikTokers' Content Moderation Experiences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+Y">Yao Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+J">Jie Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Callis%2C+A">Anisa Callis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cotter%2C+K">Kelley Cotter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 paged, 1 Figure, accepted by CHI'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>The Human-Computer Interaction (HCI) community has consistently focused on
the experiences of users moderated by social media platforms. Recently,
scholars have noticed that moderation practices could perpetuate biases,
resulting in the marginalization of user groups undergoing moderation. However,
most studies have primarily addressed marginalization related to issues such as
racism or sexism, with little attention given to the experiences of people with
disabilities. In this paper, we present a study on the moderation experiences
of blind users on TikTok, also known as "BlindToker," to address this gap. We
conducted semi-structured interviews with 20 BlindTokers and used thematic
analysis to analyze the data. Two main themes emerged: BlindTokers' situated
content moderation experiences and their reactions to content moderation. We
reported on the lack of accessibility on TikTok's platform, contributing to the
moderation and marginalization of BlindTokers. Additionally, we discovered
instances of harassment from trolls that prompted BlindTokers to respond with
harsh language, triggering further moderation. We discussed these findings in
the context of the literature on moderation, marginalization, and
transformative justice, seeking solutions to address such issues.
</p>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11664 title=Abstract>arXiv:2401.11664</a> [<a href=https://arxiv.org/pdf/2401.11664 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11664 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-Space Cost Fault Tolerance for Transformer-based Language Models on ReRAM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bingbing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+G">Geng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zigeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+H">Hongwu Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behnam%2C+P">Payman Behnam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+W">Wujie Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
</div>
<p class=mathjax>Resistive Random Access Memory (ReRAM) has emerged as a promising platform
for deep neural networks (DNNs) due to its support for parallel in-situ
matrix-vector multiplication. However, hardware failures, such as
stuck-at-fault defects, can result in significant prediction errors during
model inference. While additional crossbars can be used to address these
failures, they come with storage overhead and are not efficient in terms of
space, energy, and cost. In this paper, we propose a fault protection mechanism
that incurs zero space cost. Our approach includes: 1) differentiable structure
pruning of rows and columns to reduce model redundancy, 2) weight duplication
and voting for robust output, and 3) embedding duplicated most significant bits
(MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE
benchmark with the BERT model, and experimental results prove its
effectiveness.
</p>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11666 title=Abstract>arXiv:2401.11666</a> [<a href=https://arxiv.org/pdf/2401.11666 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11666 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> P2DT: Mitigating Forgetting in task-incremental Learning with progressive prompt Decision Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xiaoyang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jing Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Bokui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 49th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Catastrophic forgetting poses a substantial challenge for managing
intelligent agents controlled by a large model, causing performance degradation
when these agents face new tasks. In our work, we propose a novel solution -
the Progressive Prompt Decision Transformer (P2DT). This method enhances a
transformer-based model by dynamically appending decision tokens during new
task training, thus fostering task-specific policies. Our approach mitigates
forgetting in continual and offline reinforcement learning scenarios. Moreover,
P2DT leverages trajectories collected via traditional reinforcement learning
from all tasks and generates new task-specific tokens during training, thereby
retaining knowledge from previous studies. Preliminary results demonstrate that
our model effectively alleviates catastrophic forgetting and scales well with
increasing task environments.
</p>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11667 title=Abstract>arXiv:2401.11667</a> [<a href=https://arxiv.org/pdf/2401.11667 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11667 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> INCPrompt: Task-Aware incremental Prompting for Rehearsal-Free Class-incremental Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xiaoyang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jing Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Bokui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 49th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper introduces INCPrompt, an innovative continual learning solution
that effectively addresses catastrophic forgetting. INCPrompt's key innovation
lies in its use of adaptive key-learner and task-aware prompts that capture
task-relevant information. This unique combination encapsulates general
knowledge across tasks and encodes task-specific knowledge. Our comprehensive
evaluation across multiple continual learning benchmarks demonstrates
INCPrompt's superiority over existing algorithms, showing its effectiveness in
mitigating catastrophic forgetting while maintaining high performance. These
results highlight the significant impact of task-aware incremental prompting on
continual learning performance.
</p>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11669 title=Abstract>arXiv:2401.11669</a> [<a href=https://arxiv.org/pdf/2401.11669 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11669 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11669 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Improved Grey Wolf Optimization Algorithm for Heart Disease Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+S">Sihan Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhikai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Shuyao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yujun Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>This paper presents a unique solution to challenges in medical image
processing by incorporating an adaptive curve grey wolf optimization (ACGWO)
algorithm into neural network backpropagation. Neural networks show potential
in medical data but suffer from issues like overfitting and lack of
interpretability due to imbalanced and scarce data. Traditional Gray Wolf
Optimization (GWO) also has its drawbacks, such as a lack of population
diversity and premature convergence. This paper addresses these problems by
introducing an adaptive algorithm, enhancing the standard GWO with a sigmoid
function. This algorithm was extensively compared to four leading algorithms
using six well-known test functions, outperforming them effectively. Moreover,
by utilizing the ACGWO, we increase the robustness and generalization of the
neural network, resulting in more interpretable predictions. Applied to the
publicly accessible Cleveland Heart Disease dataset, our technique surpasses
ten other methods, achieving 86.8% accuracy, indicating its potential for
efficient heart disease prediction in the clinical setting.
</p>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11673 title=Abstract>arXiv:2401.11673</a> [<a href=https://arxiv.org/pdf/2401.11673 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11673 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+C">Chenjie Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xinlin Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR2024
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> ICLR(International Conference on Learning Representations) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent advancements in learning-based Multi-View Stereo (MVS) methods have
prominently featured transformer-based models with attention mechanisms.
However, existing approaches have not thoroughly investigated the profound
influence of transformers on different MVS modules, resulting in limited depth
estimation capabilities. In this paper, we introduce MVSFormer++, a method that
prudently maximizes the inherent characteristics of attention to enhance
various components of the MVS pipeline. Formally, our approach involves
infusing cross-view information into the pre-trained DINOv2 model to facilitate
MVS learning. Furthermore, we employ different attention mechanisms for the
feature encoder and cost volume regularization, focusing on feature and spatial
aggregations respectively. Additionally, we uncover that some design details
would substantially impact the performance of transformer modules in MVS,
including normalized 3D positional encoding, adaptive attention scaling, and
the position of layer normalization. Comprehensive experiments on DTU,
Tanks-and-Temples, BlendedMVS, and ETH3D validate the effectiveness of the
proposed method. Notably, MVSFormer++ achieves state-of-the-art performance on
the challenging DTU and Tanks-and-Temples benchmarks.
</p>
</div>
</dd>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11674 title=Abstract>arXiv:2401.11674</a> [<a href=https://arxiv.org/pdf/2401.11674 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11674 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Memory-Efficient Prompt Tuning for Incremental Histopathology Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lequan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heng%2C+P">Pheng-Ann Heng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recent studies have made remarkable progress in histopathology
classification. Based on current successes, contemporary works proposed to
further upgrade the model towards a more generalizable and robust direction
through incrementally learning from the sequentially delivered domains. Unlike
previous parameter isolation based approaches that usually demand massive
computation resources during model updating, we present a memory-efficient
prompt tuning framework to cultivate model generalization potential in
economical memory cost. For each incoming domain, we reuse the existing
parameters of the initial classification model and attach lightweight trainable
prompts into it for customized tuning. Considering the domain heterogeneity, we
perform decoupled prompt tuning, where we adopt a domain-specific prompt for
each domain to independently investigate its distinctive characteristics, and
one domain-invariant prompt shared across all domains to continually explore
the common content embedding throughout time. All domain-specific prompts will
be appended to the prompt bank and isolated from further changes to prevent
forgetting the distinctive features of early-seen domains. While the
domain-invariant prompt will be passed on and iteratively evolve by
style-augmented prompt refining to improve model generalization capability over
time. In specific, we construct a graph with existing prompts and build a
style-augmented graph attention network to guide the domain-invariant prompt
exploring the overlapped latent embedding among all delivered domains for more
domain generic representations. We have extensively evaluated our framework
with two histopathology tasks, i.e., breast cancer metastasis classification
and epithelium-stroma tissue classification, where our approach yielded
superior performance and memory efficiency over the competing methods.
</p>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11677 title=Abstract>arXiv:2401.11677</a> [<a href=https://arxiv.org/pdf/2401.11677 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11677 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11677 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Emulation-based Stabilization for Networked Control Systems with Stochastic Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ren%2C+W">Wei Ren</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pan%2C+Z">Zhuo-Rui Pan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sun%2C+X">Xi-Ming Sun</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Teel%2C+A+R">Andrew R. Teel</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nesic%2C+D">Dragan Nesic</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures, accepted
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper studies the stabilization problem of networked control systems
(NCSs) with random packet dropouts caused by stochastic channels. To describe
the effects of stochastic channels on the information transmission, the
transmission times are assumed to be deterministic, whereas the packet
transmission is assumed to be random. We first propose a stochastic scheduling
protocol to model random packet dropouts, and address the properties of the
proposed stochastic scheduling protocol. The proposed scheduling protocol
provides a unified modelling framework for a general class of random packet
dropouts due to different stochastic channels. Next, the proposed scheduling
protocol is embedded into the closed-loop system, which leads to a stochastic
hybrid model for NCSs with random packet dropouts. Based on this stochastic
hybrid model, we follow the emulation approach to establish sufficient
conditions to guarantee uniform global asymptotical stability in probability.
In particular, an upper bound on the maximally allowable transmission interval
is derived explicitly for all stochastic protocols satisfying Lyapunov
conditions that guarantee uniform global asymptotic stability in probability.
Finally, two numerical examples are presented to demonstrate the derived
results.
</p>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11681 title=Abstract>arXiv:2401.11681</a> [<a href=https://arxiv.org/pdf/2401.11681 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11681 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Functional Eigen-Grasping Using Approach Heatmaps
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aburub%2C+M">Malek Aburub</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Higashi%2C+K">Kazuki Higashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+W">Weiwei Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harada%2C+K">Kensuke Harada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This work presents a framework for a robot with a multi-fingered hand to
freely utilize daily tools, including functional parts like buttons and
triggers. An approach heatmap is generated by selecting a functional finger,
indicating optimal palm positions on the object's surface that enable the
functional finger to contact the tool's functional part. Once the palm position
is identified through the heatmap, achieving the functional grasp becomes a
straightforward process where the fingers stably grasp the object with
low-dimensional inputs using the eigengrasp. As our approach does not need
human demonstrations, it can easily adapt to various sizes and designs,
extending its applicability to different objects. In our approach, we use
directional manipulability to obtain the approach heatmap. In addition, we add
two kinds of energy functions, i.e., palm energy and functional energy
functions, to realize the eigengrasp. Using this method, each robotic gripper
can autonomously identify its optimal workspace for functional grasping,
extending its applicability to non-anthropomorphic robotic hands. We show that
several daily tools like spray, drill, and remotes can be efficiently used by
not only an anthropomorphic Shadow hand but also a non-anthropomorphic Barrett
hand.
</p>
</div>
</dd>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11685 title=Abstract>arXiv:2401.11685</a> [<a href=https://arxiv.org/pdf/2401.11685 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11685 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golden%2C+C">Courtney Golden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ilan%2C+D">Dan Ilan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cebry%2C+N">Nicholas Cebry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batten%2C+C">Christopher Batten</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 5th Workshop on Accelerator Architecture in Computational Biology
 and Bioinformatics (AACBB), June 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Genomics (q-bio.GN)
</div>
<p class=mathjax>DNA sequence alignment is an important workload in computational genomics.
Reference-guided DNA assembly involves aligning many read sequences against
candidate locations in a long reference genome. To reduce the computational
load of this alignment, candidate locations can be pre-filtered using simpler
alignment algorithms like edit distance. Prior work has explored accelerating
filtering on simulated compute-in-DRAM, due to the massive parallelism of
compute-in-memory architectures. In this paper, we present work-in-progress on
accelerating filtering using a commercial compute-in-SRAM accelerator. We
leverage the recently released Gemini accelerator platform from GSI Technology,
which is the first, to our knowledge, commercial-scale compute-in-SRAM system.
We accelerate the Myers' bit-parallel edit distance algorithm, producing
average speedups of 14.1x over single-core CPU performance. Individual
query/candidate alignments produce speedups of up to 24.1x. These early results
suggest this novel architecture is well-suited to accelerating the filtering
step of sequence-to-sequence DNA alignment.
</p>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11686 title=Abstract>arXiv:2401.11686</a> [<a href=https://arxiv.org/pdf/2401.11686 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11686 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolutionary dynamics of any multiplayer game on regular graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaoqian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perc%2C+M">Matjaž Perc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szolnoki%2C+A">Attila Szolnoki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Complexity (cs.CC); Cellular Automata and Lattice Gases (nlin.CG); Populations and Evolution (q-bio.PE)
</div>
<p class=mathjax>Multiplayer games on graphs are at the heart of theoretical descriptions of
key evolutionary processes that govern vital social and natural systems.
However, a comprehensive theoretical framework for solving multiplayer games
with an arbitrary number of strategies on graphs is still missing. Here, we
solve this by drawing an analogy with the Ball-and-Box problem, based on which
we show that the local configuration of multiplayer games on graphs is
equivalent to distributing <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-125-Frame tabindex=0><nobr><span class=math id=MathJax-Span-724 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-725><span class=mi id=MathJax-Span-726 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> identical co-players among <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-126-Frame tabindex=0><nobr><span class=math id=MathJax-Span-727 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-728><span class=mi id=MathJax-Span-729 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> distinct
strategies. We use this to derive the replicator equation for any <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-127-Frame tabindex=0><nobr><span class=math id=MathJax-Span-730 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-731><span class=mi id=MathJax-Span-732 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-strategy
multiplayer game under weak selection, which can be solved in polynomial time.
As an example, we revisit the second-order free-riding problem, where costly
punishment cannot truly resolve social dilemmas in a well-mixed population.
Yet, in structured populations, we derive an accurate threshold for the
punishment strength, beyond which punishment can either lead to the extinction
of defection or transform the system into a rock-paper-scissors-like cycle. The
analytical solution also qualitatively agrees with the phase diagrams that were
previously obtained for non-marginal selection strengths. Our framework thus
allows an exploration of any multi-strategy multiplayer game on regular graphs.
</p>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11687 title=Abstract>arXiv:2401.11687</a> [<a href=https://arxiv.org/pdf/2401.11687 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11687 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TIM: An Efficient Temporal Interaction Module for Spiking Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+S">Sicheng Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+G">Guobin Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10pages,6figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Spiking Neural Networks (SNNs), as the third generation of neural networks,
have gained prominence for their biological plausibility and computational
efficiency, especially in processing diverse datasets. The integration of
attention mechanisms, inspired by advancements in neural network architectures,
has led to the development of Spiking Transformers. These have shown promise in
enhancing SNNs' capabilities, particularly in the realms of both static and
neuromorphic datasets. Despite their progress, a discernible gap exists in
these systems, specifically in the Spiking Self Attention (SSA) mechanism's
effectiveness in leveraging the temporal processing potential of SNNs. To
address this, we introduce the Temporal Interaction Module (TIM), a novel,
convolution-based enhancement designed to augment the temporal data processing
abilities within SNN architectures. TIM's integration into existing SNN
frameworks is seamless and efficient, requiring minimal additional parameters
while significantly boosting their temporal information handling capabilities.
Through rigorous experimentation, TIM has demonstrated its effectiveness in
exploiting temporal information, leading to state-of-the-art performance across
various neuromorphic datasets.
</p>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11694 title=Abstract>arXiv:2401.11694</a> [<a href=https://arxiv.org/pdf/2401.11694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parametric Matrix Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cook%2C+P">Patrick Cook</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jammooa%2C+D">Danny Jammooa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hjorth-Jensen%2C+M">Morten Hjorth-Jensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D+D">Daniel D. Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dean Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Nuclear Theory (nucl-th); Computational Physics (physics.comp-ph); Quantum Physics (quant-ph)
</div>
<p class=mathjax>We present a general class of machine learning algorithms called parametric
matrix models. Parametric matrix models are based on matrix equations, and the
design is motivated by the efficiency of reduced basis methods for
approximating solutions of parametric equations. The dependent variables can be
defined implicitly or explicitly, and the equations may use algebraic,
differential, or integral relations. Parametric matrix models can be trained
with empirical data only, and no high-fidelity model calculations are needed.
While originally designed for scientific computing, parametric matrix models
are universal function approximators that can be applied to general machine
learning problems. After introducing the underlying theory, we apply parametric
matrix models to a series of different challenges that show their performance
for a wide range of problems. For all the challenges tested here, parametric
matrix models produce accurate results within a computational framework that
allows for parameter extrapolation and interpretability.
</p>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11697 title=Abstract>arXiv:2401.11697</a> [<a href=https://arxiv.org/pdf/2401.11697 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11697 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11697 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A risk-based approach to assessing liability risk for AI-driven harms considering EU liability directive
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayanan%2C+S">Sundaraparipurnan Narayanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potkewitz%2C+M">Mark Potkewitz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Artificial intelligence can cause inconvenience, harm, or other unintended
consequences in various ways, including those that arise from defects or
malfunctions in the AI system itself or those caused by its use or misuse.
Responsibility for AI harms or unintended consequences must be addressed to
hold accountable the people who caused such harms and ensure that victims
receive compensation for any damages or losses they may have sustained.
Historical instances of harm caused by AI have led to European Union
establishing an AI Liability Directive. The directive aims to lay down a
uniform set of rules for access to information, delineate the duty and level of
care required for AI development and use, and clarify the burden of proof for
damages or harms caused by AI systems, establishing broader protection for
victims. The future ability of provider to contest a product liability claim
will depend on good practices adopted in designing, developing, and maintaining
AI systems in the market. This paper provides a risk-based approach to
examining liability for AI-driven injuries. It also provides an overview of
existing liability approaches, insights into limitations and complexities in
these approaches, and a detailed self-assessment questionnaire to assess the
risk associated with liability for a specific AI system from a provider's
perspective.
</p>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11698 title=Abstract>arXiv:2401.11698</a> [<a href=https://arxiv.org/pdf/2401.11698 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11698 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Admission Prediction in Undergraduate Applications: an Interpretable Deep Learning Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Priyadarshini%2C+A">Amisha Priyadarshini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinez-Neda%2C+B">Barbara Martinez-Neda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gago-Masague%2C+S">Sergio Gago-Masague</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted for Transdisciplinary AI 2023 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This article addresses the challenge of validating the admission committee's
decisions for undergraduate admissions. In recent years, the traditional review
process has struggled to handle the overwhelmingly large amount of applicants'
data. Moreover, this traditional assessment often leads to human bias, which
might result in discrimination among applicants. Although classical machine
learning-based approaches exist that aim to verify the quantitative assessment
made by the application reviewers, these methods lack scalability and suffer
from performance issues when a large volume of data is in place. In this
context, we propose deep learning-based classifiers, namely Feed-Forward and
Input Convex neural networks, which overcome the challenges faced by the
existing methods. Furthermore, we give additional insights into our model by
incorporating an interpretability module, namely LIME. Our training and test
datasets comprise applicants' data with a wide range of variables and
information. Our models achieve higher accuracy compared to the best-performing
traditional machine learning-based approach by a considerable margin of 3.03\%.
Additionally, we show the sensitivity of different features and their relative
impacts on the overall admission decision using the LIME technique.
</p>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11699 title=Abstract>arXiv:2401.11699</a> [<a href=https://arxiv.org/pdf/2401.11699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11699 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dissecting Bias of ChatGPT in College Major Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+A">Alex Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>I investigate bias in terms of ChatGPT's college major recommendations for
students with various profiles, looking at demographic disparities in factors
such as race, gender, and socioeconomic status, as well as educational
disparities such as score percentiles. By constructing prompts for the ChatGPT
API, allowing the model to recommend majors based on high school student
profiles, I evaluate bias using various metrics, including the Jaccard
Coefficient, Wasserstein Metric, and STEM Disparity Score. The results of this
study reveal a significant disparity in the set of recommended college majors,
irrespective of the bias metric applied.
</p>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11700 title=Abstract>arXiv:2401.11700</a> [<a href=https://arxiv.org/pdf/2401.11700 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11700 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Keep Decoding Parallel with Effective Knowledge Distillation from Language Models to End-to-end Speech Recognisers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hentschel%2C+M">Michael Hentschel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nishikawa%2C+Y">Yuta Nishikawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Komatsu%2C+T">Tatsuya Komatsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fujita%2C+Y">Yusuke Fujita</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>This study presents a novel approach for knowledge distillation (KD) from a
BERT teacher model to an automatic speech recognition (ASR) model using
intermediate layers. To distil the teacher's knowledge, we use an attention
decoder that learns from BERT's token probabilities. Our method shows that
language model (LM) information can be more effectively distilled into an ASR
model using both the intermediate layers and the final layer. By using the
intermediate layers as distillation target, we can more effectively distil LM
knowledge into the lower network layers. Using our method, we achieve better
recognition accuracy than with shallow fusion of an external LM, allowing us to
maintain fast parallel decoding. Experiments on the LibriSpeech dataset
demonstrate the effectiveness of our approach in enhancing greedy decoding with
connectionist temporal classification (CTC).
</p>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11704 title=Abstract>arXiv:2401.11704</a> [<a href=https://arxiv.org/pdf/2401.11704 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11704 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EK-Net:Real-time Scene Text Detection with Expand Kernel Distance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+B">Boyuan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fagui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Q">Quan Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 IEEE International Conference on Acoustics, Speech and Signal Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, scene text detection has received significant attention due to its
wide application. However, accurate detection in complex scenes of multiple
scales, orientations, and curvature remains a challenge. Numerous detection
methods adopt the Vatti clipping (VC) algorithm for multiple-instance training
to address the issue of arbitrary-shaped text. Yet we identify several bias
results from these approaches called the "shrinked kernel". Specifically, it
refers to a decrease in accuracy resulting from an output that overly favors
the text kernel. In this paper, we propose a new approach named Expand Kernel
Network (EK-Net) with expand kernel distance to compensate for the previous
deficiency, which includes three-stages regression to complete instance
detection. Moreover, EK-Net not only realize the precise positioning of
arbitrary-shaped text, but also achieve a trade-off between performance and
speed. Evaluation results demonstrate that EK-Net achieves state-of-the-art or
competitive performance compared to other advanced methods, e.g., F-measure of
85.72% at 35.42 FPS on ICDAR 2015, F-measure of 85.75% at 40.13 FPS on CTW1500.
</p>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11705 title=Abstract>arXiv:2401.11705</a> [<a href=https://arxiv.org/pdf/2401.11705 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11705 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain-Aware Cross-Attention for Cross-domain Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuhao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+S">Shiwei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+M">Mingjun Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+C">Changping Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+J">Jingping Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qianfang Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Cross-domain recommendation (CDR) is an important method to improve
recommender system performance, especially when observations in target domains
are sparse. However, most existing cross-domain recommendations fail to fully
utilize the target domain's special features and are hard to be generalized to
new domains. The designed network is complex and is not suitable for rapid
industrial deployment. Our method introduces a two-step domain-aware
cross-attention, extracting transferable features of the source domain from
different granularity, which allows the efficient expression of both domain and
user interests. In addition, we simplify the training process, and our model
can be easily deployed on new domains. We conduct experiments on both public
datasets and industrial datasets, and the experimental results demonstrate the
effectiveness of our method. We have also deployed the model in an online
advertising system and observed significant improvements in both
Click-Through-Rate (CTR) and effective cost per mille (ECPM).
</p>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11708 title=Abstract>arXiv:2401.11708</a> [<a href=https://arxiv.org/pdf/2401.11708 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11708 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Ling Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhaochen Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+C">Chenlin Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Minkai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project: <a href=https://github.com/YangLing0818/RPG-DiffusionMaster>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Diffusion models have exhibit exceptional performance in text-to-image
generation and editing. However, existing methods often face challenges when
handling complex text prompts that involve multiple objects with multiple
attributes and relationships. In this paper, we propose a brand new
training-free text-to-image generation/editing framework, namely Recaption,
Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning
ability of multimodal LLMs to enhance the compositionality of text-to-image
diffusion models. Our approach employs the MLLM as a global planner to
decompose the process of generating complex images into multiple simpler
generation tasks within subregions. We propose complementary regional diffusion
to enable region-wise compositional generation. Furthermore, we integrate
text-guided image generation and editing within the proposed RPG in a
closed-loop fashion, thereby enhancing generalization ability. Extensive
experiments demonstrate our RPG outperforms state-of-the-art text-to-image
diffusion models, including DALL-E 3 and SDXL, particularly in multi-category
object composition and text-image semantic alignment. Notably, our RPG
framework exhibits wide compatibility with various MLLM architectures (e.g.,
MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available
at: https://github.com/YangLing0818/RPG-DiffusionMaster
</p>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11709 title=Abstract>arXiv:2401.11709</a> [<a href=https://arxiv.org/pdf/2401.11709 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11709 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Haptic-Assisted Collaborative Robot Framework for Improved Situational Awareness in Skull Base Surgery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishida%2C+H">Hisashi Ishida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+M">Manish Sahu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munawar%2C+A">Adnan Munawar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagururu%2C+N">Nimesh Nagururu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galaiya%2C+D">Deepa Galaiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazanzides%2C+P">Peter Kazanzides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Creighton%2C+F+X">Francis X. Creighton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taylor%2C+R+H">Russell H. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> *These authors contributed equally
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Skull base surgery is a demanding field in which surgeons operate in and
around the skull while avoiding critical anatomical structures including nerves
and vasculature. While image-guided surgical navigation is the prevailing
standard, limitation still exists requiring personalized planning and
recognizing the irreplaceable role of a skilled surgeon. This paper presents a
collaboratively controlled robotic system tailored for assisted drilling in
skull base surgery. Our central hypothesis posits that this collaborative
system, enriched with haptic assistive modes to enforce virtual fixtures, holds
the potential to significantly enhance surgical safety, streamline efficiency,
and alleviate the physical demands on the surgeon. The paper describes the
intricate system development work required to enable these virtual fixtures
through haptic assistive modes. To validate our system's performance and
effectiveness, we conducted initial feasibility experiments involving a medical
student and two experienced surgeons. The experiment focused on drilling around
critical structures following cortical mastoidectomy, utilizing dental stone
phantom and cadaveric models. Our experimental results demonstrate that our
proposed haptic feedback mechanism enhances the safety of drilling around
critical structures compared to systems lacking haptic assistance. With the aid
of our system, surgeons were able to safely skeletonize the critical structures
without breaching any critical structure even under obstructed view of the
surgical site.
</p>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11711 title=Abstract>arXiv:2401.11711</a> [<a href=https://arxiv.org/pdf/2401.11711 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11711 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided Neural Radiance Fields for Sparse View Inputs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zelin Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+W">Weichen Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Neural Radiance Fields (NeRF) have garnered considerable attention as a
paradigm for novel view synthesis by learning scene representations from
discrete observations. Nevertheless, NeRF exhibit pronounced performance
degradation when confronted with sparse view inputs, consequently curtailing
its further applicability. In this work, we introduce Hierarchical Geometric,
Semantic, and Photometric Guided NeRF (HG3-NeRF), a novel methodology that can
address the aforementioned limitation and enhance consistency of geometry,
semantic content, and appearance across different views. We propose
Hierarchical Geometric Guidance (HGG) to incorporate the attachment of
Structure from Motion (SfM), namely sparse depth prior, into the scene
representations. Different from direct depth supervision, HGG samples volume
points from local-to-global geometric regions, mitigating the misalignment
caused by inherent bias in the depth prior. Furthermore, we draw inspiration
from notable variations in semantic consistency observed across images of
different resolutions and propose Hierarchical Semantic Guidance (HSG) to learn
the coarse-to-fine semantic content, which corresponds to the coarse-to-fine
scene representations. Experimental results demonstrate that HG3-NeRF can
outperform other state-of-the-art methods on different standard benchmarks and
achieve high-fidelity synthesis results for sparse view inputs.
</p>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11712 title=Abstract>arXiv:2401.11712</a> [<a href=https://arxiv.org/pdf/2401.11712 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11712 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A First Step Towards Runtime Analysis of Evolutionary Neural Architecture Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+Z">Zeqiong Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+C">Chao Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yanan Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>Evolutionary neural architecture search (ENAS) employs evolutionary
algorithms to find high-performing neural architectures automatically, and has
achieved great success. However, compared to the empirical success, its
rigorous theoretical analysis has yet to be touched. This work goes preliminary
steps toward the mathematical runtime analysis of ENAS. In particular, we
define a binary classification problem UNIFORM, and formulate an explicit
fitness function to represent the relationship between neural architecture and
classification accuracy. Furthermore, we consider (1+1)-ENAS algorithm with
mutation to optimize the neural architecture, and obtain the following runtime
bounds: 1) the one-bit mutation finds the optimum in an expected runtime of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-128-Frame tabindex=0><nobr><span class=math id=MathJax-Span-733 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-734><span class=mi id=MathJax-Span-735 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-736 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-737 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-738 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-129-Frame tabindex=0><nobr><span class=math id=MathJax-Span-739 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-740><span class=mi id=MathJax-Span-741 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-742 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-743 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-744></span><span class=mi id=MathJax-Span-745 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-746 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>; 2) the multi-bit mutation finds the optimum in an
expected runtime of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-130-Frame tabindex=0><nobr><span class=math id=MathJax-Span-747 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-748><span class=mi id=MathJax-Span-749 style=font-family:MathJax_Main>Θ</span><span class=mo id=MathJax-Span-750 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-751 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-752 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. These theoretical results show that one-bit
and multi-bit mutations achieve nearly the same performance on UNIFORM. We
provide insight into the choices of mutation in the ENAS community: although
multi-bit mutation can change the step size to prevent a local trap, this may
not always improve runtime. Empirical results also verify the equivalence of
these two mutation operators. This work begins the runtime analysis of ENAS,
laying the foundation for further theoretical studies to guide the design of
ENAS.
</p>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11713 title=Abstract>arXiv:2401.11713</a> [<a href=https://arxiv.org/pdf/2401.11713 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11713 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Luyang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Minghao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z">Zhuoyue Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 5 figures, 3 tables. Code and benchmark will be released via <a href=https://github.com/LLYXC/Ada-ABC/tree/main>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Deep learning could be prone to learning shortcuts raised by dataset bias and
result in inaccurate, unreliable, and unfair models, which impedes its adoption
in real-world clinical applications. Despite its significance, there is a
dearth of research in the medical image classification domain to address
dataset bias. Furthermore, the bias labels are often agnostic, as identifying
biases can be laborious and depend on post-hoc interpretation. This paper
proposes learning Adaptive Agreement from a Biased Council (Ada-ABC), a
debiasing framework that does not rely on explicit bias labels to tackle
dataset bias in medical images. Ada-ABC develops a biased council consisting of
multiple classifiers optimized with generalized cross entropy loss to learn the
dataset bias. A debiasing model is then simultaneously trained under the
guidance of the biased council. Specifically, the debiasing model is required
to learn adaptive agreement with the biased council by agreeing on the
correctly predicted samples and disagreeing on the wrongly predicted samples by
the biased council. In this way, the debiasing model could learn the target
attribute on the samples without spurious correlations while also avoiding
ignoring the rich information in samples with spurious correlations. We
theoretically demonstrated that the debiasing model could learn the target
features when the biased model successfully captures dataset bias. Moreover, to
our best knowledge, we constructed the first medical debiasing benchmark from
four datasets containing seven different bias scenarios. Our extensive
experiments practically showed that our proposed Ada-ABC outperformed
competitive approaches, verifying its effectiveness in mitigating dataset bias
for medical image classification. The codes and organized benchmark datasets
will be made publicly available.
</p>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11714 title=Abstract>arXiv:2401.11714</a> [<a href=https://arxiv.org/pdf/2401.11714 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11714 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conjugate Direction Methods Under Inconsistent Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lim%2C+A">Alexander Lim</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Roosta%2C+F">Fred Roosta</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Since the development of the conjugate gradient (CG) method in 1952 by
Hestenes and Stiefel, CG, has become an indispensable tool in computational
mathematics for solving positive definite linear systems. On the other hand,
the conjugate residual (CR) method, closely related CG and introduced by
Stiefel in 1955 for the same settings, remains relatively less known outside
the numerical linear algebra community. Since their inception, these methods --
henceforth collectively referred to as conjugate direction methods -- have been
extended beyond positive definite to indefinite, albeit consistent, settings.
Going one step further, in this paper, we investigate theoretical and empirical
properties of these methods under inconsistent systems. Among other things, we
show that small modifications to the original algorithms allow for the
pseudo-inverse solution. Furthermore, we show that CR is essentially equivalent
to the minimum residual method, proposed by Paige and Saunders in 1975, in such
contexts. Lastly, we conduct a series of numerical experiments to shed lights
on their numerical stability (or lack thereof) and their performance for
inconsistent systems. Surprisingly, we will demonstrate that, unlike CR and
contrary to popular belief, CG can exhibit significant numerical instability,
bordering on catastrophe in some instances.
</p>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11715 title=Abstract>arXiv:2401.11715</a> [<a href=https://arxiv.org/pdf/2401.11715 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11715 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrating 3D Slicer with a Dynamic Simulator for Situational Aware Robotic Interventions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+M">Manish Sahu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishida%2C+H">Hisashi Ishida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Connolly%2C+L">Laura Connolly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+H">Hongyi Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deguet%2C+A">Anton Deguet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazanzides%2C+P">Peter Kazanzides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Creighton%2C+F+X">Francis X. Creighton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taylor%2C+R+H">Russell H. Taylor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munawar%2C+A">Adnan Munawar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> *These authors contributed equally
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Image-guided robotic interventions represent a transformative frontier in
surgery, blending advanced imaging and robotics for improved precision and
outcomes. This paper addresses the critical need for integrating open-source
platforms to enhance situational awareness in image-guided robotic research. We
present an open-source toolset that seamlessly combines a physics-based
constraint formulation framework, AMBF, with a state-of-the-art imaging
platform application, 3D Slicer. Our toolset facilitates the creation of highly
customizable interactive digital twins, that incorporates processing and
visualization of medical imaging, robot kinematics, and scene dynamics for
real-time robot control. Through a feasibility study, we showcase real-time
synchronization of a physical robotic interventional environment in both 3D
Slicer and AMBF, highlighting low-latency updates and improved visualization.
</p>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11718 title=Abstract>arXiv:2401.11718</a> [<a href=https://arxiv.org/pdf/2401.11718 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11718 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MsSVT++: Mixed-scale Sparse Voxel Transformer with Center Voting for 3D Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+S">Shaocong Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+L">Lihe Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+T">Tingfa Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Accurate 3D object detection in large-scale outdoor scenes, characterized by
considerable variations in object scales, necessitates features rich in both
long-range and fine-grained information. While recent detectors have utilized
window-based transformers to model long-range dependencies, they tend to
overlook fine-grained details. To bridge this gap, we propose MsSVT++, an
innovative Mixed-scale Sparse Voxel Transformer that simultaneously captures
both types of information through a divide-and-conquer approach. This approach
involves explicitly dividing attention heads into multiple groups, each
responsible for attending to information within a specific range. The outputs
of these groups are subsequently merged to obtain final mixed-scale features.
To mitigate the computational complexity associated with applying a
window-based transformer in 3D voxel space, we introduce a novel Chessboard
Sampling strategy and implement voxel sampling and gathering operations
sparsely using a hash map. Moreover, an important challenge stems from the
observation that non-empty voxels are primarily located on the surface of
objects, which impedes the accurate estimation of bounding boxes. To overcome
this challenge, we introduce a Center Voting module that integrates newly voted
voxels enriched with mixed-scale contextual information towards the centers of
the objects, thereby improving precise object localization. Extensive
experiments demonstrate that our single-stage detector, built upon the
foundation of MsSVT++, consistently delivers exceptional performance across
diverse datasets.
</p>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11719 title=Abstract>arXiv:2401.11719</a> [<a href=https://arxiv.org/pdf/2401.11719 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11719 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xinqiao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+F">Feilong Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jimin Xiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Image-level weakly supervised semantic segmentation has received increasing
attention due to its low annotation cost. Existing methods mainly rely on Class
Activation Mapping (CAM) to obtain pseudo-labels for training semantic
segmentation models. In this work, we are the first to demonstrate that
long-tailed distribution in training data can cause the CAM calculated through
classifier weights over-activated for head classes and under-activated for tail
classes due to the shared features among head- and tail- classes. This degrades
pseudo-label quality and further influences final semantic segmentation
performance. To address this issue, we propose a Shared Feature Calibration
(SFC) method for CAM generation. Specifically, we leverage the class prototypes
that carry positive shared features and propose a Multi-Scaled
Distribution-Weighted (MSDW) consistency loss for narrowing the gap between the
CAMs generated through classifier weights and class prototypes during training.
The MSDW loss counterbalances over-activation and under-activation by
calibrating the shared features in head-/tail-class classifier weights.
Experimental results show that our SFC significantly improves CAM boundaries
and achieves new state-of-the-art performances. The project is available at
https://github.com/Barrett-python/SFC.
</p>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11720 title=Abstract>arXiv:2401.11720</a> [<a href=https://arxiv.org/pdf/2401.11720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Condensation: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xinyi Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Junliang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The burgeoning volume of graph data poses significant challenges in storage,
transmission, and particularly the training of graph neural networks (GNNs). To
address these challenges, graph condensation (GC) has emerged as an innovative
solution. GC focuses on synthesizing a compact yet highly representative graph,
on which GNNs can achieve performance comparable to trained on the large
original graph. The notable efficacy of GC and its broad prospects have
garnered significant attention and spurred extensive research. This survey
paper provides an up-to-date and systematic overview of GC, organizing existing
research into four categories aligned with critical GC evaluation criteria:
effectiveness, generalization, fairness, and efficiency. To facilitate an
in-depth and comprehensive understanding of GC, we examine various methods
under each category and thoroughly discuss two essential components within GC:
optimization strategies and condensed graph generation. Additionally, we
introduce the applications of GC in a variety of fields, and highlight the
present challenges and novel insights in GC, promoting advancements in future
research.
</p>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11721 title=Abstract>arXiv:2401.11721</a> [<a href=https://arxiv.org/pdf/2401.11721 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11721 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond the Manual Touch: Situational-aware Force Control for Increased Safety in Robot-assisted Skullbase Surgery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishida%2C+H">Hisashi Ishida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galaiya%2C+D">Deepa Galaiya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagururu%2C+N">Nimesh Nagururu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Creighton%2C+F">Francis Creighton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazanzides%2C+P">Peter Kazanzides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taylor%2C+R">Russell Taylor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+M">Manish Sahu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> *These authors contributed equally to this work
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Purpose - Skullbase surgery demands exceptional precision when removing bone
in the lateral skull base. Robotic assistance can alleviate the effect of human
sensory-motor limitations. However, the stiffness and inertia of the robot can
significantly impact the surgeon's perception and control of the tool-to-tissue
interaction forces. Methods - We present a situational-aware, force control
technique aimed at regulating interaction forces during robot-assisted
skullbase drilling. The contextual interaction information derived from the
digital twin environment is used to enhance sensory perception and suppress
undesired high forces. Results - To validate our approach, we conducted initial
feasibility experiments involving a medical and two engineering students. The
experiment focused on further drilling around critical structures following
cortical mastoidectomy. The experiment results demonstrate that robotic
assistance coupled with our proposed control scheme effectively limited
undesired interaction forces when compared to robotic assistance without the
proposed force control. Conclusions - The proposed force control techniques
show promise in significantly reducing undesired interaction forces during
robot-assisted skullbase surgery. These findings contribute to the ongoing
efforts to enhance surgical precision and safety in complex procedures
involving the lateral skull base.
</p>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11723 title=Abstract>arXiv:2401.11723</a> [<a href=https://arxiv.org/pdf/2401.11723 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11723 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Boxi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+W">Wei Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chris Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kelvin Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The advent of the Internet of Things (IoT) has brought forth an era of
unprecedented connectivity, with an estimated 80 billion smart devices expected
to be in operation by the end of 2025. These devices facilitate a multitude of
smart applications, enhancing the quality of life and efficiency across various
domains. Machine Learning (ML) serves as a crucial technology, not only for
analyzing IoT-generated data but also for diverse applications within the IoT
ecosystem. For instance, ML finds utility in IoT device recognition, anomaly
detection, and even in uncovering malicious activities. This paper embarks on a
comprehensive exploration of the security threats arising from ML's integration
into various facets of IoT, spanning various attack types including membership
inference, adversarial evasion, reconstruction, property inference, model
extraction, and poisoning attacks. Unlike previous studies, our work offers a
holistic perspective, categorizing threats based on criteria such as adversary
models, attack targets, and key security attributes (confidentiality,
availability, and integrity). We delve into the underlying techniques of ML
attacks in IoT environment, providing a critical evaluation of their mechanisms
and impacts. Furthermore, our research thoroughly assesses 65 libraries, both
author-contributed and third-party, evaluating their role in safeguarding model
and data privacy. We emphasize the availability and usability of these
libraries, aiming to arm the community with the necessary tools to bolster
their defenses against the evolving threat landscape. Through our comprehensive
review and analysis, this paper seeks to contribute to the ongoing discourse on
ML-based IoT security, offering valuable insights and practical solutions to
secure ML models and data in the rapidly expanding field of artificial
intelligence in IoT.
</p>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11724 title=Abstract>arXiv:2401.11724</a> [<a href=https://arxiv.org/pdf/2401.11724 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11724 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Augmenting Prototype Network with TransMix for Few-shot Hyperspectral Image Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Longwei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+D">Dongmei Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhigang Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiayao Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Few-shot hyperspectral image classification aims to identify the classes of
each pixel in the images by only marking few of these pixels. And in order to
obtain the spatial-spectral joint features of each pixel, the fixed-size
patches centering around each pixel are often used for classification. However,
observing the classification results of existing methods, we found that
boundary patches corresponding to the pixels which are located at the boundary
of the objects in the hyperspectral images, are hard to classify. These
boundary patchs are mixed with multi-class spectral information. Inspired by
this, we propose to augment the prototype network with TransMix for few-shot
hyperspectrial image classification(APNT). While taking the prototype network
as the backbone, it adopts the transformer as feature extractor to learn the
pixel-to-pixel relation and pay different attentions to different pixels. At
the same time, instead of directly using the patches which are cut from the
hyperspectral images for training, it randomly mixs up two patches to imitate
the boundary patches and uses the synthetic patches to train the model, with
the aim to enlarge the number of hard training samples and enhance their
diversity. And by following the data agumentation technique TransMix, the
attention returned by the transformer is also used to mix up the labels of two
patches to generate better labels for synthetic patches. Compared with existing
methods, the proposed method has demonstrated sate of the art performance and
better robustness for few-shot hyperspectral image classification in our
experiments.
</p>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11725 title=Abstract>arXiv:2401.11725</a> [<a href=https://arxiv.org/pdf/2401.11725 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11725 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yile Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+S">Sijie Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zixin Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Peng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Symbols (or more broadly, non-natural language textual representations) such
as numerical sequences, molecular formulas, and table delimiters widely exist,
playing important roles in various tasks such as abstract reasoning, chemical
property prediction, and table question answering. Despite the impressive
natural language comprehension capabilities of large language models (LLMs),
their reasoning abilities for symbols remain inadequate, which could attributed
to the difference between symbol representations and general natural languages.
We propose symbol-to-language (S2L), a tuning-free method that enables large
language models to solve symbol-related problems with information expressed in
natural language. Specifically, S2L first converts the symbols involved to
language-based representations, which can be implemented by prompting LLMs or
leveraging external tools, then these language-based representations are
integrated into the original problem via direct substitution or concatenation,
serving as useful input information for LLMs. We evaluate the S2L method using
both API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight
symbol-related tasks, ranging from symbol-only abstract reasoning to sentiment
analysis in social media. Experimental results show that S2L consistently leads
to superior performance. For example, by employing S2L for GPT-4, there can be
average significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and
Dyck language, respectively. Codes and data are available at
https://github.com/THUNLP-MT/symbol2language.
</p>
</div>
</dd>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11726 title=Abstract>arXiv:2401.11726</a> [<a href=https://arxiv.org/pdf/2401.11726 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11726 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Out-of-Distribution Samples via Conditional Distribution Entropy with Optimal Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chuanwen Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenlong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ke%2C+A">Ao Ke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yilong Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xike Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+S+K">S.Kevin Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>When deploying a trained machine learning model in the real world, it is
inevitable to receive inputs from out-of-distribution (OOD) sources. For
instance, in continual learning settings, it is common to encounter OOD samples
due to the non-stationarity of a domain. More generally, when we have access to
a set of test inputs, the existing rich line of OOD detection solutions,
especially the recent promise of distance-based methods, falls short in
effectively utilizing the distribution information from training samples and
test inputs. In this paper, we argue that empirical probability distributions
that incorporate geometric information from both training samples and test
inputs can be highly beneficial for OOD detection in the presence of test
inputs available. To address this, we propose to model OOD detection as a
discrete optimal transport problem. Within the framework of optimal transport,
we propose a novel score function known as the \emph{conditional distribution
entropy} to quantify the uncertainty of a test input being an OOD sample. Our
proposal inherits the merits of certain distance-based methods while
eliminating the reliance on distribution assumptions, a-prior knowledge, and
specific training mechanisms. Extensive experiments conducted on benchmark
datasets demonstrate that our method outperforms its competitors in OOD
detection.
</p>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11730 title=Abstract>arXiv:2401.11730</a> [<a href=https://arxiv.org/pdf/2401.11730 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11730 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11730 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Massive Synchrony in Distributed Antenna Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Signal Processing, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Distributed antennas must be phase-calibrated (phase-synchronized) for
certain operations, such as reciprocity-based joint coherent downlink
beamforming, to work. We use rigorous signal processing tools to analyze the
accuracy of calibration protocols that are based on over-the-air measurements
between antennas, with a focus on scalability aspects for large systems. We
show that (i) for some who-measures-on-whom topologies, the errors in the
calibration process are unbounded when the network grows; and (ii) despite that
conclusion, it is optimal -- irrespective of the topology -- to solve a single
calibration problem for the entire system and use the result everywhere to
support the beamforming. The analyses are exemplified by investigating specific
topologies, including lines, rings, and two-dimensional surfaces.
</p>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11731 title=Abstract>arXiv:2401.11731</a> [<a href=https://arxiv.org/pdf/2401.11731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast and Scalable Network Slicing by Integrating Deep Learning with Lagrangian Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+T">Tianlun Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+Q">Qi Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qiang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Massaro%2C+A">Antonio Massaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carle%2C+G">Georg Carle</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures, IEEE Global Communications Conference 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Network slicing is a key technique in 5G and beyond for efficiently
supporting diverse services. Many network slicing solutions rely on deep
learning to manage complex and high-dimensional resource allocation problems.
However, deep learning models suffer limited generalization and adaptability to
dynamic slicing configurations. In this paper, we propose a novel framework
that integrates constrained optimization methods and deep learning models,
resulting in strong generalization and superior approximation capability. Based
on the proposed framework, we design a new neural-assisted algorithm to
allocate radio resources to slices to maximize the network utility under
inter-slice resource constraints. The algorithm exhibits high scalability,
accommodating varying numbers of slices and slice configurations with ease. We
implement the proposed solution in a system-level network simulator and
evaluate its performance extensively by comparing it to state-of-the-art
solutions including deep reinforcement learning approaches. The numerical
results show that our solution obtains near-optimal quality-of-service
satisfaction and promising generalization performance under different network
slicing scenarios.
</p>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11734 title=Abstract>arXiv:2401.11734</a> [<a href=https://arxiv.org/pdf/2401.11734 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11734 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Colorectal Polyp Segmentation in the Deep Learning Era: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+F">Fengmao Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chenglizhao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+A">Aimin Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shuo Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Colorectal polyp segmentation (CPS), an essential problem in medical image
analysis, has garnered growing research attention. Recently, the deep
learning-based model completely overwhelmed traditional methods in the field of
CPS, and more and more deep CPS methods have emerged, bringing the CPS into the
deep learning era. To help the researchers quickly grasp the main techniques,
datasets, evaluation metrics, challenges, and trending of deep CPS, this paper
presents a systematic and comprehensive review of deep-learning-based CPS
methods from 2014 to 2023, a total of 115 technical papers. In particular, we
first provide a comprehensive review of the current deep CPS with a novel
taxonomy, including network architectures, level of supervision, and learning
paradigm. More specifically, network architectures include eight subcategories,
the level of supervision comprises six subcategories, and the learning paradigm
encompasses 12 subcategories, totaling 26 subcategories. Then, we provided a
comprehensive analysis the characteristics of each dataset, including the
number of datasets, annotation types, image resolution, polyp size, contrast
values, and polyp location. Following that, we summarized CPS's commonly used
evaluation metrics and conducted a detailed analysis of 40 deep SOTA models,
including out-of-distribution generalization and attribute-based performance
analysis. Finally, we discussed deep learning-based CPS methods' main
challenges and opportunities.
</p>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11735 title=Abstract>arXiv:2401.11735</a> [<a href=https://arxiv.org/pdf/2401.11735 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11735 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baldimtsi%2C+F">Foteini Baldimtsi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chalkias%2C+K+K">Konstantinos Kryptos Chalkias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yan Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindstr%C3%B8m%2C+J">Jonas Lindstrøm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maram%2C+D">Deepak Maram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riva%2C+B">Ben Riva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+A">Arnab Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sedaghat%2C+M">Mahdi Sedaghat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Joy Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>For many users, a private key based wallet serves as the primary entry point
to blockchains. Commonly recommended wallet authentication methods, such as
mnemonics or hardware wallets, can be cumbersome. This difficulty in user
onboarding has significantly hindered the adoption of blockchain-based
applications.
<br>We develop zkLogin, a novel technique that leverages identity tokens issued
by popular platforms (any OpenID Connect enabled platform e.g. Google,
Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a
signature scheme allowing the signer to \textit{sign using their existing
OpenID accounts} and nothing else. This improves the user experience
significantly as users do not need to remember a new secret and can reuse their
existing accounts.
<br>zkLogin provides strong security and privacy guarantees. By design, zkLogin
builds on top of the underlying platform's authentication mechanisms, and
derives its security from there. Unlike prior related works however, zkLogin
avoids the use of additional trusted parties (e.g., trusted hardware or
oracles) for its security guarantees. zkLogin leverages zero-knowledge proofs
(ZKP) to ensure that the link between a user's off-chain and on-chain
identities is hidden, even from the platform itself.
<br>We have implemented and deployed zkLogin on the Sui blockchain as an
alternative to traditional digital signature-based addresses. Due to the ease
of web3 on-boarding just with social login, without requiring mnemonics, many
hundreds of thousands zkLogin accounts have already been generated in various
industries such as gaming, DeFi, direct payments, NFT collections, ride
sharing, sports racing and many more.
</p>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11736 title=Abstract>arXiv:2401.11736</a> [<a href=https://arxiv.org/pdf/2401.11736 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11736 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Attention on Personalized Clinical Decision Support System: Federated Learning Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thar%2C+K">Kyi Thar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in IEEE BigComp 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Health management has become a primary problem as new kinds of diseases and
complex symptoms are introduced to a rapidly growing modern society. Building a
better and smarter healthcare infrastructure is one of the ultimate goals of a
smart city. To the best of our knowledge, neural network models are already
employed to assist healthcare professionals in achieving this goal. Typically,
training a neural network requires a rich amount of data but heterogeneous and
vulnerable properties of clinical data introduce a challenge for the
traditional centralized network. Moreover, adding new inputs to a medical
database requires re-training an existing model from scratch. To tackle these
challenges, we proposed a deep learning-based clinical decision support system
trained and managed under a federated learning paradigm. We focused on a novel
strategy to guarantee the safety of patient privacy and overcome the risk of
cyberattacks while enabling large-scale clinical data mining. As a result, we
can leverage rich clinical data for training each local neural network without
the need for exchanging the confidential data of patients. Moreover, we
implemented the proposed scheme as a sequence-to-sequence model architecture
integrating the attention mechanism. Thus, our objective is to provide a
personalized clinical decision support system with evolvable characteristics
that can deliver accurate solutions and assist healthcare professionals in
medical diagnosing.
</p>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11737 title=Abstract>arXiv:2401.11737</a> [<a href=https://arxiv.org/pdf/2401.11737 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11737 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sphractal: Estimating the Fractal Dimension of Surfaces Computed from Precise Atomic Coordinates via Box-Counting Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ting%2C+J+Y+C">Jonathan Yik Chang Ting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+A+T+A">Andrew Thomas Agars Wood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barnard%2C+A+S">Amanda Susan Barnard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 46 pages, 26 figures, submitted to Advanced Theory and Simulations
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>; Atomic Physics (physics.atom-ph); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>The fractal dimension of a surface allows its degree of roughness to be
characterised quantitatively. However, limited effort has been attempted to
compute the fractal dimension of surfaces computed from precisely known atomic
coordinates from computational biomolecular and nanomaterial studies. This work
proposes methods to estimate the fractal dimension of the surface of any
three-dimensional object composed of spheres, by representing it as either a
voxelised point cloud or a mathematically exact surface, and computing its
box-counting dimension. Sphractal is published as a Python package that
provides these functionalities, and its utility is demonstrated on a set of
simulated palladium nanoparticle data.
</p>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11738 title=Abstract>arXiv:2401.11738</a> [<a href=https://arxiv.org/pdf/2401.11738 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11738 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+S">Shenwang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Ying Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wenxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jizhou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+B">Bo Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+T">Tingfa Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Noisy labels, inevitably existing in pseudo segmentation labels generated
from weak object-level annotations, severely hampers model optimization for
semantic segmentation. Previous works often rely on massive hand-crafted losses
and carefully-tuned hyper-parameters to resist noise, suffering poor
generalization capability and high model complexity. Inspired by recent
advances in meta learning, we argue that rather than struggling to tolerate
noise hidden behind clean labels passively, a more feasible solution would be
to find out the noisy regions actively, so as to simply ignore them during
model optimization. With this in mind, this work presents a novel meta learning
based semantic segmentation method, MetaSeg, that comprises a primary
content-aware meta-net (CAM-Net) to sever as a noise indicator for an arbitrary
segmentation model counterpart. Specifically, CAM-Net learns to generate
pixel-wise weights to suppress noisy regions with incorrect pseudo labels while
highlighting clean ones by exploiting hybrid strengthened features from image
content, providing straightforward and reliable guidance for optimizing the
segmentation model. Moreover, to break the barrier of time-consuming training
when applying meta learning to common large segmentation models, we further
present a new decoupled training strategy that optimizes different model layers
in a divide-and-conquer manner. Extensive experiments on object, medical,
remote sensing and human segmentation shows that our method achieves superior
performance, approaching that of fully supervised settings, which paves a new
promising way for omni-supervised semantic segmentation.
</p>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11739 title=Abstract>arXiv:2401.11739</a> [<a href=https://arxiv.org/pdf/2401.11739 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11739 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Namekata%2C+K">Koichi Namekata</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabour%2C+A">Amirmojtaba Sabour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S+W">Seung Wook Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. Project page: <a href=https://kmcode1.github.io/Projects/EmerDiff/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Diffusion models have recently received increasing research attention for
their remarkable transfer abilities in semantic segmentation tasks. However,
generating fine-grained segmentation masks with diffusion models often requires
additional training on annotated datasets, leaving it unclear to what extent
pre-trained diffusion models alone understand the semantic relations of their
generated images. To address this question, we leverage the semantic knowledge
extracted from Stable Diffusion (SD) and aim to develop an image segmentor
capable of generating fine-grained segmentation maps without any additional
training. The primary difficulty stems from the fact that semantically
meaningful feature maps typically exist only in the spatially lower-dimensional
layers, which poses a challenge in directly extracting pixel-level semantic
relations from these feature maps. To overcome this issue, our framework
identifies semantic correspondences between image pixels and spatial locations
of low-dimensional feature maps by exploiting SD's generation process and
utilizes them for constructing image-resolution segmentation maps. In extensive
experiments, the produced segmentation maps are demonstrated to be well
delineated and capture detailed parts of the images, indicating the existence
of highly accurate pixel-level semantic knowledge in diffusion models.
</p>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11740 title=Abstract>arXiv:2401.11740</a> [<a href=https://arxiv.org/pdf/2401.11740 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11740 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-level Cross-modal Alignment for Image Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+L">Liping Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaojun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+S">Shaotian Cai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Recently, the cross-modal pretraining model has been employed to produce
meaningful pseudo-labels to supervise the training of an image clustering
model. However, numerous erroneous alignments in a cross-modal pre-training
model could produce poor-quality pseudo-labels and degrade clustering
performance. To solve the aforementioned issue, we propose a novel
\textbf{Multi-level Cross-modal Alignment} method to improve the alignments in
a cross-modal pretraining model for downstream tasks, by building a smaller but
better semantic space and aligning the images and texts in three levels, i.e.,
instance-level, prototype-level, and semantic-level. Theoretical results show
that our proposed method converges, and suggests effective means to reduce the
expected clustering risk of our method. Experimental results on five benchmark
datasets clearly show the superiority of our new method.
</p>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11742 title=Abstract>arXiv:2401.11742</a> [<a href=https://arxiv.org/pdf/2401.11742 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11742 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11742 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Navigation: Inferring the Interlocking Map of Knowledge from Research Trajectories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+S">Shibing Xiang</a> (1 and 2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bing Liu</a> (3 and 4), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yurui Huang</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+C">Chaolin Tian</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xin Jiang</a> (3), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yifang Ma</a> (1) ((1) Department of Statistics and Data Science, Southern University of Science and Technology, Shenzhen, China, (2) Peng Cheng Laboratory, Shenzhen, Guangdong, China, (3) LMIB &amp; School of Mathematical Sciences, Beihang University, Beijing, China, (4) Zhengzhou Aerotropolis Institute of Artificial Intelligence, Zhengzhou, Henan, China)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 9 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL); Applications (stat.AP)
</div>
<p class=mathjax>"If I have seen further, it is by standing on the shoulders of giants," Isaac
Newton's renowned statement hints that new knowledge builds upon existing
foundations, which means there exists an interdependent relationship between
knowledge, which, yet uncovered, is implied in the historical development of
scientific systems for hundreds of years. By leveraging natural language
processing techniques, this study introduces an innovative embedding scheme
designed to infer the "knowledge interlocking map." This map, derived from the
research trajectories of millions of scholars, reveals the intricate
connections among knowledge. We validate that the inferred map effectively
delineates disciplinary boundaries and captures the intricate relationships
between diverse concepts. The utility of the interlocking map is showcased
through multiple applications. Firstly, we demonstrated the multi-step analogy
inferences within the knowledge space and the functional connectivity between
concepts in different disciplines. Secondly, we trace the evolution of
knowledge across domains, observing trends such as shifts from "Theoretical" to
"Applied" or "Chemistry" to "Biomedical" along predefined functional
directions. Lastly, by analyzing the high-dimensional knowledge network
structure, we found that knowledge connects each other with shorter global
pathways, and the interdisciplinary knowledge plays a critical role in
accessibility of the global knowledge network. Our framework offers a novel
approach to mining knowledge inheritance pathways in extensive scientific
literature, which is of great significance for understanding scientific
development patterns, tailoring scientific learning trajectories, and
accelerating scientific progress.
</p>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11748 title=Abstract>arXiv:2401.11748</a> [<a href=https://arxiv.org/pdf/2401.11748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=sun%2C+Y">Yu sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+G">Gaojian Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+X">Xianxun Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+K">Kailang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+J">Jian Cui</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5pages, 5 figures, accepted to ICASSP 2024, not published yet
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Deep gradient inversion attacks expose a serious threat to Federated Learning
(FL) by accurately recovering private data from shared gradients. However, the
state-of-the-art heavily relies on impractical assumptions to access excessive
auxiliary data, which violates the basic data partitioning principle of FL. In
this paper, a novel method, Gradient Inversion Attack using Practical Image
Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits
anomaly detection models to capture the underlying distribution from fewer
data, while GAN-based methods consume significant more data to synthesize
images. The extracted distribution is then leveraged to regulate the attack
process as Anomaly Score loss. Experimental results show that GI-PIP achieves a
16.12 dB PSNR recovery using only 3.8\% data of ImageNet, while GAN-based
methods necessitate over 70\%. Moreover, GI-PIP exhibits superior capability on
distribution generalization compared to GAN-based methods. Our approach
significantly alleviates the auxiliary data requirement on both amount and
distribution in gradient inversion attacks, hence posing more substantial
threat to real-world FL.
</p>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11750 title=Abstract>arXiv:2401.11750</a> [<a href=https://arxiv.org/pdf/2401.11750 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11750 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AdaFGL: A New Paradigm for Federated Node Classification with Topology Heterogeneity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xunkai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+H">Henan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rong-Hua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICDE 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Recently, Federated Graph Learning (FGL) has attracted significant attention
as a distributed framework based on graph neural networks, primarily due to its
capability to break data silos. Existing FGL studies employ community split on
the homophilous global graph by default to simulate federated semi-supervised
node classification settings. Such a strategy assumes the consistency of
topology between the multi-client subgraphs and the global graph, where
connected nodes are highly likely to possess similar feature distributions and
the same label. However, in real-world implementations, the varying
perspectives of local data engineering result in various subgraph topologies,
posing unique heterogeneity challenges in FGL. Unlike the well-known label
Non-independent identical distribution (Non-iid) problems in federated
learning, FGL heterogeneity essentially reveals the topological divergence
among multiple clients, namely homophily or heterophily. To simulate and handle
this unique challenge, we introduce the concept of structure Non-iid split and
then present a new paradigm called \underline{Ada}ptive \underline{F}ederated
\underline{G}raph \underline{L}earning (AdaFGL), a decoupled two-step
personalized approach. To begin with, AdaFGL employs standard multi-client
federated collaborative training to acquire the federated knowledge extractor
by aggregating uploaded models in the final round at the server. Then, each
client conducts personalized training based on the local subgraph and the
federated knowledge extractor. Extensive experiments on the 12 graph benchmark
datasets validate the superior performance of AdaFGL over state-of-the-art
baselines. Specifically, in terms of test accuracy, our proposed AdaFGL
outperforms baselines by significant margins of 3.24\% and 5.57\% on community
split and structure Non-iid split, respectively.
</p>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11751 title=Abstract>arXiv:2401.11751</a> [<a href=https://arxiv.org/pdf/2401.11751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting Multi-view Stereo with Late Cost Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wenxun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jinqiu Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and models are available at <a href=https://github.com/Wuuu3511/LAMVSNET>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Pairwise matching cost aggregation is a crucial step for modern
learning-based Multi-view Stereo (MVS). Prior works adopt an early aggregation
scheme, which adds up pairwise costs into an intermediate cost. However, we
analyze that this process can degrade informative pairwise matchings, thereby
blocking the depth network from fully utilizing the original geometric matching
cues.To address this challenge, we present a late aggregation approach that
allows for aggregating pairwise costs throughout the network feed-forward
process, achieving accurate estimations with only minor changes of the plain
CasMVSNet.Instead of building an intermediate cost by weighted sum, late
aggregation preserves all pairwise costs along a distinct view channel. This
enables the succeeding depth network to fully utilize the crucial geometric
cues without loss of cost fidelity. Grounded in the new aggregation scheme, we
propose further techniques addressing view order dependence inside the
preserved cost, handling flexible testing views, and improving the depth
filtering process. Despite its technical simplicity, our method improves
significantly upon the baseline cascade-based approach, achieving comparable
results with state-of-the-art methods with favorable computation overhead.
</p>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11752 title=Abstract>arXiv:2401.11752</a> [<a href=https://arxiv.org/pdf/2401.11752 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11752 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Univalent Enriched Categories and the Enriched Rezk Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+der+Weide%2C+N">Niels van der Weide</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)
</div>
<p class=mathjax>Enriched categories are categories whose sets of morphisms are enriched with
extra structure. Such categories play a prominent role in the study of higher
categories, homotopy theory, and the semantics of programming languages. In
this paper, we study univalent enriched categories. We prove that all
essentially surjective and fully faithful functors between univalent enriched
categories are equivalences, and we show that every enriched category admits a
Rezk completion. Finally, we use the Rezk completion for enriched categories to
construct univalent enriched Kleisli categories.
</p>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11753 title=Abstract>arXiv:2401.11753</a> [<a href=https://arxiv.org/pdf/2401.11753 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11753 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11753 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From Knowledge Organization to Knowledge Representation and Back
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giunchiglia%2C+F">Fausto Giunchiglia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagchi%2C+M">Mayukh Bagchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+S">Subhashis Das</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted @ Annals of Library and Information Studies (ALIS) Journal - Ranganathan Commemorative Issue (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Digital Libraries (cs.DL)
</div>
<p class=mathjax>Knowledge Organization (KO) and Knowledge Representation (KR) have been the
two mainstream methodologies of knowledge modelling in the Information Science
community and the Artificial Intelligence community, respectively. The
facet-analytical tradition of KO has developed an exhaustive set of guiding
canons for ensuring quality in organising and managing knowledge but has
remained limited in terms of technology-driven activities to expand its scope
and services beyond the bibliographic universe of knowledge. KR, on the other
hand, boasts of a robust ecosystem of technologies and technology-driven
service design which can be tailored to model any entity or scale to any
service in the entire universe of knowledge. This paper elucidates both the
facet-analytical KO and KR methodologies in detail and provides a functional
mapping between them. Out of the mapping, the paper proposes an integrated
KR-enriched KO methodology with all the standard components of a KO methodology
plus the advanced technologies provided by the KR approach. The practical
benefits of the methodological integration has been exemplified through the
flagship application of the Digital University at the University of Trento,
Italy.
</p>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11755 title=Abstract>arXiv:2401.11755</a> [<a href=https://arxiv.org/pdf/2401.11755 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11755 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FedGTA: Topology-aware Averaging for Federated Graph Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xunkai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yinlin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rong-Hua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by VLDB 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Federated Graph Learning (FGL) is a distributed machine learning paradigm
that enables collaborative training on large-scale subgraphs across multiple
local systems. Existing FGL studies fall into two categories: (i) FGL
Optimization, which improves multi-client training in existing machine learning
models; (ii) FGL Model, which enhances performance with complex local models
and multi-client interactions. However, most FGL optimization strategies are
designed specifically for the computer vision domain and ignore graph
structure, presenting dissatisfied performance and slow convergence. Meanwhile,
complex local model architectures in FGL Models studies lack scalability for
handling large-scale subgraphs and have deployment limitations. To address
these issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a
personalized optimization strategy that optimizes through topology-aware local
smoothing confidence and mixed neighbor features. During experiments, we deploy
FedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.
This allows us to evaluate the performance and robustness of FedGTA across a
range of scenarios. Extensive experiments demonstrate that FedGTA achieves
state-of-the-art performance while exhibiting high scalability and efficiency.
The experiment includes ogbn-papers100M, the most representative large-scale
graph database so that we can verify the applicability of our method to
large-scale graph learning. To the best of our knowledge, our study is the
first to bridge large-scale graph learning with FGL using this optimization
strategy, contributing to the development of efficient and scalable FGL
methods.
</p>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11759 title=Abstract>arXiv:2401.11759</a> [<a href=https://arxiv.org/pdf/2401.11759 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11759 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrated Sensing, Communication, and Computing: An Information-oriented Resource Transaction Mechanism
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+N">Ning Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zhipeng Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+X">Xuwei Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+B">Bangzhen Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yifeng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Lianfen Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 4 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Information acquisition from target perception represents the key enabling
technology of the Internet of Automatic Vehicles (IoAV), which is essential for
the decision-making and control operation of connected automatic vehicles
(CAVs). Exploring target information involves multiple operations on data,
e.g., wireless sensing (for data acquisition), communication (for data
transmission), and computing (for data analysis), which all rely on the
consumption of time-space-frequency-computing (TSFC) multi-domain resources.
Due to the coupled resource sharing of sensing, communication, and computing
procedures, the resource management of information-oriented IoAV is commonly
formulated as a non-convex NP-hard problem. In this article, further combining
the integrated sensing and communication (ISAC) and computing, we introduce the
integrated sensing, communication, and computing (ISCC), wherein the TSFC
resources are decoupled from the specific processes and shared universally
among sensing, communication, and computing processes. Furthermore, the
information-oriented resource trading platform (IRTP) is established, which
transforms the problem of ISCC resource management into a resource-information
substitution model. Finally, we embed the employment topology structure in IoAV
into neural network architecture, taking advantage of the graph neural network
(GNN) and multi-worker reinforcement learning, and propose the dynamic resource
management strategy based on the asynchronous advantage GNN (A2GNN) algorithm,
which can achieve the convergence both of information gain maximization and
resource consumption minimization, realizing efficient information-oriented
resource management.
</p>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11760 title=Abstract>arXiv:2401.11760</a> [<a href=https://arxiv.org/pdf/2401.11760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Effective and General Graph Unlearning via Mutual Evolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xunkai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yulin Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rong-Hua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024 Oral
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>With the rapid advancement of AI applications, the growing needs for data
privacy and model robustness have highlighted the importance of machine
unlearning, especially in thriving graph-based scenarios. However, most
existing graph unlearning strategies primarily rely on well-designed
architectures or manual process, rendering them less user-friendly and posing
challenges in terms of deployment efficiency. Furthermore, striking a balance
between unlearning performance and framework generalization is also a pivotal
concern. To address the above issues, we propose \underline{\textbf{M}}utual
\underline{\textbf{E}}volution \underline{\textbf{G}}raph
\underline{\textbf{U}}nlearning (MEGU), a new mutual evolution paradigm that
simultaneously evolves the predictive and unlearning capacities of graph
unlearning. By incorporating aforementioned two components, MEGU ensures
complementary optimization in a unified training framework that aligns with the
prediction and unlearning requirements. Extensive experiments on 9 graph
benchmark datasets demonstrate the superior performance of MEGU in addressing
unlearning requirements at the feature, node, and edge levels. Specifically,
MEGU achieves average performance improvements of 2.7\%, 2.5\%, and 3.2\%
across these three levels of unlearning tasks when compared to state-of-the-art
baselines. Furthermore, MEGU exhibits satisfactory training efficiency,
reducing time and space overhead by an average of 159.8x and 9.6x,
respectively, in comparison to retraining GNN from scratch.
</p>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11761 title=Abstract>arXiv:2401.11761</a> [<a href=https://arxiv.org/pdf/2401.11761 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11761 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-oriented Coordinated Uplink Transmission for Massive IoT System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%A4m%C3%A4l%C3%A4inen%2C+J">Jyri Hämäläinen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dinis%2C+R">Rui Dinis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ilter%2C+M+C">Mehmet C. Ilter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>Recently, the paradigm of massive ultra-reliable low-latency IoT
communications (URLLC-IoT) has gained growing interest. Reliable delay-critical
uplink transmission in IoT is a challenging task since low-complex devices
typically do not support multiple antennas or demanding signal processing
tasks. However, in many IoT services the data volumes are small and deployments
may include massive number of devices. We consider on a clustered uplink
transmission with two cooperation approaches: First, we focus on scenario where
location-based channel knowledge map (CKM) is applied to enable cooperation.
Second, we consider a scenario where scarce channel side-information is applied
in transmission. In both scenarios we also model and analyse the impact of
erroneous information. In the performance evaluation we apply the recently
introduced data-oriented approach that has gathered significant attention in
the context of short-packet transmissions. Specifically, it introduces a
transient performance metric for small data transmissions, where the amount of
data and available bandwidth play crucial roles. Results show that cooperation
between clustered IoT devices may provide notable benefits in terms of
increased range. It is noticed that the performance is heavily depending on the
strength of the static channel component in the CKM based cooperation. The
channel side-information based cooperation is robust against changes in the
radio environment but sensitive to possible errors in the channel
side-information. Even with large IoT device clusters, side-information errors
may set a limit for the use of services assuming high-reliability and
low-latency. Analytic results are verified against simulations, showing only
minor differences at low probability levels.
</p>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11764 title=Abstract>arXiv:2401.11764</a> [<a href=https://arxiv.org/pdf/2401.11764 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11764 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identity-Driven Multimedia Forgery Detection via Reference Assistance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Junhao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jingjing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+X">Xue Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+F">Feng Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+H">Haijun Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yugang Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
<p class=mathjax>Recent advancements in technologies, such as the 'deepfake' technique, have
paved the way for the generation of various media forgeries. In response to the
potential hazards of these media forgeries, many researchers engage in
exploring detection methods, increasing the demand for high-quality media
forgery datasets. Despite this, existing datasets have certain limitations.
Firstly, most of datasets focus on the manipulation of visual modality and
usually lack diversity, as only a few forgery approaches are considered.
Secondly, the quality of media is often inadequate in clarity and naturalness.
Meanwhile, the size of the dataset is also limited. Thirdly, while many
real-world forgeries are driven by identity, the identity information of the
subject in media is frequently neglected. For detection, identity information
could be an essential clue to boost accuracy. Moreover, official media
concerning certain identities on the Internet can serve as prior knowledge,
aiding both the audience and forgery detectors in determining the true
identity. Therefore, we propose an identity-driven multimedia forgery dataset,
IDForge, which contains 249,138 video shots. All video shots are sourced from
324 wild videos collected of 54 celebrities from the Internet. The fake video
shots involve 9 types of manipulation across visual, audio and textual
modalities. Additionally, IDForge provides extra 214,438 real video shots as a
reference set for the 54 celebrities. Correspondingly, we design an effective
multimedia detection network, Reference-assisted Multimodal Forgery Detection
Network (R-MFDN). Through extensive experiments on the proposed dataset, we
demonstrate the effectiveness of R-MFDN on the multimedia detection task.
</p>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11767 title=Abstract>arXiv:2401.11767</a> [<a href=https://arxiv.org/pdf/2401.11767 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11767 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Concealed Object Segmentation with Hierarchical Coherence Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+F">Fengyang Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Pan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+C">Chunming He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+R">Runze Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yutao Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to CICAI 2023. 13 pages, 6 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Concealed object segmentation (COS) is a challenging task that involves
localizing and segmenting those concealed objects that are visually blended
with their surrounding environments. Despite achieving remarkable success,
existing COS segmenters still struggle to achieve complete segmentation results
in extremely concealed scenarios. In this paper, we propose a Hierarchical
Coherence Modeling (HCM) segmenter for COS, aiming to address this incomplete
segmentation limitation. In specific, HCM promotes feature coherence by
leveraging the intra-stage coherence and cross-stage coherence modules,
exploring feature correlations at both the single-stage and contextual levels.
Additionally, we introduce the reversible re-calibration decoder to detect
previously undetected parts in low-confidence regions, resulting in further
enhancing segmentation performance. Extensive experiments conducted on three
COS tasks, including camouflaged object detection, polyp image segmentation,
and transparent object detection, demonstrate the promising results achieved by
the proposed HCM segmenter.
</p>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11768 title=Abstract>arXiv:2401.11768</a> [<a href=https://arxiv.org/pdf/2401.11768 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11768 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ADA-GNN: Atom-Distance-Angle Graph Neural Network for Crystal Material Property Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Q">Qianli Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jinglong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Bo Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)
</div>
<p class=mathjax>Property prediction is a fundamental task in crystal material research. To
model atoms and structures, structures represented as graphs are widely used
and graph learning-based methods have achieved significant progress. Bond
angles and bond distances are two key structural information that greatly
influence crystal properties. However, most of the existing works only consider
bond distances and overlook bond angles. The main challenge lies in the time
cost of handling bond angles, which leads to a significant increase in
inference time. To solve this issue, we first propose a crystal structure
modeling based on dual scale neighbor partitioning mechanism, which uses a
larger scale cutoff for edge neighbors and a smaller scale cutoff for angle
neighbors. Then, we propose a novel Atom-Distance-Angle Graph Neural Network
(ADA-GNN) for property prediction tasks, which can process node information and
structural information separately. The accuracy of predictions and inference
time are improved with the dual scale modeling and the specially designed
architecture of ADA-GNN. The experimental results validate that our approach
achieves state-of-the-art results in two large-scale material benchmark
datasets on property prediction tasks.
</p>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11772 title=Abstract>arXiv:2401.11772</a> [<a href=https://arxiv.org/pdf/2401.11772 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11772 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LightDiC: A Simple yet Effective Approach for Large-scale Digraph Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xunkai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+M">Meihao Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+D">Daohan Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Rong-Hua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Most existing graph neural networks (GNNs) are limited to undirected graphs,
whose restricted scope of the captured relational information hinders their
expressive capabilities and deployments in real-world scenarios. Compared with
undirected graphs, directed graphs (digraphs) fit the demand for modeling more
complex topological systems by capturing more intricate relationships between
nodes, such as formulating transportation and financial networks. While some
directed GNNs have been introduced, their inspiration mainly comes from deep
learning architectures, which lead to redundant complexity and computation,
making them inapplicable to large-scale databases. To address these issues, we
propose LightDiC, a scalable variant of the digraph convolution based on the
magnetic Laplacian. Since topology-related computations are conducted solely
during offline pre-processing, LightDiC achieves exceptional scalability,
enabling downstream predictions to be trained separately without incurring
recursive computational costs. Theoretical analysis shows that LightDiC
utilizes directed information to achieve message passing based on the complex
field, which corresponds to the proximal gradient descent process of the
Dirichlet energy optimization function from the perspective of digraph signal
denoising, ensuring its expressiveness. Experimental results demonstrate that
LightDiC performs comparably well or even outperforms other SOTA methods in
various downstream tasks, with fewer learnable parameters and higher training
efficiency. Notably, LightDiC is the first DiGNN to provide satisfactory
results in the most representative large-scale database (ogbn-papers100M).
</p>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11775 title=Abstract>arXiv:2401.11775</a> [<a href=https://arxiv.org/pdf/2401.11775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative Position Reasoning Network for Referring Image Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+J">Jianjian Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+B">Beiya Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yulin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+X">Xiameng Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Given an image and a natural language expression as input, the goal of
referring image segmentation is to segment the foreground masks of the entities
referred by the expression. Existing methods mainly focus on interactive
learning between vision and language to enhance the multi-modal representations
for global context reasoning. However, predicting directly in pixel-level space
can lead to collapsed positioning and poor segmentation results. Its main
challenge lies in how to explicitly model entity localization, especially for
non-salient entities. In this paper, we tackle this problem by executing a
Collaborative Position Reasoning Network (CPRN) via the proposed novel
Row-and-Column interactive (RoCo) and Guided Holistic interactive (Holi)
modules. Specifically, RoCo aggregates the visual features into the row- and
column-wise features corresponding two directional axes respectively. It offers
a fine-grained matching behavior that perceives the associations between the
linguistic features and two decoupled visual features to perform position
reasoning over a hierarchical space. Holi integrates features of the two
modalities by a cross-modal attention mechanism, which suppresses the
irrelevant redundancy under the guide of positioning information from RoCo.
Thus, with the incorporation of RoCo and Holi modules, CPRN captures the visual
details of position reasoning so that the model can achieve more accurate
segmentation. To our knowledge, this is the first work that explicitly focuses
on position reasoning modeling. We also validate the proposed method on three
evaluation datasets. It consistently outperforms existing state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11776 title=Abstract>arXiv:2401.11776</a> [<a href=https://arxiv.org/pdf/2401.11776 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11776 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the impact of robot personalization on human-robot interaction: A review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vindolet%2C+C">Camille Vindolet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olvera%2C+J+R+G">Julio Rogelio Guadarrama Olvera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+G">Gordon Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This study reviews the impact of personalization on human-robot interaction.
Firstly, the various strategies used to achieve personalization are briefly
described. Secondly, the effects of personalization known to date are
discussed. They are presented along with the personalized parameters,
personalized features, used technology, and use case they relate to. It is
observed that various positive effects have been discussed in the literature
while possible negative effects seem to require further investigation.
</p>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11779 title=Abstract>arXiv:2401.11779</a> [<a href=https://arxiv.org/pdf/2401.11779 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11779 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11779 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analyzing the coupling process of distributed mixed real-virtual prototypes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Baumann%2C+P">Peter Baumann</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mikelsons%2C+L">Lars Mikelsons</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kotte%2C+O">Oliver Kotte</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schramm%2C+D">Dieter Schramm</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 12 figures, published at 33rd Annual European Simulation and Modelling Conference, ESM 2019
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 33rd Annual European Simulation and Modelling Conference 2019, ESM
 2019, Pages 251 - 258, 2019, Plama de Mallorca, 28 October 2019 through 30
 October 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The ongoing connection and automation of vehicles leads to a closer
interaction of the individual vehicle components, which demands for
consideration throughout the entire development process. In the design phase,
this is achieved through co-simulation of component models. However, complex
co-simulation environments are rarely (re-)used in the verification and
validation phases, in which mixed real-virtual prototypes (e.g.
Hardware-in-the-Loop) are already available. One reason for this are coupling
errors such as time-delays, which inevitably occur in co-simulation of virtual
and real-time systems, and which influence system behavior in an unknown and
generally detrimental way. This contribution introduces a novel, adaptive
method to compensate for constant time-delays in potentially highly nonlinear,
spatially distributed mixed real-virtual prototypes, using small feedforward
neural networks. Their optimal initialization with respect to defined frequency
domain features results from a-priori frequency domain analysis of the entire
coupled system, including coupling faults and compensation methods. A linear
and a nonlinear example demonstrate the method and emphasize its suitability
for nonlinear systems due to online training and adaptation. As the
compensation method requires knowledge only of the bandwidths, the proposed
method is applicable to distributed mixed real-virtual prototypes in general.
</p>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11783 title=Abstract>arXiv:2401.11783</a> [<a href=https://arxiv.org/pdf/2401.11783 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11783 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Full-Body Motion Reconstruction with Sparse Sensing from Graph Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+F">Feiyu Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zongkai Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+L">Li Yi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Estimating 3D full-body pose from sparse sensor data is a pivotal technique
employed for the reconstruction of realistic human motions in Augmented Reality
and Virtual Reality. However, translating sparse sensor signals into
comprehensive human motion remains a challenge since the sparsely distributed
sensors in common VR systems fail to capture the motion of full human body. In
this paper, we use well-designed Body Pose Graph (BPG) to represent the human
body and translate the challenge into a prediction problem of graph missing
nodes. Then, we propose a novel full-body motion reconstruction framework based
on BPG. To establish BPG, nodes are initially endowed with features extracted
from sparse sensor signals. Features from identifiable joint nodes across
diverse sensors are amalgamated and processed from both temporal and spatial
perspectives. Temporal dynamics are captured using the Temporal Pyramid
Structure, while spatial relations in joint movements inform the spatial
attributes. The resultant features serve as the foundational elements of the
BPG nodes. To further refine the BPG, node features are updated through a graph
neural network that incorporates edge reflecting varying joint relations. Our
method's effectiveness is evidenced by the attained state-of-the-art
performance, particularly in lower body motion, outperforming other baseline
methods. Additionally, an ablation study validates the efficacy of each module
in our proposed framework.
</p>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11786 title=Abstract>arXiv:2401.11786</a> [<a href=https://arxiv.org/pdf/2401.11786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EPIC: a provable accelerated Eigensolver based on Preconditioning and Implicit Convexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shao%2C+N">Nian Shao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+W">Wenbin Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bai%2C+Z">Zhaojun Bai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>This paper is concerned with the extraction of the smallest eigenvalue and
the corresponding eigenvector of a symmetric positive definite matrix pencil.
We reveal implicit convexity of the eigenvalue problem in Euclidean space. A
provable accelerated eigensolver based on preconditioning and implicit
convexity (EPIC) is proposed. Theoretical analysis shows the acceleration of
EPIC with the rate of convergence resembling the expected rate of convergence
of the well-known locally optimal preconditioned conjugate gradient (LOPCG). A
complete proof of the expected rate of convergence of LOPCG is elusive so far.
Numerical results confirm our theoretical findings of EPIC.
</p>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11787 title=Abstract>arXiv:2401.11787</a> [<a href=https://arxiv.org/pdf/2401.11787 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11787 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11787 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparative Study of Numerical Methods for Approximating the Solutions of a Macroscopic Automated-Vehicle Traffic Flow Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Titakis%2C+G">George Titakis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Karafyllis%2C+I">Iasson Karafyllis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Theodosis%2C+D">Dionysis Theodosis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Papamichail%2C+I">Ioannis Papamichail</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Papageorgiou%2C+M">Markos Papageorgiou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 19 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this paper, a particle method is used to approximate the solutions of a
"fluid-like" macroscopic traffic flow model for automated vehicles. It is shown
that this method preserves certain differential inequalities that hold for the
macroscopic traffic model: mass is preserved, the mechanical energy is decaying
and an energy functional is also decaying. To demonstrate the advantages of the
particle method under consideration, a comparison with other numerical methods
for viscous compressible fluid models is provided. Since the solutions of the
macroscopic traffic model can be approximated by the solutions of a reduced
model consisting of a single nonlinear heat-type partial differential equation,
the numerical solutions produced by the particle method are also compared with
the numerical solutions of the reduced model. Finally, a traffic simulation
scenario and a comparison with the Aw-Rascle-Zhang (ARZ) model are provided,
illustrating the advantages of the use of automated vehicles.
</p>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11788 title=Abstract>arXiv:2401.11788</a> [<a href=https://arxiv.org/pdf/2401.11788 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11788 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Obtaining the pseudoinverse solution of singular range-symmetric linear systems with GMRES-type methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Du%2C+K">Kai Du</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fan%2C+J">Jia-Jun Fan</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+F">Fang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>It is well known that for singular inconsistent range-symmetric linear
systems, the generalized minimal residual (GMRES) method determines a least
squares solution without breakdown. The reached least squares solution may be
or not be the pseudoinverse solution. We show that a lift strategy can be used
to obtain the pseudoinverse solution. In addition, we propose a new iterative
method named RSMAR (minimum <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-131-Frame tabindex=0><nobr><span class=math id=MathJax-Span-753 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.81em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-754><span class=texatom id=MathJax-Span-755><span class=mrow id=MathJax-Span-756><span class=mi id=MathJax-Span-757 style=font-family:MathJax_Main-bold>A</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-residual) for range-symmetric linear
systems <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-132-Frame tabindex=0><nobr><span class=math id=MathJax-Span-758 style=width:4.17em;display:inline-block><span style=display:inline-block;position:relative;width:3.475em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.42em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-759><span class=texatom id=MathJax-Span-760><span class=mrow id=MathJax-Span-761><span class=mi id=MathJax-Span-762 style=font-family:MathJax_Main-bold>A</span></span></span><span class=texatom id=MathJax-Span-763><span class=mrow id=MathJax-Span-764><span class=mi id=MathJax-Span-765 style=font-family:MathJax_Main-bold>x</span></span></span><span class=mo id=MathJax-Span-766 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=texatom id=MathJax-Span-767 style=padding-left:0.292em><span class=mrow id=MathJax-Span-768><span class=mi id=MathJax-Span-769 style=font-family:MathJax_Main-bold>b</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. At step <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-133-Frame tabindex=0><nobr><span class=math id=MathJax-Span-770 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-771><span class=mi id=MathJax-Span-772 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> RSMAR minimizes <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-134-Frame tabindex=0><nobr><span class=math id=MathJax-Span-773 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.66em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-774><span class=mo id=MathJax-Span-775 style=font-family:MathJax_Main>∥</span><span class=texatom id=MathJax-Span-776><span class=mrow id=MathJax-Span-777><span class=mi id=MathJax-Span-778 style=font-family:MathJax_Main-bold>A</span></span></span><span class=msubsup id=MathJax-Span-779><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-780><span class=mrow id=MathJax-Span-781><span class=mi id=MathJax-Span-782 style=font-family:MathJax_Main-bold>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-783 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-784 style=font-family:MathJax_Main>∥</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> in the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-135-Frame tabindex=0><nobr><span class=math id=MathJax-Span-785 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-786><span class=mi id=MathJax-Span-787 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>th Krylov subspace generated with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-136-Frame tabindex=0><nobr><span class=math id=MathJax-Span-788 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.19em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-789><span class=mo id=MathJax-Span-790 style=font-family:MathJax_Main>{</span><span class=texatom id=MathJax-Span-791><span class=mrow id=MathJax-Span-792><span class=mi id=MathJax-Span-793 style=font-family:MathJax_Main-bold>A</span></span></span><span class=mo id=MathJax-Span-794 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-795 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-796><span class=mrow id=MathJax-Span-797><span class=mi id=MathJax-Span-798 style=font-family:MathJax_Main-bold>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mn id=MathJax-Span-799 style=font-size:70.7%;font-family:MathJax_Main>0</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-800 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> rather than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-137-Frame tabindex=0><nobr><span class=math id=MathJax-Span-801 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-802><span class=mo id=MathJax-Span-803 style=font-family:MathJax_Main>∥</span><span class=msubsup id=MathJax-Span-804><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-805><span class=mrow id=MathJax-Span-806><span class=mi id=MathJax-Span-807 style=font-family:MathJax_Main-bold>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-808 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-809 style=font-family:MathJax_Main>∥</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-138-Frame tabindex=0><nobr><span class=math id=MathJax-Span-810 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.93em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-811><span class=msubsup id=MathJax-Span-812><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-813><span class=mrow id=MathJax-Span-814><span class=mi id=MathJax-Span-815 style=font-family:MathJax_Main-bold>r</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-816 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> is the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-139-Frame tabindex=0><nobr><span class=math id=MathJax-Span-817 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-818><span class=mi id=MathJax-Span-819 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>th
residual vector and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-140-Frame tabindex=0><nobr><span class=math id=MathJax-Span-820 style=width:2.086em;display:inline-block><span style=display:inline-block;position:relative;width:1.739em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.62em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-821><span class=mo id=MathJax-Span-822 style=font-family:MathJax_Main>∥</span><span class=mo id=MathJax-Span-823 style=font-family:MathJax_Main;padding-left:0.234em>⋅</span><span class=mo id=MathJax-Span-824 style=font-family:MathJax_Main;padding-left:0.234em>∥</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> denotes the Euclidean vector norm. We show that
RSMAR and GMRES terminate with the same least squares solution when applied to
range-symmetric linear systems. We provide two implementations for RSMAR. Our
numerical experiments show that RSMAR is the most suitable method among
GMRES-type methods for singular inconsistent range-symmetric linear systems.
</p>
</div>
</dd>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11790 title=Abstract>arXiv:2401.11790</a> [<a href=https://arxiv.org/pdf/2401.11790 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11790 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning for Computer Vision based Activity Recognition and Fall Detection of the Elderly: a Systematic Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaya-Morey%2C+F+X">F. Xavier Gaya-Morey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manresa-Yee%2C+C">Cristina Manresa-Yee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buades-Rubio%2C+J+M">Jose M. Buades-Rubio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>As the percentage of elderly people in developed countries increases
worldwide, the healthcare of this collective is a worrying matter, especially
if it includes the preservation of their autonomy. In this direction, many
studies are being published on Ambient Assisted Living (AAL) systems, which
help to reduce the preoccupations raised by the independent living of the
elderly. In this study, a systematic review of the literature is presented on
fall detection and Human Activity Recognition (HAR) for the elderly, as the two
main tasks to solve to guarantee the safety of elderly people living alone. To
address the current tendency to perform these two tasks, the review focuses on
the use of Deep Learning (DL) based approaches on computer vision data. In
addition, different collections of data like DL models, datasets or hardware
(e.g. depth or thermal cameras) are gathered from the reviewed studies and
provided for reference in future studies. Strengths and weaknesses of existing
approaches are also discussed and, based on them, our recommendations for
future works are provided.
</p>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11791 title=Abstract>arXiv:2401.11791</a> [<a href=https://arxiv.org/pdf/2401.11791 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11791 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Ci-Siang Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chien-Yi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Min-Hung Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation
models using training image data with only image-level supervision. Since
precise pixel-level annotations are not accessible, existing methods typically
focus on producing pseudo masks for training segmentation models by refining
CAM-like heatmaps. However, the produced heatmaps may only capture
discriminative image regions of target object categories or the associated
co-occurring backgrounds. To address the issues, we propose a Semantic Prompt
Learning for WSSS (SemPLeS) framework, which learns to effectively prompt the
CLIP space to enhance the semantic alignment between the segmented regions and
the target object categories. More specifically, we propose Contrastive Prompt
Learning and Class-associated Semantic Refinement to learn the prompts that
adequately describe and suppress the image backgrounds associated with each
target object category. In this way, our proposed framework is able to perform
better semantic matching between object regions and the associated text labels,
resulting in desired pseudo masks for training the segmentation model. The
proposed SemPLeS framework achieves SOTA performance on the standard WSSS
benchmarks, PASCAL VOC and MS COCO, and demonstrated interpretability with the
semantic visualization of our learned prompts. The codes will be released.
</p>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11792 title=Abstract>arXiv:2401.11792</a> [<a href=https://arxiv.org/pdf/2401.11792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zuojin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">YongQiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianyu Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>An intelligent driving system should be capable of dynamically formulating
appropriate driving strategies based on the current environment and vehicle
status, while ensuring the security and reliability of the system. However,
existing methods based on reinforcement learning and imitation learning suffer
from low safety, poor generalization, and inefficient sampling. Additionally,
they cannot accurately predict future driving trajectories, and the accurate
prediction of future driving trajectories is a precondition for making optimal
decisions. To solve these problems, in this paper, we introduce a Safe and
Generalized end-to-end Autonomous Driving System (SGADS) for complex and
various scenarios. Our SGADS incorporates variational inference with
normalizing flows, enabling the intelligent vehicle to accurately predict
future driving trajectories. Moreover, we propose the formulation of robust
safety constraints. Furthermore, we combine reinforcement learning with
demonstrations to augment search process of the agent. The experimental results
demonstrate that our SGADS can significantly improve safety performance,
exhibit strong generalization, and enhance the training efficiency of
intelligent vehicles in complex urban scenarios compared to existing methods.
</p>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11795 title=Abstract>arXiv:2401.11795</a> [<a href=https://arxiv.org/pdf/2401.11795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spherical Density-Equalizing Map for Genus-0 Closed Surfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+Z">Zhiyuan Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lui%2C+L+M">Lok Ming Lui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+G+P+T">Gary P. T. Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computational Geometry (cs.CG); Differential Geometry (math.DG); Numerical Analysis (math.NA)
</div>
<p class=mathjax>Density-equalizing maps are a class of mapping methods in which the shape
deformation is driven by prescribed density information. In recent years, they
have been widely used for data visualization on planar domains and planar
parameterization of open surfaces. However, the theory and computation of
density-equalizing maps for closed surfaces are much less explored. In this
work, we develop a novel method for computing spherical density-equalizing maps
for genus-0 closed surfaces. Specifically, we first compute a conformal
parameterization of the given genus-0 closed surface onto the unit sphere.
Then, we perform density equalization on the spherical domain based on the
given density information to achieve a spherical density-equalizing map. The
bijectivity of the mapping is guaranteed using quasi-conformal theory. We
further propose a method for incorporating the harmonic energy and landmark
constraints into our formulation to achieve landmark-aligned spherical
density-equalizing maps balancing different distortion measures. Using the
proposed methods, a large variety of spherical parameterizations can be
achieved. Applications to surface registration, remeshing, and data
visualization are presented to demonstrate the effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11796 title=Abstract>arXiv:2401.11796</a> [<a href=https://arxiv.org/pdf/2401.11796 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11796 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Agnostic Video Explanations: a Study on the Applicability of Removal-Based Explanations to Video
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaya-Morey%2C+F+X">F. Xavier Gaya-Morey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buades-Rubio%2C+J+M">Jose M. Buades-Rubio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manresa-Yee%2C+C">Cristina Manresa-Yee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Explainable artificial intelligence techniques are becoming increasingly
important with the rise of deep learning applications in various domains. These
techniques aim to provide a better understanding of complex "black box" models
and enhance user trust while maintaining high learning performance. While many
studies have focused on explaining deep learning models in computer vision for
image input, video explanations remain relatively unexplored due to the
temporal dimension's complexity. In this paper, we present a unified framework
for local agnostic explanations in the video domain. Our contributions include:
(1) Extending a fine-grained explanation framework tailored for computer vision
data, (2) Adapting six existing explanation techniques to work on video data by
incorporating temporal information and enabling local explanations, and (3)
Conducting an evaluation and comparison of the adapted explanation methods
using different models and datasets. We discuss the possibilities and choices
involved in the removal-based explanation process for visual data. The
adaptation of six explanation methods for video is explained, with comparisons
to existing approaches. We evaluate the performance of the methods using
automated metrics and user-based evaluation, showing that 3D RISE, 3D LIME, and
3D Kernel SHAP outperform other methods. By decomposing the explanation process
into manageable steps, we facilitate the study of each choice's impact and
allow for further refinement of explanation methods to suit specific datasets
and models.
</p>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11798 title=Abstract>arXiv:2401.11798</a> [<a href=https://arxiv.org/pdf/2401.11798 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11798 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Izadi%2C+M">Mohammad Izadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Safayani%2C+M">Mehran Safayani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirzaei%2C+A">Abdolreza Mirzaei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Efficient real-time traffic prediction is crucial for reducing transportation
time. To predict traffic conditions, we employ a spatio-temporal graph neural
network (ST-GNN) to model our real-time traffic data as temporal graphs.
Despite its capabilities, it often encounters challenges in delivering
efficient real-time predictions for real-world traffic data. Recognizing the
significance of timely prediction due to the dynamic nature of real-time data,
we employ knowledge distillation (KD) as a solution to enhance the execution
time of ST-GNNs for traffic prediction. In this paper, We introduce a cost
function designed to train a network with fewer parameters (the student) using
distilled data from a complex network (the teacher) while maintaining its
accuracy close to that of the teacher. We use knowledge distillation,
incorporating spatial-temporal correlations from the teacher network to enable
the student to learn the complex patterns perceived by the teacher. However, a
challenge arises in determining the student network architecture rather than
considering it inadvertently. To address this challenge, we propose an
algorithm that utilizes the cost function to calculate pruning scores,
addressing small network architecture search issues, and jointly fine-tunes the
network resulting from each pruning stage using KD. Ultimately, we evaluate our
proposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results
indicate that our method can maintain the student's accuracy close to that of
the teacher, even with the retention of only <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-141-Frame tabindex=0><nobr><span class=math id=MathJax-Span-825 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.28em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-826><span class=mn id=MathJax-Span-827 style=font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-828 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of network parameters.
</p>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11800 title=Abstract>arXiv:2401.11800</a> [<a href=https://arxiv.org/pdf/2401.11800 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11800 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting Document-Level Relation Extraction with Context-Guided Link Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+M">Monika Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mutharaju%2C+R">Raghava Mutharaju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kavuluru%2C+R">Ramakanth Kavuluru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+K">Kuldeep Singh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Document-level relation extraction (DocRE) poses the challenge of identifying
relationships between entities within a document as opposed to the traditional
RE setting where a single sentence is input. Existing approaches rely on
logical reasoning or contextual cues from entities. This paper reframes
document-level RE as link prediction over a knowledge graph with distinct
benefits: 1) Our approach combines entity context with document-derived logical
reasoning, enhancing link prediction quality. 2) Predicted links between
entities offer interpretability, elucidating employed reasoning. We evaluate
our approach on three benchmark datasets: DocRED, ReDocRED, and DWIE. The
results indicate that our proposed method outperforms the state-of-the-art
models and suggests that incorporating context-based link prediction techniques
can enhance the performance of document-level relation extraction models.
</p>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11805 title=Abstract>arXiv:2401.11805</a> [<a href=https://arxiv.org/pdf/2401.11805 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11805 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simultaneous Blind Demixing and Super-resolution via Vectorized Hankel Lift
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haifeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jinchi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+H">Hulei Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yuxiang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Li Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this work, we investigate the problem of simultaneous blind demixing and
super-resolution. Leveraging the subspace assumption regarding unknown point
spread functions, this problem can be reformulated as a low-rank matrix
demixing problem. We propose a convex recovery approach that utilizes the
low-rank structure of each vectorized Hankel matrix associated with the target
matrix. Our analysis reveals that for achieving exact recovery, the number of
samples needs to satisfy the condition <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-142-Frame tabindex=0><nobr><span class=math id=MathJax-Span-829 style=width:8.568em;display:inline-block><span style=display:inline-block;position:relative;width:7.121em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1007em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-830><span class=mi id=MathJax-Span-831 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-832 style=font-family:MathJax_AMS;padding-left:0.292em>≳</span><span class=mi id=MathJax-Span-833 style=font-family:MathJax_Math-italic;padding-left:0.292em>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-834 style=font-family:MathJax_Math-italic>s</span><span class=mi id=MathJax-Span-835 style=font-family:MathJax_Math-italic>r</span><span class=mi id=MathJax-Span-836 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-837></span><span class=mo id=MathJax-Span-838 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-839 style=font-family:MathJax_Math-italic>s</span><span class=mi id=MathJax-Span-840 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-841 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. Empirical
evaluations demonstrate the recovery capabilities and the computational
efficiency of the convex method.
</p>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11810 title=Abstract>arXiv:2401.11810</a> [<a href=https://arxiv.org/pdf/2401.11810 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11810 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalization and Informativeness of Conformal Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zecchin%2C+M">Matteo Zecchin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Sangwoo Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hellstr%C3%B6m%2C+F">Fredrik Hellström</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)
</div>
<p class=mathjax>The safe integration of machine learning modules in decision-making processes
hinges on their ability to quantify uncertainty. A popular technique to achieve
this goal is conformal prediction (CP), which transforms an arbitrary base
predictor into a set predictor with coverage guarantees. While CP certifies the
predicted set to contain the target quantity with a user-defined tolerance, it
does not provide control over the average size of the predicted sets, i.e.,
over the informativeness of the prediction. In this work, a theoretical
connection is established between the generalization properties of the base
predictor and the informativeness of the resulting CP prediction sets. To this
end, an upper bound is derived on the expected size of the CP set predictor
that builds on generalization error bounds for the base predictor. The derived
upper bound provides insights into the dependence of the average size of the CP
set predictor on the amount of calibration data, the target reliability, and
the generalization performance of the base predictor. The theoretical insights
are validated using simple numerical regression and classification tasks.
</p>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11813 title=Abstract>arXiv:2401.11813</a> [<a href=https://arxiv.org/pdf/2401.11813 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11813 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11813 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cyclic viscoelastic-viscoplastic behavior of epoxy nanocomposites under hygrothermal conditions: A phase-field fracture model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arash%2C+B">Behrouz Arash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zakavati%2C+S">Shadab Zakavati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bahtiri%2C+B">Betim Bahtiri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jux%2C+M">Maximilian Jux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rolfes%2C+R">Raimund Rolfes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>In this study, a finite deformation phase-field formulation is developed to
investigate the effect of hygrothermal conditions on the
viscoelastic-viscoplastic fracture behavior of epoxy nanocomposites under
cyclic loading. The formulation incorporates a definition of the Helmholtz free
energy, which considers the effect of nanoparticles, moisture content, and
temperature. The free energy is additively decomposed into a deviatoric
equilibrium, a deviatoric non-equilibrium, and a volumetric contribution, with
distinct definitions for tension and compression. The proposed derivation
offers a realistic modeling of damage and viscoplasticity mechanisms in the
nanocomposites by coupling the phase-field damage model with a modified crack
driving force and a viscoelastic-viscoplastic model. Numerical simulations are
conducted to study the cyclic force-displacement response of both dry and
saturated boehmite nanoparticle (BNP)/epoxy samples, considering BNP contents
and temperature. Comparing numerical results with experimental data shows good
agreement at various BNP contents. In addition, the predictive capability of
the phase-field model is evaluated through simulations of single-edge notched
nanocomposite plates subjected to monolithic tensile and shear loading.
</p>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11814 title=Abstract>arXiv:2401.11814</a> [<a href=https://arxiv.org/pdf/2401.11814 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11814 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11814 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symbrain: A large-scale dataset of MRI images for neonatal brain symmetry analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gucciardi%2C+A">Arnaud Gucciardi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghazouali%2C+S+E">Safouane El Ghazouali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venturini%2C+F">Francesca Venturini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Groznik%2C+V">Vida Groznik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michelucci%2C+U">Umberto Michelucci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 2 figures, Dataset Paper, Medical AI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper presents an annotated dataset of brain MRI images designed to
advance the field of brain symmetry study. Magnetic resonance imaging (MRI) has
gained interest in analyzing brain symmetry in neonatal infants, and challenges
remain due to the vast size differences between fetal and adult brains.
Classification methods for brain structural MRI use scales and visual cues to
assess hemisphere symmetry, which can help diagnose neonatal patients by
comparing hemispheres and anatomical regions of interest in the brain. Using
the Developing Human Connectome Project dataset, this work presents a dataset
comprising cerebral images extracted as slices across selected portions of
interest for clinical evaluation . All the extracted images are annotated with
the brain's midline. All the extracted images are annotated with the brain's
midline. From the assumption that a decrease in symmetry is directly related to
possible clinical pathologies, the dataset can contribute to a more precise
diagnosis because it can be used to train deep learning model application in
neonatal cerebral MRI anomaly detection from postnatal infant scans thanks to
computer vision. Such models learn to identify and classify anomalies by
identifying potential asymmetrical patterns in medical MRI images. Furthermore,
this dataset can contribute to the research and development of methods using
the relative symmetry of the two brain hemispheres for crucial diagnosis and
treatment planning.
</p>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11817 title=Abstract>arXiv:2401.11817</a> [<a href=https://arxiv.org/pdf/2401.11817 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11817 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hallucination is Inevitable: An Innate Limitation of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Ziwei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+S">Sanjay Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Hallucination has been widely recognized to be a significant drawback for
large language models (LLMs). There have been many works that attempt to reduce
the extent of hallucination. These efforts have mostly been empirical so far,
which cannot answer the fundamental question whether it can be completely
eliminated. In this paper, we formalize the problem and show that it is
impossible to eliminate hallucination in LLMs. Specifically, we define a formal
world where hallucination is defined as inconsistencies between a computable
LLM and a computable ground truth function. By employing results from learning
theory, we show that LLMs cannot learn all of the computable functions and will
therefore always hallucinate. Since the formal world is a part of the real
world which is much more complicated, hallucinations are also inevitable for
real world LLMs. Furthermore, for real world LLMs constrained by provable time
complexity, we describe the hallucination-prone tasks and empirically validate
our claims. Finally, using the formal world framework, we discuss the possible
mechanisms and efficacies of existing hallucination mitigators as well as the
practical implications on the safe deployment of LLMs.
</p>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11818 title=Abstract>arXiv:2401.11818</a> [<a href=https://arxiv.org/pdf/2401.11818 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11818 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MInD: Improving Multimodal Sentiment Analysis via Multimodal Information Disentanglement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+W">Weichen Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xingyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+P">Pengbo Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+J">Ji Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+J">Jianlin Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
<p class=mathjax>Learning effective joint representations has been a central task in
multimodal sentiment analysis. Previous methods focus on leveraging the
correlations between different modalities and enhancing performance through
sophisticated fusion techniques. However, challenges still exist due to the
inherent heterogeneity of distinct modalities, which may lead to distributional
gap, impeding the full exploitation of inter-modal information and resulting in
redundancy and impurity in the information extracted from features. To address
this problem, we introduce the Multimodal Information Disentanglement (MInD)
approach. MInD decomposes the multimodal inputs into a modality-invariant
component, a modality-specific component, and a remnant noise component for
each modality through a shared encoder and multiple private encoders. The
shared encoder aims to explore the shared information and commonality across
modalities, while the private encoders are deployed to capture the distinctive
information and characteristic features. These representations thus furnish a
comprehensive perspective of the multimodal data, facilitating the fusion
process instrumental for subsequent prediction tasks. Furthermore, MInD
improves the learned representations by explicitly modeling the task-irrelevant
noise in an adversarial manner. Experimental evaluations conducted on benchmark
datasets, including CMU-MOSI, CMU-MOSEI, and UR-Funny, demonstrate MInD's
superior performance over existing state-of-the-art methods in both multimodal
emotion recognition and multimodal humor detection tasks.
</p>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11819 title=Abstract>arXiv:2401.11819</a> [<a href=https://arxiv.org/pdf/2401.11819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Liang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+H">Hang Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+L">Lei Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+K">Kangkang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 7 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate
the mathematical reasoning abilities of Chinese language models. SC-Math6 is
designed as an upgraded Chinese version of the GSM8K dataset with enhanced
difficulty, diversity, and application scope. It consists of over 2000
mathematical word problems requiring multi-step reasoning and providing natural
language solutions. We propose an innovative scheme to quantify the reasoning
capability of large models based on performance over problems with different
reasoning steps. Experiments on 12 representative Chinese models demonstrate a
clear stratification of reasoning levels, with top models like GPT-4 showing
superior performance. SC-Math6 fills the gap in Chinese mathematical reasoning
benchmarks and provides a comprehensive testbed to advance the intelligence of
Chinese language models.
</p>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11820 title=Abstract>arXiv:2401.11820</a> [<a href=https://arxiv.org/pdf/2401.11820 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11820 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Analysis of Fluid Antenna-aided Backscatter Communications Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghadi%2C+F+R">Farshad Rostami Ghadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaveh%2C+M">Masoud Kaveh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kai-Kit Wong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper studies the performance of backscatter communications (BC) over
emerging fluid antenna (FA) technology. In particular, a single-antenna source
sends information to a FA reader through the wireless forward (i.e.,
source-to-tag) and backscatter (tag-to-reader) channels. For the considered BC,
we first derive the cumulative distribution function (CDF) of the equivalent
channel at the FA receiver, and then we obtain closed-form expressions of the
outage probability (OP) and delay outage rate (DOR) under a correlated Rayleigh
distribution. Moreover, in order to gain more insights into the system
performance, we present analytical expressions of the OP and DOR at the high
SNR regime. Numerical results indicate that considering the FA at the reader
can significantly improve the performance of BC in terms of the OP and DOR
compared with a single-antenna reader.
</p>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11823 title=Abstract>arXiv:2401.11823</a> [<a href=https://arxiv.org/pdf/2401.11823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11823 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards a satisfactory conversion of messages among agent-based information systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berges%2C+I">Idoia Berges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berm%C3%BAdez%2C+J">Jesús Bermúdez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Go%C3%B1i%2C+A">Alfredo Goñi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted manuscript of: Idoia Berges, Jes\'us Berm\'udez, Alfredo Go\~ni, Arantza Illarramendi.Towards a satisfactory conversion of messages among agent-based information systems,Expert Syst. Appl.40(7):2462-2475(2013), published in final form at <a href=https://doi.org/10.1016/j.eswa.2012.10.055.Copyright>this https URL</a> 2012 Elsevier under CC BY-NC-ND license (<a href=http://creativecommons.org/licenses/by-nc-nd/4.0/>this http URL</a>)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Expert Syst. Appl.40(7) : 2462-2475 (2013)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>Over the last years, there has been a change of perspective concerning the
management of information systems, since they are no longer isolated and need
to communicate with others. However, from a semantic point of view, real
communication is difficult to achieve due to the heterogeneity of the systems.
We present a proposal which, considering information systems are represented by
software agents, provides a framework that favours a semantic communication
among them, overcoming the heterogeneity of their agent communication
languages. The main components of the framework are a suite of ontologies --
conceptualizing communication acts -- that will be used for generating the
communication conversion, and an Event Calculus interpretation of the
communications, which will be used for formalizing the notion of a satisfactory
conversion. Moreover, we present a motivating example in order to complete the
explanation of the whole picture.
</p>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11824 title=Abstract>arXiv:2401.11824</a> [<a href=https://arxiv.org/pdf/2401.11824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rethinking Centered Kernel Alignment in Knowledge Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+S">Shitong Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Huanran Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+L">Linrui Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shaohui Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Knowledge distillation has emerged as a highly effective method for bridging
the representation discrepancy between large-scale models and lightweight
models. Prevalent approaches involve leveraging appropriate metrics to minimize
the divergence or distance between the knowledge extracted from the teacher
model and the knowledge learned by the student model. Centered Kernel Alignment
(CKA) is widely used to measure representation similarity and has been applied
in several knowledge distillation methods. However, these methods are complex
and fail to uncover the essence of CKA, thus not answering the question of how
to use CKA to achieve simple and effective distillation properly. This paper
first provides a theoretical perspective to illustrate the effectiveness of
CKA, which decouples CKA to the upper bound of Maximum Mean Discrepancy~(MMD)
and a constant term. Drawing from this, we propose a novel Relation-Centered
Kernel Alignment~(RCKA) framework, which practically establishes a connection
between CKA and MMD. Furthermore, we dynamically customize the application of
CKA based on the characteristics of each task, with less computational source
yet comparable performance than the previous methods. The extensive experiments
on the CIFAR-100, ImageNet-1k, and MS-COCO demonstrate that our method achieves
state-of-the-art performance on almost all teacher-student pairs for image
classification and object detection, validating the effectiveness of our
approaches.
</p>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11825 title=Abstract>arXiv:2401.11825</a> [<a href=https://arxiv.org/pdf/2401.11825 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11825 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sparse discovery of differential equations based on multi-fidelity Gaussian process
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meng%2C+Y">Yuhuang Meng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Qiu%2C+Y">Yue Qiu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Sparse identification of differential equations aims to compute the analytic
expressions from the observed data explicitly. However, there exist two primary
challenges. Firstly, it exhibits sensitivity to the noise in the observed data,
particularly for the derivatives computations. Secondly, existing literature
predominantly concentrates on single-fidelity (SF) data, which imposes
limitations on its applicability due to the computational cost. In this paper,
we present two novel approaches to address these problems from the view of
uncertainty quantification. We construct a surrogate model employing the
Gaussian process regression (GPR) to mitigate the effect of noise in the
observed data, quantify its uncertainty, and ultimately recover the equations
accurately. Subsequently, we exploit the multi-fidelity Gaussian processes
(MFGP) to address scenarios involving multi-fidelity (MF), sparse, and noisy
observed data. We demonstrate the robustness and effectiveness of our
methodologies through several numerical experiments.
</p>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11831 title=Abstract>arXiv:2401.11831</a> [<a href=https://arxiv.org/pdf/2401.11831 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11831 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Fair Evaluation of Various Deep Learning-Based Document Image Binarization Approaches
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sukesh%2C+R">Richin Sukesh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seuret%2C+M">Mathias Seuret</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nicolaou%2C+A">Anguelos Nicolaou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayr%2C+M">Martin Mayr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Christlein%2C+V">Vincent Christlein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> DAS 2022
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Document Analysis Systems. DAS 2022. Lecture Notes in Computer
 Science, vol 13237. Springer, Cham
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Binarization of document images is an important pre-processing step in the
field of document analysis. Traditional image binarization techniques usually
rely on histograms or local statistics to identify a valid threshold to
differentiate between different aspects of the image. Deep learning techniques
are able to generate binarized versions of the images by learning
context-dependent features that are less error-prone to degradation typically
occurring in document images. In recent years, many deep learning-based methods
have been developed for document binarization. But which one to choose? There
have been no studies that compare these methods rigorously. Therefore, this
work focuses on the evaluation of different deep learning-based methods under
the same evaluation protocol. We evaluate them on different Document Image
Binarization Contest (DIBCO) datasets and obtain very heterogeneous results. We
show that the DE-GAN model was able to perform better compared to other models
when evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on the
DIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset while
SauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we make
the code, all models and evaluation publicly available
(https://github.com/RichSu95/Document_Binarization_Collection) to ensure
reproducibility and simplify future binarization evaluations.
</p>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11834 title=Abstract>arXiv:2401.11834</a> [<a href=https://arxiv.org/pdf/2401.11834 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11834 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> End-to-end Multi-Instance Robotic Reaching from Monocular Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+Z">Zheyu Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This manuscript was published in ICRA21, not a new paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Multi-instance scenes are especially challenging for end-to-end visuomotor
(image-to-control) learning algorithms. "Pipeline" visual servo control
algorithms use separate detection, selection and servo stages, allowing
algorithms to focus on a single object instance during servo control.
End-to-end systems do not have separate detection and selection stages and need
to address the visual ambiguities introduced by the presence of arbitrary
number of visually identical or similar objects during servo control. However,
end-to-end schemes avoid embedding errors from detection and selection stages
in the servo control behaviour, are more dynamically robust to changing scenes,
and are algorithmically simpler. In this paper, we present a real-time
end-to-end visuomotor learning algorithm for multi-instance reaching. The
proposed algorithm uses a monocular RGB image and the manipulator's joint
angles as the input to a light-weight fully-convolutional network (FCN) to
generate control candidates. A key innovation of the proposed method is
identifying the optimal control candidate by regressing a control-Lyapunov
function (cLf) value. The multi-instance capability emerges naturally from the
stability analysis associated with the cLf formulation. We demonstrate the
proposed algorithm effectively reaching and grasping objects from different
categories on a table-top amid other instances and distractors from an
over-the-shoulder monocular RGB camera.
<br>The network is able to run up to approximately 160 fps during inference on
one GTX 1080 Ti GPU.
</p>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11835 title=Abstract>arXiv:2401.11835</a> [<a href=https://arxiv.org/pdf/2401.11835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unveiling the Human-like Similarities of Automatic Facial Expression Recognition: An Empirical Exploration through Explainable AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaya-Morey%2C+F+X">F. Xavier Gaya-Morey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramis-Guarinos%2C+S">Silvia Ramis-Guarinos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manresa-Yee%2C+C">Cristina Manresa-Yee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buades-Rubio%2C+J+M">Jose M. Buades-Rubio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Facial expression recognition is vital for human behavior analysis, and deep
learning has enabled models that can outperform humans. However, it is unclear
how closely they mimic human processing. This study aims to explore the
similarity between deep neural networks and human perception by comparing
twelve different networks, including both general object classifiers and
FER-specific models. We employ an innovative global explainable AI method to
generate heatmaps, revealing crucial facial regions for the twelve networks
trained on six facial expressions. We assess these results both quantitatively
and qualitatively, comparing them to ground truth masks based on Friesen and
Ekman's description and among them. We use Intersection over Union (IoU) and
normalized correlation coefficients for comparisons. We generate 72 heatmaps to
highlight critical regions for each expression and architecture. Qualitatively,
models with pre-trained weights show more similarity in heatmaps compared to
those without pre-training. Specifically, eye and nose areas influence certain
facial expressions, while the mouth is consistently important across all models
and expressions. Quantitatively, we find low average IoU values (avg. 0.2702)
across all expressions and architectures. The best-performing architecture
averages 0.3269, while the worst-performing one averages 0.2066. Dendrograms,
built with the normalized correlation coefficient, reveal two main clusters for
most expressions: models with pre-training and models without pre-training.
Findings suggest limited alignment between human and AI facial expression
recognition, with network architectures influencing the similarity, as similar
architectures prioritize similar facial regions.
</p>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11836 title=Abstract>arXiv:2401.11836</a> [<a href=https://arxiv.org/pdf/2401.11836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical Federated Learning Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qiqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaidi Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper proposes a privacy-preserving data fusion method for traffic state
estimation (TSE). Unlike existing works that assume all data sources to be
accessible by a single trusted party, we explicitly address data privacy
concerns that arise in the collaboration and data sharing between multiple data
owners, such as municipal authorities (MAs) and mobility providers (MPs). To
this end, we propose a novel vertical federated learning (FL) approach, FedTSE,
that enables multiple data owners to collaboratively train and apply a TSE
model without having to exchange their private data. To enhance the
applicability of the proposed FedTSE in common TSE scenarios with limited
availability of ground-truth data, we further propose a privacy-preserving
physics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models
into FL. Real-world data validation shows that the proposed methods can protect
privacy while yielding similar accuracy to the oracle method without privacy
considerations.
</p>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11838 title=Abstract>arXiv:2401.11838</a> [<a href=https://arxiv.org/pdf/2401.11838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Conversation is the Command: Interacting with Real-World Autonomous Robot Through Natural Language
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nwankwo%2C+L">Linus Nwankwo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rueckert%2C+E">Elmar Rueckert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>In recent years, autonomous agents have surged in real-world environments
such as our homes, offices, and public spaces. However, natural human-robot
interaction remains a key challenge. In this paper, we introduce an approach
that synergistically exploits the capabilities of large language models (LLMs)
and multimodal vision-language models (VLMs) to enable humans to interact
naturally with autonomous robots through conversational dialogue. We leveraged
the LLMs to decode the high-level natural language instructions from humans and
abstract them into precise robot actionable commands or queries. Further, we
utilised the VLMs to provide a visual and semantic understanding of the robot's
task environment. Our results with 99.13% command recognition accuracy and
97.96% commands execution success show that our approach can enhance
human-robot interaction in real-world applications. The video demonstrations of
this paper can be found at https://osf.io/wzyf6 and the code is available at
our GitHub repository (https://github.com/LinusNEP/TCC_IRoNL.git).
</p>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11839 title=Abstract>arXiv:2401.11839</a> [<a href=https://arxiv.org/pdf/2401.11839 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11839 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI for social science and social science of AI: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Ruoxi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yingfei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+M">Mengjie Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Shiguang Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+R">Ruotong Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hongyu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Le Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+X">Xianpei Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by Information Processing and Management (IP&amp;M)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Recent advancements in artificial intelligence, particularly with the
emergence of large language models (LLMs), have sparked a rethinking of
artificial general intelligence possibilities. The increasing human-like
capabilities of AI are also attracting attention in social science research,
leading to various studies exploring the combination of these two fields. In
this survey, we systematically categorize previous explorations in the
combination of AI and social science into two directions that share common
technical approaches but differ in their research objectives. The first
direction is focused on AI for social science, where AI is utilized as a
powerful tool to enhance various stages of social science research. While the
second direction is the social science of AI, which examines AI agents as
social entities with their human-like cognitive and linguistic capabilities. By
conducting a thorough review, particularly on the substantial progress
facilitated by recent advancements in large language models, this paper
introduces a fresh perspective to reassess the relationship between AI and
social science, provides a cohesive framework that allows researchers to
understand the distinctions and connections between AI for social science and
social science of AI, and also summarized state-of-art experiment simulation
platforms to facilitate research in these two directions. We believe that as AI
technology continues to advance and intelligent agents find increasing
applications in our daily lives, the significance of the combination of AI and
social science will become even more prominent.
</p>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11840 title=Abstract>arXiv:2401.11840</a> [<a href=https://arxiv.org/pdf/2401.11840 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11840 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Approximate Adaptive Kernel Convolution on Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%2C+J">Jaeyoon Sim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon%2C+S">Sooyeon Jeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+I">InJun Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+G">Guorong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+W+H">Won Hwa Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, Accepted to AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Various Graph Neural Networks (GNNs) have been successful in analyzing data
in non-Euclidean spaces, however, they have limitations such as oversmoothing,
i.e., information becomes excessively averaged as the number of hidden layers
increases. The issue stems from the intrinsic formulation of conventional graph
convolution where the nodal features are aggregated from a direct neighborhood
per layer across the entire nodes in the graph. As setting different number of
hidden layers per node is infeasible, recent works leverage a diffusion kernel
to redefine the graph structure and incorporate information from farther nodes.
Unfortunately, such approaches suffer from heavy diagonalization of a graph
Laplacian or learning a large transform matrix. In this regards, we propose a
diffusion learning framework, where the range of feature aggregation is
controlled by the scale of a diffusion kernel. For efficient computation, we
derive closed-form derivatives of approximations of the graph convolution with
respect to the scale, so that node-wise range can be adaptively learned. With a
downstream classifier, the entire framework is made trainable in an end-to-end
manner. Our model is tested on various standard datasets for node-wise
classification for the state-of-the-art performance, and it is also validated
on a real-world brain network data for graph classifications to demonstrate its
practicality for Alzheimer classification.
</p>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11841 title=Abstract>arXiv:2401.11841</a> [<a href=https://arxiv.org/pdf/2401.11841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11841 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Web Technology for Agent Communication Protocols
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berges%2C+I">Idoia Berges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berm%C3%BAdez%2C+J">Jesús Bermúdez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Go%C3%B1i%2C+A">Alfredo Goñi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted version of: Semantic Web Technology for Agent Communication Protocols. The Semantic Web: Research and Applications, ESWC 2008. Proceedings. LNCS 5021. pages 5-18. <a href=https://doi.org/10.1007/978-3-540-68234-9_4>this https URL</a>, copyright Springer-Verlag Berlin Heidelberg 2008
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> The Semantic Web: Research and Applications, ESWC 2008
 Proceedings. LNCS 5021. pages 5-18
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>One relevant aspect in the development of the Semantic Web framework is the
achievement of a real inter-agents communication capability at the semantic
level. The agents should be able to communicate and understand each other using
standard communication protocols freely, that is, without needing a laborious a
priori preparation, before the communication takes place. For that setting we
present in this paper a proposal that promotes to describe standard
communication protocols using Semantic Web technology (specifically, OWL-DL and
SWRL). Those protocols are constituted by communication acts. In our proposal
those communication acts are described as terms that belong to a communication
acts ontology, that we have developed, called CommOnt. The intended semantics
associated to the communication acts in the ontology is expressed through
social commitments that are formalized as fluents in the Event Calculus. In
summary, OWL-DL reasoners and rule engines help in our proposal for reasoning
about protocols. We define some comparison relationships (dealing with notions
of equivalence and specialization) between protocols used by agents from
different systems.
</p>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11844 title=Abstract>arXiv:2401.11844</a> [<a href=https://arxiv.org/pdf/2401.11844 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11844 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mena%2C+F">Francisco Mena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Najjar%2C+H">Hiba Najjar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez%2C+C">Cristhian Sanchez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Helber%2C+P">Patrick Helber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bischke%2C+B">Benjamin Bischke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Habelitz%2C+P">Peter Habelitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miranda%2C+M">Miro Miranda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siddamsetty%2C+J">Jayanth Siddamsetty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nuske%2C+M">Marlon Nuske</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Charfuelan%2C+M">Marcela Charfuelan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arenas%2C+D">Diego Arenas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vollmer%2C+M">Michaela Vollmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Accurate crop yield prediction is of utmost importance for informed
decision-making in agriculture, aiding farmers, and industry stakeholders.
However, this task is complex and depends on multiple factors, such as
environmental conditions, soil properties, and management practices. Combining
heterogeneous data views poses a fusion challenge, like identifying the
view-specific contribution to the predictive task. We present a novel
multi-view learning approach to predict crop yield for different crops
(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our
multi-view input data includes multi-spectral optical images from Sentinel-2
satellites and weather data as dynamic features during the crop growing season,
complemented by static features like soil properties and topographic
information. To effectively fuse the data, we introduce a Multi-view Gated
Fusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)
module. The view-encoders handle the heterogeneity of data sources with varying
temporal resolutions by learning a view-specific representation. These
representations are adaptively fused via a weighted sum. The fusion weights are
computed for each sample by the GU using a concatenation of the
view-representations. The MVGF model is trained at sub-field level with 10 m
resolution pixels. Our evaluations show that the MVGF outperforms conventional
models on the same task, achieving the best results by incorporating all the
data sources, unlike the usual fusion results in the literature. For Argentina,
the MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,
while at field level evaluation (comparing field averages), it reaches around
0.80 across different countries. The GU module learned different weights based
on the country and crop-type, aligning with the variable significance of each
data source to the prediction task.
</p>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11847 title=Abstract>arXiv:2401.11847</a> [<a href=https://arxiv.org/pdf/2401.11847 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11847 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaze Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Ziyu Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinpeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+D">Donghao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+B">Bian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+C">Chenyong Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guangyong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heng%2C+P">Pheng-Ann Heng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Sign language recognition (SLR) plays a vital role in facilitating
communication for the hearing-impaired community. SLR is a weakly supervised
task where entire videos are annotated with glosses, making it challenging to
identify the corresponding gloss within a video segment. Recent studies
indicate that the main bottleneck in SLR is the insufficient training caused by
the limited availability of large-scale datasets. To address this challenge, we
present SignVTCL, a multi-modal continuous sign language recognition framework
enhanced by visual-textual contrastive learning, which leverages the full
potential of multi-modal data and the generalization ability of language model.
SignVTCL integrates multi-modal data (video, keypoints, and optical flow)
simultaneously to train a unified visual backbone, thereby yielding more robust
visual representations. Furthermore, SignVTCL contains a visual-textual
alignment approach incorporating gloss-level and sentence-level alignment to
ensure precise correspondence between visual features and glosses at the level
of individual glosses and sentence. Experimental results conducted on three
datasets, Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrate that SignVTCL
achieves state-of-the-art results compared with previous methods.
</p>
</div>
</dd>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11848 title=Abstract>arXiv:2401.11848</a> [<a href=https://arxiv.org/pdf/2401.11848 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11848 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ExtruOnt: An ontology for describing a type of manufacturing machine for Industry 4.0 systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ram%C3%ADrez-Dur%C3%A1n%2C+V+J">Víctor Julio Ramírez-Durán</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berges%2C+I">Idoia Berges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the accepted manuscript. The definitive, peer reviewed and edited version of this article is published in Semantic Web 11(6): 887-909 (2020) <a href=https://doi.org/10.3233/sw-200376>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Semantic Web 11(6): 887-909 (2020)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Semantically rich descriptions of manufacturing machines, offered in a
machine-interpretable code, can provide interesting benefits in Industry 4.0
scenarios. However, the lack of that type of descriptions is evident. In this
paper we present the development effort made to build an ontology, called
ExtruOnt, for describing a type of manufacturing machine, more precisely, a
type that performs an extrusion process (extruder). Although the scope of the
ontology is restricted to a concrete domain, it could be used as a model for
the development of other ontologies for describing manufacturing machines in
Industry 4.0 scenarios. The terms of the ExtruOnt ontology provide different
types of information related with an extruder, which are reflected in distinct
modules that constitute the ontology. Thus, it contains classes and properties
for expressing descriptions about components of an extruder, spatial
connections, features, and 3D representations of those components, and finally
the sensors used to capture indicators about the performance of this type of
machine. The ontology development process has been carried out in close
collaboration with domain experts.
</p>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11849 title=Abstract>arXiv:2401.11849</a> [<a href=https://arxiv.org/pdf/2401.11849 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11849 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Labeling the Job Shop Scheduling Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corsini%2C+A">Andrea Corsini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porrello%2C+A">Angelo Porrello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calderara%2C+S">Simone Calderara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dell%27Amico%2C+M">Mauro Dell'Amico</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Combinatorics (math.CO)
</div>
<p class=mathjax>In this work, we propose a Self-Supervised training strategy specifically
designed for combinatorial problems. One of the main obstacles in applying
supervised paradigms to such problems is the requirement of expensive target
solutions as ground-truth, often produced with costly exact solvers. Inspired
by Semi- and Self-Supervised learning, we show that it is possible to easily
train generative models by sampling multiple solutions and using the best one
according to the problem objective as a pseudo-label. In this way, we
iteratively improve the model generation capability by relying only on its
self-supervision, completely removing the need for optimality information. We
prove the effectiveness of this Self-Labeling strategy on the Job Shop
Scheduling (JSP), a complex combinatorial problem that is receiving much
attention from the Reinforcement Learning community. We propose a generative
model based on the well-known Pointer Network and train it with our strategy.
Experiments on two popular benchmarks demonstrate the potential of this
approach as the resulting models outperform constructive heuristics and current
state-of-the-art Reinforcement Learning proposals.
</p>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11851 title=Abstract>arXiv:2401.11851</a> [<a href=https://arxiv.org/pdf/2401.11851 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11851 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yuhao Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+C">Chao Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is accepted by 2024 IEEE International Symposium on Circuits and Systems (ISCAS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Existing binary Transformers are promising in edge deployment due to their
compact model size, low computational complexity, and considerable inference
accuracy.However, deploying binary Transformers faces challenges on prior
processors due to inefficient execution of quantized matrix multiplication
(QMM) and the energy consumption overhead caused by multi-precision
activations.To tackle the challenges above, we first develop a computation flow
abstraction method for binary Transformers to improve QMM execution efficiency
by optimizing the computation order.Furthermore, a binarized energy-efficient
Transformer accelerator, namely BETA, is proposed to boost the efficient
deployment at the edge.Notably, BETA features a configurable QMM engine,
accommodating diverse activation precisions of binary Transformers and offering
high-parallelism and high-speed for QMMs with impressive energy
efficiency.Experimental results evaluated on ZCU102 FPGA show BETA achieves an
average energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior
FPGA-based accelerators, showing BETA's good potential for edge Transformer
acceleration.
</p>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11852 title=Abstract>arXiv:2401.11852</a> [<a href=https://arxiv.org/pdf/2401.11852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Right Model for the Job: An Evaluation of Legal Multi-Label Classification Baselines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forster%2C+M">Martina Forster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schulz%2C+C">Claudia Schulz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nokku%2C+P">Prudhvi Nokku</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirsafian%2C+M">Melicaalsadat Mirsafian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasundra%2C+J">Jaykumar Kasundra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Skylaki%2C+S">Stavroula Skylaki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Multi-Label Classification (MLC) is a common task in the legal domain, where
more than one label may be assigned to a legal document. A wide range of
methods can be applied, ranging from traditional ML approaches to the latest
Transformer-based architectures. In this work, we perform an evaluation of
different MLC methods using two public legal datasets, POSTURE50K and
EURLEX57K. By varying the amount of training data and the number of labels, we
explore the comparative advantage offered by different approaches in relation
to the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT
as performing consistently well in legal MLC with reasonable computational
demands. T5 also demonstrates comparable performance while offering advantages
as a generative model in the presence of changing label sets. Finally, we show
that the CrossEncoder exhibits potential for notable macro-F1 score
improvements, albeit with increased computational costs.
</p>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11854 title=Abstract>arXiv:2401.11854</a> [<a href=https://arxiv.org/pdf/2401.11854 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11854 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11854 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization in Sanger Sequencing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carpente%2C+L">Luisa Carpente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cerdeira-Pena%2C+A">Ana Cerdeira-Pena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lorenzo-Freire%2C+S">Silvia Lorenzo-Freire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Places%2C+%C3%81+S">Ángeles S. Places</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> \copyright 2019. This manuscript version is made available under the CC-BY-NC-ND 4.0 license (<a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>this https URL</a>). This version of the article has been accepted for publication in Computers &amp; Operations Research. The Version of Record is available online at <a href=https://doi.org/10.1016/j.cor.2019.05.011>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>The main objective of this paper is to solve the optimization problem that is
associated with the classification of DNA samples in PCR plates for Sanger
sequencing. To achieve this goal, we design an integer linear programming
model. Given that the real instances involve the classification of thousands of
samples and the linear model can only be solved for small instances, the paper
includes a heuristic to cope with bigger problems. The heuristic algorithm is
based on the simulated annealing technique. This algorithm obtains satisfactory
solutions to the problem in a short amount of time. It has been tested with
real data and yields improved results compared to some commercial software
typically used in (clinical) laboratories. Moreover, the algorithm has already
been implemented in the laboratory and is being successfully used.
</p>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11860 title=Abstract>arXiv:2401.11860</a> [<a href=https://arxiv.org/pdf/2401.11860 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11860 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuandi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sicard%2C+B">Brett Sicard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gadsden%2C+S+A">Stephen Andrew Gadsden</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper has been submitted for review to the journal Expert Systems with Applications (December 31, 2023). 90 pages, 22 figures, 9 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
</div>
<p class=mathjax>This study presents a comprehensive overview of PIML techniques in the
context of condition monitoring. The central concept driving PIML is the
incorporation of known physical laws and constraints into machine learning
algorithms, enabling them to learn from available data while remaining
consistent with physical principles. Through fusing domain knowledge with
data-driven learning, PIML methods offer enhanced accuracy and interpretability
in comparison to purely data-driven approaches. In this comprehensive survey,
detailed examinations are performed with regard to the methodology by which
known physical principles are integrated within machine learning frameworks, as
well as their suitability for specific tasks within condition monitoring.
Incorporation of physical knowledge into the ML model may be realized in a
variety of methods, with each having its unique advantages and drawbacks. The
distinct advantages and limitations of each methodology for the integration of
physics within data-driven models are detailed, considering factors such as
computational efficiency, model interpretability, and generalizability to
different systems in condition monitoring and fault detection. Several case
studies and works of literature utilizing this emerging concept are presented
to demonstrate the efficacy of PIML in condition monitoring applications. From
the literature reviewed, the versatility and potential of PIML in condition
monitoring may be demonstrated. Novel PIML methods offer an innovative solution
for addressing the complexities of condition monitoring and associated
challenges. This comprehensive survey helps form the foundation for future work
in the field. As the technology continues to advance, PIML is expected to play
a crucial role in enhancing maintenance strategies, system reliability, and
overall operational efficiency in engineering systems.
</p>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11861 title=Abstract>arXiv:2401.11861</a> [<a href=https://arxiv.org/pdf/2401.11861 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11861 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11861 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Fixed-Parameter Study on Propositional Dynamic Logic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hosseinpour%2C+M+J">Mohammad Javad Hosseinpour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Didehvar%2C+F">Farzad Didehvar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, A version of this paper is to be submitted in the 11th annual conference of Iran Association of Logic
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Since its establishment, propositional dynamic logic (PDL) has been a subject
of intensive academic research and frequent use in the industry. We have
studied the complexity of some PDL problems and in this paper, we show results
for some special cases of PL and PDL.
</p>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11864 title=Abstract>arXiv:2401.11864</a> [<a href=https://arxiv.org/pdf/2401.11864 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11864 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xunyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Can Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weiping Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This work addresses the challenge of democratizing advanced Large Language
Models (LLMs) by compressing their mathematical reasoning capabilities into
sub-billion parameter Small Language Models (SLMs) without compromising
performance. We introduce Equation-of-Thought Distillation (EoTD), a novel
technique that encapsulates the reasoning process into equation-based
representations to construct an EoTD dataset for fine-tuning SLMs.
Additionally, we propose the Mix Thoughts Distillation (MTD) framework to
enhance the reasoning performance of SLMs. This involves creating a reasoning
dataset with multiple thought processes and using it for fine-tuning. Our
experimental findings demonstrate that EoTD significantly boosts the reasoning
abilities of SLMs, while MTD enables these models to achieve state-of-the-art
reasoning performance.
</p>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11865 title=Abstract>arXiv:2401.11865</a> [<a href=https://arxiv.org/pdf/2401.11865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11865 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Semantic Interoperability of Electronic Health Records
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berges%2C+I">Idoia Berges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berm%C3%BAdez%2C+J">Jesús Bermúdez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the Accepted Manuscript. The definitive, peer reviewed and edited version of this article is: Idoia Berges, Jes\'us Berm\'udez, Arantza Illarramendi: Toward Semantic Interoperability of Electronic Health Records. IEEE Trans. Inf. Technol. Biomed. 16(3): 424-431 (2012). DOI:10.1109/TITB.2011.2180917. Copyright 2011 IEEE
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Trans. Inf. Technol. Biomed. 16(3): 424-431 (2012)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Although the goal of achieving semantic interoperability of electronic health
records (EHRs) is pursued by many researchers, it has not been accomplished
yet. In this paper, we present a proposal that smoothes out the way toward the
achievement of that goal. In particular, our study focuses on medical diagnoses
statements. In summary, the main contributions of our ontology-based proposal
are the following: first, it includes a canonical ontology whose EHR-related
terms focus on semantic aspects. As a result, their descriptions are
independent of languages and technology aspects used in different organizations
to represent EHRs. Moreover, those terms are related to their corresponding
codes in well-known medical terminologies. Second, it deals with modules that
allow obtaining rich ontological representations of EHR information managed by
proprietary models of health information systems. The features of one specific
module are shown as reference. Third, it considers the necessary mapping axioms
between ontological terms enhanced with so-called path mappings. This feature
smoothes out structural differences between heterogeneous EHR representations,
allowing proper alignment of information.
</p>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11867 title=Abstract>arXiv:2401.11867</a> [<a href=https://arxiv.org/pdf/2401.11867 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11867 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modular Monolith: Is This the Trend in Software Architecture?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+R">Ruoyu Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaozhou Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Recently modular monolith architecture has attracted the attention of
practitioners, as Google proposed "Service Weaver" framework to enable
developers to write applications as modular monolithic and deploy them as a set
of microservices. Google considered it as a framework that has the best of both
worlds and it seems to be a trend in software architecture. This paper aims to
understand the definition of the modular monolith in industry and investigate
frameworks and cases building modular monolith architecture. We conducted a
systematic grey literature review, and the results show that modular monolith
combines the advantages of monoliths with microservices. We found three
frameworks and four cases of building modular monolith architecture. In
general, the modular monolith is an alternative way to microservices, and it
also could be a previous step before systems migrate to microservices.
</p>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11868 title=Abstract>arXiv:2401.11868</a> [<a href=https://arxiv.org/pdf/2401.11868 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11868 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Balancing Semi-Hierarchical PCNs for CBDCs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benedetti%2C+M">Marco Benedetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Sclavis%2C+F">Francesco De Sclavis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Favorito%2C+M">Marco Favorito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galano%2C+G">Giuseppe Galano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giammusso%2C+S">Sara Giammusso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muci%2C+A">Antonio Muci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nardelli%2C+M">Matteo Nardelli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>We introduce a family of PCNs (Payment Channel Networks) characterized by a
semi-hierarchical topology and a custom set of channel rebalancing strategies.
This family exhibits two interesting benefits, if used as a platform for
large-scale, instant, retail payment systems, such as CBDCs: Technically, the
solution offers state-of-the-art guarantees of fault-tolerance and integrity,
while providing a latency and throughput comparable to centralized systems;
from a business perspective, the solution perfectly suits the 3-tier
architecture of the current banking ecosystem (central banks / commercial banks
/ retail users), assigning a pivotal and peculiar role to the members of each
tier. Furthermore, the cryptographic privacy of payments for retail users --
typical of PCNs such as the public Lightning Network -- is largely (possibly
fully) retained. We study the system by simulating a scaled-down version of a
hypothetical European CBDC, exploring the trade-offs among liquidity locked by
market operators, payment success rate, throughput, latency, and load on the
underpinning blockchain.
</p>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11870 title=Abstract>arXiv:2401.11870</a> [<a href=https://arxiv.org/pdf/2401.11870 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11870 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Experimental Comparison of Multiwinner Voting Rules on Approval Elections
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faliszewski%2C+P">Piotr Faliszewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lackner%2C+M">Martin Lackner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sornat%2C+K">Krzysztof Sornat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szufa%2C+S">Stanisław Szufa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>In this paper, we experimentally compare major approval-based
<br>multiwinner voting rules. To this end, we define a measure of
<br>similarity between two equal-sized committees subject to a given
<br>election. Using synthetic elections coming from several
<br>distributions, we analyze how similar are the committees provided by
<br>prominent voting rules. Our results can be visualized as ``maps of
<br>voting rules'', which provide a counterpoint to a purely axiomatic
<br>classification of voting rules.
<br>The strength of our proposed method is its independence from preimposed
classifications (such as the satisfaction of concrete axioms),
<br>and that it indeed offers a much finer distinction than
<br>the current state of axiomatic analysis.
</p>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11872 title=Abstract>arXiv:2401.11872</a> [<a href=https://arxiv.org/pdf/2401.11872 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11872 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11872 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The complexity of elliptic normal bases
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panario%2C+D">Daniel Panario</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sall%2C+M">Mohamadou Sall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qiang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We study the complexity (that is, the weight of the multiplication table) of
the elliptic normal bases introduced by Couveignes and Lercier. We give an
upper bound on the complexity of these elliptic normal bases, and we analyze
the weight of some special vectors related to the multiplication table of those
bases. This analysis leads us to some perspectives on the search for low
complexity normal bases from elliptic periods.
</p>
</div>
</dd>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11874 title=Abstract>arXiv:2401.11874</a> [<a href=https://arxiv.org/pdf/2401.11874 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11874 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detect-Order-Construct: A Tree Construction based Approach for Hierarchical Document Structure Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiawei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+K">Kai Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhuoyao Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huo%2C+Q">Qiang Huo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to Pattern Recognition
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Document structure analysis (aka document layout analysis) is crucial for
understanding the physical layout and logical structure of documents, with
applications in information retrieval, document summarization, knowledge
extraction, etc. In this paper, we concentrate on Hierarchical Document
Structure Analysis (HDSA) to explore hierarchical relationships within
structured documents created using authoring software employing hierarchical
schemas, such as LaTeX, Microsoft Word, and HTML. To comprehensively analyze
hierarchical document structures, we propose a tree construction based approach
that addresses multiple subtasks concurrently, including page object detection
(Detect), reading order prediction of identified objects (Order), and the
construction of intended hierarchical structure (Construct). We present an
effective end-to-end solution based on this framework to demonstrate its
performance. To assess our approach, we develop a comprehensive benchmark
called Comp-HRDoc, which evaluates the above subtasks simultaneously. Our
end-to-end system achieves state-of-the-art performance on two large-scale
document layout analysis datasets (PubLayNet and DocLayNet), a high-quality
hierarchical document structure reconstruction dataset (HRDoc), and our
Comp-HRDoc benchmark. The Comp-HRDoc benchmark will be released to facilitate
further research in this field.
</p>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11876 title=Abstract>arXiv:2401.11876</a> [<a href=https://arxiv.org/pdf/2401.11876 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11876 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> First-principles Based 3D Virtual Simulation Testing for Discovering SOTIF Corner Cases of Autonomous Driving
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lehang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Haokuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+B">Botao Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+T">Tianyu He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Shuohan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chuanyi Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>3D virtual simulation, which generates diversified test scenarios and tests
full-stack of Autonomous Driving Systems (ADSes) modules dynamically as a
whole, is a promising approach for Safety of The Intended Functionality (SOTIF)
ADS testing. However, as different configurations of a test scenario will
affect the sensor perceptions and environment interaction, e.g. light pulses
emitted by the LiDAR sensor will undergo backscattering and attenuation, which
is usually overlooked by existing works, leading to false positives or wrong
results. Moreover, the input space of an ADS is extremely large, with infinite
number of possible initial scenarios and mutations, along both temporal and
spatial domains.
<br>This paper proposes a first-principles based sensor modeling and environment
interaction scheme, and integrates it into CARLA simulator. With this scheme, a
long-overlooked category of adverse weather related corner cases are
discovered, along with their root causes. Moreover, a meta-heuristic algorithm
is designed based on several empirical insights, which guide both seed
scenarios and mutations, significantly reducing the search dimensions of
scenarios and enhancing the efficiency of corner case identification.
Experimental results show that under identical simulation setups, our algorithm
discovers about four times as many corner cases as compared to state-of-the-art
work.
</p>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11877 title=Abstract>arXiv:2401.11877</a> [<a href=https://arxiv.org/pdf/2401.11877 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11877 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating the Feasibility of Standard Facial Expression Recognition in Individuals with Moderate to Severe Intellectual Disabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaya-Morey%2C+F+X">F. Xavier Gaya-Morey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramis%2C+S">Silvia Ramis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buades-Rubio%2C+J+M">Jose M. Buades-Rubio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manresa-Yee%2C+C">Cristina Manresa-Yee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent research has underscored the increasing preference of users for
human-like interactions with machines. Consequently, facial expression
recognition has gained significance as a means of imparting social robots with
the capacity to discern the emotional states of users. In this investigation,
we assess the suitability of deep learning approaches, known for their
remarkable performance in this domain, for recognizing facial expressions in
individuals with intellectual disabilities, which has not been yet studied in
the literature, to the best of our knowledge. To address this objective, we
train a set of twelve distinct convolutional neural networks in different
approaches, including an ensemble of datasets without individuals with
intellectual disabilities and a dataset featuring such individuals. Our
examination of the outcomes achieved by the various models under distinct
training conditions, coupled with a comprehensive analysis of critical facial
regions during expression recognition facilitated by explainable artificial
intelligence techniques, revealed significant distinctions in facial
expressions between individuals with and without intellectual disabilities, as
well as among individuals with intellectual disabilities. Remarkably, our
findings demonstrate the feasibility of facial expression recognition within
this population through tailored user-specific training methodologies, which
enable the models to effectively address the unique expressions of each user.
</p>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11880 title=Abstract>arXiv:2401.11880</a> [<a href=https://arxiv.org/pdf/2401.11880 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11880 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zaibin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongting Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lijun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+H">Hongzhi Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lijun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Huchuan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+F">Feng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+J">Jing Shao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Multi-agent systems, augmented with Large Language Models (LLMs), demonstrate
significant capabilities for collective intelligence. However, the potential
misuse of this intelligence for malicious purposes presents significant risks.
To date, comprehensive research on the safety issues associated with
multi-agent systems remains limited. From the perspective of agent psychology,
we discover that the dark psychological states of agents can lead to severe
safety issues. To address these issues, we propose a comprehensive framework
grounded in agent psychology. In our framework, we focus on three aspects:
identifying how dark personality traits in agents might lead to risky
behaviors, designing defense strategies to mitigate these risks, and evaluating
the safety of multi-agent systems from both psychological and behavioral
perspectives. Our experiments reveal several intriguing phenomena, such as the
collective dangerous behaviors among agents, agents' propensity for
self-reflection when engaging in dangerous behavior, and the correlation
between agents' psychological assessments and their dangerous behaviors. We
anticipate that our framework and observations will provide valuable insights
for further research into the safety of multi-agent systems. We will make our
data and code publicly accessible at https:/github.com/AI4Good24/PsySafe.
</p>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11881 title=Abstract>arXiv:2401.11881</a> [<a href=https://arxiv.org/pdf/2401.11881 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11881 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modelling the Dynamics of Identity and Fairness in Ultimatum Game
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chhabra%2C+J">Janvi Chhabra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshmukh%2C+J">Jayati Deshmukh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasa%2C+S">Srinath Srinivasa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Allocation games are zero-sum games that model the distribution of resources
among multiple agents. In this paper, we explore the interplay between an
elastic sense of subjective identity and its impact on notions of fairness in
allocation. An elastic sense of identity in agents is known to lead to
responsible decision-making in non-cooperative, non-zero-sum games like
Prisoners' Dilemma, and is a desirable feature to add into agent models.
However, when it comes to allocation, an elastic sense of identity can be shown
to exacerbate inequities in allocation, giving no rational incentive for agents
to act fairly towards one another. This lead us to introduce a sense of
fairness as an innate characteristic of autonomous agency. For this, we
implement the well-known Ultimatum Game between two agents, where their elastic
sense of self (controlled by a parameter called <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-143-Frame tabindex=0><nobr><span class=math id=MathJax-Span-842 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-843><span class=mi id=MathJax-Span-844 style=font-family:MathJax_Math-italic>γ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>) and a sense of
fairness (controlled by a parameter called <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-144-Frame tabindex=0><nobr><span class=math id=MathJax-Span-845 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-846><span class=mi id=MathJax-Span-847 style=font-family:MathJax_Math-italic>τ<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>) are both varied. We study
the points at which agents find it no longer rational to identify with the
other agent, and uphold their sense of fairness, and vice versa. Such a study
also helps us discern the subtle difference between responsibility and fairness
when it comes to autonomous agency.
</p>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11888 title=Abstract>arXiv:2401.11888</a> [<a href=https://arxiv.org/pdf/2401.11888 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11888 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Deep Learning of Word-of-Mouth Text and Demographics to Predict Customer Rating: Handling Consumer Heterogeneity in Marketing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niimi%2C+J">Junichiro Niimi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In the marketing field, understanding consumer heterogeneity, which is the
internal or psychological difference among consumers that cannot be captured by
behavioral logs, has long been a critical challenge. However, a number of
consumers today usually post their evaluation on the specific product on the
online platform, which can be the valuable source of such unobservable
differences among consumers. Several previous studies have shown the validity
of the analysis on text modality, but on the other hand, such analyses may not
necessarily demonstrate sufficient predictive accuracy for text alone, as they
may not include information readily available from cross-sectional data, such
as consumer profile data. In addition, recent advances in machine learning
techniques, such as large-scale language models (LLMs) and multimodal learning
have made it possible to deal with the various kind of dataset simultaneously,
including textual data and the traditional cross-sectional data, and the joint
representations can be effectively obtained from multiple modalities.
Therefore, this study constructs a product evaluation model that takes into
account consumer heterogeneity by multimodal learning of online product reviews
and consumer profile information. We also compare multiple models using
different modalities or hyper-parameters to demonstrate the robustness of
multimodal learning in marketing analysis.
</p>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11890 title=Abstract>arXiv:2401.11890</a> [<a href=https://arxiv.org/pdf/2401.11890 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11890 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shape uncertainty quantification of Maxwell eigenvalues and -modes with application to TESLA cavities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=D%C3%B6lz%2C+J">Jürgen Dölz</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ebert%2C+D">David Ebert</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sch%C3%B6ps%2C+S">Sebastian Schöps</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ziegler%2C+A">Anna Ziegler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>We consider Maxwell eigenvalue problems on uncertain shapes with perfectly
conducting TESLA cavities being the driving example. Due to the shape
uncertainty, the resulting eigenvalues and eigenmodes are also uncertain and it
is well known that the eigenvalues may exhibit crossings or bifurcations under
perturbation. We discuss how the shape uncertainties can be modelled using the
domain mapping approach and how the deformation mapping can be expressed as
coefficients in Maxwell's equations. Using derivatives of these coefficients
and derivatives of the eigenpairs, we follow a perturbation approach to compute
approximations of mean and covariance of the eigenpairs. For small
perturbations, these approximations are faster and more accurate than Monte
Carlo or similar sampling-based strategies. Numerical experiments for a
three-dimensional 9-cell TESLA cavity are presented.
</p>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11892 title=Abstract>arXiv:2401.11892</a> [<a href=https://arxiv.org/pdf/2401.11892 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11892 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11892 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI, insurance, discrimination and unfair differentiation. An overview and research agenda
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Bekkum%2C+M+S+L">Marvin S. L. van Bekkum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borgesius%2C+F+J+Z">Frederik J. Zuiderveen Borgesius</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Insurers increasingly use AI. We distinguish two situations in which insurers
use AI: (i) data-intensive underwriting, and (ii) behaviour-based insurance.
(i) First, insurers can use AI for data analysis to assess risks:
data-intensive underwriting. Underwriting is, in short, calculating risks and
amending the insurance premium accordingly. (ii) Second, insurers can use AI to
monitor the behaviour of consumers in real-time: behaviour-based insurance. For
example, some car insurers give a discount if a consumer agrees to being
tracked by the insurer and drives safely. While the two trends bring many
advantages, they may also have discriminatory effects. This paper focuses on
the following question. Which discrimination-related effects may occur if
insurers use data-intensive underwriting and behaviour-based insurance? We
focus on two types of discrimination-related effects: discrimination and other
unfair differentiation. (i) Discrimination harms certain groups who are
protected by non-discrimination law, for instance people with certain
ethnicities. (ii) Unfair differentiation does not harm groups that are
protected by non-discrimination law, but it does seem unfair. We introduce four
factors to consider when assessing the fairness of insurance practices. The
paper builds on literature from various disciplines including law, philosophy,
and computer science.
</p>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11897 title=Abstract>arXiv:2401.11897</a> [<a href=https://arxiv.org/pdf/2401.11897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Automatic Transformations of Coq Proof Scripts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magaud%2C+N">Nicolas Magaud</a> (Lab. ICube CNRS Université de Strasbourg, France)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 4-10
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Symbolic Computation (cs.SC); Software Engineering (cs.SE)
</div>
<p class=mathjax>Proof assistants like Coq are increasingly popular to help mathematicians
carry out proofs of the results they conjecture. However, formal proofs remain
highly technical and are especially difficult to reuse. In this paper, we
present a framework to carry out a posteriori script transformations. These
transformations are meant to be applied as an automated post-processing step,
once the proof has been completed. As an example, we present a transformation
which takes an arbitrary large proof script and produces an equivalent
single-line proof script, which can be executed by Coq in one single step.
Other applications, such as fully expanding a proof script (for debugging
purposes), removing all named hypotheses, etc. could be developed within this
framework. We apply our tool to various Coq proof scripts, including some from
the GeoCoq library.
</p>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11898 title=Abstract>arXiv:2401.11898</a> [<a href=https://arxiv.org/pdf/2401.11898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+S+T">Salwa Tabet Gonzalez</a> (University of Strasbourg), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jani%C4%8Di%C4%87%2C+P">Predrag Janičić</a> (University of Belgrade), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narboux%2C+J">Julien Narboux</a> (University of Strasbourg)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 21-37
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Mathematical Software (cs.MS)
</div>
<p class=mathjax>Conjecturing and theorem proving are activities at the center of mathematical
practice and are difficult to separate. In this paper, we propose a framework
for completing incomplete conjectures and incomplete proofs. The framework can
turn a conjecture with missing assumptions and with an under-specified goal
into a proper theorem. Also, the proposed framework can help in completing a
proof sketch into a human-readable and machine-checkable proof. Our approach is
focused on synthetic geometry, and uses coherent logic and constraint solving.
The proposed approach is uniform for all three kinds of tasks, flexible and, to
our knowledge, unique such approach.
</p>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11900 title=Abstract>arXiv:2401.11900</a> [<a href=https://arxiv.org/pdf/2401.11900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Showing Proofs, Assessing Difficulty with GeoGebra Discovery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltán Kovács</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Recio%2C+T">Tomás Recio</a> (Escuela Politécnica Superior, Universidad Antonio de Nebrija, Madrid, Spain), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=V%C3%A9lez%2C+M+P">M. Pilar Vélez</a> (Escuela Politécnica Superior, Universidad Antonio de Nebrija, Madrid, Spain)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 43-52
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Mathematical Software (cs.MS)
</div>
<p class=mathjax>In our contribution we describe some on-going improvements concerning the
Automated Reasoning Tools developed in GeoGebra Discovery, providing different
examples of the performance of these new features. We describe the new
ShowProof command, that outputs both the sequence of the different steps
performed by GeoGebra Discovery to confirm a certain statement, as well as a
number intending to grade the difficulty or interest of the assertion. The
proposal of this assessment measure, involving the comparison of the expression
of the thesis (or conclusion) as a combination of the hypotheses, will be
developed.
</p>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11901 title=Abstract>arXiv:2401.11901</a> [<a href=https://arxiv.org/pdf/2401.11901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ORBGRAND: Achievable Rate for General Bit Channels and Application in BICM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Guessing random additive noise decoding (GRAND) has received widespread
attention recently, and among its variants, ordered reliability bits GRAND
(ORBGRAND) is particularly attractive due to its efficient utilization of soft
information and its amenability to hardware implementation. It has been
recently shown that ORBGRAND is almost capacity-achieving in additive white
Gaussian noise channels under antipodal input. In this work, we first extend
the analysis of ORBGRAND achievable rate to memoryless binary-input bit
channels with general output conditional probability distributions. The
analytical result also sheds insight into understanding the gap between the
ORBGRAND achievable rate and the channel mutual information. As an application
of the analysis, we study the ORBGRAND achievable rate of bit-interleaved coded
modulation (BICM). Numerical results indicate that for BICM, the gap between
the ORBGRAND achievable rate and the channel mutual information is typically
small, and hence suggest the feasibility of ORBGRAND for channels with
high-order coded modulation schemes.
</p>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11903 title=Abstract>arXiv:2401.11903</a> [<a href=https://arxiv.org/pdf/2401.11903 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11903 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automation of Triangle Ruler-and-Compass Constructions Using Constraint Solvers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bankovi%C4%87%2C+M">Milan Banković</a> (Faculty of Mathematics, University of Belgrade, Serbia)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 62-72
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>In this paper, we present an approach to automated solving of triangle
ruler-and-compass construction problems using finite-domain constraint solvers.
The constraint model is described in the MiniZinc modeling language, and is
based on the automated planning. The main benefit of using general constraint
solvers for such purpose, instead of developing dedicated tools, is that we can
rely on the efficient search that is already implemented within the solver,
enabling us to focus on geometric aspects of the problem. We may also use the
solver's built-in optimization capabilities to search for the shortest possible
constructions. We evaluate our approach on 74 solvable problems from the
Wernick's list, and compare it to the dedicated triangle construction solver
ArgoTriCS. The results show that our approach is comparable to dedicated tools,
while it requires much less effort to implement. Also, our model often finds
shorter constructions, thanks to the optimization capabilities offered by the
constraint solvers.
</p>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11904 title=Abstract>arXiv:2401.11904</a> [<a href=https://arxiv.org/pdf/2401.11904 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11904 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards an Independent Version of Tarski's System of Geometry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boutry%2C+P">Pierre Boutry</a> (Centre Inria d'Université Côte d'Azur, Sophia Antipolis, France), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kastenbaum%2C+S">Stéphane Kastenbaum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saintier%2C+C">Clément Saintier</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 73-84
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>In 1926-1927, Tarski designed a set of axioms for Euclidean geometry which
reached its final form in a manuscript by Schwabh\"auser, Szmielew and Tarski
in 1983. The differences amount to simplifications obtained by Tarski and
Gupta. Gupta presented an independent version of Tarski's system of geometry,
thus establishing that his version could not be further simplified without
modifying the axioms. To obtain the independence of one of his axioms, namely
Pasch's axiom, he proved the independence of one of its consequences: the
previously eliminated symmetry of betweenness. However, an independence model
for the non-degenerate part of Pasch's axiom was provided by Szczerba for
another version of Tarski's system of geometry in which the symmetry of
betweenness holds. This independence proof cannot be directly used for Gupta's
version as the statements of the parallel postulate differ.
<br>In this paper, we present our progress towards obtaining an independent
version of a variant of Gupta's system. Compared to Gupta's version, we split
Pasch's axiom into this previously eliminated axiom and its non-degenerate part
and change the statement of the parallel postulate. We verified the
independence properties by mechanizing counter-models using the Coq
proof-assistant.
</p>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11905 title=Abstract>arXiv:2401.11905</a> [<a href=https://arxiv.org/pdf/2401.11905 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11905 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Considerations on Approaches and Metrics in Automated Theorem Generation/Finding in Geometry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quaresma%2C+P">Pedro Quaresma</a> (University of Coimbra), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Graziani%2C+P">Pierluigi Graziani</a> (University of Urbino), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nicoletti%2C+S+M">Stefano M. Nicoletti</a> (University of Twente)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 85-100
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>The pursue of what are properties that can be identified to permit an
automated reasoning program to generate and find new and interesting theorems
is an interesting research goal (pun intended). The automatic discovery of new
theorems is a goal in itself, and it has been addressed in specific areas, with
different methods. The separation of the "weeds", uninteresting, trivial facts,
from the "wheat", new and interesting facts, is much harder, but is also being
addressed by different authors using different approaches. In this paper we
will focus on geometry. We present and discuss different approaches for the
automatic discovery of geometric theorems (and properties), and different
metrics to find the interesting theorems among all those that were generated.
After this description we will introduce the first result of this article: an
undecidability result proving that having an algorithmic procedure that decides
for every possible Turing Machine that produces theorems, whether it is able to
produce also interesting theorems, is an undecidable problem. Consequently, we
will argue that judging whether a theorem prover is able to produce interesting
theorems remains a non deterministic task, at best a task to be addressed by
program based in an algorithm guided by heuristics criteria. Therefore, as a
human, to satisfy this task two things are necessary: an expert survey that
sheds light on what a theorem prover/finder of interesting geometric theorems
is, and - to enable this analysis - other surveys that clarify metrics and
approaches related to the interestingness of geometric theorems. In the
conclusion of this article we will introduce the structure of two of these
surveys - the second result of this article - and we will discuss some future
work.
</p>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11906 title=Abstract>arXiv:2401.11906</a> [<a href=https://arxiv.org/pdf/2401.11906 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11906 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving with GeoGebra Discovery an Austrian Mathematics Olympiad problem: Lessons Learned
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ari%C3%B1o-Morera%2C+B">Belén Ariño-Morera</a> (Departamento de Economía Financiera y Contabilidad, Universidad Rey Juan Carlos, Madrid, Spain), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltán Kovács</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Recio%2C+T">Tomás Recio</a> (Escuela Politécnica Superior, Universidad Antonio de Nebrija, Madrid, Spain), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolmos%2C+P">Piedad Tolmos</a> (Departamento de Economía Financiera y Contabilidad, Universidad Rey Juan Carlos, Madrid, Spain)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 101-109
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Mathematical Software (cs.MS)
</div>
<p class=mathjax>We address, through the automated reasoning tools in GeoGebra Discovery, a
problem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying
to solve this problem gives rise to four different kind of feedback: the almost
instantaneous, automated solution of the proposed problem; the measure of its
complexity, according to some recent proposals; the automated discovery of a
generalization of the given assertion, showing that the same statement is true
over more general polygons than those mentioned in the problem; and the
difficulties associated to the analysis of the surprising and involved high
number of degenerate cases that appear when using the LocusEquation command in
this problem. In our communication we will describe and reflect on these
diverse issues, enhancing its exemplar role for showing some of the advantages,
problems, and current fields of development of GeoGebra Discovery.
</p>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11908 title=Abstract>arXiv:2401.11908</a> [<a href=https://arxiv.org/pdf/2401.11908 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11908 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Locus Story of a Rocking Camel in a Medical Center in the City of Freistadt
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%A4ferb%C3%B6ck%2C+A">Anna Käferböck</a> (The Private University College of Education of the Diocese of Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+Z">Zoltán Kovács</a> (The Private University College of Education of the Diocese of Linz, Austria)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 132-141
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computational Geometry (cs.CG); Mathematical Software (cs.MS); Symbolic Computation (cs.SC)
</div>
<p class=mathjax>We give an example of automated geometry reasoning for an imaginary classroom
project by using the free software package GeoGebra Discovery. The project is
motivated by a publicly available toy, a rocking camel, installed at a medical
center in Upper Austria. We explain how the process of a false conjecture,
experimenting, modeling, a precise mathematical setup, and then a proof by
automated reasoning could help extend mathematical knowledge at secondary
school level and above.
</p>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11909 title=Abstract>arXiv:2401.11909</a> [<a href=https://arxiv.org/pdf/2401.11909 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11909 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D Space Trajectories and beyond: Abstract Art Creation with 3D Printing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dana-Picard%2C+T">Thierry Dana-Picard</a> (Jerusalem College of Technology), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tejera%2C+M">Matias Tejera</a> (Johannes Kepler University Linz, Austria), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulbrich%2C+E">Eva Ulbrich</a> (Johannes Kepler University Linz, Austria)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 142-152
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>; Mathematical Software (cs.MS); Symbolic Computation (cs.SC)
</div>
<p class=mathjax>We present simple models of trajectories in space, both in 2D and in 3D. The
first examples, which model bicircular moves in the same direction, are
classical curves (epicycloids, etc.). Then, we explore bicircular moves in
reverse direction and tricircular moves in 2D and 3D, to explore complex
visualisations of extraplanetary movements. These moves are studied in a plane
setting. Then, adding increasing complexity, we explore them in a non planar
setting (which is a closer model of the real situation). The exploration is
followed by using these approaches for creating mathematical art in 2D and 3D
printed objects, providing new ways of mathematical representations. Students'
activities are organized around this exploration.
</p>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11910 title=Abstract>arXiv:2401.11910</a> [<a href=https://arxiv.org/pdf/2401.11910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Angular Speed Uniformity by Piecewise Radical Reparameterization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+H">Hoon Hong</a> (North Carolina State University), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dongming Wang</a> (Beihang University), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a> (Guangxi Minzu University)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proceedings ADG 2023, <a href=https://arxiv.org/abs/2401.10725>arXiv:2401.10725</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EPTCS 398, 2024, pp. 165-178
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
<p class=mathjax>For a rational parameterization of a curve, it is desirable that its angular
speed is as uniform as possible. Hence, given a rational parameterization, one
wants to find re-parameterization with better uniformity. One natural way is to
use piecewise rational reparameterization. However, it turns out that the
piecewise rational reparameterization does not help when the angular speed of
the given rational parameterization is zero at some points on the curve. In
this paper, we show how to overcome the challenge by using piecewise radical
reparameterization.
</p>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11911 title=Abstract>arXiv:2401.11911</a> [<a href=https://arxiv.org/pdf/2401.11911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Hexiang Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F">Fei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wanli Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuanzhuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Q">Qi Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>While auxiliary information has become a key to enhance Large Language Models
(LLMs), relatively little is known about how well LLMs merge these contexts,
specifically generated and retrieved. To study this, we formulate a task
specifically designed to identify whether the answers, derived from the
integration of generated and retrieved contexts, are attributed to either
generated or retrieved contexts. To support this task, we develop a methodology
to construct datasets with conflicting contexts, where each question is paired
with both generated and retrieved contexts, yet only one of them contains the
correct answer. Our experiments reveal a significant bias in LLMs towards
generated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b)
and closed (GPT 3.5/4) systems. We further identify two key factors
contributing to this bias: i) Contexts generated by LLMs typically show greater
similarity to the questions, increasing their likelihood of selection; ii) The
segmentation process used in retrieved contexts disrupts their completeness,
thereby hindering their full utilization in LLMs. Our analysis enhances the
understanding of how LLMs merge diverse contexts, offering valuable insights
for advancing current augmentation methods for LLMs.
</p>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11913 title=Abstract>arXiv:2401.11913</a> [<a href=https://arxiv.org/pdf/2401.11913 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11913 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large receptive field strategy and important feature extraction strategy in 3D object detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Leichao Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiuxian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+M">Min Meng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The enhancement of 3D object detection is pivotal for precise environmental
perception and improved task execution capabilities in autonomous driving.
LiDAR point clouds, offering accurate depth information, serve as a crucial
information for this purpose. Our study focuses on key challenges in 3D target
detection. To tackle the challenge of expanding the receptive field of a 3D
convolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).
This module achieves adaptive expansion of the 3D convolutional kernel's
receptive field, balancing the expansion with acceptable computational loads.
This innovation reduces operations, expands the receptive field, and allows the
model to dynamically adjust to different object requirements. Simultaneously,
we identify redundant information in 3D features. Employing the Feature
Selection Module (FSM) quantitatively evaluates and eliminates non-important
features, achieving the separation of output box fitting and feature
extraction. This innovation enables the detector to focus on critical features,
resulting in model compression, reduced computational burden, and minimized
candidate frame interference. Extensive experiments confirm that both DFFM and
FSM not only enhance current benchmarks, particularly in small target
detection, but also accelerate network performance. Importantly, these modules
exhibit effective complementarity.
</p>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11914 title=Abstract>arXiv:2401.11914</a> [<a href=https://arxiv.org/pdf/2401.11914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Saliency Enhanced Feature Fusion based multiscale RGB-D Salient Object Detection Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+R">Rui Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qingyi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Y">Yan Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Sihua Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Weifeng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+W">Wei Fan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accpeted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multiscale convolutional neural network (CNN) has demonstrated remarkable
capabilities in solving various vision problems. However, fusing features of
different scales alwaysresults in large model sizes, impeding the application
of multiscale CNNs in RGB-D saliency detection. In this paper, we propose a
customized feature fusion module, called Saliency Enhanced Feature Fusion
(SEFF), for RGB-D saliency detection. SEFF utilizes saliency maps of the
neighboring scales to enhance the necessary features for fusing, resulting in
more representative fused features. Our multiscale RGB-D saliency detector uses
SEFF and processes images with three different scales. SEFF is used to fuse the
features of RGB and depth images, as well as the features of decoders at
different scales. Extensive experiments on five benchmark datasets have
demonstrated the superiority of our method over ten SOTA saliency detectors.
</p>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11915 title=Abstract>arXiv:2401.11915</a> [<a href=https://arxiv.org/pdf/2401.11915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11915 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Secure Multi-hop Telemetry Broadcasts for UAV Swarm Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rotta%2C+R">Randolf Rotta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mykytyn%2C+P">Pavlo Mykytyn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2 pages, 8 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Unmanned Aerial Vehicles (UAVs) are evolving as adaptable platforms for a
wide range of applications such as precise inspections, emergency response, and
remote sensing. Autonomous UAV swarms require efficient and stable
communication during deployment for a successful mission execution. For
instance, the periodic exchange of telemetry data between all swarm members
provides the foundation for formation flight and collision avoidance. However,
due to the mobility of the vehicles and instability of wireless transmissions,
maintaining a secure and reliable all-to-all communication remains challenging.
This paper investigates encrypted and authenticated multi-hop broadcast
communication based on the transmission of custom IEEE 802.11 Wi-Fi data
frames.
</p>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11921 title=Abstract>arXiv:2401.11921</a> [<a href=https://arxiv.org/pdf/2401.11921 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11921 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Maximizing Spectral and Energy Efficiency in Multi-user MIMO OFDM Systems with RIS and Hardware Impairment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soleymani%2C+M">Mohammad Soleymani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santamaria%2C+I">Ignacio Santamaria</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sezgin%2C+A">Aydin Sezgin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jorswieck%2C+E">Eduard Jorswieck</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>An emerging technology to enhance the spectral efficiency (SE) and energy
efficiency (EE) of wireless communication systems is reconfigurable intelligent
surface (RIS), which is shown to be very powerful in single-carrier systems.
However, in multi-user orthogonal frequency division multiplexing (OFDM)
systems, RIS may not be as promising as in single-carrier systems since an
independent optimization of RIS elements at each sub-carrier is impossible in
multi-carrier systems. Thus, this paper investigates the performance of various
RIS technologies like regular (reflective and passive), simultaneously transmit
and reflect (STAR), and multi-sector beyond diagonal (BD) RIS in multi-user
multiple-input multiple-output (MIMO) OFDM broadcast channels (BC). This
requires to formulate and solve a joint MIMO precoding and RIS optimization
problem. The obtained solution reveals that RIS can significantly improve the
system performance even when the number of RIS elements is relatively low.
Moreover, we develop resource allocation schemes for STAR-RIS and multi-sector
BD-RIS in MIMO OFDM BCs, and show that these RIS technologies can outperform a
regular RIS, especially when the regular RIS cannot assist the communications
for all the users.
</p>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11923 title=Abstract>arXiv:2401.11923</a> [<a href=https://arxiv.org/pdf/2401.11923 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11923 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+L">Linping Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liangwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+B">Bingchuan Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zeng Wei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Tour guidance in virtual museums encourages multi-modal interactions to boost
user experiences, concerning engagement, immersion, and spatial awareness.
Nevertheless, achieving the goal is challenging due to the complexity of
comprehending diverse user needs and accommodating personalized user
preferences. Informed by a formative study that characterizes guidance-seeking
contexts, we establish a multi-modal interaction design framework for virtual
tour guidance. We then design VirtuWander, a two-stage innovative system using
domain-oriented large language models to transform user inquiries into diverse
guidance-seeking contexts and facilitate multi-modal interactions. The
feasibility and versatility of VirtuWander are demonstrated with virtual
guiding examples that encompass various touring scenarios and cater to
personalized preferences. We further evaluate VirtuWander through a user study
within an immersive simulated museum. The results suggest that our system
enhances engaging virtual tour experiences through personalized communication
and knowledgeable assistance, indicating its potential for expanding into
real-world scenarios.
</p>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11929 title=Abstract>arXiv:2401.11929</a> [<a href=https://arxiv.org/pdf/2401.11929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+J">Jinliang Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+X">Xuan Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsang%2C+I+W">Ivor W. Tsang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Long-term time series forecasting (LTSF) represents a critical frontier in
time series analysis, distinguished by its focus on extensive input sequences,
in contrast to the constrained lengths typical of traditional approaches. While
longer sequences inherently convey richer information, potentially enhancing
predictive precision, prevailing techniques often respond by escalating model
complexity. These intricate models can inflate into millions of parameters,
incorporating parameter-intensive elements like positional encodings,
feed-forward networks and self-attention mechanisms. This complexity, however,
leads to prohibitive model scale, particularly given the time series data's
semantic simplicity. Motivated by the pursuit of parsimony, our research
employs conditional correlation and auto-correlation as investigative tools,
revealing significant redundancies within the input data. Leveraging these
insights, we introduce the HDformer, a lightweight Transformer variant enhanced
with hierarchical decomposition. This novel architecture not only inverts the
prevailing trend toward model expansion but also accomplishes precise
forecasting with drastically fewer computations and parameters. Remarkably,
HDformer outperforms existing state-of-the-art LTSF models, while requiring
over 99\% fewer parameters. Through this work, we advocate a paradigm shift in
LTSF, emphasizing the importance to tailor the model to the inherent dynamics
of time series data-a timely reminder that in the realm of LTSF, bigger is not
invariably better.
</p>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11932 title=Abstract>arXiv:2401.11932</a> [<a href=https://arxiv.org/pdf/2401.11932 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11932 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Causal Algorithms for Industrial-scale Data: A Distributed Computing Approach with Ray Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verma%2C+V">Vishal Verma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reddy%2C+V">Vinod Reddy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravi%2C+J">Jaiprakash Ravi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The increasing need for causal analysis in large-scale industrial datasets
necessitates the development of efficient and scalable causal algorithms for
real-world applications. This paper addresses the challenge of scaling causal
algorithms in the context of conducting causal analysis on extensive datasets
commonly encountered in industrial settings. Our proposed solution involves
enhancing the scalability of causal algorithm libraries, such as EconML, by
leveraging the parallelism capabilities offered by the distributed computing
framework Ray. We explore the potential of parallelizing key iterative steps
within causal algorithms to significantly reduce overall runtime, supported by
a case study that examines the impact on estimation times and costs. Through
this approach, we aim to provide a more effective solution for implementing
causal analysis in large-scale industrial applications.
</p>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11934 title=Abstract>arXiv:2401.11934</a> [<a href=https://arxiv.org/pdf/2401.11934 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11934 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11934 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Systematic Performance Evaluation Framework for LEO Mega-Constellation Satellite Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+C">Chuili Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+X">Xian Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+H">Hejia Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Ke-Xin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 8 figures, accepted by IEEE ICC2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Performance (cs.PF)</span>
</div>
<p class=mathjax>Low Earth orbit (LEO) mega-constellation satellite networks have shown great
potential to extend the coverage capability of conventional terrestrial
networks. How to systematically define, quantify, and assess the technical
performance of LEO mega-constellation satellite networks remains an open issue.
In this paper, we propose a comprehensive key performance indicator (KPI)
framework for mega-constellation based LEO satellite networks. An efficient LEO
constellation oriented performance evaluation methodology is then carefully
designed by resorting to the concept of interfering area and spherical
geographic cell. We have carried out rigorous system-level simulations and
provided numerical results to assess the KPI framework. It can be observed that
the achieved area traffic capacity of the reference LEO constellation is around
4 Kbps/km2, with service availability ranging from 0.36 to 0.39. Besides, the
average access success probability and handover failure rate is approximate to
96% and 10%, respectively, in the nearest satellite association scheme.
</p>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11940 title=Abstract>arXiv:2401.11940</a> [<a href=https://arxiv.org/pdf/2401.11940 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11940 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhi Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yandong Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xi-Le Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yao Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)
</div>
<p class=mathjax>This paper considers the problem of recovering a tensor with an underlying
low-tubal-rank structure from a small number of corrupted linear measurements.
Traditional approaches tackling such a problem require the computation of
tensor Singular Value Decomposition (t-SVD), that is a computationally
intensive process, rendering them impractical for dealing with large-scale
tensors. Aim to address this challenge, we propose an efficient and effective
low-tubal-rank tensor recovery method based on a factorization procedure akin
to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves
decomposing a large tensor into two smaller factor tensors, followed by solving
the problem through factorized gradient descent (FGD). This strategy eliminates
the need for t-SVD computation, thereby reducing computational costs and
storage requirements. We provide rigorous theoretical analysis to ensure the
convergence of FGD under both noise-free and noisy situations. Additionally, it
is worth noting that our method does not require the precise estimation of the
tensor tubal-rank. Even in cases where the tubal-rank is slightly
overestimated, our approach continues to demonstrate robust performance. A
series of experiments have been carried out to demonstrate that, as compared to
other popular ones, our approach exhibits superior performance in multiple
scenarios, in terms of the faster computational speed and the smaller
convergence error.
</p>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11943 title=Abstract>arXiv:2401.11943</a> [<a href=https://arxiv.org/pdf/2401.11943 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11943 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking Large Multimodal Models against Common Corruptions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pang%2C+T">Tianyu Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+C">Chao Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yi Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)
</div>
<p class=mathjax>This technical report aims to fill a deficiency in the assessment of large
multimodal models (LMMs) by specifically examining the self-consistency of
their outputs when subjected to common corruptions. We investigate the
cross-modal interactions between text, image, and speech, encompassing four
essential generation tasks: text-to-image, image-to-text, text-to-speech, and
speech-to-text. We create a comprehensive benchmark, named MMCBench, that
covers more than 100 popular LMMs (totally over 150 model checkpoints). A
thorough evaluation under common corruptions is critical for practical
deployment and facilitates a better understanding of the reliability of
cutting-edge LMMs. The benchmarking code is available at
https://github.com/sail-sg/MMCBench
</p>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11944 title=Abstract>arXiv:2401.11944</a> [<a href=https://arxiv.org/pdf/2401.11944 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11944 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xinrun Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Bei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yiming Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+T">Tongxu Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K">Kang Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yuyang Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chunpu Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Shuyue Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+X">Xingwei Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Junjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yizhi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zekun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yudong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yu-Hsuan Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fengji Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chenghua Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wenhao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jie Fu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>As the capabilities of large multimodal models (LMMs) continue to advance,
evaluating the performance of LMMs emerges as an increasing need. Additionally,
there is an even larger gap in evaluating the advanced knowledge and reasoning
abilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,
a new Chinese Massive Multi-discipline Multimodal Understanding benchmark
designed to evaluate LMMs on tasks demanding college-level subject knowledge
and deliberate reasoning in a Chinese context. CMMMU is inspired by and
strictly follows the annotation and analysis pattern of MMMU.
<br>CMMMU includes 12k manually collected multimodal questions from college
exams, quizzes, and textbooks, covering six core disciplines: Art &amp; Design,
Business, Science, Health &amp; Medicine, Humanities &amp; Social Science, and Tech &amp;
Engineering, like its companion, MMMU. These questions span 30 subjects and
comprise 39 highly heterogeneous image types, such as charts, diagrams, maps,
tables, music sheets, and chemical structures.
<br>CMMMU focuses on complex perception and reasoning with domain-specific
knowledge in the Chinese context. We evaluate 11 open-source LLMs and one
proprietary GPT-4V(ision). Even GPT-4V only achieves accuracies of 42%,
indicating a large space for improvement. CMMMU will boost the community to
build the next-generation LMMs towards expert artificial intelligence and
promote the democratization of LMMs by providing diverse language contexts.
</p>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11945 title=Abstract>arXiv:2401.11945</a> [<a href=https://arxiv.org/pdf/2401.11945 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11945 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Effect of Predictive Formal Modelling at Runtime on Performance in Human-Swarm Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abioye%2C+A+O">Ayodeji O. Abioye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hunt%2C+W">William Hunt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yue Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneiders%2C+E">Eike Schneiders</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naiseh%2C+M">Mohammad Naiseh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+J+E">Joel E. Fischer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramchurn%2C+S+D">Sarvapali D. Ramchurn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soorati%2C+M+D">Mohammad D. Soorati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Archibald%2C+B">Blair Archibald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sevegnani%2C+M">Michele Sevegnani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been accepted in HRI '24 LBR track. It consist of 5 pages, 2 figures, and 2 tables. This is the author's submitted manuscript, for your personal use. Not for redistribution. The definitive Version of Record will be published in the Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24 Companion), <a href=https://doi.org/10.1145/3610978.3640725>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Formal Modelling is often used as part of the design and testing process of
software development to ensure that components operate within suitable bounds
even in unexpected circumstances. In this paper, we use predictive formal
modelling (PFM) at runtime in a human-swarm mission and show that this
integration can be used to improve the performance of human-swarm teams. We
recruited 60 participants to operate a simulated aerial swarm to deliver
parcels to target locations. In the PFM condition, operators were informed of
the estimated completion times given the number of drones deployed, whereas in
the No-PFM condition, operators did not have this information. The operators
could control the mission by adding or removing drones from the mission and
thereby, increasing or decreasing the overall mission cost. The evaluation of
human-swarm performance relied on four key metrics: the time taken to complete
tasks, the number of agents involved, the total number of tasks accomplished,
and the overall cost associated with the human-swarm task. Our results show
that PFM modelling at runtime improves mission performance without
significantly affecting the operator's workload or the system's usability.
</p>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11946 title=Abstract>arXiv:2401.11946</a> [<a href=https://arxiv.org/pdf/2401.11946 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11946 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Dynamic YOLO-Based Sequence-Matching Model for Efficient Coverless Image Steganography
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiajun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+L">Lina Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhili Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Peng Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Many existing coverless steganography methods establish a mapping
relationship between cover images and hidden data. There exists an issue that
the number of images stored in the database grows exponentially as the
steganographic capacity rises. The need for a high steganographic capacity
makes it challenging to build an image database. To improve the image library
utilization and anti-attack capability of the steganography system, we present
an efficient coverless scheme based on dynamically matched substrings. YOLO is
employed for selecting optimal objects, and a mapping dictionary is established
between these objects and scrambling factors. With the aid of this dictionary,
each image is effectively assigned to a specific scrambling factor, which is
used to scramble the receiver's sequence key. To achieve sufficient
steganography capability based on a limited image library, all substrings of
the scrambled sequences hold the potential to hide data. After completing the
secret information matching, the ideal number of stego images will be obtained
from the database. According to experimental results, this technology
outperforms most previous works on data load, transmission security, and hiding
capacity. Under typical geometric attacks, it can recover 79.85\% of secret
information on average. Furthermore, only approximately 200 random images are
needed to meet a capacity of 19 bits per image.
</p>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11948 title=Abstract>arXiv:2401.11948</a> [<a href=https://arxiv.org/pdf/2401.11948 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11948 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11948 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Ensemble Kalman Filter for Dynamic Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Weissmann%2C+S">Simon Weissmann</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chada%2C+N+K">Neil K. Chada</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tong%2C+X+T">Xin T. Tong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Methodology (stat.ME)
</div>
<p class=mathjax>In inverse problems, the goal is to estimate unknown model parameters from
noisy observational data. Traditionally, inverse problems are solved under the
assumption of a fixed forward operator describing the observation model. In
this article, we consider the extension of this approach to situations where we
have a dynamic forward model, motivated by applications in scientific
computation and engineering. We specifically consider this extension for a
derivative-free optimizer, the ensemble Kalman inversion (EKI). We introduce
and justify a new methodology called dynamic-EKI, which is a particle-based
method with a changing forward operator. We analyze our new method, presenting
results related to the control of our particle system through its covariance
structure. This analysis includes moment bounds and an ensemble collapse, which
are essential for demonstrating a convergence result. We establish convergence
in expectation and validate our theoretical findings through experiments with
dynamic-EKI applied to a 2D Darcy flow partial differential equation.
</p>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11949 title=Abstract>arXiv:2401.11949</a> [<a href=https://arxiv.org/pdf/2401.11949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Feature Denoising Diffusion Model for Blind Image Quality Assessment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xudong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jingyuan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+R">Runze Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Ke Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yutao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">ShengChuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+P">Pingyang Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Blind Image Quality Assessment (BIQA) aims to evaluate image quality in line
with human perception, without reference benchmarks. Currently, deep learning
BIQA methods typically depend on using features from high-level tasks for
transfer learning. However, the inherent differences between BIQA and these
high-level tasks inevitably introduce noise into the quality-aware features. In
this paper, we take an initial step towards exploring the diffusion model for
feature denoising in BIQA, namely Perceptual Feature Diffusion for IQA
(PFD-IQA), which aims to remove noise from quality-aware features.
Specifically, (i) We propose a {Perceptual Prior Discovery and Aggregation
module to establish two auxiliary tasks to discover potential low-level
features in images that are used to aggregate perceptual text conditions for
the diffusion model. (ii) We propose a Perceptual Prior-based Feature
Refinement strategy, which matches noisy features to predefined denoising
trajectories and then performs exact feature denoising based on text
conditions. Extensive experiments on eight standard BIQA datasets demonstrate
the superior performance to the state-of-the-art BIQA methods, i.e., achieving
the PLCC values of 0.935 ( vs. 0.905 in KADID) and 0.922 ( vs. 0.894 in LIVEC).
</p>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11951 title=Abstract>arXiv:2401.11951</a> [<a href=https://arxiv.org/pdf/2401.11951 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11951 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Stabilised Semi-Implicit Double-Point Material Point Method for Soil-Water Coupled Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xie%2C+M">Mian Xie</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Navas%2C+P">Pedro Navas</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lopez-Querol%2C+S">Susana Lopez-Querol</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>A semi-implicit two-phase double-point Material Point Method (MPM)
formulation, based on the incremental fractional-step method to model large
deformation geotechnical problems has been derived. The semi-implicit
formulation has two advantages compared with the explicit approach: the time
step is independent of the water phase, and the pore pressure field is more
stable. The semi-implicit MPM models based on the incremental fractional-step
method available in the literature consist of modelling the soil and water
mixture using a single set of material points only, in order to save
computational time. In this study, we further derive this formulation with two
sets of material points to represent the soil and water phases separately. The
stress oscillations that are frequently found in the water and soil phases are
stabilised with this approach. A new stabilisation method is developed based on
the modified F-bar method. The proposed method is validated with two numerical
examples under small and large deformations, respectively. After that, Nor-Sand
constitutive soil model is used to simulate landslides. Numerical examples show
an excellent performance of the proposed coupled MPM and the stabilisation
method. The formulation with two sets of material points yields significantly
different but more reliable results in the landslides analysis, compared with
the single-point approach. Additionally, this research shows that the
additional computational cost caused by the additional water material points is
acceptable. Therefore, it is recommended to use two sets of material points for
certain large deformation geotechnical problems.
</p>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11954 title=Abstract>arXiv:2401.11954</a> [<a href=https://arxiv.org/pdf/2401.11954 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11954 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RUMBoost: Gradient Boosted Random Utility Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salvad%C3%A9%2C+N">Nicolas Salvadé</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hillel%2C+T">Tim Hillel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>This paper introduces the RUMBoost model, a novel discrete choice modelling
approach that combines the interpretability and behavioural robustness of
Random Utility Models (RUMs) with the generalisation and predictive ability of
deep learning methods. We obtain the full functional form of non-linear utility
specifications by replacing each linear parameter in the utility functions of a
RUM with an ensemble of gradient boosted regression trees. This enables
piece-wise constant utility values to be imputed for all alternatives directly
from the data for any possible combination of input variables. We introduce
additional constraints on the ensembles to ensure three crucial features of the
utility specifications: (i) dependency of the utilities of each alternative on
only the attributes of that alternative, (ii) monotonicity of marginal
utilities, and (iii) an intrinsically interpretable functional form, where the
exact response of the model is known throughout the entire input space.
Furthermore, we introduce an optimisation-based smoothing technique that
replaces the piece-wise constant utility values of alternative attributes with
monotonic piece-wise cubic splines to identify non-linear parameters with
defined gradient. We demonstrate the potential of the RUMBoost model compared
to various ML and Random Utility benchmark models for revealed preference mode
choice data from London. The results highlight the great predictive performance
and the direct interpretability of our proposed approach. Furthermore, the
smoothed attribute utility functions allow for the calculation of various
behavioural indicators and marginal utilities. Finally, we demonstrate the
flexibility of our methodology by showing how the RUMBoost model can be
extended to complex model specifications, including attribute interactions,
correlation within alternative error terms and heterogeneity within the
population.
</p>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11960 title=Abstract>arXiv:2401.11960</a> [<a href=https://arxiv.org/pdf/2401.11960 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11960 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Observation-Guided Meteorological Field Downscaling at Station Scale: A Benchmark and a New Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zili Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Keyan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Downscaling (DS) of meteorological variables involves obtaining
high-resolution states from low-resolution meteorological fields and is an
important task in weather forecasting. Previous methods based on deep learning
treat downscaling as a super-resolution task in computer vision and utilize
high-resolution gridded meteorological fields as supervision to improve
resolution at specific grid scales. However, this approach has struggled to
align with the continuous distribution characteristics of meteorological
fields, leading to an inherent systematic bias between the downscaled results
and the actual observations at meteorological stations. In this paper, we
extend meteorological downscaling to arbitrary scattered station scales,
establish a brand new benchmark and dataset, and retrieve meteorological states
at any given station location from a coarse-resolution meteorological field.
Inspired by data assimilation techniques, we integrate observational data into
the downscaling process, providing multi-scale observational priors. Building
on this foundation, we propose a new downscaling model based on hypernetwork
architecture, namely HyperDS, which efficiently integrates different
observational information into the model training, achieving continuous scale
modeling of the meteorological field. Through extensive experiments, our
proposed method outperforms other specially designed baseline models on
multiple surface variables. Notably, the mean squared error (MSE) for wind
speed and surface pressure improved by 67% and 19.5% compared to other methods.
We will release the dataset and code subsequently.
</p>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11961 title=Abstract>arXiv:2401.11961</a> [<a href=https://arxiv.org/pdf/2401.11961 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11961 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Safety in Nonlinear Systems: Design and Stability Analysis of Adaptive Cruise Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+F">Fan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoqi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+M">Maolong Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiangping Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qingrui Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+B+K">Bijoy K. Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11pages,9figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The safety of autonomous driving systems, particularly self-driving vehicles,
remains of paramount concern. These systems exhibit affine nonlinear dynamics
and face the challenge of executing predefined control tasks while adhering to
state and input constraints to mitigate risks. However, achieving safety
control within the framework of control input constraints, such as collision
avoidance and maintaining system states within secure boundaries, presents
challenges due to limited options. In this study, we introduce a novel approach
to address safety concerns by transforming safety conditions into control
constraints with a relative degree of 1. This transformation is facilitated
through the design of control barrier functions, enabling the creation of a
safety control system for affine nonlinear networks. Subsequently, we formulate
a robust control strategy that incorporates safety protocols and conduct a
comprehensive analysis of its stability and reliability. To illustrate the
effectiveness of our approach, we apply it to a specific problem involving
adaptive cruise control. Through simulations, we validate the efficiency of our
model in ensuring safety without compromising control performance. Our approach
signifies significant progress in the field, providing a practical solution to
enhance safety for autonomous driving systems operating within the context of
affine nonlinear dynamics.
</p>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11963 title=Abstract>arXiv:2401.11963</a> [<a href=https://arxiv.org/pdf/2401.11963 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11963 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Pengyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+J">Jianye Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+H">Hongyao Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+X">Xian Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+K">Ke Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary
Algorithms (EAs) and Reinforcement Learning (RL) for optimization, has
demonstrated remarkable performance advancements. By fusing the strengths of
both approaches, ERL has emerged as a promising research direction. This survey
offers a comprehensive overview of the diverse research branches in ERL.
Specifically, we systematically summarize recent advancements in relevant
algorithms and identify three primary research directions: EA-assisted
optimization of RL, RL-assisted optimization of EA, and synergistic
optimization of EA and RL. Following that, we conduct an in-depth analysis of
each research direction, organizing multiple research branches. We elucidate
the problems that each branch aims to tackle and how the integration of EA and
RL addresses these challenges. In conclusion, we discuss potential challenges
and prospective future research directions across various research directions.
</p>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11968 title=Abstract>arXiv:2401.11968</a> [<a href=https://arxiv.org/pdf/2401.11968 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11968 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Effective Intrusion Detection in Heterogeneous Internet-of-Things Networks via Ensemble Knowledge Distillation-based Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+J">Jiyuan Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenzhuo Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhaowei Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+J">Jiani Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>With the rapid development of low-cost consumer electronics and cloud
computing, Internet-of-Things (IoT) devices are widely adopted for supporting
next-generation distributed systems such as smart cities and industrial control
systems. IoT devices are often susceptible to cyber attacks due to their open
deployment environment and limited computing capabilities for stringent
security controls. Hence, Intrusion Detection Systems (IDS) have emerged as one
of the effective ways of securing IoT networks by monitoring and detecting
abnormal activities. However, existing IDS approaches rely on centralized
servers to generate behaviour profiles and detect anomalies, causing high
response time and large operational costs due to communication overhead.
Besides, sharing of behaviour data in an open and distributed IoT network
environment may violate on-device privacy requirements. Additionally, various
IoT devices tend to capture heterogeneous data, which complicates the training
of behaviour models. In this paper, we introduce Federated Learning (FL) to
collaboratively train a decentralized shared model of IDS, without exposing
training data to others. Furthermore, we propose an effective method called
Federated Learning Ensemble Knowledge Distillation (FLEKD) to mitigate the
heterogeneity problems across various clients. FLEKD enables a more flexible
aggregation method than conventional model fusion techniques. Experiment
results on the public dataset CICIDS2019 demonstrate that the proposed approach
outperforms local training and traditional FL in terms of both speed and
performance and significantly improves the system's ability to detect unknown
attacks. Finally, we evaluate our proposed framework's performance in three
potential real-world scenarios and show FLEKD has a clear advantage in
experimental results.
</p>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11969 title=Abstract>arXiv:2401.11969</a> [<a href=https://arxiv.org/pdf/2401.11969 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11969 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Claim Detection for Automated Fact-checking: A Survey on Monolingual, Multilingual and Cross-Lingual Research
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panchendrarajan%2C+R">Rrubaa Panchendrarajan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zubiaga%2C+A">Arkaitz Zubiaga</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Automated fact-checking has drawn considerable attention over the past few
decades due to the increase in the diffusion of misinformation on online
platforms. This is often carried out as a sequence of tasks comprising (i) the
detection of sentences circulating in online platforms which constitute claims
needing verification, followed by (ii) the verification process of those
claims. This survey focuses on the former, by discussing existing efforts
towards detecting claims needing fact-checking, with a particular focus on
multilingual data and methods. This is a challenging and fertile direction
where existing methods are yet far from matching human performance due to the
profoundly challenging nature of the issue. Especially, the dissemination of
information across multiple social platforms, articulated in multiple languages
and modalities demands more generalized solutions for combating misinformation.
Focusing on multilingual misinformation, we present a comprehensive survey of
existing multilingual claim detection research. We present state-of-the-art
multilingual claim detection research categorized into three key factors of the
problem, verifiability, priority, and similarity. Further, we present a
detailed overview of the existing multilingual datasets along with the
challenges and suggest possible future advancements.
</p>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11972 title=Abstract>arXiv:2401.11972</a> [<a href=https://arxiv.org/pdf/2401.11972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Synergizing Machine Learning &amp; Symbolic Methods: A Survey on Hybrid Approaches to Natural Language Processing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panchendrarajan%2C+R">Rrubaa Panchendrarajan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zubiaga%2C+A">Arkaitz Zubiaga</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The advancement of machine learning and symbolic approaches have underscored
their strengths and weaknesses in Natural Language Processing (NLP). While
machine learning approaches are powerful in identifying patterns in data, they
often fall short in learning commonsense and the factual knowledge required for
the NLP tasks. Meanwhile, the symbolic methods excel in representing
knowledge-rich data. However, they struggle to adapt dynamic data and
generalize the knowledge. Bridging these two paradigms through hybrid
approaches enables the alleviation of weaknesses in both while preserving their
strengths. Recent studies extol the virtues of this union, showcasing promising
results in a wide range of NLP tasks. In this paper, we present an overview of
hybrid approaches used for NLP. Specifically, we delve into the
state-of-the-art hybrid approaches used for a broad spectrum of NLP tasks
requiring natural language understanding, generation, and reasoning.
Furthermore, we discuss the existing resources available for hybrid approaches
for NLP along with the challenges, offering a roadmap for future directions.
</p>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11974 title=Abstract>arXiv:2401.11974</a> [<a href=https://arxiv.org/pdf/2401.11974 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11974 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-Validation Conformal Risk Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+K+M">Kfir M. Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Sangwoo Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shamai%2C+S">Shlomo Shamai</a> (Shitz)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Conformal risk control (CRC) is a recently proposed technique that applies
post-hoc to a conventional point predictor to provide calibration guarantees.
Generalizing conformal prediction (CP), with CRC, calibration is ensured for a
set predictor that is extracted from the point predictor to control a risk
function such as the probability of miscoverage or the false negative rate. The
original CRC requires the available data set to be split between training and
validation data sets. This can be problematic when data availability is
limited, resulting in inefficient set predictors. In this paper, a novel CRC
method is introduced that is based on cross-validation, rather than on
validation as the original CRC. The proposed cross-validation CRC (CV-CRC)
extends a version of the jackknife-minmax from CP to CRC, allowing for the
control of a broader range of risk functions. CV-CRC is proved to offer
theoretical guarantees on the average risk of the set predictor. Furthermore,
numerical experiments show that CV-CRC can reduce the average set size with
respect to CRC when the available data are limited.
</p>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11977 title=Abstract>arXiv:2401.11977</a> [<a href=https://arxiv.org/pdf/2401.11977 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11977 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Motion Planning for Multi-fingered Functional Grasp via Force Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+D">Dongying Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xiangbo Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yi Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages,7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Enabling multi-fingered robots to grasp and manipulate objects with
human-like dexterity is especially challenging during the dynamic, continuous
hand-object interactions. Closed-loop feedback control is essential for
dexterous hands to dynamically finetune hand poses when performing precise
functional grasps. This work proposes an adaptive motion planning method based
on deep reinforcement learning to adjust grasping poses according to real-time
feedback from joint torques from pre-grasp to goal grasp. We find the
multi-joint torques of the dexterous hand can sense object positions through
contacts and collisions, enabling real-time adjustment of grasps to generate
varying grasping trajectories for objects in different positions. In our
experiments, the performance gap with and without force feedback reveals the
important role of force feedback in adaptive manipulation. Our approach
utilizing force feedback preliminarily exhibits human-like flexibility,
adaptability, and precision.
</p>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11981 title=Abstract>arXiv:2401.11981</a> [<a href=https://arxiv.org/pdf/2401.11981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11981 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Analytics in Higher Education -- Exploring Students and Teachers Expectations in Germany
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fritz%2C+B">Birthe Fritz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kube%2C+D">Dana Kube</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scherer%2C+S">Sonja Scherer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Drachsler%2C+H">Hendrik Drachsler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Technology enhanced learning analytics has the potential to play a
significant role in higher education in the future. Opinions and expectations
towards technology and learning analytics, thus, are vital to consider for
institutional developments in higher education institutions. The Sheila
framework offers instruments to yield exploratory knowledge about stakeholder
aspirations towards technology, such as learning analytics in higher education.
The sample of the study consists of students (N = 1169) and teachers (N = 497)
at a higher education institution in Germany. Using self-report questionnaires,
we assessed students and teachers attitudes towards learning analytics in
higher education teaching, comparing ideal and expected circumstances. We
report results on the attitudes of students, teachers, as well as comparisons
of the two groups and different disciplines. We discuss the results with regard
to practical implications for the implementation and further developments of
learning analytics in higher education.
</p>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11983 title=Abstract>arXiv:2401.11983</a> [<a href=https://arxiv.org/pdf/2401.11983 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11983 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lightweight Protection for Privacy in Offloaded Speech Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+D">Dongqi Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shangguang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zeling Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+F+X">Felix Xiaozhu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengwei Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Speech is a common input method for mobile embedded devices, but cloud-based
speech recognition systems pose privacy risks. Disentanglement-based encoders,
designed to safeguard user privacy by filtering sensitive information from
speech signals, unfortunately require substantial memory and computational
resources, which limits their use in less powerful devices. To overcome this,
we introduce a novel system, XXX, optimized for such devices. XXX is built on
the insight that speech understanding primarily relies on understanding the
entire utterance's long-term dependencies, while privacy concerns are often
linked to short-term details. Therefore, XXX focuses on selectively masking
these short-term elements, preserving the quality of long-term speech
understanding. The core of XXX is an innovative differential mask generator,
grounded in interpretable learning, which fine-tunes the masking process. We
tested XXX on the STM32H7 microcontroller, assessing its performance in various
potential attack scenarios. The results show that XXX maintains speech
understanding accuracy and privacy at levels comparable to existing encoders,
but with a significant improvement in efficiency, achieving up to 53.3<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-145-Frame tabindex=0><nobr><span class=math id=MathJax-Span-848 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-849><span class=mo id=MathJax-Span-850 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
faster processing and a 134.1<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-146-Frame tabindex=0><nobr><span class=math id=MathJax-Span-851 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-852><span class=mo id=MathJax-Span-853 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> smaller memory footprint.
</p>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11985 title=Abstract>arXiv:2401.11985</a> [<a href=https://arxiv.org/pdf/2401.11985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling Face Interaction Graph Networks to Real World Scenes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lopez-Guevara%2C+T">Tatiana Lopez-Guevara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rubanova%2C+Y">Yulia Rubanova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Whitney%2C+W+F">William F. Whitney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfaff%2C+T">Tobias Pfaff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stachenfeld%2C+K">Kimberly Stachenfeld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allen%2C+K+R">Kelsey R. Allen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
</div>
<p class=mathjax>Accurately simulating real world object dynamics is essential for various
applications such as robotics, engineering, graphics, and design. To better
capture complex real dynamics such as contact and friction, learned simulators
based on graph networks have recently shown great promise. However, applying
these learned simulators to real scenes comes with two major challenges: first,
scaling learned simulators to handle the complexity of real world scenes which
can involve hundreds of objects each with complicated 3D shapes, and second,
handling inputs from perception rather than 3D state information. Here we
introduce a method which substantially reduces the memory required to run
graph-based learned simulators. Based on this memory-efficient simulation
model, we then present a perceptual interface in the form of editable NeRFs
which can convert real-world scenes into a structured representation that can
be processed by graph network simulator. We show that our method uses
substantially less memory than previous graph-based simulators while retaining
their accuracy, and that the simulators learned in synthetic environments can
be applied to real world scenes captured from multiple camera angles. This
paves the way for expanding the application of learned simulators to settings
where only perceptual information is available at inference time.
</p>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11991 title=Abstract>arXiv:2401.11991</a> [<a href=https://arxiv.org/pdf/2401.11991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tight Bounds on the Message Complexity of Distributed Tree Verification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutten%2C+S">Shay Kutten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+P">Peter Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+M+M">Ming Ming Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Appeared at OPODIS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)
</div>
<p class=mathjax>We consider the message complexity of verifying whether a given subgraph of
the communication network forms a tree with specific properties both in the
KT-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-147-Frame tabindex=0><nobr><span class=math id=MathJax-Span-854 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-855><span class=mi id=MathJax-Span-856 style=font-family:MathJax_Math-italic>ρ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> (nodes know their <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-148-Frame tabindex=0><nobr><span class=math id=MathJax-Span-857 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-858><span class=mi id=MathJax-Span-859 style=font-family:MathJax_Math-italic>ρ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-hop neighborhood, including node IDs) and
the KT-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-149-Frame tabindex=0><nobr><span class=math id=MathJax-Span-860 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-861><span class=mn id=MathJax-Span-862 style=font-family:MathJax_Main>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> (nodes do not have this knowledge) models. We develop a rather
general framework that helps in establishing tight lower bounds for various
tree verification problems. We also consider two different verification
requirements: namely that every node detects in the case the input is
incorrect, as well as the requirement that at least one node detects. The
results are stronger than previous ones in the sense that we assume that each
node knows the number <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-150-Frame tabindex=0><nobr><span class=math id=MathJax-Span-863 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-864><span class=mi id=MathJax-Span-865 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> of nodes in the graph (in some cases) or an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-151-Frame tabindex=0><nobr><span class=math id=MathJax-Span-866 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-867><span class=mi id=MathJax-Span-868 style=font-family:MathJax_Math-italic>α</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
approximation of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-152-Frame tabindex=0><nobr><span class=math id=MathJax-Span-869 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-870><span class=mi id=MathJax-Span-871 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> (in other cases). For spanning tree verification, we show
that the message complexity inherently depends on the quality of the given
approximation of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-153-Frame tabindex=0><nobr><span class=math id=MathJax-Span-872 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-873><span class=mi id=MathJax-Span-874 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>: We show a tight lower bound of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-154-Frame tabindex=0><nobr><span class=math id=MathJax-Span-875 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-876><span class=mi id=MathJax-Span-877 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-878 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-879><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-880 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-881 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-882 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> for the case
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-155-Frame tabindex=0><nobr><span class=math id=MathJax-Span-883 style=width:4.054em;display:inline-block><span style=display:inline-block;position:relative;width:3.359em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.36em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-884><span class=mi id=MathJax-Span-885 style=font-family:MathJax_Math-italic>α</span><span class=mo id=MathJax-Span-886 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=msqrt id=MathJax-Span-887 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-888><span class=mn id=MathJax-Span-889 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.511em;left:0.813em><span style=font-family:MathJax_Main>–</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and a much better upper bound (i.e., <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-156-Frame tabindex=0><nobr><span class=math id=MathJax-Span-890 style=width:5.327em;display:inline-block><span style=display:inline-block;position:relative;width:4.401em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.28em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-891><span class=mi id=MathJax-Span-892 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-893 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-894 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-895 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-896></span><span class=mi id=MathJax-Span-897 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-898 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>) when
nodes are given a tighter approximation. On the other hand, our framework also
yields an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-157-Frame tabindex=0><nobr><span class=math id=MathJax-Span-899 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-900><span class=mi id=MathJax-Span-901 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-902 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-903><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-904 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-905 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-906 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> lower bound on the message complexity of verifying a
minimum spanning tree (MST), which reveals a polynomial separation between ST
verification and MST verification. This result holds for randomized algorithms
with perfect knowledge of the network size, and even when just one node detects
illegal inputs, thus improving over the work of Kor, Korman, and Peleg (2013).
For verifying a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-158-Frame tabindex=0><nobr><span class=math id=MathJax-Span-907 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-908><span class=mi id=MathJax-Span-909 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-approximate BFS tree, we show that the same lower bound
holds even if nodes know <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-159-Frame tabindex=0><nobr><span class=math id=MathJax-Span-910 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-911><span class=mi id=MathJax-Span-912 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> exactly, however, the lower bound is sensitive to
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-160-Frame tabindex=0><nobr><span class=math id=MathJax-Span-913 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-914><span class=mi id=MathJax-Span-915 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, which is the stretch parameter.
</p>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11993 title=Abstract>arXiv:2401.11993</a> [<a href=https://arxiv.org/pdf/2401.11993 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11993 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Expert-Driven Monitoring of Operational ML Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leest%2C+J">Joran Leest</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raibulet%2C+C">Claudia Raibulet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerostathopoulos%2C+I">Ilias Gerostathopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lago%2C+P">Patricia Lago</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>We propose Expert Monitoring, an approach that leverages domain expertise to
enhance the detection and mitigation of concept drift in machine learning (ML)
models. Our approach supports practitioners by consolidating domain expertise
related to concept drift-inducing events, making this expertise accessible to
on-call personnel, and enabling automatic adaptability with expert oversight.
</p>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12000 title=Abstract>arXiv:2401.12000</a> [<a href=https://arxiv.org/pdf/2401.12000 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12000 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrating Statistical Significance and Discriminative Power in Pattern Discovery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexandre%2C+L">Leonardo Alexandre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+R+S">Rafael S. Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henriques%2C+R">Rui Henriques</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>Pattern discovery plays a central role in both descriptive and predictive
tasks across multiple domains. Actionable patterns must meet rigorous
statistical significance criteria and, in the presence of target variables,
further uphold discriminative power. Our work addresses the underexplored area
of guiding pattern discovery by integrating statistical significance and
discriminative power criteria into state-of-the-art algorithms while preserving
pattern quality. We also address how pattern quality thresholds, imposed by
some algorithms, can be rectified to accommodate these additional criteria. To
test the proposed methodology, we select the triclustering task as the guiding
pattern discovery case and extend well-known greedy and multi-objective
optimization triclustering algorithms, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-161-Frame tabindex=0><nobr><span class=math id=MathJax-Span-916 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-917><span class=mi id=MathJax-Span-918 style=font-family:MathJax_Math-italic>δ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>-Trimax and TriGen, that use
various pattern quality criteria, such as Mean Squared Residual (MSR), Least
Squared Lines (LSL), and Multi Slope Measure (MSL). Results from three case
studies show the role of the proposed methodology in discovering patterns with
pronounced improvements of discriminative power and statistical significance
without quality deterioration, highlighting its importance in supervisedly
guiding the search. Although the proposed methodology is motivated over
multivariate time series data, it can be straightforwardly extended to pattern
discovery tasks involving multivariate, N-way (N&gt;3), transactional, and
sequential data structures.
<br>Availability: The code is freely available at
https://github.com/JupitersMight/MOF_Triclustering under the MIT license.
</p>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12001 title=Abstract>arXiv:2401.12001</a> [<a href=https://arxiv.org/pdf/2401.12001 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12001 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling Stereo-Confidence Out of the End-to-End Stereo-Matching Network via Disparity Plane Sweep
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J+Y">Jae Young Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ka%2C+W">Woonghyun Ka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024. The first two authors contributed equally
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We propose a novel stereo-confidence that can be measured externally to
various stereo-matching networks, offering an alternative input modality choice
of the cost volume for learning-based approaches, especially in safety-critical
systems. Grounded in the foundational concepts of disparity definition and the
disparity plane sweep, the proposed stereo-confidence method is built upon the
idea that any shift in a stereo-image pair should be updated in a corresponding
amount shift in the disparity map. Based on this idea, the proposed
stereo-confidence method can be summarized in three folds. 1) Using the
disparity plane sweep, multiple disparity maps can be obtained and treated as a
3-D volume (predicted disparity volume), like the cost volume is constructed.
2) One of these disparity maps serves as an anchor, allowing us to define a
desirable (or ideal) disparity profile at every spatial point. 3) By comparing
the desirable and predicted disparity profiles, we can quantify the level of
matching ambiguity between left and right images for confidence measurement.
Extensive experimental results using various stereo-matching networks and
datasets demonstrate that the proposed stereo-confidence method not only shows
competitive performance on its own but also consistent performance improvements
when it is used as an input modality for learning-based stereo-confidence
methods.
</p>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12002 title=Abstract>arXiv:2401.12002</a> [<a href=https://arxiv.org/pdf/2401.12002 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12002 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HgbNet: predicting hemoglobin level/anemia degree from EHR data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhi%2C+Z">Zhuo Zhi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elbadawi%2C+M">Moe Elbadawi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daneshmend%2C+A">Adam Daneshmend</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orlu%2C+M">Mine Orlu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basit%2C+A">Abdul Basit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demosthenous%2C+A">Andreas Demosthenous</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodrigues%2C+M">Miguel Rodrigues</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Anemia is a prevalent medical condition that typically requires invasive
blood tests for diagnosis and monitoring. Electronic health records (EHRs) have
emerged as valuable data sources for numerous medical studies. EHR-based
hemoglobin level/anemia degree prediction is non-invasive and rapid but still
faces some challenges due to the fact that EHR data is typically an irregular
multivariate time series containing a significant number of missing values and
irregular time intervals. To address these issues, we introduce HgbNet, a
machine learning-based prediction model that emulates clinicians'
decision-making processes for hemoglobin level/anemia degree prediction. The
model incorporates a NanDense layer with a missing indicator to handle missing
values and employs attention mechanisms to account for both local irregularity
and global irregularity. We evaluate the proposed method using two real-world
datasets across two use cases. In our first use case, we predict hemoglobin
level/anemia degree at moment T+1 by utilizing records from moments prior to
T+1. In our second use case, we integrate all historical records with
additional selected test results at moment T+1 to predict hemoglobin
level/anemia degree at the same moment, T+1. HgbNet outperforms the best
baseline results across all datasets and use cases. These findings demonstrate
the feasibility of estimating hemoglobin levels and anemia degree from EHR
data, positioning HgbNet as an effective non-invasive anemia diagnosis solution
that could potentially enhance the quality of life for millions of affected
individuals worldwide. To our knowledge, HgbNet is the first machine learning
model leveraging EHR data for hemoglobin level/anemia degree prediction.
</p>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12005 title=Abstract>arXiv:2401.12005</a> [<a href=https://arxiv.org/pdf/2401.12005 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12005 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ALMs: Authorial Language Models for Authorship Attribution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Weihang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murakami%2C+A">Akira Murakami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grieve%2C+J">Jack Grieve</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In this paper, we introduce an authorship attribution method called Authorial
Language Models (ALMs) that involves identifying the most likely author of a
questioned document based on the perplexity of the questioned document
calculated for a set of causal language models fine-tuned on the writings of a
set of candidate author. We benchmarked ALMs against state-of-art-systems using
the CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a
macro-average accuracy score of 83.6% on Blogs50, outperforming all other
methods, and 74.9% on CCAT50, matching the performance of the best method. To
assess the performance of ALMs on shorter texts, we also conducted text
ablation testing. We found that to reach a macro-average accuracy of 70%, ALMs
needs 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs
requires 20 tokens on Blogs50 and 70 tokens on CCAT50.
</p>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12007 title=Abstract>arXiv:2401.12007</a> [<a href=https://arxiv.org/pdf/2401.12007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor-view Topological Graph Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+T">Tao Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+E">Elynn Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuzhou Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Graph classification is an important learning task for graph-structured data.
Graph neural networks (GNNs) have recently gained growing attention in graph
learning and have shown significant improvements in many important graph
problems. Despite their state-of-the-art performances, existing GNNs only use
local information from a very limited neighborhood around each node, suffering
from loss of multi-modal information and overheads of excessive computation. To
address these issues, we propose a novel Tensor-view Topological Graph Neural
Network (TTG-NN), a class of simple yet effective topological deep learning
built upon persistent homology, graph convolution, and tensor operations. This
new method incorporates tensor learning to simultaneously capture Tensor-view
Topological (TT), as well as Tensor-view Graph (TG) structural information on
both local and global levels. Computationally, to fully exploit graph topology
and structure, we propose two flexible TT and TG representation learning
modules that disentangle feature tensor aggregation and transformation and
learn to preserve multi-modal structure with less computation. Theoretically,
we derive high probability bounds on both the out-of-sample and in-sample mean
squared approximation errors for our proposed Tensor Transformation Layer
(TTL). Real data experiments show that the proposed TTG-NN outperforms 20
state-of-the-art methods on various graph benchmarks.
</p>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12010 title=Abstract>arXiv:2401.12010</a> [<a href=https://arxiv.org/pdf/2401.12010 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12010 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On a class of interdiction problems with partition matroids: complexity and polynomial-time algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ketkov%2C+S+S">Sergey S. Ketkov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prokopyev%2C+O+A">Oleg A. Prokopyev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>In this study, we consider a class of linear matroid interdiction problems,
where the feasible sets for the upper-level decision-maker (referred to as the
leader) and the lower-level decision-maker (referred to as the follower) are
given by partition matroids with a common ground set. In contrast to classical
network interdiction models where the leader is subject to a single budget
constraint, in our setting, both the leader and the follower are subject to
several independent cardinality constraints and engage in a zero-sum game.
While a single-level linear integer programming problem over a partition
matroid is known to be polynomially solvable, we prove that the considered
bilevel problem is NP-hard, even when the objective function coefficients are
all binary. On a positive note, it turns out that, if the number of cardinality
constraints is fixed for either the leader or the follower, then the considered
class of bilevel problems admits several polynomial-time solution schemes.
Specifically, these schemes are based on a single-level dual reformulation, a
dynamic programming-based approach, and a 2-flip local search algorithm for the
leader.
</p>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12011 title=Abstract>arXiv:2401.12011</a> [<a href=https://arxiv.org/pdf/2401.12011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Architecting Data-Intensive Applications : From Data Architecture Design to Its Quality Assurance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abughazala%2C+M">Moamin Abughazala</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> PhD thesis
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Context - The exponential growth of data is becoming a significant concern.
Managing this data has become incredibly challenging, especially when dealing
with various sources in different formats and speeds. Moreover, Ensuring data
quality has become increasingly crucial for effective decision-making and
operational processes. Data Architecture is crucial in describing, collecting,
storing, processing, and analyzing data to meet business needs. Providing an
abstract view of data-intensive applications is essential to ensure that the
data is transformed into valuable information. We must take these challenges
seriously to ensure we can effectively manage and use the data to our
advantage. Objective - To establish an architecture framework that enables a
comprehensive description of the data architecture and effectively streamlines
data quality monitoring. Method - The architecture framework utilizes Model
Driven Engineering (MDE) techniques. Its backing of data-intensive architecture
descriptions empowers with an automated generation for data quality checks.
Result - The Framework offers a comprehensive solution for data-intensive
applications to model their architecture efficiently and monitor the quality of
their data. It automates the entire process and ensures precision and
consistency in data. With DAT, architects and analysts gain access to a
powerful tool that simplifies their workflow and empowers them to make informed
decisions based on reliable data insights. Conclusion - We have evaluated the
DAT on more than five cases within various industry domains, demonstrating its
exceptional adaptability and effectiveness.
</p>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12012 title=Abstract>arXiv:2401.12012</a> [<a href=https://arxiv.org/pdf/2401.12012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mengdi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodonhelyi%2C+A">Anna Bodonhelyi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bozkir%2C+E">Efe Bozkir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Federated learning is a distributed collaborative machine learning paradigm
that has gained strong momentum in recent years. In federated learning, a
central server periodically coordinates models with clients and aggregates the
models trained locally by clients without necessitating access to local data.
Despite its potential, the implementation of federated learning continues to
encounter several challenges, predominantly the slow convergence that is
largely due to data heterogeneity. The slow convergence becomes particularly
problematic in cross-device federated learning scenarios where clients may be
strongly limited by computing power and storage space, and hence counteracting
methods that induce additional computation or memory cost on the client side
such as auxiliary objective terms and larger training iterations can be
impractical. In this paper, we propose a novel federated aggregation strategy,
TurboSVM-FL, that poses no additional computation burden on the client side and
can significantly accelerate convergence for federated classification task,
especially when clients are "lazy" and train their models solely for few epochs
for next global aggregation. TurboSVM-FL extensively utilizes support vector
machine to conduct selective aggregation and max-margin spread-out
regularization on class embeddings. We evaluate TurboSVM-FL on multiple
datasets including FEMNIST, CelebA, and Shakespeare using user-independent
validation with non-iid data distribution. Our results show that TurboSVM-FL
can significantly outperform existing popular algorithms on convergence rate
and reduce communication rounds while delivering better test metrics including
accuracy, F1 score, and MCC.
</p>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12014 title=Abstract>arXiv:2401.12014</a> [<a href=https://arxiv.org/pdf/2401.12014 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12014 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robustness to distribution shifts of compressed networks for edge devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+L">Lulan Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edalati%2C+A">Ali Edalati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meyer%2C+B">Brett Meyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gross%2C+W">Warren Gross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clark%2C+J+J">James J. Clark</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>It is necessary to develop efficient DNNs deployed on edge devices with
limited computation resources. However, the compressed networks often execute
new tasks in the target domain, which is different from the source domain where
the original network is trained. It is important to investigate the robustness
of compressed networks in two types of data distribution shifts: domain shifts
and adversarial perturbations. In this study, we discover that compressed
models are less robust to distribution shifts than their original networks.
Interestingly, larger networks are more vulnerable to losing robustness than
smaller ones, even when they are compressed to a similar size as the smaller
networks. Furthermore, compact networks obtained by knowledge distillation are
much more robust to distribution shifts than pruned networks. Finally,
post-training quantization is a reliable method for achieving significant
robustness to distribution shifts, and it outperforms both pruned and distilled
models in terms of robustness.
</p>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12018 title=Abstract>arXiv:2401.12018</a> [<a href=https://arxiv.org/pdf/2401.12018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PairwiseHist: Fast, Accurate and Space-Efficient Approximate Query Processing with Data Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hurst%2C+A">Aaron Hurst</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lucani%2C+D+E">Daniel E. Lucani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>Exponential growth in data collection is creating significant challenges for
data storage and analytics latency.Approximate Query Processing (AQP) has long
been touted as a solution for accelerating analytics on large datasets,
however, there is still room for improvement across all key performance
criteria. In this paper, we propose a novel histogram-based data synopsis
called PairwiseHist that uses recursive hypothesis testing to ensure accurate
histograms and can be built on top of data compressed using Generalized
Deduplication (GD). We thus show that GD data compression can contribute to
AQP. Compared to state-of-the-art AQP approaches, PairwiseHist achieves better
performance across all key metrics, including 2.6<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-162-Frame tabindex=0><nobr><span class=math id=MathJax-Span-919 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-920><span class=mo id=MathJax-Span-921 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> higher accuracy,
3.5<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-163-Frame tabindex=0><nobr><span class=math id=MathJax-Span-922 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-923><span class=mo id=MathJax-Span-924 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> lower latency, 24<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-164-Frame tabindex=0><nobr><span class=math id=MathJax-Span-925 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-926><span class=mo id=MathJax-Span-927 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> smaller synopses and 1.5--4<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-165-Frame tabindex=0><nobr><span class=math id=MathJax-Span-928 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-929><span class=mo id=MathJax-Span-930 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
faster construction time.
</p>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12019 title=Abstract>arXiv:2401.12019</a> [<a href=https://arxiv.org/pdf/2401.12019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered by Multiple Disparity Consistency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ka%2C+W">Woonghyun Ka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J+Y">Jae Young Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICASSP 2024. The first two authors are equally contributed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In stereo-matching knowledge distillation methods of the self-supervised
monocular depth estimation, the stereo-matching network's knowledge is
distilled into a monocular depth network through pseudo-depth maps. In these
methods, the learning-based stereo-confidence network is generally utilized to
identify errors in the pseudo-depth maps to prevent transferring the errors.
However, the learning-based stereo-confidence networks should be trained with
ground truth (GT), which is not feasible in a self-supervised setting. In this
paper, we propose a method to identify and filter errors in the pseudo-depth
map using multiple disparity maps by checking their consistency without the
need for GT and a training process. Experimental results show that the proposed
method outperforms the previous methods and works well on various
configurations by filtering out erroneous areas where the stereo-matching is
vulnerable, especially such as textureless regions, occlusion boundaries, and
reflective surfaces.
</p>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12023 title=Abstract>arXiv:2401.12023</a> [<a href=https://arxiv.org/pdf/2401.12023 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12023 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12023 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Simulation of Optimal Dryness When Moving in the Rain or Snow Using MATLAB
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+N">Neil Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brockner%2C+E">Emilee Brockner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Winslow%2C+A">Asia Winslow</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seraydarian%2C+M">Megan Seraydarian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Mathematical Software (cs.MS)
</div>
<p class=mathjax>The classic question of whether one should walk or run in the rain to remain
the least wet has inspired a myriad of solutions ranging from physically
performing test runs in raining conditions to mathematically modeling human
movement through rain. This manuscript approaches the classical problem by
simulating movement through rainfall using MATLAB. Our simulation was
generalizable to include snowfall as well. An increase in walking speed
resulted in a corresponding decrease in raindrop and snowflake collisions. When
raindrops or snowflakes were given a horizontal movement vector due to wind, a
local minimum in collisions was achieved when moving in parallel with the same
horizontal speed as the raindrop; no local minimum was detected with
antiparallel movement. In general, our simulation revealed that the faster one
moves, the drier one remains.
</p>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12024 title=Abstract>arXiv:2401.12024</a> [<a href=https://arxiv.org/pdf/2401.12024 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12024 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dave%2C+V">Vedant Dave</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lygerakis%2C+F">Fotios Lygerakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rueckert%2C+E">Elmar Rueckert</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The rapidly evolving field of robotics necessitates methods that can
facilitate the fusion of multiple modalities. Specifically, when it comes to
interacting with tangible objects, effectively combining visual and tactile
sensory data is key to understanding and navigating the complex dynamics of the
physical world, enabling a more nuanced and adaptable response to changing
environments. Nevertheless, much of the earlier work in merging these two
sensory modalities has relied on supervised methods utilizing datasets labeled
by humans.This paper introduces MViTac, a novel methodology that leverages
contrastive learning to integrate vision and touch sensations in a
self-supervised fashion. By availing both sensory inputs, MViTac leverages
intra and inter-modality losses for learning representations, resulting in
enhanced material property classification and more adept grasping prediction.
Through a series of experiments, we showcase the effectiveness of our method
and its superiority over existing state-of-the-art self-supervised and
supervised techniques. In evaluating our methodology, we focus on two distinct
tasks: material classification and grasping success prediction. Our results
indicate that MViTac facilitates the development of improved modality encoders,
yielding more robust representations as evidenced by linear probing
assessments.
</p>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12025 title=Abstract>arXiv:2401.12025</a> [<a href=https://arxiv.org/pdf/2401.12025 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12025 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey of Advances in Optimization Methods for Wireless Communication System Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Ya-Feng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+T">Tsung-Hui Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+M">Mingyi Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zheyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=So%2C+A+M">Anthony Man-Cho So</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, 10 figures, submitted for possible publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)
</div>
<p class=mathjax>Mathematical optimization is now widely regarded as an indispensable modeling
and solution tool for the design of wireless communications systems. While
optimization has played a significant role in the revolutionary progress in
wireless communication and networking technologies from 1G to 5G and onto the
future 6G, the innovations in wireless technologies have also substantially
transformed the nature of the underlying mathematical optimization problems
upon which the system designs are based and have sparked significant
innovations in the development of methodologies to understand, to analyze, and
to solve those problems. In this paper, we provide a comprehensive survey of
recent advances in mathematical optimization theory and algorithms for wireless
communication system design. We begin by illustrating common features of
mathematical optimization problems arising in wireless communication system
design. We discuss various scenarios and use cases and their associated
mathematical structures from an optimization perspective. We then provide an
overview of recent advances in mathematical optimization theory and algorithms,
from nonconvex optimization, global optimization, and integer programming, to
distributed optimization and learning-based optimization. The key to successful
solution of mathematical optimization problems is in carefully choosing and/or
developing suitable optimization algorithms (or neural network architectures)
that can exploit the underlying problem structure. We conclude the paper by
identifying several open research challenges and outlining future research
directions.
</p>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12029 title=Abstract>arXiv:2401.12029</a> [<a href=https://arxiv.org/pdf/2401.12029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Near-Field Localization with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-166-Frame tabindex=0><nobr><span class=math id=MathJax-Span-931 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1000.42em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-932><span class=mn id=MathJax-Span-933 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span>-bit Quantized Hybrid A/D Reception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavras%2C+I">Ioannis Gavras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atzeni%2C+I">Italo Atzeni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, IEEE ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>In this paper, we consider a hybrid Analog and Digital (A/D) receiver
architecture with an extremely large Dynamic Metasurface Antenna (DMA) and an
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-167-Frame tabindex=0><nobr><span class=math id=MathJax-Span-934 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-935><span class=mn id=MathJax-Span-936 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-bit resolution Analog-to-Digital Converter (ADC) at each of its reception
radio-frequency chains, and present a localization approach for User Equipment
(UE) lying in its near-field regime. The proposed algorithm scans the UE area
of interest to identify the DMA-based analog combining configuration resulting
to the peak in a received pseudo-spectrum, yielding the UE position estimation
in three dimensions. Our simulation results demonstrate the validity of the
proposed scheme, especially for increasing DMA sizes, and showcase the
interplay among various system parameters.
</p>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12032 title=Abstract>arXiv:2401.12032</a> [<a href=https://arxiv.org/pdf/2401.12032 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12032 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MINT: A wrapper to make multi-modal and multi-image AI models interactive
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freyberg%2C+J">Jan Freyberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+A+G">Abhijit Guha Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spitz%2C+T">Terry Spitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freeman%2C+B">Beverly Freeman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaekermann%2C+M">Mike Schaekermann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strachan%2C+P">Patricia Strachan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schnider%2C+E">Eva Schnider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+R">Renee Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Webster%2C+D+R">Dale R Webster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Telang%2C+U">Umesh Telang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>During the diagnostic process, doctors incorporate multimodal information
including imaging and the medical history - and similarly medical AI
development has increasingly become multimodal. In this paper we tackle a more
subtle challenge: doctors take a targeted medical history to obtain only the
most pertinent pieces of information; how do we enable AI to do the same? We
develop a wrapper method named MINT (Make your model INTeractive) that
automatically determines what pieces of information are most valuable at each
step, and ask for only the most useful information. We demonstrate the efficacy
of MINT wrapping a skin disease prediction model, where multiple images and a
set of optional answers to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-168-Frame tabindex=0><nobr><span class=math id=MathJax-Span-937 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-938><span class=mn id=MathJax-Span-939 style=font-family:MathJax_Main>25</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> standard metadata questions (i.e., structured
medical history) are used by a multi-modal deep network to provide a
differential diagnosis. We show that MINT can identify whether metadata inputs
are needed and if so, which question to ask next. We also demonstrate that when
collecting multiple images, MINT can identify if an additional image would be
beneficial, and if so, which type of image to capture. We showed that MINT
reduces the number of metadata and image inputs needed by 82% and 36.2%
respectively, while maintaining predictive performance. Using real-world AI
dermatology system data, we show that needing fewer inputs can retain users
that may otherwise fail to complete the system submission and drop off without
a diagnosis. Qualitative examples show MINT can closely mimic the step-by-step
decision making process of a clinical workflow and how this is different for
straight forward cases versus more difficult, ambiguous cases. Finally we
demonstrate how MINT is robust to different underlying multi-model classifiers
and can be easily adapted to user requirements without significant model
re-training.
</p>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12033 title=Abstract>arXiv:2401.12033</a> [<a href=https://arxiv.org/pdf/2401.12033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Momentum-SAM: Sharpness Aware Minimization without Computational Overhead
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Becker%2C+M">Marlon Becker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altrock%2C+F">Frederick Altrock</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Risse%2C+B">Benjamin Risse</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The recently proposed optimization algorithm for deep neural networks
Sharpness Aware Minimization (SAM) suggests perturbing parameters before
gradient calculation by a gradient ascent step to guide the optimization into
parameter space regions of flat loss. While significant generalization
improvements and thus reduction of overfitting could be demonstrated, the
computational costs are doubled due to the additionally needed gradient
calculation, making SAM unfeasible in case of limited computationally
capacities. Motivated by Nesterov Accelerated Gradient (NAG) we propose
Momentum-SAM (MSAM), which perturbs parameters in the direction of the
accumulated momentum vector to achieve low sharpness without significant
computational overhead or memory demands over SGD or Adam. We evaluate MSAM in
detail and reveal insights on separable mechanisms of NAG, SAM and MSAM
regarding training optimization and generalization. Code is available at
https://github.com/MarlonBecker/MSAM.
</p>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12036 title=Abstract>arXiv:2401.12036</a> [<a href=https://arxiv.org/pdf/2401.12036 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12036 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Near-Field Target Tracking and Communications with Full Duplex Holographic MIMO
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavras%2C+I">Ioannis Gavras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, IEEE ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>In this paper, we present a simultaneous target tracking and multi-user
communications system realized by a full duplex holographic Multiple-Input
Multiple-Output (MIMO) node equipped with Dynamic Metasurface Antennas (DMAs)
at both its communication ends. Focusing on the near-field regime, we extend
Fresnel's approximation to metasurfaces and devise a subspace tracking scheme
with DMA-based hybrid Analog and Digital (A/D) reception as well as hybrid A/D
transmission with a DMA for sum-rate maximization. The presented simulation
results corroborate the efficiency of the proposed framework for various system
parameters.
</p>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12039 title=Abstract>arXiv:2401.12039</a> [<a href=https://arxiv.org/pdf/2401.12039 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12039 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Korbar%2C+B">Bruno Korbar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huh%2C+J">Jaesung Huh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>The goal of this paper is automatic character-aware subtitle generation.
Given a video and a minimal amount of metadata, we propose an audio-visual
method that generates a full transcript of the dialogue, with precise speech
timestamps, and the character speaking identified. The key idea is to first use
audio-visual cues to select a set of high-precision audio exemplars for each
character, and then use these exemplars to classify all speech segments by
speaker identity. Notably, the method does not require face detection or
tracking. We evaluate the method over a variety of TV sitcoms, including
Seinfeld, Fraiser and Scrubs. We envision this system being useful for the
automatic generation of subtitles to improve the accessibility of the vast
amount of videos available on modern streaming services. Project page :
\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}
</p>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12043 title=Abstract>arXiv:2401.12043</a> [<a href=https://arxiv.org/pdf/2401.12043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12043 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy-Conserving Hermite Methods for Maxwell's Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Appelo%2C+D">Daniel Appelo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hagstrom%2C+T">Thomas Hagstrom</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Law-Kam-Cio%2C+Y">Yann-Meing Law-Kam-Cio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Energy-conserving Hermite methods for solving Maxwell's equations in
dielectric and dispersive media are described and analyzed. In three space
dimensions methods of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-169-Frame tabindex=0><nobr><span class=math id=MathJax-Span-940 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.39em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-941><span class=mn id=MathJax-Span-942 style=font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-943 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-170-Frame tabindex=0><nobr><span class=math id=MathJax-Span-944 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-945><span class=mn id=MathJax-Span-946 style=font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-947 style=font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-948 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-949 style=font-family:MathJax_Main;padding-left:0.234em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> require <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-171-Frame tabindex=0><nobr><span class=math id=MathJax-Span-950 style=width:4.633em;display:inline-block><span style=display:inline-block;position:relative;width:3.822em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.82em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-951><span class=mo id=MathJax-Span-952 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-953 style=font-family:MathJax_Math-italic>m</span><span class=mo id=MathJax-Span-954 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-955 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=msubsup id=MathJax-Span-956><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-957 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mn id=MathJax-Span-958 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> degrees-of-freedom
per node for each field variable and can be explicitly marched in time with
steps independent of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-172-Frame tabindex=0><nobr><span class=math id=MathJax-Span-959 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-960><span class=mi id=MathJax-Span-961 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. We prove stability for time steps limited only by
domain-of-dependence requirements along with error estimates in a special
seminorm associated with the interpolation process. Numerical experiments are
presented which demonstrate that Hermite methods of very high order enable the
efficient simulation of electromagnetic wave propagation over thousands of
wavelengths.
</p>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12046 title=Abstract>arXiv:2401.12046</a> [<a href=https://arxiv.org/pdf/2401.12046 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12046 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Haojie Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howell%2C+O">Owen Howell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xupeng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Walters%2C+R">Robin Walters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Platt%2C+R">Robert Platt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Many complex robotic manipulation tasks can be decomposed as a sequence of
pick and place actions. Training a robotic agent to learn this sequence over
many different starting conditions typically requires many iterations or
demonstrations, especially in 3D environments. In this work, we propose Fourier
Transporter (\ours{}) which leverages the two-fold <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-173-Frame tabindex=0><span class=math id=MathJax-Span-962><span class=noError id=MathJax-Span-963>$\SE(d)\times\SE(d)$</span></span></span>
symmetry in the pick-place problem to achieve much higher sample efficiency.
\ours{} is an open-loop behavior cloning method trained using expert
demonstrations to predict pick-place actions on new environments. \ours{} is
constrained to incorporate symmetries of the pick and place actions
independently. Our method utilizes a fiber space Fourier transformation that
allows for memory-efficient construction. We test our proposed network on the
RLbench benchmark and achieve state-of-the-art results across various tasks.
</p>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12048 title=Abstract>arXiv:2401.12048</a> [<a href=https://arxiv.org/pdf/2401.12048 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12048 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HomeRobot Open Vocabulary Mobile Manipulation Challenge 2023 Participant Report (Team KuzHum)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuzma%2C+V">Volodymyr Kuzma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Humennyy%2C+V">Vladyslav Humennyy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Partsey%2C+R">Ruslan Partsey</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>We report an improvements to NeurIPS 2023 HomeRobot: Open Vocabulary Mobile
Manipulation (OVMM) Challenge reinforcement learning baseline. More
specifically, we propose more accurate semantic segmentation module, along with
better place skill policy, and high-level heuristic that outperforms the
baseline by 2.4% of overall success rate (sevenfold improvement) and 8.2% of
partial success rate (1.75 times improvement) on Test Standard split of the
challenge dataset. With aforementioned enhancements incorporated our agent
scored 3rd place in the challenge on both simulation and real-world stages.
</p>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12051 title=Abstract>arXiv:2401.12051</a> [<a href=https://arxiv.org/pdf/2401.12051 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12051 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CloSe: A 3D Clothing Segmentation Dataset and Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anti%C4%87%2C+D">Dimitrije Antić</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiwari%2C+G">Garvita Tiwari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozcomlekci%2C+B">Batuhan Ozcomlekci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marin%2C+R">Riccardo Marin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>3D Clothing modeling and datasets play crucial role in the entertainment,
animation, and digital fashion industries. Existing work often lacks detailed
semantic understanding or uses synthetic datasets, lacking realism and
personalization. To address this, we first introduce CloSe-D: a novel
large-scale dataset containing 3D clothing segmentation of 3167 scans, covering
a range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,
the first learning-based 3D clothing segmentation model for fine-grained
segmentation from colored point clouds. CloSe-Net uses local point features,
body-clothing correlation, and a garment-class and point features-based
attention module, improving performance over baselines and prior work. The
proposed attention module enables our model to learn appearance and
geometry-dependent clothing prior from data. We further validate the efficacy
of our approach by successfully segmenting publicly available datasets of
people in clothing. We also introduce CloSe-T, a 3D interactive tool for
refining segmentation labels. Combining the tool with CloSe-T in a continual
learning setup demonstrates improved generalization on real-world data.
Dataset, model, and tool can be found at
https://virtualhumans.mpi-inf.mpg.de/close3dv24/.
</p>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12055 title=Abstract>arXiv:2401.12055</a> [<a href=https://arxiv.org/pdf/2401.12055 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12055 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NEUROSEC: FPGA-Based Neuromorphic Audio Security
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isik%2C+M">Murat Isik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vishwamith%2C+H">Hiruna Vishwamith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sur%2C+Y">Yusuf Sur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Inadagbo%2C+K">Kayode Inadagbo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dikmen%2C+I+C">I. Can Dikmen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Audio processing, FPGA, Hardware Security, Neuromorphic Computing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Neuromorphic systems, inspired by the complexity and functionality of the
human brain, have gained interest in academic and industrial attention due to
their unparalleled potential across a wide range of applications. While their
capabilities herald innovation, it is imperative to underscore that these
computational paradigms, analogous to their traditional counterparts, are not
impervious to security threats. Although the exploration of neuromorphic
methodologies for image and video processing has been rigorously pursued, the
realm of neuromorphic audio processing remains in its early stages. Our results
highlight the robustness and precision of our FPGA-based neuromorphic system.
Specifically, our system showcases a commendable balance between desired signal
and background noise, efficient spike rate encoding, and unparalleled
resilience against adversarial attacks such as FGSM and PGD. A standout feature
of our framework is its detection rate of 94%, which, when compared to other
methodologies, underscores its greater capability in identifying and mitigating
threats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic
computing and hardware security serve many sensor domains in mission-critical
and privacy-preserving applications.
</p>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12058 title=Abstract>arXiv:2401.12058</a> [<a href=https://arxiv.org/pdf/2401.12058 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12058 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12058 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schliserman%2C+M">Matan Schliserman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sherman%2C+U">Uri Sherman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koren%2C+T">Tomer Koren</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
<p class=mathjax>We study the generalization performance of gradient methods in the
fundamental stochastic convex optimization setting, focusing on its dimension
dependence. First, for full-batch gradient descent (GD) we give a construction
of a learning problem in dimension <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-174-Frame tabindex=0><nobr><span class=math id=MathJax-Span-964 style=width:5.385em;display:inline-block><span style=display:inline-block;position:relative;width:4.459em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1004.34em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-965><span class=mi id=MathJax-Span-966 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-967 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-968 style=font-family:MathJax_Math-italic;padding-left:0.292em>O</span><span class=mo id=MathJax-Span-969 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-970><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-971 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-972 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-973 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, where the canonical version of
GD (tuned for optimal performance of the empirical risk) trained with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-175-Frame tabindex=0><nobr><span class=math id=MathJax-Span-974 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-975><span class=mi id=MathJax-Span-976 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
training examples converges, with constant probability, to an approximate
empirical risk minimizer with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-176-Frame tabindex=0><nobr><span class=math id=MathJax-Span-977 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-978><span class=mi id=MathJax-Span-979 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-980 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-981 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-982 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> population excess risk. Our bound
translates to a lower bound of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-177-Frame tabindex=0><nobr><span class=math id=MathJax-Span-983 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-984><span class=mi id=MathJax-Span-985 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-986 style=font-family:MathJax_Main>(</span><span class=msqrt id=MathJax-Span-987><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-988><span class=mi id=MathJax-Span-989 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.569em;left:0.813em><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.171em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-990 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> on the number of training
examples required for standard GD to reach a non-trivial test error, answering
an open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b)
and showing that a non-trivial dimension dependence is unavoidable.
Furthermore, for standard one-pass stochastic gradient descent (SGD), we show
that an application of the same construction technique provides a similar
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-178-Frame tabindex=0><nobr><span class=math id=MathJax-Span-991 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-992><span class=mi id=MathJax-Span-993 style=font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-994 style=font-family:MathJax_Main>(</span><span class=msqrt id=MathJax-Span-995><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-996><span class=mi id=MathJax-Span-997 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.569em;left:0.813em><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.171em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-998 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> lower bound for the sample complexity of SGD to reach a
non-trivial empirical error, despite achieving optimal test performance. This
again provides an exponential improvement in the dimension dependence compared
to previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an open
question left therein.
</p>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12060 title=Abstract>arXiv:2401.12060</a> [<a href=https://arxiv.org/pdf/2401.12060 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12060 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEDAC: A CVAE-Based Data Augmentation Method for Security Bug Report Identification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+Y">Y. Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">T. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Bug tracking systems store many bug reports, some of which are related to
security. Identifying those security bug reports (SBRs) may help us predict
some security-related bugs and solve security issues promptly so that the
project can avoid threats and attacks. However, in the real world, the ratio of
security bug reports is severely low; thus, directly training a prediction
model with raw data may result in inaccurate results. Faced with the massive
challenge of data imbalance, many researchers in the past have attempted to use
text filtering or clustering methods to minimize the proportion of non-security
bug reports (NSBRs) or apply oversampling methods to synthesize SBRs to make
the dataset as balanced as possible. Nevertheless, there are still two
challenges to those methods: 1) They ignore long-distance contextual
information. 2) They fail to generate an utterly balanced dataset. To tackle
these two challenges, we propose SEDAC, a new SBR identification method that
generates similar bug report vectors to solve data imbalance problems and
accurately detect security bug reports. Unlike previous studies, it first
converts bug reports into individual bug report vectors with distilBERT, which
are based on word2vec. Then, it trains a generative model through conditional
variational auto-encoder (CVAE) to generate similar vectors with security
labels, which makes the number of SBRs equal to NSBRs'. Finally, balanced data
are used to train a security bug report classifier. To evaluate the
effectiveness of our framework, we conduct it on 45,940 bug reports from
Chromium and four Apache projects. The experimental results show that SEDAC
outperforms all the baselines in g-measure with improvements of around
14.24%-50.10%.
</p>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12061 title=Abstract>arXiv:2401.12061</a> [<a href=https://arxiv.org/pdf/2401.12061 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12061 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Automated Verification for Cyber-Physical Systems in Isabelle/HOL
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munive%2C+J+J+H+y">Jonathan Julián Huerta y Munive</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foster%2C+S">Simon Foster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gleirscher%2C+M">Mario Gleirscher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Struth%2C+G">Georg Struth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laursen%2C+C+P">Christian Pardillo Laursen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hickman%2C+T">Thomas Hickman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the Journal of Automated Reasoning
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Mathematical Software (cs.MS)
</div>
<p class=mathjax>We formally introduce IsaVODEs (Isabelle verification with Ordinary
Differential Equations), a framework for the verification of cyber-physical
systems. We describe the semantic foundations of the framework's formalisation
in the Isabelle/HOL proof assistant. A user-friendly language specification
based on a robust state model makes our framework flexible and adaptable to
various engineering workflows. New additions to the framework increase both its
expressivity and proof automation. Specifically, formalisations related to
forward diamond correctness specifications, certification of unique solutions
to ordinary differential equations (ODEs) as flows, and invariant reasoning for
systems of ODEs contribute to the framework's scalability and usability.
Various examples and an evaluation validate the effectiveness of our framework.
</p>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12067 title=Abstract>arXiv:2401.12067</a> [<a href=https://arxiv.org/pdf/2401.12067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12067 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A concise proof of Commoner's theorem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jancar%2C+P">Petr Jancar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A slight elaboration of the 1-page text in Petri Net Newsletter, No 49, page 43 (October 1995)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>The textbook proofs of Commoner's theorem characterizing liveness in
free-choice Petri nets are given in contexts of technical notions and claims
that make the proofs look a bit long. The aim of this note is to give a concise
self-contained proof.
</p>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12068 title=Abstract>arXiv:2401.12068</a> [<a href=https://arxiv.org/pdf/2401.12068 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12068 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Resource-constrained stereo singing voice cancellation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borrelli%2C+C">Clara Borrelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rae%2C+J">James Rae</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basaran%2C+D">Dogac Basaran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McVicar%2C+M">Matt McVicar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Souden%2C+M">Mehrez Souden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mauch%2C+M">Matthias Mauch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>We study the problem of stereo singing voice cancellation, a subtask of music
source separation, whose goal is to estimate an instrumental background from a
stereo mix. We explore how to achieve performance similar to large
state-of-the-art source separation networks starting from a small, efficient
model for real-time speech separation. Such a model is useful when memory and
compute are limited and singing voice processing has to run with limited
look-ahead. In practice, this is realised by adapting an existing mono model to
handle stereo input. Improvements in quality are obtained by tuning model
parameters and expanding the training set. Moreover, we highlight the benefits
a stereo model brings by introducing a new metric which detects attenuation
inconsistencies between channels. Our approach is evaluated using objective
offline metrics and a large-scale MUSHRA trial, confirming the effectiveness of
our techniques in stringent listening tests.
</p>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12069 title=Abstract>arXiv:2401.12069</a> [<a href=https://arxiv.org/pdf/2401.12069 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12069 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muschalik%2C+M">Maximilian Muschalik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fumagalli%2C+F">Fabian Fumagalli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hammer%2C+B">Barbara Hammer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hüllermeier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>While shallow decision trees may be interpretable, larger ensemble models
like gradient-boosted trees, which often set the state of the art in machine
learning problems involving tabular data, still remain black box models. As a
remedy, the Shapley value (SV) is a well-known concept in explainable
artificial intelligence (XAI) research for quantifying additive feature
attributions of predictions. The model-specific TreeSHAP methodology solves the
exponential complexity for retrieving exact SVs from tree-based models.
Expanding beyond individual feature attribution, Shapley interactions reveal
the impact of intricate feature interactions of any order. In this work, we
present TreeSHAP-IQ, an efficient method to compute any-order additive Shapley
interactions for predictions of tree-based models. TreeSHAP-IQ is supported by
a mathematical framework that exploits polynomial arithmetic to compute the
interaction scores in a single recursive traversal of the tree, akin to Linear
TreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and explore
interactions on well-established benchmark datasets.
</p>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12070 title=Abstract>arXiv:2401.12070</a> [<a href=https://arxiv.org/pdf/2401.12070 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12070 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hans%2C+A">Abhimanyu Hans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cherepanova%2C+V">Valeriia Cherepanova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kazemi%2C+H">Hamid Kazemi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+A">Aniruddha Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldstein%2C+T">Tom Goldstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, code available at <a href=https://github.com/ahans30/Binoculars>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Detecting text generated by modern large language models is thought to be
hard, as both LLMs and humans can exhibit a wide range of complex behaviors.
However, we find that a score based on contrasting two closely related language
models is highly accurate at separating human-generated and machine-generated
text. Based on this mechanism, we propose a novel LLM detector that only
requires simple calculations using a pair of pre-trained LLMs. The method,
called Binoculars, achieves state-of-the-art accuracy without any training
data. It is capable of spotting machine text from a range of modern LLMs
without any model-specific modifications. We comprehensively evaluate
Binoculars on a number of text sources and in varied situations. Over a wide
range of document types, Binoculars detects over 90% of generated samples from
ChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being
trained on any ChatGPT data.
</p>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12071 title=Abstract>arXiv:2401.12071</a> [<a href=https://arxiv.org/pdf/2401.12071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Irredundant and Compressed Data Layout to Optimize Bandwidth Utilization of FPGA Accelerators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferry%2C+C">Corentin Ferry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Derumigny%2C+N">Nicolas Derumigny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Derrien%2C+S">Steven Derrien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajopadhye%2C+S">Sanjay Rajopadhye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 11 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>Memory bandwidth is known to be a performance bottleneck for FPGA
accelerators, especially when they deal with large multi-dimensional data-sets.
A large body of work focuses on reducing of off-chip transfers, but few authors
try to improve the efficiency of transfers. This paper addresses the later
issue by proposing (i) a compiler-based approach to accelerator's data layout
to maximize contiguous access to off-chip memory, and (ii) data packing and
runtime compression techniques that take advantage of this layout to further
improve memory performance. We show that our approach can decrease the I/O
cycles up to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-179-Frame tabindex=0><nobr><span class=math id=MathJax-Span-999 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.1em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1000><span class=mn id=MathJax-Span-1001 style=font-family:MathJax_Main>7</span><span class=mo id=MathJax-Span-1002 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> compared to un-optimized memory accesses.
</p>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12072 title=Abstract>arXiv:2401.12072</a> [<a href=https://arxiv.org/pdf/2401.12072 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12072 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-lingual Transfer Learning for Javanese Dependency Parsing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghiffari%2C+F+A+A">Fadli Aulawi Al Ghiffari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alfina%2C+I">Ika Alfina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azizah%2C+K">Kurniawati Azizah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at IJCNLP-AACL 2023 SRW
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>While structure learning achieves remarkable performance in high-resource
languages, the situation differs for under-represented languages due to the
scarcity of annotated data. This study focuses on assessing the efficacy of
transfer learning in enhancing dependency parsing for Javanese, a language
spoken by 80 million individuals but characterized by limited representation in
natural language processing. We utilized the Universal Dependencies dataset
consisting of dependency treebanks from more than 100 languages, including
Javanese. We propose two learning strategies to train the model: transfer
learning (TL) and hierarchical transfer learning (HTL). While TL only uses a
source language to pre-train the model, the HTL method uses a source language
and an intermediate language in the learning process. The results show that our
best model uses the HTL method, which improves performance with an increase of
10% for both UAS and LAS evaluations compared to the baseline model.
</p>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12073 title=Abstract>arXiv:2401.12073</a> [<a href=https://arxiv.org/pdf/2401.12073 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12073 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The time slot allocation problem in liberalised passenger railway markets: a multi-objective approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Be%C5%A1inovi%C4%87%2C+N">Nikola Bešinović</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-R%C3%B3denas%2C+R">Ricardo García-Ródenas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B3pez-Garc%C3%ADa%2C+M+L">María Luz López-García</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=L%C3%B3pez-G%C3%B3mez%2C+J+A">Julio Alberto López-Gómez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADn-Baos%2C+J+%C3%81">José Ángel Martín-Baos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages and 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>The liberalisation of the European passenger railway markets through the
European Directive EU 91/440/EEC states a new scenario where different Railway
Undertakings compete with each other in a bidding process for time slots. The
infrastructure resources are provided by the Infrastructure Manager, who
analyses and assesses the bids received, allocating the resources to each
Railway Undertaking. Time slot allocation is a fact that drastically influences
the market equilibrium. In this paper, we address the time slot allocation
problem within the context of a liberalized passenger railway market as a
multi-objective model. The Infrastructure Manager is tasked with selecting a
point from the Pareto front as the solution to the time slot allocation
problem. We propose two criteria for making this selection: the first one
allocates time slots to each company according to a set of priorities, while
the second one introduces a criterion of fairness in the treatment of companies
to incentive competition. The assessment of the impact of these rules on market
equilibrium has been conducted on a liberalized high-speed corridor within the
Spanish railway network.
</p>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12075 title=Abstract>arXiv:2401.12075</a> [<a href=https://arxiv.org/pdf/2401.12075 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12075 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NLP-based Relation Extraction Methods in RE
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Motger%2C+Q">Quim Motger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franch%2C+X">Xavier Franch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This article will appear as a chapter in a book provisionally titled "Natural Language Processing for Requirements Engineering", to be published by Springer
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Mobile app repositories have been largely used in scientific research as
large-scale, highly adaptive crowdsourced information systems. These software
platforms can potentially nourish multiple software and requirements
engineering tasks based on user reviews and other natural language documents,
including feedback analysis, recommender systems and topic modelling.
Consequently, researchers often endeavour to overcome domain-specific
challenges, including integration of heterogeneous data sources, large-scale
data collection and adaptation of a publicly available data set for a given
research scenario. In this paper, we present MApp-KG, a combination of software
resources and data artefacts in the field of mobile app repositories to support
extended knowledge generation tasks. Our contribution aims to provide a
framework for automatically constructing a knowledge graph modelling a
domain-specific catalogue of mobile apps. Complementarily, we distribute
MApp-KG in a public triplestore and as a static data snapshot, which may be
promptly employed for future research and reproduction of our findings.
</p>
</div>
</dd>
<dt><a name=item517>[517]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12076 title=Abstract>arXiv:2401.12076</a> [<a href=https://arxiv.org/pdf/2401.12076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Human Impression of Humanoid Robots Mirroring Social Cues
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+D">Di Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abawi%2C+F">Fares Abawi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allgeuer%2C+P">Philipp Allgeuer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24 Companion), March 11-14, 2024, Boulder, CO, USA. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2302.09648>arXiv:2302.09648</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Mirroring non-verbal social cues such as affect or movement can enhance
human-human and human-robot interactions in the real world. The robotic
platforms and control methods also impact people's perception of human-robot
interaction. However, limited studies have compared robot imitation across
different platforms and control methods. Our research addresses this gap by
conducting two experiments comparing people's perception of affective mirroring
between the iCub and Pepper robots and movement mirroring between vision-based
iCub control and Inertial Measurement Unit (IMU)-based iCub control. We
discovered that the iCub robot was perceived as more humanlike than the Pepper
robot when mirroring affect. A vision-based controlled iCub outperformed the
IMU-based controlled one in the movement mirroring task. Our findings suggest
that different robotic platforms impact people's perception of robots'
mirroring during HRI. The control method also contributes to the robot's
mirroring performance. Our work sheds light on the design and application of
different humanoid robots in the real world.
</p>
</div>
</dd>
<dt><a name=item518>[518]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12078 title=Abstract>arXiv:2401.12078</a> [<a href=https://arxiv.org/pdf/2401.12078 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12078 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Temporal Blind Spots in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wallat%2C+J">Jonas Wallat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jatowt%2C+A">Adam Jatowt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anand%2C+A">Avishek Anand</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at WSDM'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models (LLMs) have recently gained significant attention due
to their unparalleled ability to perform various natural language processing
tasks. These models, benefiting from their advanced natural language
understanding capabilities, have demonstrated impressive zero-shot performance.
However, the pre-training data utilized in LLMs is often confined to a specific
corpus, resulting in inherent freshness and temporal scope limitations.
Consequently, this raises concerns regarding the effectiveness of LLMs for
tasks involving temporal intents. In this study, we aim to investigate the
underlying limitations of general-purpose LLMs when deployed for tasks that
require a temporal understanding. We pay particular attention to handling
factual temporal knowledge through three popular temporal QA datasets.
Specifically, we observe low performance on detailed questions about the past
and, surprisingly, for rather new information. In manual and automatic testing,
we find multiple temporal errors and characterize the conditions under which QA
performance deteriorates. Our analysis contributes to understanding LLM
limitations and offers valuable insights into developing future models that can
better cater to the demands of temporally-oriented tasks. The code is
available\footnote{https://github.com/jwallat/temporalblindspots}.
</p>
</div>
</dd>
<dt><a name=item519>[519]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12079 title=Abstract>arXiv:2401.12079</a> [<a href=https://arxiv.org/pdf/2401.12079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative Reinforcement Learning Based Unmanned Aerial Vehicle (UAV) Trajectory Design for 3D UAV Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yujiao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sihua Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Ye Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+C">Changchuan Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, the problem of using one active unmanned aerial vehicle (UAV)
and four passive UAVs to localize a 3D target UAV in real time is investigated.
In the considered model, each passive UAV receives reflection signals from the
target UAV, which are initially transmitted by the active UAV. The received
reflection signals allow each passive UAV to estimate the signal transmission
distance which will be transmitted to a base station (BS) for the estimation of
the position of the target UAV. Due to the movement of the target UAV, each
active/passive UAV must optimize its trajectory to continuously localize the
target UAV. Meanwhile, since the accuracy of the distance estimation depends on
the signal-to-noise ratio of the transmission signals, the active UAV must
optimize its transmit power. This problem is formulated as an optimization
problem whose goal is to jointly optimize the transmit power of the active UAV
and trajectories of both active and passive UAVs so as to maximize the target
UAV positioning accuracy. To solve this problem, a Z function decomposition
based reinforcement learning (ZD-RL) method is proposed. Compared to value
function decomposition based RL (VD-RL), the proposed method can find the
probability distribution of the sum of future rewards to accurately estimate
the expected value of the sum of future rewards thus finding better transmit
power of the active UAV and trajectories for both active and passive UAVs and
improving target UAV positioning accuracy. Simulation results show that the
proposed ZD-RL method can reduce the positioning errors by up to 39.4% and
64.6%, compared to VD-RL and independent deep RL methods, respectively.
</p>
</div>
</dd>
<dt><a name=item520>[520]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12086 title=Abstract>arXiv:2401.12086</a> [<a href=https://arxiv.org/pdf/2401.12086 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12086 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> West-of-N: Synthetic Preference Generation for Improved Reward Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pace%2C+A">Alizée Pace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mallinson%2C+J">Jonathan Mallinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malmi%2C+E">Eric Malmi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krause%2C+S">Sebastian Krause</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Severyn%2C+A">Aliaksei Severyn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The success of reinforcement learning from human feedback (RLHF) in language
model alignment is strongly dependent on the quality of the underlying reward
model. In this paper, we present a novel approach to improve reward model
quality by generating synthetic preference data, thereby augmenting the
training dataset with on-policy, high-quality preference pairs. Motivated by
the promising results of Best-of-N sampling strategies in language model
training, we extend their application to reward model training. This results in
a self-training strategy to generate preference pairs by selecting the best and
worst candidates in a pool of responses to a given query. Empirically, we find
that this approach improves the performance of any reward model, with an effect
comparable to the addition of a similar quantity of human preference data. This
work opens up new avenues of research for improving RLHF for language model
alignment, by offering synthetic preference generation as a solution to reward
modeling challenges.
</p>
</div>
</dd>
<dt><a name=item521>[521]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12087 title=Abstract>arXiv:2401.12087</a> [<a href=https://arxiv.org/pdf/2401.12087 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12087 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting Demonstration Selection Strategies in In-Context Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+K">Keqin Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+L">Liang Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yancheng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xuebo Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+Y">Yuanxin Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models (LLMs) have shown an impressive ability to perform a
wide range of tasks using in-context learning (ICL), where a few examples are
used to describe a task to the model. However, the performance of ICL varies
significantly with the choice of demonstrations, and it is still unclear why
this happens or what factors will influence its choice. In this work, we first
revisit the factors contributing to this variance from both data and model
aspects, and find that the choice of demonstration is both data- and
model-dependent. We further proposed a data- and model-dependent demonstration
selection method, \textbf{TopK + ConE}, based on the assumption that
\textit{the performance of a demonstration positively correlates with its
contribution to the model's understanding of the test samples}, resulting in a
simple and effective recipe for ICL. Empirically, our method yields consistent
improvements in both language understanding and generation tasks with different
model scales. Further analyses confirm that, besides the generality and
stability under different circumstances, our method provides a unified
explanation for the effectiveness of previous methods. Code will be released.
</p>
</div>
</dd>
<dt><a name=item522>[522]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12088 title=Abstract>arXiv:2401.12088</a> [<a href=https://arxiv.org/pdf/2401.12088 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12088 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsupervised Learning of Graph from Recipes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diallo%2C+A">Aissatou Diallo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bikakis%2C+A">Antonis Bikakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dickens%2C+L">Luke Dickens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hunter%2C+A">Anthony Hunter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miller%2C+R">Rob Miller</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Cooking recipes are one of the most readily available kinds of procedural
text. They consist of natural language instructions that can be challenging to
interpret. In this paper, we propose a model to identify relevant information
from recipes and generate a graph to represent the sequence of actions in the
recipe. In contrast with other approaches, we use an unsupervised approach. We
iteratively learn the graph structure and the parameters of a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-180-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1003 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1001.97em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-1004><span class=texatom id=MathJax-Span-1005><span class=mrow id=MathJax-Span-1006><span class=mi id=MathJax-Span-1007 style=font-family:MathJax_SansSerif>G</span><span class=mi id=MathJax-Span-1008 style=font-family:MathJax_SansSerif>N</span><span class=mi id=MathJax-Span-1009 style=font-family:MathJax_SansSerif>N</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
encoding the texts (text-to-graph) one sequence at a time while providing the
supervision by decoding the graph into text (graph-to-text) and comparing the
generated text to the input. We evaluate the approach by comparing the
identified entities with annotated datasets, comparing the difference between
the input and output texts, and comparing our generated graphs with those
generated by state of the art methods.
</p>
</div>
</dd>
<dt><a name=item523>[523]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12093 title=Abstract>arXiv:2401.12093</a> [<a href=https://arxiv.org/pdf/2401.12093 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12093 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Monitoring the Future of Smart Contracts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Capretto%2C+M">Margarita Capretto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ceresa%2C+M">Martin Ceresa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez%2C+C">Cesar Sanchez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Blockchains are decentralized systems that provide trustable execution
guarantees. Smart contracts are programs written in specialized programming
languages running on blockchains that govern how tokens and cryptocurrency are
sent and received. Smart contracts can invoke other smart contracts during the
execution of transactions always initiated by external users.
<br>Once deployed, smart contracts cannot be modified, so techniques like runtime
verification are very appealing for improving their reliability. However, the
conventional model of computation of smart contracts is transactional: once
operations commit, their effects are permanent and cannot be undone.
<br>In this paper, we proposed the concept of future monitors which allows
monitors to remain waiting for future transactions to occur before committing
or aborting. This is inspired by optimistic rollups, which are modern
blockchain implementations that increase efficiency (and reduce cost) by
delaying transaction effects. We exploit this delay to propose a model of
computation that allows (bounded) future monitors. We show our monitors correct
respect of legacy transactions, how they implement future bounded monitors and
how they guarantee progress. We illustrate the use of future bounded monitors
to implement correctly multi-transaction flash loans.
</p>
</div>
</dd>
<dt><a name=item524>[524]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12094 title=Abstract>arXiv:2401.12094</a> [<a href=https://arxiv.org/pdf/2401.12094 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12094 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12094 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CLIQUE as an AND of Polynomial-Sized Monotone Constant-Depth Circuits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodn%C3%A1r%2C+L">Levente Bodnár</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
<p class=mathjax>This paper shows that calculating <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-181-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1010 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1011><span class=mi id=MathJax-Span-1012 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-CLIQUE on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-182-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1013 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1014><span class=mi id=MathJax-Span-1015 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> vertex graphs, requires
the AND of at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-183-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1016 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.113em,1002.09em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1017><span class=msubsup id=MathJax-Span-1018><span style=display:inline-block;position:relative;width:2.086em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1019 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=texatom id=MathJax-Span-1020><span class=mrow id=MathJax-Span-1021><span class=mi id=MathJax-Span-1022 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span class=texatom id=MathJax-Span-1023><span class=mrow id=MathJax-Span-1024><span class=mo id=MathJax-Span-1025 style=font-size:70.7%;font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-1026 style=font-size:70.7%;font-family:MathJax_Main>4</span><span class=mi id=MathJax-Span-1027 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> monotone, constant-depth, and polynomial-sized
circuits, for sufficiently large values of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-184-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1028 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1029><span class=mi id=MathJax-Span-1030 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. The proof relies on a new,
monotone, one-sided switching lemma, designed for cliques.
</p>
</div>
</dd>
<dt><a name=item525>[525]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12097 title=Abstract>arXiv:2401.12097</a> [<a href=https://arxiv.org/pdf/2401.12097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Empirical Analysis of In-context Learning Abilities of LLMs for MT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chitale%2C+P+A">Pranjal A. Chitale</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gala%2C+J">Jay Gala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gumma%2C+V">Varun Gumma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khapra%2C+M+M">Mitesh M. Khapra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dabre%2C+R">Raj Dabre</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In-context learning (ICL) has consistently demonstrated superior performance
over zero-shot performance in large language models (LLMs). However, the
understanding of the dynamics of ICL and the aspects that influence downstream
performance remains limited, especially for natural language generation (NLG)
tasks. This work aims to address this gap by investigating the ICL capabilities
of LLMs and studying the impact of different aspects of the in-context
demonstrations for the task of machine translation (MT). Our preliminary
investigations aim to discern whether in-context learning (ICL) is
predominantly influenced by demonstrations or instructions by applying diverse
perturbations to in-context demonstrations while preserving the task
instruction. We observe varying behavior to perturbed examples across different
model families, notably with BLOOM-7B derivatives being severely influenced by
noise, whereas Llama 2 derivatives not only exhibit robustness but also tend to
show enhancements over the clean baseline when subject to perturbed
demonstrations. This suggests that the robustness of ICL may be governed by
several factors, including the type of noise, perturbation direction (source or
target), the extent of pretraining of the specific model, and fine-tuning for
downstream tasks if applicable. Further investigation is warranted to develop a
comprehensive understanding of these factors in future research.
</p>
</div>
</dd>
<dt><a name=item526>[526]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12103 title=Abstract>arXiv:2401.12103</a> [<a href=https://arxiv.org/pdf/2401.12103 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12103 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LearnedWMP: Workload Memory Prediction Using Distribution of Query Templates
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quader%2C+S">Shaikh Quader</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaramillo%2C+A">Andres Jaramillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukhopadhyay%2C+S">Sumona Mukhopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abuoda%2C+G">Ghadeer Abuoda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuzarte%2C+C">Calisto Zuzarte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalmuk%2C+D">David Kalmuk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Litoiu%2C+M">Marin Litoiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papagelis%2C+M">Manos Papagelis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In a modern DBMS, working memory is frequently the limiting factor when
processing in-memory analytic query operations such as joins, sorting, and
aggregation. Existing resource estimation approaches for a DBMS estimate the
resource consumption of a query by computing an estimate of each individual
database operator in the query execution plan. Such an approach is slow and
error-prone as it relies upon simplifying assumptions, such as uniformity and
independence of the underlying data. Additionally, the existing approach
focuses on individual queries separately and does not factor in other queries
in the workload that may be executed concurrently. In this research, we are
interested in query performance optimization under concurrent execution of a
batch of queries (a workload). Specifically, we focus on predicting the memory
demand for a workload rather than providing separate estimates for each query
within it. We introduce the problem of workload memory prediction and formalize
it as a distribution regression problem. We propose Learned Workload Memory
Prediction (LearnedWMP) to improve and simplify estimating the working memory
demands of workloads. Through a comprehensive experimental evaluation, we show
that LearnedWMP reduces the memory estimation error of the
state-of-the-practice method by up to 47.6%. Compared to an alternative
single-query model, during training and inferencing, the LearnedWMP model and
its variants were 3x to 10x faster. Moreover, LearnedWMP-based models were at
least 50% smaller in most cases. Overall, the results demonstrate the
advantages of the LearnedWMP approach and its potential for a broader impact on
query performance optimization.
</p>
</div>
</dd>
<dt><a name=item527>[527]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12107 title=Abstract>arXiv:2401.12107</a> [<a href=https://arxiv.org/pdf/2401.12107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy-aware Trajectory Optimization for UAV-mounted RIS and Full-duplex Relay
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tyrovolas%2C+D">Dimitrios Tyrovolas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitsiou%2C+N+A">Nikos A. Mitsiou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boufikos%2C+T+G">Thomas G. Boufikos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mekikis%2C+P">Prodromos-Vasileios Mekikis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tegos%2C+S+A">Sotiris A. Tegos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diamantoulakis%2C+P+D">Panagiotis D. Diamantoulakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioannidis%2C+S">Sotiris Ioannidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liaskos%2C+C+K">Christos K. Liaskos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karagiannidis%2C+G+K">George K. Karagiannidis</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In the evolving landscape of sixth-generation (6G) wireless networks,
unmanned aerial vehicles (UAVs) have emerged as transformative tools for
dynamic and adaptive connectivity. However, dynamically adjusting their
position to offer favorable communication channels introduces operational
challenges in terms of energy consumption, especially when integrating advanced
communication technologies like reconfigurable intelligent surfaces (RISs) and
full-duplex relays (FDRs). To this end, by recognizing the pivotal role of UAV
mobility, the paper introduces an energy-aware trajectory design for
UAV-mounted RISs and UAV-mounted FDRs using the decode and forward (DF)
protocol, aiming to maximize the network minimum rate and enhance user
fairness, while taking into consideration the available on-board energy.
Specifically, this work highlights their distinct energy consumption
characteristics and their associated integration challenges by developing
appropriate energy consumption models for both UAV-mounted RISs and FDRs that
capture the intricate relationship between key factors such as weight, and
their operational characteristics. Furthermore, a joint time-division multiple
access (TDMA) user scheduling-UAV trajectory optimization problem is
formulated, considering the power dynamics of both systems, while assuring that
the UAV energy is not depleted mid-air. Finally, simulation results underscore
the importance of energy considerations in determining the optimal trajectory
and scheduling and provide insights into the performance comparison of
UAV-mounted RISs and FDRs in UAV-assisted wireless networks.
</p>
</div>
</dd>
<dt><a name=item528>[528]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12108 title=Abstract>arXiv:2401.12108</a> [<a href=https://arxiv.org/pdf/2401.12108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using Streaming Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%B6tterl%2C+J">Jeremias Dötterl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruns%2C+R">Ralf Bruns</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dunkel%2C+J">Jürgen Dunkel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Frontiers in Artificial Intelligence and Applications. Volume 325:
 ECAI 2020. Pages 51-58
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>In parcel delivery, the "last mile" from the parcel hub to the customer is
costly, especially for time-sensitive delivery tasks that have to be completed
within hours after arrival. Recently, crowdshipping has attracted increased
attention as a new alternative to traditional delivery modes. In crowdshipping,
private citizens ("the crowd") perform short detours in their daily lives to
contribute to parcel delivery in exchange for small incentives. However,
achieving desirable crowd behavior is challenging as the crowd is highly
dynamic and consists of autonomous, self-interested individuals. Leveraging
crowdshipping for time-sensitive deliveries remains an open challenge. In this
paper, we present an agent-based approach to on-time parcel delivery with
crowds. Our system performs data stream processing on the couriers' smartphone
sensor data to predict delivery delays. Whenever a delay is predicted, the
system attempts to forge an agreement for transferring the parcel from the
current deliverer to a more promising courier nearby. Our experiments show that
through accurate delay predictions and purposeful task transfers many delays
can be prevented that would occur without our approach.
</p>
</div>
</dd>
<dt><a name=item529>[529]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12111 title=Abstract>arXiv:2401.12111</a> [<a href=https://arxiv.org/pdf/2401.12111 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12111 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constrained Multi-Tildes: Derived Term and Position Automata
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Attou%2C+S">Samira Attou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mignot%2C+L">Ludovic Mignot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miklarz%2C+C">Clément Miklarz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nicart%2C+F">Florent Nicart</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version of <a href=https://doi.org/10.1007/978-3-031-40247-0_4>this https URL</a>, submitted to International Journal of Foundations of Computer Science
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
<p class=mathjax>Multi-tildes are regular operators that were introduced to enhance the
factorization power of regular expressions, allowing us to add the empty word
in several factors of a catenation product of languages. In addition to
multi-bars, which dually remove the empty word, they allow representing any
acyclic automaton by a linear-sized expression, whereas the lower bound is
exponential in the classic case.
<br>In this paper, we extend multi-tildes from disjunctive combinations to any
Boolean combination, allowing us to exponentially enhance the factorization
power of tildes expressions. Moreover, we show how to convert these expressions
into finite automata and give a Haskell implementation of them using advanced
techniques of functional programming.
</p>
</div>
</dd>
<dt><a name=item530>[530]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12113 title=Abstract>arXiv:2401.12113</a> [<a href=https://arxiv.org/pdf/2401.12113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extracting Formulae in Many-Valued Logic from Deep Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yani Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%B6lcskei%2C+H">Helmut Bölcskei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>We propose a new perspective on deep ReLU networks, namely as circuit
counterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)
generalization of Boolean logic. An algorithm for extracting formulae in MV
logic from deep ReLU networks is presented. As the algorithm applies to
networks with general, in particular also real-valued, weights, it can be used
to extract logical formulae from deep ReLU networks trained on data.
</p>
</div>
</dd>
<dt><a name=item531>[531]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12114 title=Abstract>arXiv:2401.12114</a> [<a href=https://arxiv.org/pdf/2401.12114 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12114 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved accuracy of continuum surface flux models for metal additive manufacturing melt pool simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Much%2C+N">Nils Much</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schreter-Fleischhacker%2C+M">Magdalena Schreter-Fleischhacker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munch%2C+P">Peter Munch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kronbichler%2C+M">Martin Kronbichler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wall%2C+W+A">Wolfgang A. Wall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meier%2C+C">Christoph Meier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>Computational modeling of the melt pool dynamics in laser-based powder bed
fusion metal additive manufacturing (PBF-LB/M) promises to shed light on
fundamental defect generation mechanisms. These processes are typically
accompanied by rapid evaporation so that the evaporation-induced recoil
pressure and cooling arise as major driving forces for fluid dynamics and
temperature evolution. The magnitude of these interface fluxes depends
exponentially on the melt pool surface temperature, which, therefore, must be
predicted with high accuracy. The present work utilizes a diffuse interface
model based on a continuum surface flux (CSF) description on the interfaces to
study dimensionally reduced thermal two-phase problems representing PBF-LB/M in
a finite element framework. It is demonstrated that the extreme temperature
gradients combined with the high ratios of material properties between metal
and ambient gas lead to significant errors in the interface temperatures and
fluxes when classical CSF approaches, along with typical interface thicknesses
and discretizations, are applied. A novel parameter-scaled CSF approach is
proposed, which is constructed to yield a smoother temperature rate in the
diffuse interface region, significantly increasing the solution accuracy. The
interface thickness required to predict the temperature field with a given
level of accuracy is less restrictive by at least one order of magnitude for
the proposed parameter-scaled CSF approach compared to classical CSF,
drastically reducing computational costs. Finally, we showcased the general
applicability of the parameter-scaled CSF to a three-dimensional simulation of
stationary laser melting of PBF-LB/M considering the fully coupled
thermo-hydrodynamic multi-phase problem, including phase change.
</p>
</div>
</dd>
<dt><a name=item532>[532]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12117 title=Abstract>arXiv:2401.12117</a> [<a href=https://arxiv.org/pdf/2401.12117 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12117 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahrabian%2C+K">Kian Ahrabian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+K">Kexuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiarui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pujara%2C+J">Jay Pujara</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and datasets are available at <a href=https://github.com/kahrabian/mllm-nvar>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>While large language models (LLMs) are still being adopted to new domains and
utilized in novel applications, we are experiencing an influx of the new
generation of foundation models, namely multi-modal large language models
(MLLMs). These models integrate verbal and visual information, opening new
possibilities to demonstrate more complex reasoning abilities at the
intersection of the two modalities. However, despite the revolutionizing
prospect of MLLMs, our understanding of their reasoning abilities is limited.
In this study, we assess the nonverbal abstract reasoning abilities of
open-source and closed-source MLLMs using variations of Raven's Progressive
Matrices. Our experiments expose the difficulty of solving such problems while
showcasing the immense gap between open-source and closed-source models. We
also reveal critical shortcomings with individual visual and textual modules,
subjecting the models to low-performance ceilings. Finally, to improve MLLMs'
performance, we experiment with various methods, such as Chain-of-Thought
prompting, resulting in a significant (up to 100%) boost in performance.
</p>
</div>
</dd>
<dt><a name=item533>[533]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12120 title=Abstract>arXiv:2401.12120</a> [<a href=https://arxiv.org/pdf/2401.12120 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12120 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Centralization in Block Building and Proposer-Builder Separation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bahrani%2C+M">Maryam Bahrani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garimidi%2C+P">Pranav Garimidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Theoretical Economics (econ.TH)
</div>
<p class=mathjax>The goal of this paper is to rigorously interrogate conventional wisdom about
centralization in block-building (due to, e.g., MEV and private order flow) and
the outsourcing of block-building by validators to specialists (i.e.,
proposer-builder separation):
<br>1. Does heterogeneity in skills and knowledge across block producers
inevitably lead to centralization?
<br>2. Does proposer-builder separation eliminate heterogeneity and preserve
decentralization among proposers?
<br>This paper develops mathematical models and results that offer answers to
these questions:
<br>1. In a game-theoretic model with endogenous staking, heterogeneous block
producer rewards, and staking costs, we quantify the extent to which
heterogeneous rewards lead to concentration in the equilibrium staking
distribution.
<br>2. In a stochastic model in which heterogeneous block producers repeatedly
reinvest rewards into staking, we quantify, as a function of the block producer
heterogeneity, the rate at which stake concentrates on the most sophisticated
block producers.
<br>3. In a model with heterogeneous proposers and specialized builders, we
quantify, as a function of the competitiveness of the builder ecosystem, the
extent to which proposer-builder separation reduces the heterogeneity in
rewards across different proposers.
<br>Our models and results take advantage of connections to contest design,
P\'olya urn processes, and auction theory.
</p>
</div>
</dd>
<dt><a name=item534>[534]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12121 title=Abstract>arXiv:2401.12121</a> [<a href=https://arxiv.org/pdf/2401.12121 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12121 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12121 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving genetic algorithms performance via deterministic population shrinkage
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laredo%2C+J+L+J">Juan Luis Jiménez Laredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandes%2C+C">Carlos Fernandes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merelo%2C+J+J">Juan Julián Merelo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gagn%C3%A9%2C+C">Christian Gagné</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>Despite the intuition that the same population size is not needed throughout
the run of an Evolutionary Algorithm (EA), most EAs use a fixed population
size. This paper presents an empirical study on the possible benefits of a
Simple Variable Population Sizing (SVPS) scheme on the performance of Genetic
Algorithms (GAs). It consists in decreasing the population for a GA run
following a predetermined schedule, configured by a speed and a severity
parameter. The method uses as initial population size an estimation of the
minimum size needed to supply enough building blocks, using a fixed-size
selectorecombinative GA converging within some confidence interval toward good
solutions for a particular problem. Following this methodology, a scalability
analysis is conducted on deceptive, quasi-deceptive, and non-deceptive trap
functions in order to assess whether SVPS-GA improves performances compared to
a fixed-size GA under different problem instances and difficulty levels.
Results show several combinations of speed-severity where SVPS-GA preserves the
solution quality while improving performances, by reducing the number of
evaluations needed for success.
</p>
</div>
</dd>
<dt><a name=item535>[535]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12125 title=Abstract>arXiv:2401.12125</a> [<a href=https://arxiv.org/pdf/2401.12125 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12125 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CodeTailor: Personalized Parsons Puzzles are Preferred Over AI-Generated Solutions to Support Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+X">Xinying Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zihan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ericson%2C+B+J">Barbara J. Ericson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Programming can be challenging for novices, but it is difficult to provide
high-quality, comprehensive, and timely support at scale. Generative AI and its
products, like ChatGPT, can create a solution for most introductory programming
problems. However, students may become overly reliant on these tools for quick
code generation and homework completion, leading to reduced engagement and
limited learning. In this work, we present \sys{}, a system that utilizes large
language models (LLM) while still promoting students' cognitive engagement.
\sys{} provides a personalized Parsons puzzle to support struggling students.
In a Parsons puzzle, students place mixed-up code blocks in the correct order
to solve a problem. A technical evaluation with 800 incorrect student code
demonstrated that \sys{} can efficiently create high-quality (correct,
personalized, and concise) Parsons puzzles for students. In a within-subjects
experiment with 18 novice programmers, most students rated using \sys{} as more
engaging, and they preferred \sys{} for learning rather than simply receiving
an AI-generated solution. Additionally, students recalled more new elements
from the supported practice to the posttest after using \sys{}, compared to
when they simply received a direct solution. Qualitative observations and
interviews provided evidence for the benefits of \sys{} including emphasizing
algorithmic thinking, fostering continuity in learning, promoting metacognitive
reflection, and boosting student confidence. We conclude by suggesting future
designs for applying generative AI in a way that minimizes over-reliance and
enhances learning.
</p>
</div>
</dd>
<dt><a name=item536>[536]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12129 title=Abstract>arXiv:2401.12129</a> [<a href=https://arxiv.org/pdf/2401.12129 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12129 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Out-of-Distribution Detection &amp; Applications With Ablated Learned Temperature Energy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=LeVine%2C+W">Will LeVine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pikus%2C+B">Benjamin Pikus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phillips%2C+J">Jacob Phillips</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Norman%2C+B">Berk Norman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gil%2C+F+A">Fernando Amat Gil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>As deep neural networks become adopted in high-stakes domains, it is crucial
to be able to identify when inference inputs are Out-of-Distribution (OOD) so
that users can be alerted of likely drops in performance and calibration
despite high confidence. Among many others, existing methods use the following
two scores to do so without training on any apriori OOD examples: a learned
temperature and an energy score. In this paper we introduce Ablated Learned
Temperature Energy (or "AbeT" for short), a method which combines these prior
methods in novel ways with effective modifications. Due to these contributions,
AbeT lowers the False Positive Rate at <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-185-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1031 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1032><span class=mn id=MathJax-Span-1033 style=font-family:MathJax_Main>95</span><span class=mi id=MathJax-Span-1034 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> True Positive Rate (FPR@95) by
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-186-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1035 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1036><span class=mn id=MathJax-Span-1037 style=font-family:MathJax_Main>35.39</span><span class=mi id=MathJax-Span-1038 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> in classification (averaged across all ID and OOD datasets measured)
compared to state of the art without training networks in multiple stages or
requiring hyperparameters or test-time backward passes. We additionally provide
empirical insights as to how our model learns to distinguish between
In-Distribution (ID) and OOD samples while only being explicitly trained on ID
samples via exposure to misclassified ID examples at training time. Lastly, we
show the efficacy of our method in identifying predicted bounding boxes and
pixels corresponding to OOD objects in object detection and semantic
segmentation, respectively - with an AUROC increase of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-187-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1039 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1040><span class=mn id=MathJax-Span-1041 style=font-family:MathJax_Main>5.15</span><span class=mi id=MathJax-Span-1042 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> in object
detection and both a decrease in FPR@95 of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-188-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1043 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1044><span class=mn id=MathJax-Span-1045 style=font-family:MathJax_Main>41.48</span><span class=mi id=MathJax-Span-1046 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and an increase in AUPRC
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-189-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1047 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1048><span class=mn id=MathJax-Span-1049 style=font-family:MathJax_Main>34.20</span><span class=mi id=MathJax-Span-1050 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> on average in semantic segmentation compared to previous state of
the art.
</p>
</div>
</dd>
<dt><a name=item537>[537]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12131 title=Abstract>arXiv:2401.12131</a> [<a href=https://arxiv.org/pdf/2401.12131 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12131 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NeuroSynt: A Neuro-symbolic Portfolio Solver for Reactive Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cosler%2C+M">Matthias Cosler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hahn%2C+C">Christopher Hahn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omar%2C+A">Ayham Omar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmitt%2C+F">Frederik Schmitt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We introduce NeuroSynt, a neuro-symbolic portfolio solver framework for
reactive synthesis. At the core of the solver lies a seamless integration of
neural and symbolic approaches to solving the reactive synthesis problem. To
ensure soundness, the neural engine is coupled with model checkers verifying
the predictions of the underlying neural models. The open-source implementation
of NeuroSynt provides an integration framework for reactive synthesis in which
new neural and state-of-the-art symbolic approaches can be seamlessly
integrated. Extensive experiments demonstrate its efficacy in handling
challenging specifications, enhancing the state-of-the-art reactive synthesis
solvers, with NeuroSynt contributing novel solves in the current SYNTCOMP
benchmarks.
</p>
</div>
</dd>
<dt><a name=item538>[538]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12132 title=Abstract>arXiv:2401.12132</a> [<a href=https://arxiv.org/pdf/2401.12132 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12132 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12132 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayfield%2C+J+D">John D. Mayfield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naqa%2C+I+E">Issam El Naqa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term
Memory (LSTM) models were studied to provide sequential relationships for each
timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot
study, we compared three QCNN-LSTM models for binary classification of MS
disability benchmarked against classical neural network architectures. Our
hypothesis is that quantum models will provide competitive performance. Methods
Matrix Product State (MPS), reverse Multistate Entanglement Renormalization
Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM
layer to process near-annual MRI data of patients diagnosed with MS. These were
benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision
Transformer (ViViT). Predicted logits were measured against ground truth labels
of each patient's Extended Disability Severity Score (EDSS) using binary
cross-entropy loss. Training/validation/holdout testing was partitioned using
5-fold cross validation with a total split of 60:20:20. Levene's test of
variance was used to measure statistical difference and Student's t-test for
paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and
TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively
(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73
and 0.77, respectively (p-value 0.631). Overall variance and mean were not
statistically significant (p-value 0.713), however, time to train was
significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,
respectively, p-value &lt;0.001). Conclusion QCNN-LSTM models perform
competitively to their classical counterparts with greater efficiency in train
time. Clinically, these can add value in terms of efficiency to time-dependent
deep learning prediction of disease progression based upon medical imaging.
</p>
</div>
</dd>
<dt><a name=item539>[539]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12133 title=Abstract>arXiv:2401.12133</a> [<a href=https://arxiv.org/pdf/2401.12133 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12133 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VRMN-bD: A Multi-modal Natural Behavior Dataset of Immersive Human Fear Responses in VR Stand-up Interactive Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">He Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuanxi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+X">Xinyi Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+C">Christine Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE VR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Understanding and recognizing emotions are important and challenging issues
in the metaverse era. Understanding, identifying, and predicting fear, which is
one of the fundamental human emotions, in virtual reality (VR) environments
plays an essential role in immersive game development, scene development, and
next-generation virtual human-computer interaction applications. In this
article, we used VR horror games as a medium to analyze fear emotions by
collecting multi-modal data (posture, audio, and physiological signals) from 23
players. We used an LSTM-based model to predict fear with accuracies of 65.31%
and 90.47% under 6-level classification (no fear and five different levels of
fear) and 2-level classification (no fear and fear), respectively. We
constructed a multi-modal natural behavior dataset of immersive human fear
responses (VRMN-bD) and compared it with existing relevant advanced datasets.
The results show that our dataset has fewer limitations in terms of collection
method, data scale and audience scope. We are unique and advanced in targeting
multi-modal datasets of fear and behavior in VR stand-up interactive
environments. Moreover, we discussed the implications of this work for
communities and applications. The dataset and pre-trained model are available
at https://github.com/KindOPSTAR/VRMN-bD.
</p>
</div>
</dd>
<dt><a name=item540>[540]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12136 title=Abstract>arXiv:2401.12136</a> [<a href=https://arxiv.org/pdf/2401.12136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spin Wave Threshold Gate
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Zegbroeck%2C+A">Arne Van Zegbroeck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anagnostou%2C+P">Pantazis Anagnostou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamdioui%2C+S">Said Hamdioui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adelmann%2C+C">Christop Adelmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ciubotaru%2C+F">Florin Ciubotaru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cotofana%2C+S">Sorin Cotofana</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has received funding from the Horizon Europe research and innovation program within the project "Spider" (grant agreement no. 101070417)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>
</div>
<p class=mathjax>While Spin Waves (SW) interaction provides natural support for low power
Majority (MAJ) gate implementations many hurdles still exists on the road
towards the realization of practically relevant SW circuits. In this paper we
leave the SW interaction avenue and propose Threshold Logic (TL) inspired SW
computing, which relies on successive phase rotations applied to one single SW
instead of on the interference of an odd number of SWs. After providing a short
TL inside we introduce the SW TL gate concept and discuss the way to mirror TL
gate weight and threshold values into physical phase-shifter parameters.
Subsequently, we design and demonstrate proper operation of a SW TL based Full
Adder (FA) by means of micro-magnetic simulations. We conclude the paper by
providing inside on the potential advantages of our proposal by means of a
conceptual comparison of MAJ and TL based FA implementations.
</p>
</div>
</dd>
<dt><a name=item541>[541]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12138 title=Abstract>arXiv:2401.12138</a> [<a href=https://arxiv.org/pdf/2401.12138 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12138 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gradient Preserving Operator Inference: Data-Driven Reduced-Order Models for Equations with Gradient Structure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Geng%2C+Y">Yuwei Geng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Singh%2C+J">Jasdeep Singh</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ju%2C+L">Lili Ju</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kramer%2C+B">Boris Kramer</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Z">Zhu Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Hamiltonian Operator Inference has been introduced in [Sharma, H., Wang, Z.,
Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn
structure-preserving reduced-order models (ROMs) for Hamiltonian systems. This
approach constructs a low-dimensional model using only data and knowledge of
the Hamiltonian function. Such ROMs can keep the intrinsic structure of the
system, allowing them to capture the physics described by the governing
equations. In this work, we extend this approach to more general systems that
are either conservative or dissipative in energy, and which possess a gradient
structure. We derive the optimization problems for inferring
structure-preserving ROMs that preserve the gradient structure. We further
derive an {\em a priori} error estimate for the reduced-order approximation. To
test the algorithms, we consider semi-discretized partial differential
equations with gradient structure, such as the parameterized wave and
Korteweg-de-Vries equations in the conservative case and the one- and
two-dimensional Allen-Cahn equations in the dissipative case. The numerical
results illustrate the accuracy, structure-preservation properties, and
predictive capabilities of the gradient-preserving Operator Inference ROMs.
</p>
</div>
</dd>
<dt><a name=item542>[542]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12143 title=Abstract>arXiv:2401.12143</a> [<a href=https://arxiv.org/pdf/2401.12143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Anisotropy Is Inherent to Self-Attention in Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Godey%2C+N">Nathan Godey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+la+Clergerie%2C+%C3%89">Éric de la Clergerie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sagot%2C+B">Benoît Sagot</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of EACL 2024. Previously presented at ACL-SRW 2023 (<a href=https://arxiv.org/abs/2306.07656>arXiv:2306.07656</a>). arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2306.07656>arXiv:2306.07656</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The representation degeneration problem is a phenomenon that is widely
observed among self-supervised learning methods based on Transformers. In NLP,
it takes the form of anisotropy, a singular property of hidden representations
which makes them unexpectedly close to each other in terms of angular distance
(cosine-similarity). Some recent works tend to show that anisotropy is a
consequence of optimizing the cross-entropy loss on long-tailed distributions
of tokens. We show in this paper that anisotropy can also be observed
empirically in language models with specific objectives that should not suffer
directly from the same consequences. We also show that the anisotropy problem
extends to Transformers trained on other modalities. Our observations suggest
that anisotropy is actually inherent to Transformers-based models.
</p>
</div>
</dd>
<dt><a name=item543>[543]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12147 title=Abstract>arXiv:2401.12147</a> [<a href=https://arxiv.org/pdf/2401.12147 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12147 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12147 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Efficient Finite Difference-based Implicit Solver for Phase-Field Equations with Spatially and Temporally Varying Parameters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mao%2C+Z">Zirui Mao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+G+R">G. R. Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Demkowicz%2C+M+J">Michael J. Demkowicz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)
</div>
<p class=mathjax>The phase field method is an effective tool for modeling microstructure
evolution in materials. Many efficient implicit numerical solvers have been
proposed for phase field simulations under uniform and time-invariant model
parameters. We use Eyre's theorem to develop an unconditionally stable implicit
solver for spatially non-uniform and time-varying model parameters. The
accuracy, unconditional stability, and efficiency of the solver is validated
against benchmarking examples. In its current form, the solver requires a
uniform mesh and may only be applied to problems with periodic, Neumann, or
mixed periodic and Neumann boundary conditions.
</p>
</div>
</dd>
<dt><a name=item544>[544]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12149 title=Abstract>arXiv:2401.12149</a> [<a href=https://arxiv.org/pdf/2401.12149 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12149 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Personalized Over-the-Air Federated Learning with Personalized Reconfigurable Intelligent Surfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+J">Jiayu Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yener%2C+A">Aylin Yener</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Copyright 2024 IEEE. Published in ICASSP 2024, 14-19 April, Seoul, Korea. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Over-the-air federated learning (OTA-FL) provides bandwidth-efficient
learning by leveraging the inherent superposition property of wireless
channels. Personalized federated learning balances performance for users with
diverse datasets, addressing real-life data heterogeneity. We propose the first
personalized OTA-FL scheme through multi-task learning, assisted by personal
reconfigurable intelligent surfaces (RIS) for each user. We take a cross-layer
approach that optimizes communication and computation resources for global and
personalized tasks in time-varying channels with imperfect channel state
information, using multi-task learning for non-i.i.d data. Our PROAR-PFed
algorithm adaptively designs power, local iterations, and RIS configurations.
We present convergence analysis for non-convex objectives and demonstrate that
PROAR-PFed outperforms state-of-the-art on the Fashion-MNIST dataset.
</p>
</div>
</dd>
<dt><a name=item545>[545]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12151 title=Abstract>arXiv:2401.12151</a> [<a href=https://arxiv.org/pdf/2401.12151 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12151 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uncoded Storage Coded Transmission Elastic Computing with Straggler Tolerance in Heterogeneous Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+X">Xi Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kliewer%2C+J">Joerg Kliewer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+M">Mingyue Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figure, accepted in ICC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)
</div>
<p class=mathjax>In 2018, Yang et al. introduced a novel and effective approach, using maximum
distance separable (MDS) codes, to mitigate the impact of elasticity in cloud
computing systems. This approach is referred to as coded elastic computing.
Some limitations of this approach include that it assumes all virtual machines
have the same computing speeds and storage capacities, and it cannot tolerate
stragglers for matrix-matrix multiplications. In order to resolve these
limitations, in this paper, we introduce a new combinatorial optimization
framework, named uncoded storage coded transmission elastic computing (USCTEC),
for heterogeneous speeds and storage constraints, aiming to minimize the
expected computation time for matrix-matrix multiplications, under the
consideration of straggler tolerance. Within this framework, we propose optimal
solutions with straggler tolerance under relaxed storage constraints. Moreover,
we propose a heuristic algorithm that considers the heterogeneous storage
constraints. Our results demonstrate that the proposed algorithm outperforms
baseline solutions utilizing cyclic storage placements, in terms of both
expected computation time and storage size.
</p>
</div>
</dd>
<dt><a name=item546>[546]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12159 title=Abstract>arXiv:2401.12159</a> [<a href=https://arxiv.org/pdf/2401.12159 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12159 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transcending To Notions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karthik%2C+S+S">Sama Sai Karthik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshmukh%2C+J">Jayati Deshmukh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasa%2C+S">Srinath Srinivasa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>Social identities play an important role in the dynamics of human societies,
and it can be argued that some sense of identification with a larger cause or
idea plays a critical role in making humans act responsibly. Often social
activists strive to get populations to identify with some cause or notion --
like green energy, diversity, etc. in order to bring about desired social
changes. We explore the problem of designing computational models for social
identities in the context of autonomous AI agents. For this, we propose an
agent model that enables agents to identify with certain notions and show how
this affects collective outcomes. We also contrast between associations of
identity with rational preferences. The proposed model is simulated in an
application context of urban mobility, where we show how changes in social
identity affect mobility patterns and collective outcomes.
</p>
</div>
</dd>
<dt><a name=item547>[547]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12161 title=Abstract>arXiv:2401.12161</a> [<a href=https://arxiv.org/pdf/2401.12161 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12161 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12161 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automated facial recognition system using deep learning for pain assessment in adults with cerebral palsy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabater-G%C3%A1rriz%2C+%C3%81">Álvaro Sabater-Gárriz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaya-Morey%2C+F+X">F. Xavier Gaya-Morey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buades-Rubio%2C+J+M">José María Buades-Rubio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yee%2C+C+M">Cristina Manresa Yee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montoya%2C+P">Pedro Montoya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riquelme%2C+I">Inmaculada Riquelme</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Background: Pain assessment in individuals with neurological conditions,
especially those with limited self-report ability and altered facial
expressions, presents challenges. Existing measures, relying on direct
observation by caregivers, lack sensitivity and specificity. In cerebral palsy,
pain is a common comorbidity and a reliable evaluation protocol is crucial.
Thus, having an automatic system that recognizes facial expressions could be of
enormous help when diagnosing pain in this type of patient.
<br>Objectives: 1) to build a dataset of facial pain expressions in individuals
with cerebral palsy, and 2) to develop an automated facial recognition system
based on deep learning for pain assessment addressed to this population.
<br>Methods: Ten neural networks were trained on three pain image databases,
including the UNBC-McMaster Shoulder Pain Expression Archive Database, the
Multimodal Intensity Pain Dataset, and the Delaware Pain Database.
Additionally, a curated dataset (CPPAIN) was created, consisting of 109
preprocessed facial pain expression images from individuals with cerebral
palsy, categorized by two physiotherapists using the Facial Action Coding
System observational scale.
<br>Results: InceptionV3 exhibited promising performance on the CP-PAIN dataset,
achieving an accuracy of 62.67% and an F1 score of 61.12%. Explainable
artificial intelligence techniques revealed consistent essential features for
pain identification across models.
<br>Conclusion: This study demonstrates the potential of deep learning models for
robust pain detection in populations with neurological conditions and
communication disabilities. The creation of a larger dataset specific to
cerebral palsy would further enhance model accuracy, offering a valuable tool
for discerning subtle and idiosyncratic pain expressions. The insights gained
could extend to other complex neurological conditions.
</p>
</div>
</dd>
<dt><a name=item548>[548]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12164 title=Abstract>arXiv:2401.12164</a> [<a href=https://arxiv.org/pdf/2401.12164 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12164 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+H">Hong Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">James Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yichao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+X">Xia Hong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Image segmentation is a clustering task whereby each pixel is assigned a
cluster label. Remote sensing data usually consists of multiple bands of
spectral images in which there exist semantically meaningful land cover
subregions, co-registered with other source data such as LIDAR (LIght Detection
And Ranging) data, where available. This suggests that, in order to account for
spatial correlation between pixels, a feature vector associated with each pixel
may be a vectorized tensor representing the multiple bands and a local patch as
appropriate. Similarly, multiple types of texture features based on a pixel's
local patch would also be beneficial for encoding locally statistical
information and spatial variations, without necessarily labelling pixel-wise a
large amount of ground truth, then training a supervised model, which is
sometimes impractical. In this work, by resorting to label only a small
quantity of pixels, a new semi-supervised segmentation approach is proposed.
Initially, over all pixels, an image data matrix is created in high dimensional
feature space. Then, t-SNE projects the high dimensional data onto 3D
embedding. By using radial basis functions as input features, which use the
labelled data samples as centres, to pair with the output class labels, a
modified canonical correlation analysis algorithm, referred to as RBF-CCA, is
introduced which learns the associated projection matrix via the small labelled
data set. The associated canonical variables, obtained for the full image, are
applied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA
algorithm has been implemented on several remotely sensed multispectral images,
demonstrating excellent segmentation results.
</p>
</div>
</dd>
<dt><a name=item549>[549]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12168 title=Abstract>arXiv:2401.12168</a> [<a href=https://arxiv.org/pdf/2401.12168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+B">Boyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhuo Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirmani%2C+S">Sean Kirmani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ichter%2C+B">Brian Ichter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Driess%2C+D">Danny Driess</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Florence%2C+P">Pete Florence</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+F">Fei Xia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)
</div>
<p class=mathjax>Understanding and reasoning about spatial relationships is a fundamental
capability for Visual Question Answering (VQA) and robotics. While Vision
Language Models (VLM) have demonstrated remarkable performance in certain VQA
benchmarks, they still lack capabilities in 3D spatial reasoning, such as
recognizing quantitative relationships of physical objects like distances or
size differences. We hypothesize that VLMs' limited spatial reasoning
capability is due to the lack of 3D spatial knowledge in training data and aim
to solve this problem by training VLMs with Internet-scale spatial reasoning
data. To this end, we present a system to facilitate this approach. We first
develop an automatic 3D spatial VQA data generation framework that scales up to
2 billion VQA examples on 10 million real-world images. We then investigate
various factors in the training recipe, including data quality, training
pipeline, and VLM architecture. Our work features the first internet-scale 3D
spatial reasoning dataset in metric space. By training a VLM on such data, we
significantly enhance its ability on both qualitative and quantitative spatial
VQA. Finally, we demonstrate that this VLM unlocks novel downstream
applications in chain-of-thought spatial reasoning and robotics due to its
quantitative estimation capability. Project website:
https://spatial-vlm.github.io/
</p>
</div>
</dd>
<dt><a name=item550>[550]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12170 title=Abstract>arXiv:2401.12170</a> [<a href=https://arxiv.org/pdf/2401.12170 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12170 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12170 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Natural Strategic Ability in Stochastic Multi-Agent Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berthon%2C+R">Raphaël Berthon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katoen%2C+J">Joost-Pieter Katoen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mittelmann%2C+M">Munyque Mittelmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murano%2C+A">Aniello Murano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version of the paper accepted at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Strategies synthesized using formal methods can be complex and often require
infinite memory, which does not correspond to the expected behavior when trying
to model Multi-Agent Systems (MAS). To capture such behaviors, natural
strategies are a recently proposed framework striking a balance between the
ability of agents to strategize with memory and the model-checking complexity,
but until now has been restricted to fully deterministic settings. For the
first time, we consider the probabilistic temporal logics PATL and PATL* under
natural strategies (NatPATL and NatPATL*, resp.). As main result we show that,
in stochastic MAS, NatPATL model-checking is NP-complete when the active
coalition is restricted to deterministic strategies. We also give a 2NEXPTIME
complexity result for NatPATL* with the same restriction. In the unrestricted
case, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for
NatPATL*.
</p>
</div>
</dd>
<dt><a name=item551>[551]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12172 title=Abstract>arXiv:2401.12172</a> [<a href=https://arxiv.org/pdf/2401.12172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust stability analysis of an energy-efficient control in a Networked Control System with application to Unmanned Ground Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+A">Antonio Gonzalez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cuenca%2C+A">Angel Cuenca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salt%2C+J">Julian Salt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jacobs%2C+J">Jelle Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 38 pages, 12 figures, Information Sciences, 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>In this paper, the robust stability and disturbance rejection performance
analysis of an energy-efficient control is addressed in the framework of
Networked Control System (NCS). The control scheme under study integrates
periodic event-triggered control, packet-based control, time-varying Kalman
filter, dual-rate control and prediction techniques, whose design is aimed at
reducing energy consumption and bandwidth usage. The robust stability against
time-varying model uncertainties is analyzed by means of a suficient condition
based on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the
proposed approach is experimentally validated in a tracking control for an
Unmanned Ground Vehicle (UGV), which is a battery-constrained mobile device
with limited computation capacities.
</p>
</div>
</dd>
<dt><a name=item552>[552]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12174 title=Abstract>arXiv:2401.12174</a> [<a href=https://arxiv.org/pdf/2401.12174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12174 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IoT-Based Wireless Networkingfor Seismic Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jamali-Rad%2C+H">Hadi Jamali-Rad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Campman%2C+X">Xander Campman</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Geophysical Prospecting 2018
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>We propose to employ a recently developed IoT-based wireless technology, so
called low-power wide-area networks (LPWANs), to exploit their long range, low
power, and inherent compatibility to cloud storage and computing. We create a
remotely-operated minimum-maintenance wireless solution for four major seismic
applications of interest. By proposing appropriate network architecture and
data coordination (aggregation and transmission) designs we show that neither
the low data-rate nor the low duty-cycle of LPWANs impose fundamental issues in
handling a considerable amount of data created by complex seismic scenarios as
long as the application is delay-tolerant. In order to confirm this claim, we
cast our ideas into a practical large-scale networking design for simultaneous
seismic monitoring and interferometry and carry out an analysis on the data
generation and transmission rates. Finally, we present some results from a
small-scale field test in which we have employed our IoT-based wireless nodes
for real-time seismic quality control (QC) over clouds.
</p>
</div>
</dd>
<dt><a name=item553>[553]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12175 title=Abstract>arXiv:2401.12175</a> [<a href=https://arxiv.org/pdf/2401.12175 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12175 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Single-View 3D Human Digitalization with Large Reconstruction Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weng%2C+Z">Zhenzhen Weng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jingyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jimei Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we introduce Human-LRM, a single-stage feed-forward Large
Reconstruction Model designed to predict human Neural Radiance Fields (NeRF)
from a single image. Our approach demonstrates remarkable adaptability in
training using extensive datasets containing 3D scans and multi-view capture.
Furthermore, to enhance the model's applicability for in-the-wild scenarios
especially with occlusions, we propose a novel strategy that distills
multi-view reconstruction into single-view via a conditional triplane diffusion
model. This generative extension addresses the inherent variations in human
body shapes when observed from a single view, and makes it possible to
reconstruct the full body human from an occluded image. Through extensive
experiments, we show that Human-LRM surpasses previous methods by a significant
margin on several benchmarks.
</p>
</div>
</dd>
<dt><a name=item554>[554]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12176 title=Abstract>arXiv:2401.12176</a> [<a href=https://arxiv.org/pdf/2401.12176 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12176 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12176 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ehsan%2C+T+Z">Tahereh Zarrat Ehsan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohtavipour%2C+S+M">Seyed Mehdi Mohtavipour</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Detecting anomalies in poultry houses is crucial for maintaining optimal
chicken health conditions, minimizing economic losses and bolstering
profitability. This paper presents a novel real-time framework for analyzing
chicken behavior in cage-free poultry houses to detect abnormal behaviors.
Specifically, two significant abnormalities, namely inactive broiler and
huddling behavior, are investigated in this study. The proposed framework
comprises three key steps: (1) chicken detection utilizing a state-of-the-art
deep learning model, (2) tracking individual chickens across consecutive frames
with a fast tracker module, and (3) detecting abnormal behaviors within the
video stream. Experimental studies are conducted to evaluate the efficacy of
the proposed algorithm in accurately assessing chicken behavior. The results
illustrate that our framework provides a precise and efficient solution for
real-time anomaly detection, facilitating timely interventions to maintain
chicken health and enhance overall productivity on poultry farms. Github:
https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis
</p>
</div>
</dd>
<dt><a name=item555>[555]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12178 title=Abstract>arXiv:2401.12178</a> [<a href=https://arxiv.org/pdf/2401.12178 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12178 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> In-Context Learning for Extreme Multi-Label Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Oosterlinck%2C+K">Karel D'Oosterlinck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khattab%2C+O">Omar Khattab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Remy%2C+F">François Remy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demeester%2C+T">Thomas Demeester</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Develder%2C+C">Chris Develder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Potts%2C+C">Christopher Potts</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Multi-label classification problems with thousands of classes are hard to
solve with in-context learning alone, as language models (LMs) might lack prior
knowledge about the precise classes or how to assign them, and it is generally
infeasible to demonstrate every class in a prompt. We propose a general
program, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-190-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1051 style=width:13.313em;display:inline-block><span style=display:inline-block;position:relative;width:11.056em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1011.06em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1052><span class=texatom id=MathJax-Span-1053><span class=mrow id=MathJax-Span-1054><span class=mtext id=MathJax-Span-1055 style=font-family:MathJax_Typewriter>Infer--Retrieve--Rank</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>, that defines multi-step interactions
between LMs and retrievers to efficiently tackle such problems. We implement
this program using the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-191-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1056 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.09em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1057><span class=texatom id=MathJax-Span-1058><span class=mrow id=MathJax-Span-1059><span class=mtext id=MathJax-Span-1060 style=font-family:MathJax_Typewriter>DSPy</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> programming model, which specifies
in-context systems in a declarative manner, and use <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-192-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1061 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.09em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1062><span class=texatom id=MathJax-Span-1063><span class=mrow id=MathJax-Span-1064><span class=mtext id=MathJax-Span-1065 style=font-family:MathJax_Typewriter>DSPy</span></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> optimizers
to tune it towards specific datasets by bootstrapping only tens of few-shot
examples. Our primary extreme classification program, optimized separately for
each task, attains state-of-the-art results across three benchmarks (HOUSE,
TECH, TECHWOLF). We apply the same program to a benchmark with vastly different
characteristics and attain competitive performance as well (BioDEX). Unlike
prior work, our proposed solution requires no finetuning, is easily applicable
to new tasks, alleviates prompt engineering, and requires only tens of labeled
examples. Our code is public at https://github.com/KarelDO/xmc.dspy.
</p>
</div>
</dd>
<dt><a name=item556>[556]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12179 title=Abstract>arXiv:2401.12179</a> [<a href=https://arxiv.org/pdf/2401.12179 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12179 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DITTO: Diffusion Inference-Time T-Optimization for Music Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Novack%2C+Z">Zachary Novack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McAuley%2C+J">Julian McAuley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berg-Kirkpatrick%2C+T">Taylor Berg-Kirkpatrick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bryan%2C+N+J">Nicholas J. Bryan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose
frame-work for controlling pre-trained text-to-music diffusion models at
inference-time via optimizing initial noise latents. Our method can be used to
optimize through any differentiable feature matching loss to achieve a target
(stylized) output and leverages gradient checkpointing for memory efficiency.
We demonstrate a surprisingly wide-range of applications for music generation
including inpainting, outpainting, and looping as well as intensity, melody,
and musical structure control - all without ever fine-tuning the underlying
model. When we compare our approach against related training, guidance, and
optimization-based methods, we find DITTO achieves state-of-the-art performance
on nearly all tasks, including outperforming comparable approaches on
controllability, audio quality, and computational efficiency, thus opening the
door for high-quality, flexible, training-free control of diffusion models.
Sound examples can be found at https://DITTO-Music.github.io/web/.
</p>
</div>
</dd>
<dt><a name=item557>[557]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12181 title=Abstract>arXiv:2401.12181</a> [<a href=https://arxiv.org/pdf/2401.12181 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12181 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Neurons in GPT2 Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gurnee%2C+W">Wes Gurnee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horsley%2C+T">Theo Horsley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z+C">Zifan Carl Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kheirkhah%2C+T+R">Tara Rezaei Kheirkhah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qinyi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hathaway%2C+W">Will Hathaway</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nanda%2C+N">Neel Nanda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bertsimas%2C+D">Dimitris Bertsimas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>A basic question within the emerging field of mechanistic interpretability is
the degree to which neural networks learn the same underlying mechanisms. In
other words, are neural mechanisms universal across different models? In this
work, we study the universality of individual neurons across GPT2 models
trained from different initial random seeds, motivated by the hypothesis that
universal neurons are likely to be interpretable. In particular, we compute
pairwise correlations of neuron activations over 100 million tokens for every
neuron pair across five different seeds and find that 1-5\% of neurons are
universal, that is, pairs of neurons which consistently activate on the same
inputs. We then study these universal neurons in detail, finding that they
usually have clear interpretations and taxonomize them into a small number of
neuron families. We conclude by studying patterns in neuron weights to
establish several universal functional roles of neurons in simple circuits:
deactivating attention heads, changing the entropy of the next token
distribution, and predicting the next token to (not) be within a particular
set.
</p>
</div>
</dd>
<dt><a name=item558>[558]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12184 title=Abstract>arXiv:2401.12184</a> [<a href=https://arxiv.org/pdf/2401.12184 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12184 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing Replay Attack Vulnerabilities on Consumer IoT Devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lazzaro%2C+S">Sara Lazzaro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Angelis%2C+V">Vincenzo De Angelis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandalari%2C+A+M">Anna Maria Mandalari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buccafurri%2C+F">Francesco Buccafurri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Consumer Internet of Things (IoT) devices often leverage the local network to
communicate with the corresponding companion app or other devices. This has
benefits in terms of efficiency since it offloads the cloud. ENISA and NIST
security guidelines underscore the importance of enabling default local
communication for safety and reliability. Indeed, an IoT device should continue
to function in case the cloud connection is not available. While the security
of cloud-device connections is typically strengthened through the usage of
standard protocols, local connectivity security is frequently overlooked.
Neglecting the security of local communication opens doors to various threats,
including replay attacks. In this paper, we investigate this class of attacks
by designing a systematic methodology for automatically testing IoT devices
vulnerability to replay attacks. Specifically, we propose a tool, named
REPLIOT, able to test whether a replay attack is successful or not, without
prior knowledge of the target devices. We perform thousands of automated
experiments using popular commercial devices spanning various vendors and
categories. Notably, our study reveals that among these devices, 51% of them do
not support local connectivity, thus they are not compliant with the
reliability and safety requirements of the ENISA/NIST guidelines. We find that
75% of the remaining devices are vulnerable to replay attacks with REPLIOT
having a detection accuracy of 0.98-1. Finally, we investigate the possible
causes of this vulnerability, discussing possible mitigation strategies.
</p>
</div>
</dd>
<dt><a name=item559>[559]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12187 title=Abstract>arXiv:2401.12187</a> [<a href=https://arxiv.org/pdf/2401.12187 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12187 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WARM: On the Benefits of Weight Averaged Reward Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ram%C3%A9%2C+A">Alexandre Ramé</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vieillard%2C+N">Nino Vieillard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hussenot%2C+L">Léonard Hussenot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dadashi%2C+R">Robert Dadashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cideron%2C+G">Geoffrey Cideron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bachem%2C+O">Olivier Bachem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferret%2C+J">Johan Ferret</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Aligning large language models (LLMs) with human preferences through
reinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit
failures in the reward model (RM) to achieve seemingly high rewards without
meeting the underlying objectives. We identify two primary challenges when
designing RMs to mitigate reward hacking: distribution shifts during the RL
process and inconsistencies in human preferences. As a solution, we propose
Weight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then
averaging them in the weight space. This strategy follows the observation that
fine-tuned weights remain linearly mode connected when sharing the same
pre-training. By averaging weights, WARM improves efficiency compared to the
traditional ensembling of predictions, while improving reliability under
distribution shifts and robustness to preference inconsistencies. Our
experiments on summarization tasks, using best-of-N and RL methods, shows that
WARM improves the overall quality and alignment of LLM predictions; for
example, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy
RL fine-tuned with a single RM.
</p>
</div>
</dd>
<dt><a name=item560>[560]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12192 title=Abstract>arXiv:2401.12192</a> [<a href=https://arxiv.org/pdf/2401.12192 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12192 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text Embedding Inversion Attacks on Multilingual Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiyi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lent%2C+H">Heather Lent</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bjerva%2C+J">Johannes Bjerva</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Representing textual information as real-numbered embeddings has become the
norm in NLP. Moreover, with the rise of public interest in large language
models (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as a
business model. This is not without outstanding security risks, as previous
research has demonstrated that sensitive data can be reconstructed from
embeddings, even without knowledge of the underlying model that generated them.
However, such work is limited by its sole focus on English, leaving all other
languages vulnerable to attacks by malicious actors. %As many international and
multilingual companies leverage EaaS, there is an urgent need for research into
multilingual LLM security. To this end, this work investigates LLM security
from the perspective of multilingual embedding inversion. Concretely, we define
the problem of black-box multilingual and cross-lingual inversion attacks, with
special attention to a cross-domain scenario. Our findings reveal that
multilingual models are potentially more vulnerable to inversion attacks than
their monolingual counterparts. This stems from the reduced data requirements
for achieving comparable inversion performance in settings where the underlying
language is not known a-priori. To our knowledge, this work is the first to
delve into multilinguality within the context of inversion attacks, and our
findings highlight the need for further investigation and enhanced defenses in
the area of NLP Security.
</p>
</div>
</dd>
<dt><a name=item561>[561]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12193 title=Abstract>arXiv:2401.12193</a> [<a href=https://arxiv.org/pdf/2401.12193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Programmable EM Sensor Array for Golden-Model Free Run-time Trojan Detection and Localization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hanqiu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panoff%2C+M">Max Panoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+Z">Zihao Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bobda%2C+C">Christophe Bobda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forte%2C+D">Domenic Forte</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures, Accepted at DATE2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Side-channel analysis has been proven effective at detecting hardware Trojans
in integrated circuits (ICs). However, most detection techniques rely on large
external probes and antennas for data collection and require a long measurement
time to detect Trojans. Such limitations make these techniques impractical for
run-time deployment and ineffective in detecting small Trojans with subtle
side-channel signatures. To overcome these challenges, we propose a
Programmable Sensor Array (PSA) for run-time hardware Trojan detection,
localization, and identification. PSA is a tampering-resilient integrated
on-chip magnetic field sensor array that can be re-programmed to change the
sensors' shape, size, and location. Using PSA, EM side-channel measurement
results collected from sensors at different locations on an IC can be analyzed
to localize and identify the Trojan. The PSA has better performance than
conventional external magnetic probes and state-of-the-art on-chip single-coil
magnetic field sensors. We fabricated an AES-128 test chip with four AES
Hardware Trojans. They were successfully detected, located, and identified with
the proposed on-chip PSA within 10 milliseconds using our proposed cross-domain
analysis.
</p>
</div>
</dd>
<dt><a name=item562>[562]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12198 title=Abstract>arXiv:2401.12198</a> [<a href=https://arxiv.org/pdf/2401.12198 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12198 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LONEStar: The Lunar Flashlight Optical Navigation Experiment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krause%2C+M">Michael Krause</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thrasher%2C+A">Ava Thrasher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soni%2C+P">Priyal Soni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smego%2C+L">Liam Smego</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isaac%2C+R">Reuben Isaac</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nolan%2C+J">Jennifer Nolan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pledger%2C+M">Micah Pledger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lightsey%2C+E+G">E. Glenn Lightsey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ready%2C+W+J">W. Jud Ready</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Christian%2C+J">John Christian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Space Physics (physics.space-ph)
</div>
<p class=mathjax>This paper documents the results from the highly successful Lunar flashlight
Optical Navigation Experiment with a Star tracker (LONEStar). Launched in
December 2022, Lunar Flashlight (LF) was a NASA-funded technology demonstration
mission. After a propulsion system anomaly prevented capture in lunar orbit, LF
was ejected from the Earth-Moon system and into heliocentric space. NASA
subsequently transferred ownership of LF to Georgia Tech to conduct an unfunded
extended mission to demonstrate further advanced technology objectives,
including LONEStar. From August-December 2023, the LONEStar team performed
on-orbit calibration of the optical instrument and a number of different OPNAV
experiments. This campaign included the processing of nearly 400 images of star
fields, Earth and Moon, and four other planets (Mercury, Mars, Jupiter, and
Saturn). LONEStar provided the first on-orbit demonstrations of heliocentric
navigation using only optical observations of planets. Of special note is the
successful in-flight demonstration of (1) instantaneous triangulation with
simultaneous sightings of two planets with the LOST algorithm and (2) dynamic
triangulation with sequential sightings of multiple planets.
</p>
</div>
</dd>
<dt><a name=item563>[563]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12200 title=Abstract>arXiv:2401.12200</a> [<a href=https://arxiv.org/pdf/2401.12200 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12200 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+B">Bowen Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Q">Qingqing Cao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Fine-tuning and inference with large Language Models (LM) are generally known
to be expensive. Parameter-efficient fine-tuning over pretrained LMs reduces
training memory by updating a small number of LM parameters but does not
improve inference efficiency. Structured pruning improves LM inference
efficiency by removing consistent parameter blocks, yet often increases
training memory and time. To improve both training and inference efficiency, we
introduce APT that adaptively prunes and tunes parameters for the LMs. At the
early stage of fine-tuning, APT dynamically adds salient tuning parameters for
fast and accurate convergence while discarding unimportant parameters for
efficiency. Compared to baselines, our experiments show that APT maintains up
to 98% task performance when pruning RoBERTa and T5 models with 40% parameters
left while keeping 86.4% LLaMA models' performance with 70% parameters
remained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduces
large LMs memory training footprint by up to 70%.
</p>
</div>
</dd>
<dt><a name=item564>[564]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12202 title=Abstract>arXiv:2401.12202</a> [<a href=https://arxiv.org/pdf/2401.12202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P">Peiqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orru%2C+Y">Yaswanth Orru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paxton%2C+C">Chris Paxton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shafiullah%2C+N+M+M">Nur Muhammad Mahi Shafiullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinto%2C+L">Lerrel Pinto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Remarkable progress has been made in recent years in the fields of vision,
language, and robotics. We now have vision models capable of recognizing
objects based on language queries, navigation systems that can effectively
control mobile systems, and grasping models that can handle a wide range of
objects. Despite these advancements, general-purpose applications of robotics
still lag behind, even though they rely on these fundamental capabilities of
recognition, navigation, and grasping. In this paper, we adopt a systems-first
approach to develop a new Open Knowledge-based robotics framework called
OK-Robot. By combining Vision-Language Models (VLMs) for object detection,
navigation primitives for movement, and grasping primitives for object
manipulation, OK-Robot offers a integrated solution for pick-and-drop
operations without requiring any training. To evaluate its performance, we run
OK-Robot in 10 real-world home environments. The results demonstrate that
OK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,
representing a new state-of-the-art in Open Vocabulary Mobile Manipulation
(OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered
environments, OK-Robot's performance increases to 82%. However, the most
important insight gained from OK-Robot is the critical role of nuanced details
when combining Open Knowledge systems like VLMs with robotic modules. Videos of
our experiments are available on our website: https://ok-robot.github.io
</p>
</div>
</dd>
<dt><a name=item565>[565]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12205 title=Abstract>arXiv:2401.12205</a> [<a href=https://arxiv.org/pdf/2401.12205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+A+B">Animesh Basak Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romanelli%2C+M">Marco Romanelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+B">Benjamin Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karri%2C+R">Ramesh Karri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garg%2C+S">Siddharth Garg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)
</div>
<p class=mathjax>Logic synthesis, a pivotal stage in chip design, entails optimizing chip
specifications encoded in hardware description languages like Verilog into
highly efficient implementations using Boolean logic gates. The process
involves a sequential application of logic minimization heuristics (``synthesis
recipe"), with their arrangement significantly impacting crucial metrics such
as area and delay. Addressing the challenge posed by the broad spectrum of
design complexities - from variations of past designs (e.g., adders and
multipliers) to entirely novel configurations (e.g., innovative processor
instructions) - requires a nuanced `synthesis recipe` guided by human expertise
and intuition. This study conducts a thorough examination of learning and
search techniques for logic synthesis, unearthing a surprising revelation:
pre-trained agents, when confronted with entirely novel designs, may veer off
course, detrimentally affecting the search trajectory. We present ABC-RL, a
meticulously tuned <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-193-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1066 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1067><span class=mi id=MathJax-Span-1068 style=font-family:MathJax_Math-italic>α</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> parameter that adeptly adjusts recommendations from
pre-trained agents during the search process. Computed based on similarity
scores through nearest neighbor retrieval from the training dataset, ABC-RL
yields superior synthesis recipes tailored for a wide array of hardware
designs. Our findings showcase substantial enhancements in the
Quality-of-result (QoR) of synthesized circuits, boasting improvements of up to
24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an
impressive up to 9x reduction in runtime (iso-QoR) when compared to current
state-of-the-art methodologies.
</p>
</div>
</dd>
<dt><a name=item566>[566]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12207 title=Abstract>arXiv:2401.12207</a> [<a href=https://arxiv.org/pdf/2401.12207 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12207 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rate-Distortion-Perception Tradeoff Based on the Conditional-Distribution Perception Measure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salehkalaibar%2C+S">Sadaf Salehkalaibar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khisti%2C+A">Ashish Khisti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+W">Wei Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We study the rate-distortion-perception (RDP) tradeoff for a memoryless
source model in the asymptotic limit of large block-lengths. Our perception
measure is based on a divergence between the distributions of the source and
reconstruction sequences conditioned on the encoder output, which was first
proposed in [1], [2]. We consider the case when there is no shared randomness
between the encoder and the decoder. For the case of discrete memoryless
sources we derive a single-letter characterization of the RDP function, thus
settling a problem that remains open for the marginal metric introduced in Blau
and Michaeli [3] (with no shared randomness). Our achievability scheme is based
on lossy source coding with a posterior reference map proposed in [4]. For the
case of continuous valued sources under squared error distortion measure and
squared quadratic Wasserstein perception measure we also derive a single-letter
characterization and show that a noise-adding mechanism at the decoder suffices
to achieve the optimal representation. For the case of zero perception loss, we
show that our characterization interestingly coincides with the results for the
marginal metric derived in [5], [6] and again demonstrate that zero perception
loss can be achieved with a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-194-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1069 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1070><span class=mn id=MathJax-Span-1071 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-dB penalty in the minimum distortion. Finally
we specialize our results to the case of Gaussian sources. We derive the RDP
function for vector Gaussian sources and propose a waterfilling type solution.
We also partially characterize the RDP function for a mixture of vector
Gaussians.
</p>
</div>
</dd>
<dt><a name=item567>[567]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12208 title=Abstract>arXiv:2401.12208</a> [<a href=https://arxiv.org/pdf/2401.12208 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12208 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhihong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varma%2C+M">Maya Varma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delbrouck%2C+J">Jean-Benoit Delbrouck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paschali%2C+M">Magdalini Paschali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blankemeier%2C+L">Louis Blankemeier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Veen%2C+D">Dave Van Veen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valanarasu%2C+J+M+J">Jeya Maria Jose Valanarasu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Youssef%2C+A">Alaa Youssef</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+J+P">Joseph Paul Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reis%2C+E+P">Eduardo Pontes Reis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+E+B">Emily B. Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johnston%2C+A">Andrew Johnston</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olsen%2C+C">Cameron Olsen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abraham%2C+T+M">Tanishq Mathew Abraham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gatidis%2C+S">Sergios Gatidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhari%2C+A+S">Akshay S. Chaudhari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langlotz%2C+C">Curtis Langlotz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Chest X-rays (CXRs) are the most frequently performed imaging test in
clinical practice. Recent advances in the development of vision-language
foundation models (FMs) give rise to the possibility of performing automated
CXR interpretation, which can assist physicians with clinical decision-making
and improve patient outcomes. However, developing FMs that can accurately
interpret CXRs is challenging due to the (1) limited availability of
large-scale vision-language datasets in the medical image domain, (2) lack of
vision and language encoders that can capture the complexities of medical data,
and (3) absence of evaluation frameworks for benchmarking the abilities of FMs
on CXR interpretation. In this work, we address these challenges by first
introducing \emph{CheXinstruct} - a large-scale instruction-tuning dataset
curated from 28 publicly-available datasets. We then present \emph{CheXagent} -
an instruction-tuned FM capable of analyzing and summarizing CXRs. To build
CheXagent, we design a clinical large language model (LLM) for parsing
radiology reports, a vision encoder for representing CXR images, and a network
to bridge the vision and language modalities. Finally, we introduce
\emph{CheXbench} - a novel benchmark designed to systematically evaluate FMs
across 8 clinically-relevant CXR interpretation tasks. Extensive quantitative
evaluations and qualitative reviews with five expert radiologists demonstrate
that CheXagent outperforms previously-developed general- and medical-domain FMs
on CheXbench tasks. Furthermore, in an effort to improve model transparency, we
perform a fairness evaluation across factors of sex, race and age to highlight
potential performance disparities. Our project is at
\url{https://stanford-aimi.github.io/chexagent.html}.
</p>
</div>
</dd>
<dt><a name=item568>[568]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12210 title=Abstract>arXiv:2401.12210</a> [<a href=https://arxiv.org/pdf/2401.12210 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12210 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Connecting the Dots: Leveraging Spatio-Temporal Graph Neural Networks for Accurate Bangla Sign Language Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahgir%2C+H+S">Haz Sameen Shahgir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sayeed%2C+K+S">Khondker Salman Sayeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tahmid%2C+M+T">Md Toki Tahmid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaman%2C+T+A">Tanjeem Azwad Zaman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alam%2C+M+Z+U">Md. Zarif Ul Alam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent advances in Deep Learning and Computer Vision have been successfully
leveraged to serve marginalized communities in various contexts. One such area
is Sign Language - a primary means of communication for the deaf community.
However, so far, the bulk of research efforts and investments have gone into
American Sign Language, and research activity into low-resource sign languages
- especially Bangla Sign Language - has lagged significantly. In this research
paper, we present a new word-level Bangla Sign Language dataset - BdSL40 -
consisting of 611 videos over 40 words, along with two different approaches:
one with a 3D Convolutional Neural Network model and another with a novel Graph
Neural Network approach for the classification of BdSL40 dataset. This is the
first study on word-level BdSL recognition, and the dataset was transcribed
from Indian Sign Language (ISL) using the Bangla Sign Language Dictionary
(1997). The proposed GNN model achieved an F1 score of 89%. The study
highlights the significant lexical and semantic similarity between BdSL, West
Bengal Sign Language, and ISL, and the lack of word-level datasets for BdSL in
the literature. We release the dataset and source code to stimulate further
research.
</p>
</div>
</dd>
<dt><a name=item569>[569]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12212 title=Abstract>arXiv:2401.12212</a> [<a href=https://arxiv.org/pdf/2401.12212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12212 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Genericity Through Stratification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arrial%2C+V">Victor Arrial</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrieri%2C+G">Giulio Guerrieri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kesner%2C+D">Delia Kesner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)
</div>
<p class=mathjax>A fundamental issue in the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-195-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1072 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1073><span class=mi id=MathJax-Span-1074 style=font-family:MathJax_Math-italic>λ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-calculus is to find appropriate notions
for meaningfulness. Inspired by well-known results for the call-by-name
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-196-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1075 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1076><span class=mi id=MathJax-Span-1077 style=font-family:MathJax_Math-italic>λ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-calculus (CbN), where meaningful terms are identified to the solvable
ones, this paper validates the challenging claim that the notion of potential
valuability (aka scrutability), previously introduced in the literature,
adequately represents meaningfulness in the call-by-value <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-197-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1078 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1079><span class=mi id=MathJax-Span-1080 style=font-family:MathJax_Math-italic>λ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-calculus
(CbV). Akin to CbN, this claim is corroborated by proving two essential
properties. The first one is genericity, stating that meaningless subterms have
no bearing on evaluating normalizing terms. To prove this, we use a novel
approach based on stratified reduction, indifferently applicable to CbN and
CbV. The second property concerns consistency of the smallest congruence
relation resulting from equating all meaningless terms (without equating all
terms). We also show that such a congruence has a unique consistent and maximal
extension, which coincides with a natural notion of observational equivalence.
Our results thus supply the formal concepts and tools that validate the
informal notion of meaningfulness underlying CbN and CbV.
</p>
</div>
</dd>
<dt><a name=item570>[570]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12214 title=Abstract>arXiv:2401.12214</a> [<a href=https://arxiv.org/pdf/2401.12214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Elsherif%2C+S+M">Salma M. Elsherif</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kazma%2C+M+H">Mohamad H. Kazma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The operation of water distribution networks is a complex procedure aimed at
efficiently delivering consumers with adequate water quantity while ensuring
its safe quality. An added challenge is the dependency of the water quality
dynamics on the system's hydraulics, which influences the performance of the
water quality controller. Prior research has addressed either solving the
optimum operational hydraulic setting problem or regulating the water quality
dynamics as separate problems. Additionally, there have been efforts to couple
these two problems and solve one compact problem resulting in trade-offs
between the contradictory objectives. In contrast, this paper examines the
dependency and influence from a control-theoretic standpoint. More
specifically, we explore the influence of accountability for water quality
controllability improvement when addressing the pump scheduling problem. We
examine its effects on the cumulative cost of the interconnected systems as
well as the subsequent performance of the water quality controller. To achieve
this, we develop a framework that incorporates different controllability
metrics within the operational hydraulic optimization problem; its aim is
attaining an adequate level of water quality control across the system. We
assess the aforementioned aspects' performance on various scaled networks with
a wide range of numerical scenarios.
</p>
</div>
</dd>
<dt><a name=item571>[571]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12215 title=Abstract>arXiv:2401.12215</a> [<a href=https://arxiv.org/pdf/2401.12215 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12215 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12215 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+C">Chenyu Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hong-Yu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yizhou Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liansheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Parameter-efficient fine-tuning (PEFT) that was initially developed for
exploiting pre-trained large language models has recently emerged as an
effective approach to perform transfer learning on computer vision tasks.
However, the effectiveness of PEFT on medical vision foundation models is still
unclear and remains to be explored. As a proof of concept, we conducted a
detailed empirical study on applying PEFT to chest radiography foundation
models. Specifically, we delved into LoRA, a representative PEFT method, and
compared it against full-parameter fine-tuning (FFT) on two self-supervised
radiography foundation models across three well-established chest radiograph
datasets. Our results showed that LoRA outperformed FFT in 13 out of 18
transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters.
Combining LoRA with foundation models, we set up new state-of-the-art on a
range of data-efficient learning tasks, such as an AUROC score of 80.6% using
1% labeled data on NIH ChestX-ray14. We hope this study can evoke more
attention from the community in the use of PEFT for transfer learning on
medical imaging tasks. Code and models are available at
https://github.com/RL4M/MED-PEFT.
</p>
</div>
</dd>
<dt><a name=item572>[572]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12217 title=Abstract>arXiv:2401.12217</a> [<a href=https://arxiv.org/pdf/2401.12217 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12217 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Simple Open-Vocabulary Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+Z">Zihang Lai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code is available at: <a href=https://github.com/zlai0/S-Seg>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Open-vocabulary semantic segmentation models aim to accurately assign a
semantic label to each pixel in an image from a set of arbitrary
open-vocabulary texts. In order to learn such pixel-level alignment, current
approaches typically rely on a combination of (i) image-level VL model (e.g.
CLIP), (ii) ground truth masks, and (iii) custom grouping encoders. In this
paper, we introduce S-Seg, a novel model that can achieve surprisingly strong
performance without depending on any of the above elements. S-Seg leverages
pseudo-mask and language to train a MaskFormer, and can be easily trained from
publicly available image-text datasets. Contrary to prior works, our model
directly trains for pixel-level features and language alignment. Once trained,
S-Seg generalizes well to multiple testing datasets without requiring
fine-tuning. In addition, S-Seg has the extra benefits of scalability with data
and consistently improvement when augmented with self-training. We believe that
our simple yet effective approach will serve as a solid baseline for future
research.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 23 Jan 24</h3>
<dl>
<dt><a name=item573>[573]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10903 title=Abstract>arXiv:2401.10903</a> (cross-list from q-fin.ST) [<a href=https://arxiv.org/pdf/2401.10903 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10903 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Huang%2C+D">Dengxin Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Applications (stat.AP)
</div>
<p class=mathjax>This document presents a stock market analysis conducted on a dataset
consisting of 750 instances and 16 attributes donated in 2014-10-23. The
analysis includes an exploratory data analysis (EDA) section, feature
engineering, data preparation, model selection, and insights from the analysis.
The Fama French 3-factor model is also utilized in the analysis. The results of
the analysis are presented, with linear regression being the best-performing
model.
</p>
</div>
</dd>
<dt><a name=item574>[574]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10910 title=Abstract>arXiv:2401.10910</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2401.10910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Toy%2C+J">Jason Toy</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=MacAdam%2C+J">Josh MacAdam</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Tabor%2C+P">Phil Tabor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recent advances in Large Language Models (LLMs) have shown impressive
capabilities in various applications, yet LLMs face challenges such as limited
context windows and difficulties in generalization. In this paper, we introduce
a metacognition module for generative agents, enabling them to observe their
own thought processes and actions. This metacognitive approach, designed to
emulate System 1 and System 2 cognitive processes, allows agents to
significantly enhance their performance by modifying their strategy. We tested
the metacognition module on a variety of scenarios, including a situation where
generative agents must survive a zombie apocalypse, and observe that our system
outperform others, while agents adapt and improve their strategies to complete
tasks over time.
</p>
</div>
</dd>
<dt><a name=item575>[575]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10927 title=Abstract>arXiv:2401.10927</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.10927 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10927 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10927 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Debiasing and a local analysis for population clustering using semidefinite programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhou%2C+S">Shuheng Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2301.00344>arXiv:2301.00344</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we consider the problem of partitioning a small data sample of
size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-198-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1081 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1082><span class=mi id=MathJax-Span-1083 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> drawn from a mixture of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-199-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1084 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1085><span class=mn id=MathJax-Span-1086 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> sub-gaussian distributions. In particular,
we analyze computational efficient algorithms proposed by the same author, to
partition data into two groups approximately according to their population of
origin given a small sample. This work is motivated by the application of
clustering individuals according to their population of origin using <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-200-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1087 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1088><span class=mi id=MathJax-Span-1089 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>
markers, when the divergence between any two of the populations is small. We
build upon the semidefinite relaxation of an integer quadratic program that is
formulated essentially as finding the maximum cut on a graph, where edge
weights in the cut represent dissimilarity scores between two nodes based on
their <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-201-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1090 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1091><span class=mi id=MathJax-Span-1092 style=font-family:MathJax_Math-italic>p</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> features. Here we use <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-202-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1093 style=width:4.748em;display:inline-block><span style=display:inline-block;position:relative;width:3.938em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.94em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1094><span class=msubsup id=MathJax-Span-1095><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1096 style=font-family:MathJax_Main>Δ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.813em><span class=mn id=MathJax-Span-1097 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1098 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=mi id=MathJax-Span-1099 style=font-family:MathJax_Math-italic;padding-left:0.292em>p</span><span class=mi id=MathJax-Span-1100 style=font-family:MathJax_Math-italic>γ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.392em"></span></span></nobr></span> to denote the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-203-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1101 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.87em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1102><span class=msubsup id=MathJax-Span-1103><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1104 style=font-family:MathJax_Main>ℓ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-4.337em;left:0.408em><span class=mn id=MathJax-Span-1105 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.701em;left:0.408em><span class=mn id=MathJax-Span-1106 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
distance between two centers (mean vectors), namely, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-204-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1107 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.57em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1108><span class=msubsup id=MathJax-Span-1109><span style=display:inline-block;position:relative;width:1.565em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1110 style=font-family:MathJax_Math-italic>μ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1111><span class=mrow id=MathJax-Span-1112><span class=mo id=MathJax-Span-1113 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1114 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1115 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-205-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1116 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.57em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1117><span class=msubsup id=MathJax-Span-1118><span style=display:inline-block;position:relative;width:1.565em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1119 style=font-family:MathJax_Math-italic>μ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1120><span class=mrow id=MathJax-Span-1121><span class=mo id=MathJax-Span-1122 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1123 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-1124 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-206-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1125 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1000.64em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1126><span class=mo id=MathJax-Span-1127 style=font-family:MathJax_Main>∈</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-207-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1128 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1129><span class=msubsup id=MathJax-Span-1130><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-1131><span class=mrow id=MathJax-Span-1132><span class=mi id=MathJax-Span-1133 style=font-family:MathJax_AMS>R</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.697em><span class=mi id=MathJax-Span-1134 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. The goal is to allow a full range of tradeoffs between
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-208-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1135 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.55em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1136><span class=mi id=MathJax-Span-1137 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1138 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1139 style=font-family:MathJax_Math-italic;padding-left:0.177em>p</span><span class=mo id=MathJax-Span-1140 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1141 style=font-family:MathJax_Math-italic;padding-left:0.177em>γ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> in the sense that partial recovery (success rate <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-209-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1142 style=width:4.112em;display:inline-block><span style=display:inline-block;position:relative;width:3.417em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.36em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1143><span class=mo id=MathJax-Span-1144 style=font-family:MathJax_Main>&lt;</span><span class=mn id=MathJax-Span-1145 style=font-family:MathJax_Main;padding-left:0.292em>100</span><span class=mi id=MathJax-Span-1146 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>) is
feasible once the signal to noise ratio <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-210-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1147 style=width:10.998em;display:inline-block><span style=display:inline-block;position:relative;width:9.146em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1009.09em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1148><span class=msubsup id=MathJax-Span-1149><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1150 style=font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=mn id=MathJax-Span-1151 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1152 style=font-family:MathJax_Main;padding-left:0.292em>:<span style=font-family:MathJax_Main>=</span></span><span class=mo id=MathJax-Span-1153 style=font-family:MathJax_Main;padding-left:0.292em>min</span><span class=mo id=MathJax-Span-1154 style=font-family:MathJax_Main>{</span><span class=mi id=MathJax-Span-1155 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-1156 style=font-family:MathJax_Math-italic>p</span><span class=msubsup id=MathJax-Span-1157><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1158 style=font-family:MathJax_Math-italic>γ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-1159 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1160 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-1161 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1162 style=font-family:MathJax_Main>Δ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.813em><span class=mn id=MathJax-Span-1163 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1164 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
is lower bounded by a constant. Importantly, we prove that the
misclassification error decays exponentially with respect to the SNR <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-211-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1165 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1000.93em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1166><span class=msubsup id=MathJax-Span-1167><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1168 style=font-family:MathJax_Math-italic>s</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=mn id=MathJax-Span-1169 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>.
This result was introduced earlier without a full proof. We therefore present
the full proof in the present work. Finally, for balanced partitions, we
consider a variant of the SDP1, and show that the new estimator has a superb
debiasing property. This is novel to the best of our knowledge.
</p>
</div>
</dd>
<dt><a name=item576>[576]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10931 title=Abstract>arXiv:2401.10931</a> (cross-list from q-fin.ST) [<a href=https://arxiv.org/pdf/2401.10931 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10931 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Forecasting Cryptocurrency Staking Rewards
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Gupta%2C+S">Sauren Gupta</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Katharaki%2C+A+H">Apoorva Hathi Katharaki</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Xu%2C+Y">Yifan Xu</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Gupta%2C+R">Rajarshi Gupta</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 18 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistical Finance (q-fin.ST)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
<p class=mathjax>This research explores a relatively unexplored area of predicting
cryptocurrency staking rewards, offering potential insights to researchers and
investors. We investigate two predictive methodologies: a) a straightforward
sliding-window average, and b) linear regression models predicated on
historical data. The findings reveal that ETH staking rewards can be forecasted
with an RMSE within 0.7% and 1.1% of the mean value for 1-day and 7-day
look-aheads respectively, using a 7-day sliding-window average approach.
Additionally, we discern diverse prediction accuracies across various
cryptocurrencies, including SOL, XTZ, ATOM, and MATIC. Linear regression is
identified as superior to the moving-window average for perdicting in the short
term for XTZ and ATOM. The results underscore the generally stable and
predictable nature of staking rewards for most assets, with MATIC presenting a
noteworthy exception.
</p>
</div>
</dd>
<dt><a name=item577>[577]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10937 title=Abstract>arXiv:2401.10937</a> (cross-list from econ.TH) [<a href=https://arxiv.org/pdf/2401.10937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10937 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Subjective Causality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Halpern%2C+J+Y">Joseph Y. Halpern</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Piermont%2C+E">Evan Piermont</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>We show that it is possible to understand and identify a decision maker's
subjective causal judgements by observing her preferences over interventions.
Following Pearl [2000], we represent causality using causal models (also called
structural equations models), where the world is described by a collection of
variables, related by equations. We show that if a preference relation over
interventions satisfies certain axioms (related to standard axioms regarding
counterfactuals), then we can define (i) a causal model, (ii) a probability
capturing the decision-maker's uncertainty regarding the external factors in
the world and (iii) a utility on outcomes such that each intervention is
associated with an expected utility and such that intervention <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-212-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1170 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1171><span class=mi id=MathJax-Span-1172 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is preferred
to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-213-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1173 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1174><span class=mi id=MathJax-Span-1175 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> iff the expected utility of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-214-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1176 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1177><span class=mi id=MathJax-Span-1178 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is greater than that of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-215-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1179 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1180><span class=mi id=MathJax-Span-1181 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In
addition, we characterize when the causal model is unique. Thus, our results
allow a modeler to test the hypothesis that a decision maker's preferences are
consistent with some causal model and to identify causal judgements from
observed behavior.
</p>
</div>
</dd>
<dt><a name=item578>[578]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10972 title=Abstract>arXiv:2401.10972</a> (cross-list from q-bio.BM) [<a href=https://arxiv.org/pdf/2401.10972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Clustering Molecular Energy Landscapes by Adaptive Network Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Mercurio%2C+P">Paula Mercurio</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Liu%2C+D">Di Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)
</div>
<p class=mathjax>In order to efficiently explore the chemical space of all possible small
molecules, a common approach is to compress the dimension of the system to
facilitate downstream machine learning tasks. Towards this end, we present a
data driven approach for clustering potential energy landscapes of molecular
structures by applying recently developed Network Embedding techniques, to
obtain latent variables defined through the embedding function. To scale up the
method, we also incorporate an entropy sensitive adaptive scheme for
hierarchical sampling of the energy landscape, based on Metadynamics and
Transition Path Theory. By taking into account the kinetic information implied
by a system's energy landscape, we are able to interpret dynamical node-node
relationships in reduced dimensions. We demonstrate the framework through
Lennard-Jones (LJ) clusters and a human DNA sequence.
</p>
</div>
</dd>
<dt><a name=item579>[579]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10989 title=Abstract>arXiv:2401.10989</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.10989 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10989 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Provably Scalable Black-Box Variational Inference with Structured Variational Families
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ko%2C+J">Joohwan Ko</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kim%2C+K">Kyurae Kim</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kim%2C+W+C">Woo Chang Kim</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)
</div>
<p class=mathjax>Variational families with full-rank covariance approximations are known not
to work well in black-box variational inference (BBVI), both empirically and
theoretically. In fact, recent computational complexity results for BBVI have
established that full-rank variational families scale poorly with the
dimensionality of the problem compared to e.g. mean field families. This is
particularly critical to hierarchical Bayesian models with local variables;
their dimensionality increases with the size of the datasets. Consequently, one
gets an iteration complexity with an explicit <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-216-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1182 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1183><span class=texatom id=MathJax-Span-1184><span class=mrow id=MathJax-Span-1185><span class=mi id=MathJax-Span-1186 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-1187 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1188><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1189 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mn id=MathJax-Span-1190 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1191 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> dependence on
the dataset size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-217-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1192 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1193><span class=mi id=MathJax-Span-1194 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In this paper, we explore a theoretical middle ground
between mean-field variational families and full-rank families: structured
variational families. We rigorously prove that certain scale matrix structures
can achieve a better iteration complexity of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-218-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1195 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1196><span class=texatom id=MathJax-Span-1197><span class=mrow id=MathJax-Span-1198><span class=mi id=MathJax-Span-1199 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-1200 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1201 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1202 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, implying better
scaling with respect to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-219-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1203 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1204><span class=mi id=MathJax-Span-1205 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We empirically verify our theoretical results on
large-scale hierarchical models.
</p>
</div>
</dd>
<dt><a name=item580>[580]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11017 title=Abstract>arXiv:2401.11017</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11017 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11017 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revealing Emotional Clusters in Speaker Embeddings: A Contrastive Learning Strategy for Speech Emotion Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ulgen%2C+I+R">Ismail Rasim Ulgen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+Z">Zongyang Du</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Busso%2C+C">Carlos Busso</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sisman%2C+B">Berrak Sisman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
<p class=mathjax>Speaker embeddings carry valuable emotion-related information, which makes
them a promising resource for enhancing speech emotion recognition (SER),
especially with limited labeled data. Traditionally, it has been assumed that
emotion information is indirectly embedded within speaker embeddings, leading
to their under-utilization. Our study reveals a direct and useful link between
emotion and state-of-the-art speaker embeddings in the form of intra-speaker
clusters. By conducting a thorough clustering analysis, we demonstrate that
emotion information can be readily extracted from speaker embeddings. In order
to leverage this information, we introduce a novel contrastive pretraining
approach applied to emotion-unlabeled data for speech emotion recognition. The
proposed approach involves the sampling of positive and the negative examples
based on the intra-speaker clusters of speaker embeddings. The proposed
strategy, which leverages extensive emotion-unlabeled data, leads to a
significant improvement in SER performance, whether employed as a standalone
pretraining task or integrated into a multi-task pretraining setting.
</p>
</div>
</dd>
<dt><a name=item581>[581]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11023 title=Abstract>arXiv:2401.11023</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11023 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11023 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum circuit model for discrete-time three-state quantum walks on Cayley graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Sarkar%2C+R+S">Rohit Sarma Sarkar</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Adhikari%2C+B">Bibhas Adhikari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>We develop qutrit circuit models for discrete-time three-state quantum walks
on Cayley graphs corresponding to Dihedral groups <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-220-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1206 style=width:1.855em;display:inline-block><span style=display:inline-block;position:relative;width:1.508em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.51em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1207><span class=msubsup id=MathJax-Span-1208><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1209 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-1210 style=font-size:70.7%;font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and the additive groups
of integers modulo any positive integer <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-221-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1211 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1212><span class=mi id=MathJax-Span-1213 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. The proposed circuits comprise of
elementary qutrit gates such as qutrit rotation gates, qutrit-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-222-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1214 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1215><span class=mi id=MathJax-Span-1216 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> gates and
two-qutrit controlled-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-223-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1217 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1218><span class=mi id=MathJax-Span-1219 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> gates. First, we propose qutrit circuit
representation of special unitary matrices of order three, and the block
diagonal special unitary matrices with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-224-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1220 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1221><span class=mn id=MathJax-Span-1222 style=font-family:MathJax_Main>3</span><span class=mo id=MathJax-Span-1223 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mn id=MathJax-Span-1224 style=font-family:MathJax_Main;padding-left:0.234em>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> diagonal blocks, which
correspond to multi-controlled <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-225-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1225 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1226><span class=mi id=MathJax-Span-1227 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> gates and permutations of qutrit Toffoli
gates. We show that one-layer qutrit circuit model need <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-226-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1228 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1229><span class=mi id=MathJax-Span-1230 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1231 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1232 style=font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-1233 style=font-family:MathJax_Math-italic>n</span><span class=mi id=MathJax-Span-1234 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1235 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> two-qutrit
control gates and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-227-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1236 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1237><span class=mi id=MathJax-Span-1238 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1239 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1240 style=font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-1241 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1242 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> one-qutrit rotation gates for these quantum walks
when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-228-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1243 style=width:3.938em;display:inline-block><span style=display:inline-block;position:relative;width:3.244em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.24em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1244><span class=mi id=MathJax-Span-1245 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1246 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-1247 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1248 style=font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-1249 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Finally, we numerically simulate these circuits to mimic its
performance such as time-averaged probability of finding the walker at any
vertex on noisy quantum computers. The simulated results for the time-averaged
probability distributions for noisy and noiseless walks are further compared
using KL-divergence and total variation distance. These results show that noise
in gates in the circuits significantly impacts the distributions than amplitude
damping or phase damping errors.
</p>
</div>
</dd>
<dt><a name=item582>[582]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11053 title=Abstract>arXiv:2401.11053</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yuanzhe Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+X">Xinsheng Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xie%2C+L">Lei Xie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuping Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuxuan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Recent language model (LM) advancements have showcased impressive zero-shot
voice conversion (VC) performance. However, existing LM-based VC models usually
apply offline conversion from source semantics to acoustic features, demanding
the complete source speech, and limiting their deployment to real-time
applications. In this paper, we introduce StreamVoice, a novel streaming
LM-based model for zero-shot VC, facilitating real-time conversion given
arbitrary speaker prompts and source speech. Specifically, to enable streaming
capability, StreamVoice employs a fully causal context-aware LM with a
temporal-independent acoustic predictor, while alternately processing semantic
and acoustic features at each time step of autoregression which eliminates the
dependence on complete source speech. To address the potential performance
degradation from the incomplete context in streaming processing, we enhance the
context-awareness of the LM through two strategies: 1) teacher-guided context
foresight, using a teacher model to summarize the present and future semantic
context during training to guide the model's forecasting for missing context;
2) semantic masking strategy, promoting acoustic prediction from preceding
corrupted semantic and acoustic input, enhancing context-learning ability.
Notably, StreamVoice is the first LM-based streaming zero-shot VC model without
any future look-ahead. Experimental results demonstrate StreamVoice's streaming
conversion capability while maintaining zero-shot performance comparable to
non-streaming VC systems.
</p>
</div>
</dd>
<dt><a name=item583>[583]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11098 title=Abstract>arXiv:2401.11098</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural auto-designer for enhanced quantum kernels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Lei%2C+C">Cong Lei</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Du%2C+Y">Yuxuan Du</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Mi%2C+P">Peng Mi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Yu%2C+J">Jun Yu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 14 figures, 9 tables, ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Quantum kernels hold great promise for offering computational advantages over
classical learners, with the effectiveness of these kernels closely tied to the
design of the quantum feature map. However, the challenge of designing
effective quantum feature maps for real-world datasets, particularly in the
absence of sufficient prior information, remains a significant obstacle. In
this study, we present a data-driven approach that automates the design of
problem-specific quantum feature maps. Our approach leverages feature-selection
techniques to handle high-dimensional data on near-term quantum machines with
limited qubits, and incorporates a deep neural predictor to efficiently
evaluate the performance of various candidate quantum kernels. Through
extensive numerical simulations on different datasets, we demonstrate the
superiority of our proposal over prior methods, especially for the capability
of eliminating the kernel concentration issue and identifying the feature map
with prediction advantages. Our work not only unlocks the potential of quantum
kernels for enhancing real-world tasks but also highlights the substantial role
of deep learning in advancing quantum machine learning.
</p>
</div>
</dd>
<dt><a name=item584>[584]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11117 title=Abstract>arXiv:2401.11117</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.11117 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11117 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11117 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Finger on the Pulse of Cardiovascular Health: Smartphone Photoplethysmography-Based Pulse Waveform Analysis for Blood Pressure Measurement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+I">Ivan Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+F">Fangyuan Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhong%2C+Q">Qi Zhong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ni%2C+S">Shiguang Ni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Routine blood pressure (BP) monitoring, crucial for health assessment, faces
challenges such as limited access to medical-grade equipment and expertise.
Portable cuff BP devices, on the other hand, are cumbersome to carry all day
and often cost-prohibitive in less developed countries. Besides, these
sphygmomanometer-based devices can cause discomfort and disrupt blood flow
during measurement. This study explores the use of smartphones for continuous
BP monitoring, focusing on overcoming the trust barriers associated with the
opacity of machine learning models in predicting BP from low-quality PPG
signals. Our approach included developing models based on cardiovascular
literature, using simple statistical methods to estimate BP from smartphone PPG
signals with comprehensive data pre-processing, applying SHAP for enhanced
interpretability and feature identification, and comparing our methods against
standard references using Bland-Altman analysis. Validated with data from 125
participants, the study demonstrated significant correlations in waveform
features between smartphone and reference BP monitoring devices. The
cross-validation of linear regression [MAE=9.86 and 8.01 mmHg for systolic
blood pressure (SBP) and diastolic blood pressure (DBP), respectively] and
random forest model (MAE=8.91 and 6.68 mmHg for SBP and DBP) using
waveform-only variables demonstrated the feasibility of using a smartphone to
estimate BP. Although SHAP analysis identified key feature sets, Bland-Altman
results did not fully meet established thresholds (84.64% and 94.69% of MAE&lt;15
mmHg for SBP and DBP, respectively). The study suggests the potential of
smartphone cameras to enhance the accuracy and interpretability of machine
learning models for daily BP estimation, but also indicates that smartphone
PPG-based BP prediction is not yet a replacement for traditional medical
devices.
</p>
</div>
</dd>
<dt><a name=item585>[585]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11176 title=Abstract>arXiv:2401.11176</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.11176 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11176 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cramér-Rao Bound
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Venkatasubramanian%2C+S">Shyam Venkatasubramanian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gogineni%2C+S">Sandeep Gogineni</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kang%2C+B">Bosung Kang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pezeshki%2C+A">Ali Pezeshki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rangaswamy%2C+M">Muralidhar Rangaswamy</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tarokh%2C+V">Vahid Tarokh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In modern radar systems, precise target localization using azimuth and
velocity estimation is paramount. Traditional unbiased estimation methods have
leveraged gradient descent algorithms to reach the theoretical limits of the
Cram\'er Rao Bound (CRB) for the error of the parameter estimates. In this
study, we present a data-driven neural network approach that outperforms these
traditional techniques, demonstrating improved accuracies in target azimuth and
velocity estimation. Using a representative simulated scenario, we show that
our proposed neural network model consistently achieves improved parameter
estimates due to its inherently biased nature, yielding a diminished mean
squared error (MSE). Our findings underscore the potential of employing deep
learning methods in radar systems, paving the way for more accurate
localization in cluttered and dynamic environments.
</p>
</div>
</dd>
<dt><a name=item586>[586]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11187 title=Abstract>arXiv:2401.11187</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.11187 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11187 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11187 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The degree-diameter problem for plane graphs with pentagonal faces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Preez%2C+B+D">Brandon Du Preez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 33 figures, 1 table. This paper is based on a chapter in the Author's PhD thesis: Distances in Planar graphs, at the University of Cape Town, faculty of science, department of mathematics and applied mathematics (2001)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>The degree-diameter problem consists of finding the maximum number of
vertices <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-229-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1250 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1251><span class=mi id=MathJax-Span-1252 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> of a graph with diameter <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-230-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1253 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1254><span class=mi id=MathJax-Span-1255 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and maximum degree <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-231-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1256 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1257><span class=mi id=MathJax-Span-1258 style=font-family:MathJax_Main>Δ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. This
problem is well studied, and has been solved for plane graphs of low diameter
in which every face is bounded by a 3-cycle (triangulations), and plane graphs
in which every face is bounded by a 4-cycle (quadrangulations). In this paper,
we solve the degree diameter problem for plane graphs of diameter 3 in which
every face is bounded by a 5-cycle (pentagulations). We prove that if <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-232-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1259 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.66em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1260><span class=mi id=MathJax-Span-1261 style=font-family:MathJax_Main>Δ</span><span class=mo id=MathJax-Span-1262 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-1263 style=font-family:MathJax_Main;padding-left:0.292em>8</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, then <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-233-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1264 style=width:6.079em;display:inline-block><span style=display:inline-block;position:relative;width:5.038em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.98em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1265><span class=mi id=MathJax-Span-1266 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1267 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mn id=MathJax-Span-1268 style=font-family:MathJax_Main;padding-left:0.292em>3</span><span class=mi id=MathJax-Span-1269 style=font-family:MathJax_Main>Δ</span><span class=mo id=MathJax-Span-1270 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-1271 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> for such graphs. This bound is sharp for
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-234-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1272 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1273><span class=mi id=MathJax-Span-1274 style=font-family:MathJax_Main>Δ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> odd.
</p>
</div>
</dd>
<dt><a name=item587>[587]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11224 title=Abstract>arXiv:2401.11224</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11224 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11224 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Susceptibility of Adversarial Attack on Medical Image Segmentation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Z">Zhongxuan Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+L">Leo Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 8 figures, presented at 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI) conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The nature of deep neural networks has given rise to a variety of attacks,
but little work has been done to address the effect of adversarial attacks on
segmentation models trained on MRI datasets. In light of the grave consequences
that such attacks could cause, we explore four models from the U-Net family and
examine their responses to the Fast Gradient Sign Method (FGSM) attack. We
conduct FGSM attacks on each of them and experiment with various schemes to
conduct the attacks. In this paper, we find that medical imaging segmentation
models are indeed vulnerable to adversarial attacks and that there is a
negligible correlation between parameter size and adversarial attack success.
Furthermore, we show that using a different loss function than the one used for
training yields higher adversarial attack success, contrary to what the FGSM
authors suggested. In future efforts, we will conduct the experiments detailed
in this paper with more segmentation models and different attacks. We will also
attempt to find ways to counteract the attacks by using model ensembles or
special data augmentations. Our code is available at
https://github.com/ZhongxuanWang/adv_attk
</p>
</div>
</dd>
<dt><a name=item588>[588]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11256 title=Abstract>arXiv:2401.11256</a> (cross-list from physics.med-ph) [<a href=https://arxiv.org/pdf/2401.11256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivariant Multiscale Learned Invertible Reconstruction for Cone Beam CT
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Moriakov%2C+N">Nikita Moriakov</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Sonke%2C+J">Jan-Jakob Sonke</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Teuwen%2C+J">Jonas Teuwen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Cone Beam CT (CBCT) is an essential imaging modality nowadays, but the image
quality of CBCT still lags behind the high quality standards established by the
conventional Computed Tomography. We propose LIRE+, a learned iterative scheme
for fast and memory-efficient CBCT reconstruction, which is a substantially
faster and more parameter-efficient alternative to the recently proposed LIRE
method. LIRE+ is a rotationally-equivariant multiscale learned invertible
primal-dual iterative scheme for CBCT reconstruction. Memory usage is optimized
by relying on simple reversible residual networks in primal/dual cells and
patch-wise computations inside the cells during forward and backward passes,
while increased inference speed is achieved by making the primal-dual scheme
multiscale so that the reconstruction process starts at low resolution and with
low resolution primal/dual latent vectors. A LIRE+ model was trained and
validated on a set of 260 + 22 thorax CT scans and tested using a set of 142
thorax CT scans with additional evaluation with and without finetuning on an
out-of-distribution set of 79 Head and Neck (HN) CT scans. Our method surpasses
classical and deep learning baselines, including LIRE, on the thorax test set.
For a similar inference time and with only 37 % of the parameter budget, LIRE+
achieves a +0.2 dB PSNR improvement over LIRE, while being able to match the
performance of LIRE in 45 % less inference time and with 28 % of the parameter
budget. Rotational equivariance ensures robustness of LIRE+ to patient
orientation, while LIRE and other deep learning baselines suffer from
substantial performance degradation when patient orientation is unusual. On the
HN dataset in the absence of finetuning, LIRE+ is generally comparable to LIRE
in performance apart from a few outlier cases, whereas after identical
finetuning LIRE+ demonstates a +1.02 dB PSNR improvement over LIRE.
</p>
</div>
</dd>
<dt><a name=item589>[589]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11258 title=Abstract>arXiv:2401.11258</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11258 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11258 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Quantum Optimized Centroid Initialization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Allgood%2C+N+R">Nicholas R. Allgood</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Borle%2C+A">Ajinkya Borle</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Nicholas%2C+C+K">Charles K. Nicholas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> QPL 2024 Submission. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.08626>arXiv:2305.08626</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>One of the major benefits of quantum computing is the potential to resolve
complex computational problems faster than can be done by classical methods.
There are many prototype-based clustering methods in use today, and selection
of the starting nodes for the center points is often done randomly. For
prototype-based clustering algorithms, this could lead to much slower
convergence times. One of the causes of this may be prototype-based clustering
accepting a local minima as a valid solution when there are possibly better
solutions. Quantum computing, specifically quantum annealing, offers a solution
to these problems by mapping the initial centroid problem to an Ising
Hamiltonian where over time the lowest energy in the spectrum correlates to a
valid, but better solution. A first approach to this problem utilizing quantum
annealing was known as Quantum Optimized Centroid Initialization (QOCI), but
this approach has some limitations both in results and performance. We will
present a modification of QOCI known as Adaptive Quantum Optimized Centroid
Initialization (AQOCI) which addresses many of the limitations in QOCI. The
results presented are comparable to those obtained using classical techniques
as well as being superior to those results found using QOCI.
</p>
</div>
</dd>
<dt><a name=item590>[590]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11333 title=Abstract>arXiv:2401.11333</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.11333 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11333 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11333 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error bounds of constant gain least-mean-squares algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+C">Chang Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Clark%2C+A+D">Antwan D. Clark</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Constant gain least-mean-squares (LMS) algorithms have a wide range of
applications in trajectory tracking problems, but the formal convergence of LMS
in mean square is not yet fully established. This work provides an upper bound
on the constant gain that guarantees a bounded mean-squared error of LMS for a
general design vector. These results highlight the role of the fourth-order
moment of the design vector. Numerical examples demonstrate the applicability
of this upper bound in setting a constant gain in LMS, while existing criteria
may fail. We also provide the associated error bound, which can be applied to
design vectors with linearly dependent elements.
</p>
</div>
</dd>
<dt><a name=item591>[591]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11344 title=Abstract>arXiv:2401.11344</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.11344 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11344 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Optimization in Networks with Arbitrary Delays
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ortega%2C+T">Tomas Ortega</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jafarkhani%2C+H">Hamid Jafarkhani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE ICC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA); Signal Processing (eess.SP); Systems and Control (eess.SY)
</div>
<p class=mathjax>We consider the problem of decentralized optimization in networks with
communication delays. To accommodate delays, we need decentralized optimization
algorithms that work on directed graphs. Existing approaches require nodes to
know their out-degree to achieve convergence. We propose a novel gossip-based
algorithm that circumvents this requirement, allowing decentralized
optimization in networks with communication delays. We prove that our algorithm
converges on non-convex objectives, with the same main complexity order term as
centralized Stochastic Gradient Descent (SGD), and show that the graph topology
and the delays only affect the higher order terms. We provide numerical
simulations that illustrate our theoretical results.
</p>
</div>
</dd>
<dt><a name=item592>[592]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11349 title=Abstract>arXiv:2401.11349</a> (cross-list from physics.flu-dyn) [<a href=https://arxiv.org/pdf/2401.11349 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11349 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Asynchronous Parallel Reinforcement Learning for Optimizing Propulsive Performance in Fin Ray Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Liu%2C+X">Xin-Yang Liu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Bodaghi%2C+D">Dariush Bodaghi</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Xue%2C+Q">Qian Xue</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zheng%2C+X">Xudong Zheng</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wang%2C+J">Jian-Xun Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>Fish fin rays constitute a sophisticated control system for ray-finned fish,
facilitating versatile locomotion within complex fluid environments. Despite
extensive research on the kinematics and hydrodynamics of fish locomotion, the
intricate control strategies in fin-ray actuation remain largely unexplored.
While deep reinforcement learning (DRL) has demonstrated potential in managing
complex nonlinear dynamics; its trial-and-error nature limits its application
to problems involving computationally demanding environmental interactions.
This study introduces a cutting-edge off-policy DRL algorithm, interacting with
a fluid-structure interaction (FSI) environment to acquire intricate fin-ray
control strategies tailored for various propulsive performance objectives. To
enhance training efficiency and enable scalable parallelism, an innovative
asynchronous parallel training (APT) strategy is proposed, which fully
decouples FSI environment interactions and policy/value network optimization.
The results demonstrated the success of the proposed method in discovering
optimal complex policies for fin-ray actuation control, resulting in a superior
propulsive performance compared to the optimal sinusoidal actuation function
identified through a parametric grid search. The merit and effectiveness of the
APT approach are also showcased through comprehensive comparison with
conventional DRL training strategies in numerical experiments of controlling
nonlinear dynamics.
</p>
</div>
</dd>
<dt><a name=item593>[593]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11351 title=Abstract>arXiv:2401.11351</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11351 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11351 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Machine Learning: from NISQ to Fault Tolerance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wang%2C+Y">Yunfei Wang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Liu%2C+J">Junyu Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages. Invited review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Quantum machine learning, which involves running machine learning algorithms
on quantum devices, has garnered significant attention in both academic and
business circles. In this paper, we offer a comprehensive and unbiased review
of the various concepts that have emerged in the field of quantum machine
learning. This includes techniques used in Noisy Intermediate-Scale Quantum
(NISQ) technologies and approaches for algorithms compatible with
fault-tolerant quantum computing hardware. Our review covers fundamental
concepts, algorithms, and the statistical learning theory pertinent to quantum
machine learning.
</p>
</div>
</dd>
<dt><a name=item594>[594]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11354 title=Abstract>arXiv:2401.11354</a> (cross-list from math.PR) [<a href=https://arxiv.org/pdf/2401.11354 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11354 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Squared Wasserstein-2 Distance for Efficient Reconstruction of Stochastic Differential Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xia%2C+M">Mingtao Xia</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+X">Xiangting Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shen%2C+Q">Qijing Shen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chou%2C+T">Tom Chou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Machine Learning (cs.LG); Methodology (stat.ME)
</div>
<p class=mathjax>We provide an analysis of the squared Wasserstein-2 (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-235-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1275 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.39em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1276><span class=msubsup id=MathJax-Span-1277><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.04em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1278 style=font-family:MathJax_Math-italic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.929em><span class=mn id=MathJax-Span-1279 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>) distance between
two probability distributions associated with two stochastic differential
equations (SDEs). Based on this analysis, we propose the use of a squared <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-236-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1280 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.39em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1281><span class=msubsup id=MathJax-Span-1282><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.04em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1283 style=font-family:MathJax_Math-italic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.929em><span class=mn id=MathJax-Span-1284 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>
distance-based loss functions in the \textit{reconstruction} of SDEs from noisy
data. To demonstrate the practicality of our Wasserstein distance-based loss
functions, we performed numerical experiments that demonstrate the efficiency
of our method in reconstructing SDEs that arise across a number of
applications.
</p>
</div>
</dd>
<dt><a name=item595>[595]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11362 title=Abstract>arXiv:2401.11362</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11362 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11362 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Circuit Simulation with Fast Tensor Decision Diagram
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhang%2C+Q">Qirui Zhang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Saligane%2C+M">Mehdi Saligane</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kim%2C+H">Hun-Seok Kim</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Blaauw%2C+D">David Blaauw</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Tzimpragos%2C+G">Georgios Tzimpragos</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Sylvester%2C+D">Dennis Sylvester</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Camera-Ready version. Accepted to ISQED 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Emerging Technologies (cs.ET)
</div>
<p class=mathjax>Quantum circuit simulation is a challenging computational problem crucial for
quantum computing research and development. The predominant approaches in this
area center on tensor networks, prized for their better concurrency and less
computation than methods using full quantum vectors and matrices. However, even
with the advantages, array-based tensors can have significant redundancy. We
present a novel open-source framework that harnesses tensor decision diagrams
to eliminate overheads and achieve significant speedups over prior approaches.
On average, it delivers a speedup of 37<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-237-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1285 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1286><span class=mo id=MathJax-Span-1287 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> over Google's TensorNetwork
library on redundancy-rich circuits, and 25<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-238-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1288 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1289><span class=mo id=MathJax-Span-1290 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and 144<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-239-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1291 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1292><span class=mo id=MathJax-Span-1293 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> over
quantum multi-valued decision diagram and prior tensor decision diagram
implementation, respectively, on Google random quantum circuits. To achieve
this, we introduce a new linear-complexity rank simplification algorithm,
Tetris, and edge-centric data structures for recursive tensor decision diagram
operations. Additionally, we explore the efficacy of tensor network contraction
ordering and optimizations from binary decision diagrams.
</p>
</div>
</dd>
<dt><a name=item596>[596]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11383 title=Abstract>arXiv:2401.11383</a> (cross-list from math.PR) [<a href=https://arxiv.org/pdf/2401.11383 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11383 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11383 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entropic Conditional Central Limit Theorem and Hadamard Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ma%2C+Z">Zhi-Ming Ma</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yao%2C+L">Liu-Quan Yao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhang%2C+H">Hua-Zi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 40 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>We make use of an entropic property to establish a convergence theorem (Main
Theorem), which reveals that the conditional entropy measures the asymptotic
Gaussianity. As an application, we establish the {\it entropic conditional
central limit theorem} (CCLT), which is stronger than the classical CCLT. As
another application, we show that continuous input under iterated Hadamard
transform, almost every distribution of the output conditional on the values of
the previous signals will tend to Gaussian, and the conditional distribution is
in fact insensitive to the condition. The results enable us to make a theoretic
study concerning Hadamard compression, which provides a solid theoretical
analysis supporting the simulation results in previous literature. We show also
that the conditional Fisher information can be used to measure the asymptotic
Gaussianity.
</p>
</div>
</dd>
<dt><a name=item597>[597]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11449 title=Abstract>arXiv:2401.11449</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.11449 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11449 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy Consumption Analysis for Continuous Phase Modulation in Smart-Grid Internet of Things of beyond 5G
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gao%2C+H">Hongjian Gao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lu%2C+Y">Yang Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+S">Shaoshi Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tan%2C+J">Jingsheng Tan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nie%2C+L">Longlong Nie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qu%2C+X">Xinyi Qu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 figures, 2 tables
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Sensors, vol. 24, no. 2, pp. 1-14, article number 533, Jan. 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>Wireless sensor network (WSN) underpinning the smart-grid Internet of Things
(SG-IoT) has been a popular research topic in recent years due to its great
potential for enabling a wide range of important applications. However, the
energy consumption (EC) characteristic of sensor nodes is a key factor that
affects the operational performance (e.g., lifetime of sensors) and the total
cost of ownership of WSNs. In this paper, to find the modulation techniques
suitable for WSNs, we investigate the EC characteristic of continuous phase
modulation (CPM), which is an attractive modulation scheme candidate for WSNs
because of its constant envelope property. We first develop an EC model for the
sensor nodes of WSNs by considering the circuits and a typical communication
protocol that relies on automatic repeat request (ARQ)-based retransmissions to
ensure successful data delivery. Then, we use this model to analyze the EC
characteristic of CPM under various configurations of modulation parameters.
Furthermore, we compare the EC characteristic of CPM with that of other
representative modulation schemes, such as offset quadrature phase-shift keying
(OQPSK) and quadrature amplitude modulation (QAM), which are commonly used in
communication protocols of WSNs. Our analysis and simulation results provide
insights into the EC characteristics of multiple modulation schemes in the
context of WSNs; thus, they are beneficial for designing energy-efficient
SG-IoT in the beyond-5G (B5G) and the 6G era.
</p>
</div>
</dd>
<dt><a name=item598>[598]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11464 title=Abstract>arXiv:2401.11464</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11464 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11464 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11464 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Task-specific regularization loss towards model calibration for reliable lung cancer detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kalra%2C+M+P">Mehar Prateek Kalra</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Singhal%2C+M">Mansi Singhal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dhanakashirur%2C+R+R">Rohan Raju Dhanakashirur</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Lung cancer is one of the significant causes of cancer-related deaths
globally. Early detection and treatment improve the chances of survival.
Traditionally CT scans have been used to extract the most significant lung
infection information and diagnose cancer. This process is carried out manually
by an expert radiologist. The imbalance in the radiologists-to-population ratio
in a country like India implies significant work pressure on them and thus
raises the need to automate a few of their responsibilities. The tendency of
modern-day Deep Neural networks to make overconfident mistakes limit their
usage to detect cancer. In this paper, we propose a new task-specific loss
function to calibrate the neural network to reduce the risk of overconfident
mistakes. We use the state-of-the-art Multi-class Difference in Confidence and
Accuracy (MDCA) loss in conjunction with the proposed task-specific loss
function to achieve the same. We also integrate post-hoc calibration by
performing temperature scaling on top of the train-time calibrated model. We
demonstrate 5.98% improvement in the Expected Calibration Error (ECE) and a
17.9% improvement in Maximum Calibration Error (MCE) as compared to the
best-performing SOTA algorithm.
</p>
</div>
</dd>
<dt><a name=item599>[599]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11513 title=Abstract>arXiv:2401.11513</a> (cross-list from hep-ph) [<a href=https://arxiv.org/pdf/2401.11513 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11513 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Truth and Beauty of Theory Landscapes with Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Matchev%2C+K+T">Konstantin T. Matchev</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Matcheva%2C+K">Katia Matcheva</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Ramond%2C+P">Pierre Ramond</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Verner%2C+S">Sarunas Verner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 9 figures. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.00087>arXiv:2311.00087</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Theoretical physicists describe nature by i) building a theory model and ii)
determining the model parameters. The latter step involves the dual aspect of
both fitting to the existing experimental data and satisfying abstract criteria
like beauty, naturalness, etc. We use the Yukawa quark sector as a toy example
to demonstrate how both of those tasks can be accomplished with machine
learning techniques. We propose loss functions whose minimization results in
true models that are also beautiful as measured by three different criteria -
uniformity, sparsity, or symmetry.
</p>
</div>
</dd>
<dt><a name=item600>[600]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11555 title=Abstract>arXiv:2401.11555</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11555 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11555 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VQC-Based Reinforcement Learning with Data Re-uploading: Performance and Trainability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Coelho%2C+R">Rodrigo Coelho</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Sequeira%2C+A">André Sequeira</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Santos%2C+L+P">Luís Paulo Santos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Reinforcement Learning (RL) consists of designing agents that make
intelligent decisions without human supervision. When used alongside function
approximators such as Neural Networks (NNs), RL is capable of solving extremely
complex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achieved
super-human performance in some specific tasks. Nonetheless, it is also
possible to use Variational Quantum Circuits (VQCs) as function approximators
in RL algorithms. This work empirically studies the performance and
trainability of such VQC-based Deep Q-Learning models in classic control
benchmark environments. More specifically, we research how data re-uploading
affects both these metrics. We show that the magnitude and the variance of the
gradients of these models remain substantial throughout training due to the
moving targets of Deep Q-Learning. Moreover, we empirically show that
increasing the number of qubits does not lead to an exponential vanishing
behavior of the magnitude and variance of the gradients for a PQC approximating
a 2-design, unlike what was expected due to the Barren Plateau Phenomenon. This
hints at the possibility of VQCs being specially adequate for being used as
function approximators in such a context.
</p>
</div>
</dd>
<dt><a name=item601>[601]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11562 title=Abstract>arXiv:2401.11562</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.11562 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11562 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing selectivity using Wasserstein distance based reweighing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Worah%2C+P">Pratik Worah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Given two labeled data-sets <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-240-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1294 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.7em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1295><span class=texatom id=MathJax-Span-1296><span class=mrow id=MathJax-Span-1297><span class=mi id=MathJax-Span-1298 style=font-family:MathJax_Caligraphic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-241-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1299 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.81em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1300><span class=texatom id=MathJax-Span-1301><span class=mrow id=MathJax-Span-1302><span class=mi id=MathJax-Span-1303 style=font-family:MathJax_Caligraphic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.292em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, we design a
simple and efficient greedy algorithm to reweigh the loss function such that
the limiting distribution of the neural network weights that result from
training on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-242-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1304 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.7em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1305><span class=texatom id=MathJax-Span-1306><span class=mrow id=MathJax-Span-1307><span class=mi id=MathJax-Span-1308 style=font-family:MathJax_Caligraphic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> approaches the limiting distribution that would have
resulted by training on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-243-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1309 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.81em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-1310><span class=texatom id=MathJax-Span-1311><span class=mrow id=MathJax-Span-1312><span class=mi id=MathJax-Span-1313 style=font-family:MathJax_Caligraphic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.292em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>.
<br>On the theoretical side, we prove that when the metric entropy of the input
data-sets is bounded, our greedy algorithm outputs a close to optimal
reweighing, i.e., the two invariant distributions of network weights will be
provably close in total variation distance. Moreover, the algorithm is simple
and scalable, and we prove bounds on the efficiency of the algorithm as well.
<br>Our algorithm can deliberately introduce distribution shift to perform (soft)
multi-criteria optimization. As a motivating application, we train a neural net
to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell
signaling) which are non-binders to MNK1 (a highly similar protein). We tune
the algorithm's parameter so that overall change in holdout loss is negligible,
but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1
non-binders, increases from 54\% to 95\%, as a result of our reweighing. Of the
43 distinct small molecules predicted to be most selective from the enamine
catalog, 2 small molecules were experimentally verified to be selective, i.e.,
they reduced the enzyme activity of MNK2 below 50\% but not MNK1, at 10<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-244-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1314 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1315><span class=mi id=MathJax-Span-1316 style=font-family:MathJax_Math-italic>μ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>M
-- a 5\% success rate.
</p>
</div>
</dd>
<dt><a name=item602>[602]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11567 title=Abstract>arXiv:2401.11567</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.11567 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11567 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deterministic Multi-stage Constellation Reconfiguration Using Integer Linear Programing and Sequential Decision-Making Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+H+W">Hang Woon Lee</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rogers%2C+D+O+W">David O. Williams Rogers</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pearl%2C+B+D">Brycen D. Pearl</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ho%2C+K">Koki Ho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 13 figures, submitted to the Journal of Spacecraft and Rockets
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper, we address the problem of reconfiguring Earth observation
satellite constellation systems through multiple stages. The Multi-stage
Constellation Reconfiguration Problem (MCRP) aims to maximize the total
observation rewards obtained by covering a set of targets of interest through
the active manipulation of the orbits and relative phasing of constituent
satellites. In this paper, we consider deterministic problem settings in which
the targets of interest are known a priori. We propose a novel integer linear
programming formulation for MCRP, capable of obtaining provably optimal
solutions. To overcome computational intractability due to the combinatorial
explosion in solving large-scale instances, we introduce two computationally
efficient sequential decision-making methods based on the principles of a
myopic policy and a rolling horizon procedure. The computational experiments
demonstrate that the devised sequential decision-making approaches yield
high-quality solutions with improved computational efficiency over the baseline
MCRP. Finally, a case study using Hurricane Harvey data showcases the
advantages of multi-stage constellation reconfiguration over single-stage and
no-reconfiguration scenarios.
</p>
</div>
</dd>
<dt><a name=item603>[603]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11576 title=Abstract>arXiv:2401.11576</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.11576 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11576 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Architecture Search with Unsupervised Representation Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Sun%2C+Y">Yize Sun</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wu%2C+Z">Zixin Wu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ma%2C+Y">Yunpu Ma</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 Pages, quantum architecture search, unsupervised representation learning
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Utilizing unsupervised representation learning for quantum architecture
search (QAS) represents a cutting-edge approach poised to realize potential
quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) devices. Most QAS
algorithms combine their search space and search algorithms together and thus
generally require evaluating a large number of quantum circuits during the
search process. Predictor-based QAS algorithms can alleviate this problem by
directly estimating the performance of circuits according to their structures.
However, a high-performance predictor generally requires very time-consuming
labeling to obtain a large number of labeled quantum circuits. Recently, a
classical neural architecture search algorithm Arch2vec inspires us by showing
that architecture search can benefit from decoupling unsupervised
representation learning from the search process. Whether unsupervised
representation learning can help QAS without any predictor is still an open
topic. In this work, we propose a framework QAS with unsupervised
representation learning and visualize how unsupervised architecture
representation learning encourages quantum circuit architectures with similar
connections and operators to cluster together. Specifically, our framework
enables the process of QAS to be decoupled from unsupervised architecture
representation learning so that the learned representation can be directly
applied to different downstream applications. Furthermore, our framework is
predictor-free eliminating the need for a large number of labeled quantum
circuits. During the search process, we use two algorithms REINFORCE and
Bayesian Optimization to directly search on the latent representation, and
compare them with the method Random Search. The results show our framework can
more efficiently get well-performing candidate circuits within a limited number
of searches.
</p>
</div>
</dd>
<dt><a name=item604>[604]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11610 title=Abstract>arXiv:2401.11610</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.11610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11610 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Note on Min-k-Planar Drawings of Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hlin%C4%9Bn%C3%BD%2C+P">Petr Hliněný</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>Binucci et al. [Graph Drawing 2023] have recently introduced the concept of
min-k-planar graphs as a generalization of k-planar graphs. In a min-k-planar
drawing edges can, generally, be crossed many times, but for any two crossing
edges, at least one of the two must have at most k crossings. In their
introductory paper, the authors made an assumption (quite usual in this area)
that they only consider simple (good) drawings; i.e., drawings in which no two
edges have two points in common. We show that this assumption on min-k-planar
graphs is far from the truth for every k&gt;=2.
</p>
</div>
</dd>
<dt><a name=item605>[605]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11621 title=Abstract>arXiv:2401.11621</a> (cross-list from q-fin.ST) [<a href=https://arxiv.org/pdf/2401.11621 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11621 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11621 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Din%2C+R+U">Riaz Ud Din</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Ahmed%2C+S">Salman Ahmed</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Khan%2C+S+H">Saddam Hussain Khan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 16 Figures, 4 Tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistical Finance (q-fin.ST)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)
</div>
<p class=mathjax>Forecasting speculative stock prices is essential for effective investment
risk management that drives the need for the development of innovative
algorithms. However, the speculative nature, volatility, and complex sequential
dependencies within financial markets present inherent challenges which
necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE
(customized attention BiLSTM-XGB decision ensemble), for predicting the daily
closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework
integrates a customized bi-directional long short-term memory (BiLSTM) with the
attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages
its learning capabilities to capture the complex sequential dependencies and
speculative market trends. Additionally, the new attention mechanism
dynamically assigns weights to influential features, thereby enhancing
interpretability, and optimizing effective cost measures and volatility
forecasting. Moreover, XGBoost handles nonlinear relationships and contributes
to the proposed CAB-XDE framework robustness. Additionally, the weight
determination theory-error reciprocal method further refines predictions. This
refinement is achieved by iteratively adjusting model weights. It is based on
discrepancies between theoretical expectations and actual errors in individual
customized attention BiLSTM and XGBoost models to enhance performance. Finally,
the predictions from both XGBoost and customized attention BiLSTM models are
concatenated to achieve diverse prediction space and are provided to the
ensemble classifier to enhance the generalization capabilities of CAB-XDE. The
proposed CAB-XDE framework is empirically validated on volatile Bitcoin market,
sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE
of 0.0037, MAE of 84.40, and RMSE of 106.14.
</p>
</div>
</dd>
<dt><a name=item606>[606]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11645 title=Abstract>arXiv:2401.11645</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Streaming Bilingual End-to-End ASR model using Attention over Multiple Softmax
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Patil%2C+A">Aditya Patil</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Joshi%2C+V">Vikas Joshi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Agrawal%2C+P">Purvi Agrawal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mehta%2C+R">Rupesh Mehta</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in IEEE's Spoken Language Technology (SLT) 2022, 8 pages (6 + 2 for references), 5 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2022 IEEE Spoken Language Technology Workshop (SLT), Doha, Qatar,
 2023, pp. 252-259
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
<p class=mathjax>Even with several advancements in multilingual modeling, it is challenging to
recognize multiple languages using a single neural model, without knowing the
input language and most multilingual models assume the availability of the
input language. In this work, we propose a novel bilingual end-to-end (E2E)
modeling approach, where a single neural model can recognize both languages and
also support switching between the languages, without any language input from
the user. The proposed model has shared encoder and prediction networks, with
language-specific joint networks that are combined via a self-attention
mechanism. As the language-specific posteriors are combined, it produces a
single posterior probability over all the output symbols, enabling a single
beam search decoding and also allowing dynamic switching between the languages.
The proposed approach outperforms the conventional bilingual baseline with
13.3%, 8.23% and 1.3% word error rate relative reduction on Hindi, English and
code-mixed test sets, respectively.
</p>
</div>
</dd>
<dt><a name=item607>[607]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11646 title=Abstract>arXiv:2401.11646</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.11646 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11646 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nonparametric Estimation via Variance-Reduced Sketching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Khoo%2C+Y">Yuehaw Khoo</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wang%2C+D">Daren Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 64 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Methodology (stat.ME)
</div>
<p class=mathjax>Nonparametric models are of great interest in various scientific and
engineering disciplines. Classical kernel methods, while numerically robust and
statistically sound in low-dimensional settings, become inadequate in
higher-dimensional settings due to the curse of dimensionality. In this paper,
we introduce a new framework called Variance-Reduced Sketching (VRS),
specifically designed to estimate density functions and nonparametric
regression functions in higher dimensions with a reduced curse of
dimensionality. Our framework conceptualizes multivariable functions as
infinite-size matrices, and facilitates a new sketching technique motivated by
numerical linear algebra literature to reduce the variance in estimation
problems. We demonstrate the robust numerical performance of VRS through a
series of simulated experiments and real-world data applications. Notably, VRS
shows remarkable improvement over existing neural network estimators and
classical kernel methods in numerous density estimation and nonparametric
regression models. Additionally, we offer theoretical justifications for VRS to
support its ability to deliver nonparametric estimation with a reduced curse of
dimensionality.
</p>
</div>
</dd>
<dt><a name=item608>[608]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11665 title=Abstract>arXiv:2401.11665</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.11665 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11665 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zheng%2C+H">Haoyang Zheng</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Deng%2C+W">Wei Deng</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Moya%2C+C">Christian Moya</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 50 pages, 1 figure, to appear in AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Approximate Thompson sampling with Langevin Monte Carlo broadens its reach
from Gaussian posterior sampling to encompass more general smooth posteriors.
However, it still encounters scalability issues in high-dimensional problems
when demanding high accuracy. To address this, we propose an approximate
Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where
the latter is the go-to workhorse for simulations of high-dimensional
posteriors. Based on the standard smoothness and log-concavity conditions, we
study the accelerated posterior concentration and sampling using a specific
potential function. This design improves the sample complexity for realizing
logarithmic regrets from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-245-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1317 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1318><span class=texatom id=MathJax-Span-1319><span class=mrow id=MathJax-Span-1320><span class=texatom id=MathJax-Span-1321><span class=mrow id=MathJax-Span-1322><span class=munderover id=MathJax-Span-1323><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1324 style=font-family:MathJax_Caligraphic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-1325 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span></span></span><span class=mo id=MathJax-Span-1326 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1327 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1328 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span> to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-246-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1329 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.9em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1330><span class=texatom id=MathJax-Span-1331><span class=mrow id=MathJax-Span-1332><span class=texatom id=MathJax-Span-1333><span class=mrow id=MathJax-Span-1334><span class=munderover id=MathJax-Span-1335><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1336 style=font-family:MathJax_Caligraphic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-1337 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span></span></span><span class=mo id=MathJax-Span-1338 style=font-family:MathJax_Main>(</span><span class=msqrt id=MathJax-Span-1339><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-1340><span class=mi id=MathJax-Span-1341 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.569em;left:0.813em><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.171em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1342 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>. The scalability and robustness of our algorithm are also
empirically validated through synthetic experiments in high-dimensional bandit
problems.
</p>
</div>
</dd>
<dt><a name=item609>[609]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11671 title=Abstract>arXiv:2401.11671</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11671 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11671 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RTA-Former: Reverse Transformer Attention for Polyp Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+Z">Zhikai Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yi%2C+M">Murong Yi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Uneri%2C+A">Ali Uneri</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Niu%2C+S">Sihan Niu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jones%2C+C">Craig Jones</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Polyp segmentation is a key aspect of colorectal cancer prevention, enabling
early detection and guiding subsequent treatments. Intelligent diagnostic
tools, including deep learning solutions, are widely explored to streamline and
potentially automate this process. However, even with many powerful network
architectures, there still comes the problem of producing accurate edge
segmentation. In this paper, we introduce a novel network, namely RTA-Former,
that employs a transformer model as the encoder backbone and innovatively
adapts Reverse Attention (RA) with a transformer stage in the decoder for
enhanced edge segmentation. The results of the experiments illustrate that
RTA-Former achieves state-of-the-art (SOTA) performance in five polyp
segmentation datasets. The strong capability of RTA-Former holds promise in
improving the accuracy of Transformer-based polyp segmentation, potentially
leading to better clinical decisions and patient outcomes. Our code will be
publicly available on GitHub.
</p>
</div>
</dd>
<dt><a name=item610>[610]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11679 title=Abstract>arXiv:2401.11679</a> (cross-list from physics.ao-ph) [<a href=https://arxiv.org/pdf/2401.11679 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11679 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simulating Nighttime Visible Satellite Imagery of Tropical Cyclones Using Conditional Generative Adversarial Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yao%2C+J">Jinghuai Yao</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Du%2C+P">Puyuan Du</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zhao%2C+Y">Yucheng Zhao</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Wang%2C+Y">Yubo Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Visible (VIS) imagery of satellites has various important applications in
meteorology, including monitoring Tropical Cyclones (TCs). However, it is
unavailable at night because of the lack of sunlight. This study presents a
Conditional Generative Adversarial Networks (CGAN) model that generates highly
accurate nighttime visible reflectance using infrared (IR) bands and sunlight
direction parameters as input. The model was trained and validated using target
area observations of the Advanced Himawari Imager (AHI) in the daytime. This
study also presents the first nighttime model validation using the Day/Night
Band (DNB) of the Visible/Infrared Imager Radiometer Suite (VIIRS). The daytime
statistical results of the Structural Similarity Index Measure (SSIM), Peak
Signal-to-Noise Ratio (PSNR), Root Mean Square Error (RMSE), Correlation
Coefficient (CC), and Bias are 0.885, 28.3, 0.0428, 0.984, and -0.0016
respectively, completely surpassing the model performance of previous studies.
The nighttime statistical results of SSIM, PSNR, RMSE, and CC are 0.821, 24.4,
0.0643, and 0.969 respectively, which are slightly negatively impacted by the
parallax between satellites. We performed full-disk model validation which
proves our model could also be readily applied in the tropical ocean without
TCs in the northern hemisphere. This model contributes to the nighttime
monitoring of meteorological phenomena by providing accurate AI-generated
visible imagery with adjustable virtual sunlight directions.
</p>
</div>
</dd>
<dt><a name=item611>[611]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11733 title=Abstract>arXiv:2401.11733</a> (cross-list from math.CA) [<a href=https://arxiv.org/pdf/2401.11733 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11733 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11733 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximate solutions to a nonlinear functional differential equation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hale%2C+N">Nicholas Hale</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Thomann%2C+E">Enrique Thomann</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Weideman%2C+J">JAC Weideman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>A functional differential equation related to the logistic equation is
studied by a combination of numerical and perturbation methods. Parameter
regions are identified where the solution to the nonlinear problem is
approximated well by known series solutions of the linear version of the
equation. The solution space for a certain class of functions is then mapped
out using a continuation approach.
</p>
</div>
</dd>
<dt><a name=item612>[612]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11771 title=Abstract>arXiv:2401.11771</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11771 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11771 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11771 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Accessibility: Voice Cloning and Speech Synthesis for Individuals with Speech Disorders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=R%2C+V">Vinotha R</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%2C+H">Hepsiba D</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Anand%2C+L+D+V">L. D. Vijay Anand</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Reji%2C+D+J">Deepak John Reji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Neural Text-to-speech (TTS) synthesis is a powerful technology that can
generate speech using neural networks. One of the most remarkable features of
TTS synthesis is its capability to produce speech in the voice of different
speakers. This paper introduces voice cloning and speech synthesis
https://pypi.org/project/voice-cloning/ an open-source python package for
helping speech disorders to communicate more effectively as well as for
professionals seeking to integrate voice cloning or speech synthesis
capabilities into their projects. This package aims to generate synthetic
speech that sounds like the natural voice of an individual, but it does not
replace the natural human voice. The architecture of the system comprises a
speaker verification system, a synthesizer, a vocoder, and noise reduction.
Speaker verification system trained on a varied set of speakers to achieve
optimal generalization performance without relying on transcriptions.
Synthesizer is trained using both audio and transcriptions that generate Mel
spectrogram from a text and vocoder which converts the generated Mel
Spectrogram into corresponding audio signal. Then the audio signal is processed
by a noise reduction algorithm to eliminate unwanted noise and enhance speech
clarity. The performance of synthesized speech from seen and unseen speakers
are then evaluated using subjective and objective evaluation such as Mean
Opinion Score (MOS), Gross Pitch Error (GPE), and Spectral distortion (SD). The
model can create speech in distinct voices by including speaker characteristics
that are chosen randomly.
</p>
</div>
</dd>
<dt><a name=item613>[613]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11782 title=Abstract>arXiv:2401.11782</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.11782 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11782 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Impact of temporal interaction on the evolution of cooperation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=He%2C+Y">Yujie He</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ren%2C+T">Tianyu Ren</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Zheng%2C+J">Junjun Zheng</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Liang%2C+H">Huawen Liang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Populations and Evolution (q-bio.PE)
</div>
<p class=mathjax>This research investigates the impact of dynamic interactions with
time-varying topologies on the evolution of cooperative behaviours in social
dilemmas. Traditional research has focused on deterministic rules governing
pairwise interactions, yet the impact of interaction frequency and
synchronicity on cooperation remains underexplored. Addressing this gap, our
work introduces two temporal interaction mechanisms to model the stochastic or
periodic participation of individuals in these games, acknowledging real-life
variances due to exogenous temporal factors and geographical time differences.
We consider that the interaction state significantly influences both game
payoff calculations and the strategy updating process, offering new insights
into the emergence and sustainability of cooperation. Our results indicate that
maximum game participation frequency is suboptimal under a stochastic
interaction mechanism. Instead, an intermediate region of activation
probability yields the highest cooperation level, especially under strong
dilemma conditions. This suggests that a balance between inactivity security
and interaction frequency is crucial. Furthermore, local synchronization of
interactions within specific areas is shown to be beneficial, as time
differences hinder the spread of cross-structures but promote the formation of
dense cooperative clusters with smoother boundaries. Our findings provide an
intuitive understanding of node-based temporality and probabilistic
interactions, contributing to the broader discourse on resolving social
dilemmas.
</p>
</div>
</dd>
<dt><a name=item614>[614]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11807 title=Abstract>arXiv:2401.11807</a> (cross-list from math.LO) [<a href=https://arxiv.org/pdf/2401.11807 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11807 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11807 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The weakness of finding descending sequences in ill-founded linear orders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Goh%2C+J+L">Jun Le Goh</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pauly%2C+A">Arno Pauly</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Valenti%2C+M">Manlio Valenti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)
</div>
<p class=mathjax>We prove that the Weihrauch degree of the problem of finding a bad sequence
in a non-well quasi order (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-247-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1343 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1001.16em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-1344><span class=texatom id=MathJax-Span-1345><span class=mrow id=MathJax-Span-1346><span class=mi id=MathJax-Span-1347 style=font-family:MathJax_SansSerif>B</span><span class=mi id=MathJax-Span-1348 style=font-family:MathJax_SansSerif>S</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>) is strictly above that of finding a
descending sequence in an ill-founded linear order (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-248-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1349 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1001.22em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-1350><span class=texatom id=MathJax-Span-1351><span class=mrow id=MathJax-Span-1352><span class=mi id=MathJax-Span-1353 style=font-family:MathJax_SansSerif>D</span><span class=mi id=MathJax-Span-1354 style=font-family:MathJax_SansSerif>S</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>). This
corrects our mistaken claim in <a href=https://arxiv.org/abs/2010.03840>arXiv:2010.03840</a>, which stated that they are
Weihrauch equivalent. We prove that K\"onig's lemma <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-249-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1355 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1001.16em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-1356><span class=texatom id=MathJax-Span-1357><span class=mrow id=MathJax-Span-1358><span class=mi id=MathJax-Span-1359 style=font-family:MathJax_SansSerif>K</span><span class=mi id=MathJax-Span-1360 style=font-family:MathJax_SansSerif>L</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is not
Weihrauch reducible to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-250-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1361 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1001.22em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-1362><span class=texatom id=MathJax-Span-1363><span class=mrow id=MathJax-Span-1364><span class=mi id=MathJax-Span-1365 style=font-family:MathJax_SansSerif>D</span><span class=mi id=MathJax-Span-1366 style=font-family:MathJax_SansSerif>S</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> either, resolving the main open question
raised in <a href=https://arxiv.org/abs/2010.03840>arXiv:2010.03840</a>.
</p>
</div>
</dd>
<dt><a name=item615>[615]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11829 title=Abstract>arXiv:2401.11829</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11829 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11829 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11829 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Harmonic Detection from Noisy Speech with Auditory Frame Gain for Intelligibility Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Queiroz%2C+A">A. Queiroz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Coelho%2C+R">R. Coelho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 6 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>This paper introduces a novel (HDAG - Harmonic Detection for Auditory Gain)
method for speech intelligibility enhancement in noisy scenarios. In the
proposed scheme, a series of selective Gammachirp filters are adopted to
emphasize the harmonic components of speech reducing the masking effects of
acoustic noises. The fundamental frequency are estimated by the HHT-Amp
technique. Harmonic patterns estimated with low accuracy are detected and
adjusted according the FSFFE low/high pitch separation. The central frequencies
of the filterbank are defined considering the third octave subbands which are
best suited to cover the regions most relevant to intelligibility. Before
signal reconstruction, the gammachirp filtered components are amplified by gain
factors regulated by FSFFE classification. The proposed HDAG solution and three
baseline techniques are examined considering six background noises with four
signal-to-noise ratios. Three objective measures are adopted for the evaluation
of speech intelligibility and quality. Several experiments are conducted to
demonstrate that the proposed scheme achieves better speech intelligibility
improvement when compared to the competing approaches. A perceptual listening
test is further considered and corroborates with the objective results.
</p>
</div>
</dd>
<dt><a name=item616>[616]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11832 title=Abstract>arXiv:2401.11832</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11832 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11832 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11832 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intelligibility Enhancement of Acoustic Noisy Speech for Autism Spectrum Disorder Condition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pillonetto%2C+M">M. Pillonetto</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Queiroz%2C+A">A. Queiroz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Coelho%2C+R">R. Coelho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figues, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>This work introduces a time domain personalized method (pGTFF0) to achieve
intelligibility improvement of noisy speech for Autism Spectrum Disorder (ASD)
situation. For this proposal, harmonic features estimated from speech frames
are considered as center frequencies of Gammatone auditory filterbanks. A gain
factor is further applied to the output of the filtered samples. The key goal
is the emulation of an external noise filtering tailored for individuals with
ASD. A perceptual listening test demonstrates that ASD volunteers attained
lower intelligibility rates than Neurotypical (NT). The proposed solution is
compared to three competing approaches considering four acoustic noises at
different signal-to-noise ratios. Two objective measures (ESTOI and PESQ) are
also adopted for evaluation. The experimental results show that the
personalized solution outperformed the competing approaches in terms of
intelligibility and quality improvement.
</p>
</div>
</dd>
<dt><a name=item617>[617]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11856 title=Abstract>arXiv:2401.11856</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+D">De-Xing Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+X">Xiao-Hu Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xie%2C+X">Xiao-Liang Xie</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+S">Shi-Qi Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+Z">Zhen-Qiu Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gui%2C+M">Mei-Jiang Gui</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+H">Hao Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xiang%2C+T">Tian-Yu Xiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+X">Xiu-Ling Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hou%2C+Z">Zeng-Guang Hou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Medical image segmentation takes an important position in various clinical
applications. Deep learning has emerged as the predominant solution for
automated segmentation of volumetric medical images. 2.5D-based segmentation
models bridge computational efficiency of 2D-based models and spatial
perception capabilities of 3D-based models. However, prevailing 2.5D-based
models often treat each slice equally, failing to effectively learn and exploit
inter-slice information, resulting in suboptimal segmentation performances. In
this paper, a novel Momentum encoder-based inter-slice fusion transformer
(MOSformer) is proposed to overcome this issue by leveraging inter-slice
information at multi-scale feature maps extracted by different encoders.
Specifically, dual encoders are employed to enhance feature distinguishability
among different slices. One of the encoders is moving-averaged to maintain the
consistency of slice representations. Moreover, an IF-Swin transformer module
is developed to fuse inter-slice multi-scale features. The MOSformer is
evaluated on three benchmark datasets (Synapse, ACDC, and AMOS), establishing a
new state-of-the-art with 85.63%, 92.19%, and 85.43% of DSC, respectively.
These promising results indicate its competitiveness in medical image
segmentation. Codes and models of MOSformer will be made publicly available
upon acceptance.
</p>
</div>
</dd>
<dt><a name=item618>[618]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11857 title=Abstract>arXiv:2401.11857</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.11857 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11857 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial speech for voice privacy protection from Personalized Speech generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+S">Shihao Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+L">Liping Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+K">KongAik Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ling%2C+Z">Zhenhua Ling</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+L">Lirong Dai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by icassp 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>The rapid progress in personalized speech generation technology, including
personalized text-to-speech (TTS) and voice conversion (VC), poses a challenge
in distinguishing between generated and real speech for human listeners,
resulting in an urgent demand in protecting speakers' voices from malicious
misuse. In this regard, we propose a speaker protection method based on
adversarial attacks. The proposed method perturbs speech signals by minimally
altering the original speech while rendering downstream speech generation
models unable to accurately generate the voice of the target speaker. For
validation, we employ the open-source pre-trained YourTTS model for speech
generation and protect the target speaker's speech in the white-box scenario.
Automatic speaker verification (ASV) evaluations were carried out on the
generated speech as the assessment of the voice protection capability. Our
experimental results show that we successfully perturbed the speaker encoder of
the YourTTS model using the gradient-based I-FGSM adversarial perturbation
method. Furthermore, the adversarial perturbation is effective in preventing
the YourTTS model from generating the speech of the target speaker. Audio
samples can be found in
https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS.
</p>
</div>
</dd>
<dt><a name=item619>[619]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11859 title=Abstract>arXiv:2401.11859</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11859 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11859 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LKFormer: Large Kernel Transformer for Infrared Image Super-Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qin%2C+F">Feiwei Qin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yan%2C+K">Kang Yan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+C">Changmiao Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Peng%2C+Y">Yong Peng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Given the broad application of infrared technology across diverse fields,
there is an increasing emphasis on investigating super-resolution techniques
for infrared images within the realm of deep learning. Despite the impressive
results of current Transformer-based methods in image super-resolution tasks,
their reliance on the self-attentive mechanism intrinsic to the Transformer
architecture results in images being treated as one-dimensional sequences,
thereby neglecting their inherent two-dimensional structure. Moreover, infrared
images exhibit a uniform pixel distribution and a limited gradient range,
posing challenges for the model to capture effective feature information.
Consequently, we suggest a potent Transformer model, termed Large Kernel
Transformer (LKFormer), to address this issue. Specifically, we have designed a
Large Kernel Residual Depth-wise Convolutional Attention (LKRDA) module with
linear complexity. This mainly employs depth-wise convolution with large
kernels to execute non-local feature modeling, thereby substituting the
standard self-attentive layer. Additionally, we have devised a novel
feed-forward network structure called Gated-Pixel Feed-Forward Network (GPFN)
to augment the LKFormer's capacity to manage the information flow within the
network. Comprehensive experimental results reveal that our method surpasses
the most advanced techniques available, using fewer parameters and yielding
considerably superior performance.
</p>
</div>
</dd>
<dt><a name=item620>[620]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11902 title=Abstract>arXiv:2401.11902</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.11902 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11902 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Training-Free Defense Framework for Robust Learned Image Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Song%2C+M">Myungseo Song</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Choi%2C+J">Jinyoung Choi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages and 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>We study the robustness of learned image compression models against
adversarial attacks and present a training-free defense technique based on
simple image transform functions. Recent learned image compression models are
vulnerable to adversarial attacks that result in poor compression rate, low
reconstruction quality, or weird artifacts. To address the limitations, we
propose a simple but effective two-way compression algorithm with random input
transforms, which is conveniently applicable to existing image compression
models. Unlike the na\"ive approaches, our approach preserves the original
rate-distortion performance of the models on clean images. Moreover, the
proposed algorithm requires no additional training or modification of existing
models, making it more practical. We demonstrate the effectiveness of the
proposed techniques through extensive experiments under multiple compression
models, evaluation metrics, and attack scenarios.
</p>
</div>
</dd>
<dt><a name=item621>[621]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11912 title=Abstract>arXiv:2401.11912</a> (cross-list from econ.TH) [<a href=https://arxiv.org/pdf/2401.11912 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11912 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Diversity of Condorcet Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Karpov%2C+A">Alexander Karpov</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Markstr%C3%B6m%2C+K">Klas Markström</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Riis%2C+S">Søren Riis</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Zhou%2C+B">Bei Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>Several of the classical results in social choice theory demonstrate that in
order for many voting systems to be well-behaved the set domain of individual
preferences must satisfy some kind of restriction, such as being single-peaked
on a political axis. As a consequence it becomes interesting to measure how
diverse the preferences in a well-behaved domain can be.
<br>In this paper we introduce an egalitarian approach to measuring preference
diversity, focusing on the abundance of distinct suborders one subsets of the
alternative. We provide a common generalisation of the frequently used concepts
of ampleness and copiousness.
<br>We give a detailed investigation of the abundance for Condorcet domains. Our
theorems imply a ceiling for the local diversity in domains on large sets of
alternatives, which show that in this measure Black's single-peaked domain is
in fact optimal. We also demonstrate that for some numbers of alternatives,
there are Condorcet domains which have largest local diversity without having
maximum order.
</p>
</div>
</dd>
<dt><a name=item622>[622]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12004 title=Abstract>arXiv:2401.12004</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.12004 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12004 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12004 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NLCG-Net: A Model-Based Zero-Shot Learning Framework for Undersampled Quantitative MRI Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang%2C+X">Xinrui Jiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jun%2C+Y">Yohan Jun</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cho%2C+J">Jaejin Cho</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gao%2C+M">Mengze Gao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yong%2C+X">Xingwang Yong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bilgic%2C+B">Berkin Bilgic</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>Typical quantitative MRI (qMRI) methods estimate parameter maps after image
reconstructing, which is prone to biases and error propagation. We propose a
Nonlinear Conjugate Gradient (NLCG) optimizer for model-based T2/T1 estimation,
which incorporates U-Net regularization trained in a scan-specific manner. This
end-to-end method directly estimates qMRI maps from undersampled k-space data
using mono-exponential signal modeling with zero-shot scan-specific neural
network regularization to enable high fidelity T1 and T2 mapping. T2 and T1
mapping results demonstrate the ability of the proposed NLCG-Net to improve
estimation quality compared to subspace reconstruction at high accelerations.
</p>
</div>
</dd>
<dt><a name=item623>[623]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12064 title=Abstract>arXiv:2401.12064</a> (cross-list from econ.GN) [<a href=https://arxiv.org/pdf/2401.12064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12064 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Market Responses to Genuine Versus Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Liang%2C+C">Chen Liang</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Tunc%2C+M">Murat Tunc</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Burtch%2C+G">Gordon Burtch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>General Economics (econ.GN)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Crypto donations now represent a significant fraction of charitable giving
worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale
of NFTs of artistic works with the proceeds donated to philanthropic causes,
have emerged as a novel development in this space. A unique aspect of NFT
charity fundraisers is the significant potential for donors to reap financial
gains from the rising value of purchased NFTs. Questions may arise about the
motivations of donors in these charity fundraisers, resulting in a negative
social image. NFT charity fundraisers thus offer a unique opportunity to
understand the economic consequences of a donor's social image. We investigate
these effects in the context of a large NFT charity fundraiser. We identify the
causal effect of purchasing an NFT within the charity fundraiser on a donor's
later market outcomes by leveraging random variation in transaction processing
times on the blockchain. Further, we demonstrate a clear pattern of
heterogeneity, based on an individual's decision to relist (versus hold) the
purchased charity NFTs (a sign of strategic generosity), and based on an
individual's degree of social exposure within the NFT marketplace. We show that
charity-NFT "relisters" experience significant penalties in the market, in
terms of the prices they are able to command on other NFT listings,
particularly among those who relist quickly and those who are more socially
exposed. Our study underscores the growing importance of digital visibility and
traceability, features that characterize crypto-philanthropy, and online
philanthropy more broadly.
</p>
</div>
</dd>
<dt><a name=item624>[624]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12074 title=Abstract>arXiv:2401.12074</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.12074 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12074 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Morell-Ortega%2C+S">Sergio Morell-Ortega</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruiz-Perez%2C+M">Marina Ruiz-Perez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gadea%2C+M">Marien Gadea</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vivo-Hernando%2C+R">Roberto Vivo-Hernando</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rubio%2C+G">Gregorio Rubio</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aparici%2C+F">Fernando Aparici</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=de+la+Iglesia-Vaya%2C+M">Mariam de la Iglesia-Vaya</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Catheline%2C+G">Gwenaelle Catheline</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Coup%C3%A9%2C+P">Pierrick Coupé</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Manj%C3%B3n%2C+J+V">José V. Manjón</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)
</div>
<p class=mathjax>This paper introduces a novel multimodal and high-resolution human brain
cerebellum lobule segmentation method. Unlike current tools that operate at
standard resolution (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-251-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1367 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.9em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1368><span class=mn id=MathJax-Span-1369 style=font-family:MathJax_Main>1</span><span class=msubsup id=MathJax-Span-1370><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.91em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mtext id=MathJax-Span-1371 style=font-family:MathJax_Main>&nbsp;mm</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:1.913em><span class=texatom id=MathJax-Span-1372><span class=mrow id=MathJax-Span-1373><span class=mn id=MathJax-Span-1374 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>) or using mono-modal data, the proposed
method improves cerebellum lobule segmentation through the use of a multimodal
and ultra-high resolution (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-252-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1375 style=width:5.558em;display:inline-block><span style=display:inline-block;position:relative;width:4.633em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1004.63em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1376><span class=mn id=MathJax-Span-1377 style=font-family:MathJax_Main>0.125</span><span class=msubsup id=MathJax-Span-1378><span style=display:inline-block;position:relative;width:2.376em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.91em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mtext id=MathJax-Span-1379 style=font-family:MathJax_Main>&nbsp;mm</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:1.913em><span class=texatom id=MathJax-Span-1380><span class=mrow id=MathJax-Span-1381><span class=mn id=MathJax-Span-1382 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>) training dataset. To develop
the method, first, a database of semi-automatically labelled cerebellum lobules
was created to train the proposed method with ultra-high resolution T1 and T2
MR images. Then, an ensemble of deep networks has been designed and developed,
allowing the proposed method to excel in the complex cerebellum lobule
segmentation task, improving precision while being memory efficient. Notably,
our approach deviates from the traditional U-Net model by exploring alternative
architectures. We have also integrated deep learning with classical machine
learning methods incorporating a priori knowledge from multi-atlas
segmentation, which improved precision and robustness. Finally, a new online
pipeline, named DeepCERES, has been developed to make available the proposed
method to the scientific community requiring as input only a single T1 MR image
at standard resolution.
</p>
</div>
</dd>
<dt><a name=item625>[625]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12085 title=Abstract>arXiv:2401.12085</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.12085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistency Based Unsupervised Self-training For ASR Personalisation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+J">Jisi Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rajan%2C+V">Vandana Rajan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mehmood%2C+H">Haaris Mehmood</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tuckey%2C+D">David Tuckey</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Parada%2C+P+P">Pablo Peso Parada</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jalal%2C+M+A">Md Asif Jalal</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Saravanan%2C+K">Karthikeyan Saravanan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+G+H">Gil Ho Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J">Jungin Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+S">Seokyeong Jung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for IEEE ASRU 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>On-device Automatic Speech Recognition (ASR) models trained on speech data of
a large population might underperform for individuals unseen during training.
This is due to a domain shift between user data and the original training data,
differed by user's speaking characteristics and environmental acoustic
conditions. ASR personalisation is a solution that aims to exploit user data to
improve model robustness. The majority of ASR personalisation methods assume
labelled user data for supervision. Personalisation without any labelled data
is challenging due to limited data size and poor quality of recorded audio
samples. This work addresses unsupervised personalisation by developing a novel
consistency based training method via pseudo-labelling. Our method achieves a
relative Word Error Rate Reduction (WERR) of 17.3% on unlabelled training data
and 8.1% on held-out data compared to a pre-trained model, and outperforms the
current state-of-the art methods.
</p>
</div>
</dd>
<dt><a name=item626>[626]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12091 title=Abstract>arXiv:2401.12091</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.12091 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12091 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Eigensolver for General Matrices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhang%2C+X">Xiao-Ming Zhang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhang%2C+Y">Yunkun Zhang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=He%2C+W">Wenhao He</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Yuan%2C+X">Xiao Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6+10 pages, 1+1 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>The eigenvalue problem, a cornerstone in linear algebra, provides profound
insights into studying matrix properties. Quantum algorithms addressing this
problem have hitherto been constrained to special normal matrices assuming
spectral decomposition, leaving the extension to general matrices an open
challenge. In this work, we present a novel family of quantum algorithms
tailored for solving the eigenvalue problem for general matrices, encompassing
scenarios with complex eigenvalues or even defective matrices. Our approach
begins by tackling the task of searching for an eigenvalue without additional
constraints. For diagonalizable matrices, our algorithm has <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-253-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1383 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.9em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1384><span class=texatom id=MathJax-Span-1385><span class=mrow id=MathJax-Span-1386><span class=munderover id=MathJax-Span-1387><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1388 style=font-family:MathJax_Math-italic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-1389 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-1390 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1391><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1392 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-1393><span class=mrow id=MathJax-Span-1394><span class=mo id=MathJax-Span-1395 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1396 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1397 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span> complexity with an error <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-254-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1398 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1399><span class=mi id=MathJax-Span-1400 style=font-family:MathJax_Math-italic>ε</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, achieving the
nearly Heisenberg scaling. Subsequently, we study the identification of
eigenvalues closest to a specified point or line, extending the results for
ground energy and energy gap problems in Hermitian matrices. We achieve an
accuracy scaling of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-255-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1401 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.9em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1402><span class=texatom id=MathJax-Span-1403><span class=mrow id=MathJax-Span-1404><span class=munderover id=MathJax-Span-1405><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1406 style=font-family:MathJax_Math-italic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-1407 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-1408 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1409><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1410 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-1411><span class=mrow id=MathJax-Span-1412><span class=mo id=MathJax-Span-1413 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1414 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1415 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span> for general diagonalizable
matrices, further refining to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-256-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1416 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.9em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1417><span class=texatom id=MathJax-Span-1418><span class=mrow id=MathJax-Span-1419><span class=munderover id=MathJax-Span-1420><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1421 style=font-family:MathJax_Math-italic>O</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.41em,3.938em,-999.997em);top:-4.627em;left:0.234em><span class=mo id=MathJax-Span-1422 style=font-family:MathJax_Main>~</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span class=mo id=MathJax-Span-1423 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1424><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1425 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.466em><span class=texatom id=MathJax-Span-1426><span class=mrow id=MathJax-Span-1427><span class=mo id=MathJax-Span-1428 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1429 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1430 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span> under the condition
of real eigenvalues or constant distance from the reference point. The
algorithm's foundation lies in the synergy of three techniques: the
relationship between eigenvalues of matrix <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-257-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1431 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1432><span class=mi id=MathJax-Span-1433 style=font-family:MathJax_Math-italic>A</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and the minimum singular value
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-258-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1434 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1435><span class=mi id=MathJax-Span-1436 style=font-family:MathJax_Math-italic>A</span><span class=mo id=MathJax-Span-1437 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1438 style=font-family:MathJax_Math-italic;padding-left:0.234em>μ</span><span class=mi id=MathJax-Span-1439 style=font-family:MathJax_Math-italic>I<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>, quantum singular value threshold subroutine extended from quantum
singular-value estimation, and problem-specific searching algorithms. Our
algorithms find applications in diverse domains, including estimating the
relaxation time of Markov chains, solving Liouvillian gaps in open quantum
systems, and verifying PT-symmetry broken/unbroken phases. These applications
underscore the significance of our quantum eigensolvers for problems across
various disciplines.
</p>
</div>
</dd>
<dt><a name=item627>[627]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12135 title=Abstract>arXiv:2401.12135</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.12135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Continuous Variable Coherent Ising Machines via Momentum
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Brown%2C+R">Robin Brown</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Venturelli%2C+D">Davide Venturelli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pavone%2C+M">Marco Pavone</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Neira%2C+D+E+B">David E. Bernal Neira</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)
</div>
<p class=mathjax>The Coherent Ising Machine (CIM) is a non-conventional architecture that
takes inspiration from physical annealing processes to solve Ising problems
heuristically. Its dynamics are naturally continuous and described by a set of
ordinary differential equations that have been proven to be useful for the
optimization of continuous variables non-convex quadratic optimization
problems. The dynamics of such Continuous Variable CIMs (CV-CIM) encourage
optimization via optical pulses whose amplitudes are determined by the negative
gradient of the objective; however, standard gradient descent is known to be
trapped by local minima and hampered by poor problem conditioning. In this
work, we propose to modify the CV-CIM dynamics using more sophisticated pulse
injections based on tried-and-true optimization techniques such as momentum and
Adam. Through numerical experiments, we show that the momentum and Adam updates
can significantly speed up the CV-CIM's convergence and improve sample
diversity over the original CV-CIM dynamics. We also find that the
Adam-CV-CIM's performance is more stable as a function of feedback strength,
especially on poorly conditioned instances, resulting in an algorithm that is
more robust, reliable, and easily tunable. More broadly, we identify the CIM
dynamical framework as a fertile opportunity for exploring the intersection of
classical optimization and modern analog computing.
</p>
</div>
</dd>
<dt><a name=item628>[628]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12140 title=Abstract>arXiv:2401.12140</a> (cross-list from math.AG) [<a href=https://arxiv.org/pdf/2401.12140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chebyshev Varieties
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bel-Afia%2C+Z">Zaïneb Bel-Afia</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meroni%2C+C">Chiara Meroni</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Telen%2C+S">Simon Telen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Geometry (math.AG)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>Chebyshev varieties are algebraic varieties parametrized by Chebyshev
polynomials or their multivariate generalizations. We determine the dimension,
degree, singular locus and defining equations of these varieties. We explain
how they play the role of toric varieties in sparse polynomial root finding,
when monomials are replaced by Chebyshev polynomials. We present numerical root
finding algorithms that exploit our results.
</p>
</div>
</dd>
<dt><a name=item629>[629]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12153 title=Abstract>arXiv:2401.12153</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.12153 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12153 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12153 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extension property for partial automorphisms of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-259-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1440 style=width:0.743em;display:inline-block><span style=display:inline-block;position:relative;width:0.604em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.6em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1441><span class=mi id=MathJax-Span-1442 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.669em"></span></span></nobr></span>-partite and semigeneric tournaments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hubi%C4%8Dka%2C+J">Jan Hubička</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jahel%2C+C">Colin Jahel</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kone%C4%8Dn%C3%BD%2C+M">Matěj Konečný</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sabok%2C+M">Marcin Sabok</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Logic (math.LO)
</div>
<p class=mathjax>We present a proof of the extension property for partial automorphisms (EPPA)
for classes of finite <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-260-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1443 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1444><span class=mi id=MathJax-Span-1445 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-partite tournaments for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-261-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1446 style=width:8.626em;display:inline-block><span style=display:inline-block;position:relative;width:7.179em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1007.12em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1447><span class=mi id=MathJax-Span-1448 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1449 style=font-family:MathJax_Main;padding-left:0.292em>∈</span><span class=mo id=MathJax-Span-1450 style=font-family:MathJax_Main;padding-left:0.292em>{</span><span class=mn id=MathJax-Span-1451 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-1452 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-1453 style=font-family:MathJax_Main;padding-left:0.177em>3</span><span class=mo id=MathJax-Span-1454 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-1455 style=font-family:MathJax_Main;padding-left:0.177em>…</span><span class=mo id=MathJax-Span-1456 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-1457 style=font-family:MathJax_Math-italic;padding-left:0.177em>ω</span><span class=mo id=MathJax-Span-1458 style=font-family:MathJax_Main>}</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, and for the class of finite semigeneric tournaments. We
also prove that the generic <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-262-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1459 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1460><span class=mi id=MathJax-Span-1461 style=font-family:MathJax_Math-italic>ω</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-partite tournament and the generic
semigeneric tournament have ample generics.
</p>
</div>
</dd>
<dt><a name=item630>[630]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12167 title=Abstract>arXiv:2401.12167</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.12167 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12167 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Semantic Compression for CNN Inference in Multi-access Edge Computing: A Graph Reinforcement Learning-based Autoencoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+N">Nan Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Iosifidis%2C+A">Alexandros Iosifidis</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2211.13745>arXiv:2211.13745</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper studies the computational offloading of CNN inference in dynamic
multi-access edge computing (MEC) networks. To address the uncertainties in
communication time and computation resource availability, we propose a novel
semantic compression method, autoencoder-based CNN architecture (AECNN), for
effective semantic extraction and compression in partial offloading. In the
semantic encoder, we introduce a feature compression module based on the
channel attention mechanism in CNNs, to compress intermediate data by selecting
the most informative features. In the semantic decoder, we design a lightweight
decoder to reconstruct the intermediate data through learning from the received
compressed data to improve accuracy. To effectively trade-off communication,
computation, and inference accuracy, we design a reward function and formulate
the offloading problem of CNN inference as a maximization problem with the goal
of maximizing the average inference accuracy and throughput over the long term.
To address this maximization problem, we propose a graph reinforcement
learning-based AECNN (GRL-AECNN) method, which outperforms existing works
DROO-AECNN, GRL-BottleNet++ and GRL-DeepJSCC under different dynamic scenarios.
This highlights the advantages of GRL-AECNN in offloading decision-making in
dynamic MEC.
</p>
</div>
</dd>
<dt><a name=item631>[631]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12182 title=Abstract>arXiv:2401.12182</a> (cross-list from math.DS) [<a href=https://arxiv.org/pdf/2401.12182 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12182 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tracking before detection using partial orders and optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Robinson%2C+M">Michael Robinson</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Stein%2C+M">Michael Stein</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Owen%2C+H+S">Henry S. Owen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Dynamical Systems (math.DS)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>This article addresses the problem of multi-object tracking by using a
non-deterministic model of target behaviors with hard constraints. To capture
the evolution of target features as well as their locations, we permit objects
to lie in a general topological target configuration space, rather than a
Euclidean space. We obtain tracker performance bounds based on sample rates,
and derive a flexible, agnostic tracking algorithm. We demonstrate our
algorithm on two scenarios involving laboratory and field data.
</p>
</div>
</dd>
<dt><a name=item632>[632]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12203 title=Abstract>arXiv:2401.12203</a> (cross-list from astro-ph.IM) [<a href=https://arxiv.org/pdf/2401.12203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=P%C3%A9rez-D%C3%ADaz%2C+V+S">Víctor Samuel Pérez-Díaz</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Mart%C3%ADnez-Galarza%2C+J+R">Juan Rafael Martínez-Galarza</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Caicedo%2C+A">Alexander Caicedo</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=D%27Abrusco%2C+R">Raffaele D'Abrusco</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 11 figures. Accepted in MNRAS
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The automatic classification of X-ray detections is a necessary step in
extracting astrophysical information from compiled catalogs of astrophysical
sources. Classification is useful for the study of individual objects,
statistics for population studies, as well as for anomaly detection, i.e., the
identification of new unexplored phenomena, including transients and spectrally
extreme sources. Despite the importance of this task, classification remains
challenging in X-ray astronomy due to the lack of optical counterparts and
representative training sets. We develop an alternative methodology that
employs an unsupervised machine learning approach to provide probabilistic
classes to Chandra Source Catalog sources with a limited number of labeled
sources, and without ancillary information from optical and infrared catalogs.
We provide a catalog of probabilistic classes for 8,756 sources, comprising a
total of 14,507 detections, and demonstrate the success of the method at
identifying emission from young stellar objects, as well as distinguishing
between small-scale and large-scale compact accretors with a significant level
of confidence. We investigate the consistency between the distribution of
features among classified objects and well-established astrophysical hypotheses
such as the unified AGN model. This provides interpretability to the
probabilistic classifier. Code and tables are available publicly through
GitHub. We provide a web playground for readers to explore our final
classification at https://umlcaxs-playground.streamlit.app.
</p>
</div>
</dd>
<dt><a name=item633>[633]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12216 title=Abstract>arXiv:2401.12216</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.12216 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12216 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Amortila%2C+P">Philip Amortila</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cao%2C+T">Tongyi Cao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)
</div>
<p class=mathjax>A pervasive phenomenon in machine learning applications is distribution
shift, where training and deployment conditions for a machine learning model
differ. As distribution shift typically results in a degradation in
performance, much attention has been devoted to algorithmic interventions that
mitigate these detrimental effects. In this paper, we study the effect of
distribution shift in the presence of model misspecification, specifically
focusing on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-263-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1462 style=width:1.739em;display:inline-block><span style=display:inline-block;position:relative;width:1.45em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.45em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1463><span class=msubsup id=MathJax-Span-1464><span style=display:inline-block;position:relative;width:1.45em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1465 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=texatom id=MathJax-Span-1466><span class=mrow id=MathJax-Span-1467><span class=mi id=MathJax-Span-1468 style=font-size:70.7%;font-family:MathJax_Main>∞</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-misspecified regression and adversarial covariate
shift, where the regression target remains fixed while the covariate
distribution changes arbitrarily. We show that empirical risk minimization, or
standard least squares regression, can result in undesirable misspecification
amplification where the error due to misspecification is amplified by the
density ratio between the training and testing distributions. As our main
result, we develop a new algorithm -- inspired by robust optimization
techniques -- that avoids this undesirable behavior, resulting in no
misspecification amplification while still obtaining optimal statistical rates.
As applications, we use this regression procedure to obtain new guarantees in
offline and online reinforcement learning with misspecification and establish
new separations between previously studied structural conditions and notions of
coverage.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 23 Jan 24</h3>
<dl>
<dt><a name=item634>[634]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1906.07054 title=Abstract>arXiv:1906.07054</a> (replaced) [<a href=https://arxiv.org/pdf/1906.07054 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/1906.07054 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/1906.07054 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discrete calculus with cubic cells on discrete manifolds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Carlo%2C+L">Leonardo De Carlo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A didactic guide for ArXiv, intended to make more explicit the computational nature with respect to the algebraic topology literature
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Differential Geometry (math.DG)
</div>
</div>
</dd>
<dt><a name=item635>[635]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2002.11503 title=Abstract>arXiv:2002.11503</a> (replaced) [<a href=https://arxiv.org/pdf/2002.11503 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2002.11503 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2002.11503 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wavelet-based temporal models of human activity for anomaly detection in smart robot-assisted environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandez-Carmona%2C+M">Manuel Fernandez-Carmona</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mghames%2C+S">Sariah Mghames</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bellotto%2C+N">Nicola Bellotto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 6 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Ambient Intelligence and Smart Environments, pp. 1-20,
 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item636>[636]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2003.09895 title=Abstract>arXiv:2003.09895</a> (replaced) [<a href=https://arxiv.org/pdf/2003.09895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2003.09895 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2003.09895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Local Information Cost of Distributed Graph Spanners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+P">Peter Robinson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A preliminary version of this paper appeared in the proceedings of SODA 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item637>[637]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2006.05259 title=Abstract>arXiv:2006.05259</a> (replaced) [<a href=https://arxiv.org/pdf/2006.05259 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2006.05259 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wavelet Networks: Scale-Translation Equivariant Learning From Raw Time-Series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romero%2C+D+W">David W. Romero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bekkers%2C+E+J">Erik J. Bekkers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tomczak%2C+J+M">Jakub M. Tomczak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoogendoorn%2C+M">Mark Hoogendoorn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item638>[638]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2009.01896 title=Abstract>arXiv:2009.01896</a> (replaced) [<a href=https://arxiv.org/pdf/2009.01896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2009.01896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Author Mentions in Science News Reveal Widespread Disparities Across Name-inferred Ethnicities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+H">Hao Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teplitskiy%2C+M">Misha Teplitskiy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jurgens%2C+D">David Jurgens</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 68 pages, 8 figures, 11 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item639>[639]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2102.00668 title=Abstract>arXiv:2102.00668</a> (replaced) [<a href=https://arxiv.org/pdf/2102.00668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2102.00668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graphs of Joint Types, Noninteractive Simulation, and Stronger Hypercontractivity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lei Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anantharam%2C+V">Venkat Anantharam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jun Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in the IEEE Transactions on Information Theory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Combinatorics (math.CO); Functional Analysis (math.FA); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item640>[640]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2103.01460 title=Abstract>arXiv:2103.01460</a> (replaced) [<a href=https://arxiv.org/pdf/2103.01460 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2103.01460 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Limited-Trust in Social Network Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murray%2C+T">Timothy Murray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garg%2C+J">Jugal Garg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagi%2C+R">Rakesh Nagi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Main paper plus e-companion
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item641>[641]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2103.11038 title=Abstract>arXiv:2103.11038</a> (replaced) [<a href=https://arxiv.org/pdf/2103.11038 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2103.11038 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2103.11038 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stochastic comparisons, differential entropy and varentropy for distributions induced by probability density functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Di+Crescenzo%2C+A">Antonio Di Crescenzo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Paolillo%2C+L">Luca Paolillo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Suarez-Llorens%2C+A">Alfonso Suarez-Llorens</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, accepted for publication in Metrika
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item642>[642]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2104.03652 title=Abstract>arXiv:2104.03652</a> (replaced) [<a href=https://arxiv.org/pdf/2104.03652 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2104.03652 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interval constraint programming for globally solving catalog-based categorical optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vanaret%2C+C">Charlie Vanaret</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> J Glob Optim (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Combinatorics (math.CO); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item643>[643]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2106.01135 title=Abstract>arXiv:2106.01135</a> (replaced) [<a href=https://arxiv.org/pdf/2106.01135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2106.01135 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2106.01135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MNL-Bandit with Knapsacks: a near-optimal algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aznag%2C+A">Abdellah Aznag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+V">Vineet Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perivier%2C+N">Noemie Perivier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item644>[644]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2106.04852 title=Abstract>arXiv:2106.04852</a> (replaced) [<a href=https://arxiv.org/pdf/2106.04852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2106.04852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Tiny Network for Recognition-Oriented Face Image Quality Assessment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+B">Baoyun Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Min Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Dongsheng Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item645>[645]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2106.05410 title=Abstract>arXiv:2106.05410</a> (replaced) [<a href=https://arxiv.org/pdf/2106.05410 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2106.05410 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hojjati%2C+H">Hadi Hojjati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Armanfard%2C+N">Narges Armanfard</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering (Early
 Access), 2023, 1-12
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item646>[646]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2109.01636 title=Abstract>arXiv:2109.01636</a> (replaced) [<a href=https://arxiv.org/pdf/2109.01636 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2109.01636 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2109.01636 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinyang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Want to correct
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item647>[647]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2109.04033 title=Abstract>arXiv:2109.04033</a> (replaced) [<a href=https://arxiv.org/pdf/2109.04033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2109.04033 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2109.04033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Versions of Gradient Temporal Difference Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Donghwan Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+H">Han-Dong Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jihoon Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+O">Okyong Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item648>[648]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.12305 title=Abstract>arXiv:2111.12305</a> (replaced) [<a href=https://arxiv.org/pdf/2111.12305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2111.12305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Thundernna: a white box adversarial attack
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+L">Linfeng Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamidi%2C+S+M">Shayan Mohajer Hamidi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item649>[649]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2111.13091 title=Abstract>arXiv:2111.13091</a> (replaced) [<a href=https://arxiv.org/pdf/2111.13091 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2111.13091 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2111.13091 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Asynchronous Session-Based Concurrency: Deadlock-freedom in Cyclic Process Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+den+Heuvel%2C+B">Bas van den Heuvel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez%2C+J+A">Jorge A. Pérez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version of <a href=https://arxiv.org/abs/2110.00146>arXiv:2110.00146</a>, doi:10.4204/EPTCS.347.3 and <a href=https://arxiv.org/abs/2209.06820>arXiv:2209.06820</a>, doi:10.4204/EPTCS.368.5
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item650>[650]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2201.08988 title=Abstract>arXiv:2201.08988</a> (replaced) [<a href=https://arxiv.org/pdf/2201.08988 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2201.08988 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2201.08988 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faster Algorithms for Sparse ILP and Hypergraph Multi-Packing/Multi-Cover Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gribanov%2C+D">Dmitry Gribanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malyshev%2C+D">Dmitry Malyshev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zolotykh%2C+N">Nikolai Zolotykh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item651>[651]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.05612 title=Abstract>arXiv:2202.05612</a> (replaced) [<a href=https://arxiv.org/pdf/2202.05612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.05612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-dimensional Inference and FDR Control for Simulated Markov Random Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wei%2C+H">Haoyu Wei</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Lei%2C+X">Xiaoyu Lei</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Han%2C+Y">Yixin Han</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhang%2C+H">Huiming Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item652>[652]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.00144 title=Abstract>arXiv:2203.00144</a> (replaced) [<a href=https://arxiv.org/pdf/2203.00144 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.00144 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Concordance Index decomposition: A measure for a deeper understanding of survival prediction models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alabdallah%2C+A">Abdallah Alabdallah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohlsson%2C+M">Mattias Ohlsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pashami%2C+S">Sepideh Pashami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%B6gnvaldsson%2C+T">Thorsteinn Rögnvaldsson</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Artificial Intelligence in Medicine, Volume 148, February 2024,
 102781
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item653>[653]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.00799 title=Abstract>arXiv:2203.00799</a> (replaced) [<a href=https://arxiv.org/pdf/2203.00799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2203.00799 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2203.00799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weighted domination models and randomized heuristics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dijkstra%2C+L">Lukas Dijkstra</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gagarin%2C+A">Andrei Gagarin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zverovich%2C+V">Vadim Zverovich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 35 pages, 4 figures, 8 tables; enhanced version from October 2023; presented at the 10th International Network Optimization Conference, INOC 2022, Aachen, Germany, June 7-10, 2022, extended abstract at <a href=https://www.math2.rwth-aachen.de/files/inoc2022/bookofabstracts.pdf>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
</div>
</dd>
<dt><a name=item654>[654]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.03986 title=Abstract>arXiv:2203.03986</a> (replaced) [<a href=https://arxiv.org/pdf/2203.03986 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.03986 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Randomized Smoothing for Optimal Control of Nonsmooth Dynamical Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lidec%2C+Q+L">Quentin Le Lidec</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schramm%2C+F">Fabian Schramm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montaut%2C+L">Louis Montaut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmid%2C+C">Cordelia Schmid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laptev%2C+I">Ivan Laptev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carpentier%2C+J">Justin Carpentier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item655>[655]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.13718 title=Abstract>arXiv:2203.13718</a> (replaced) [<a href=https://arxiv.org/pdf/2203.13718 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.13718 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Digital Fingerprinting of Microstructures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=White%2C+M+D">Michael D. White</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tarakanov%2C+A">Alexander Tarakanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Race%2C+C+P">Christopher P. Race</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Withers%2C+P+J">Philip J. Withers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Law%2C+K+J+H">Kody J.H. Law</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Materials Science (cond-mat.mtrl-sci); Computational Physics (physics.comp-ph)
</div>
</div>
</dd>
<dt><a name=item656>[656]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.14647 title=Abstract>arXiv:2203.14647</a> (replaced) [<a href=https://arxiv.org/pdf/2203.14647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.14647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruiz-Dolz%2C+R">Ramon Ruiz-Dolz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heras%2C+S">Stella Heras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Fornes%2C+A">Ana García-Fornes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EMNLP 2023 Accepted Version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item657>[657]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.03842 title=Abstract>arXiv:2204.03842</a> (replaced) [<a href=https://arxiv.org/pdf/2204.03842 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2204.03842 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From 2D Images to 3D Model:Weakly Supervised Multi-View Face Reconstruction with Deep Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+W">Weiguang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chaolong Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J">Jianan Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuyao Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+B">Bin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hussain%2C+A">Amir Hussain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item658>[658]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.07526 title=Abstract>arXiv:2204.07526</a> (replaced) [<a href=https://arxiv.org/pdf/2204.07526 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2204.07526 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dudeja%2C+R">Rishabh Dudeja</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hsu%2C+D">Daniel Hsu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item659>[659]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.10309 title=Abstract>arXiv:2204.10309</a> (replaced) [<a href=https://arxiv.org/pdf/2204.10309 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2204.10309 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On a conjecture of Talagrand on selector processes and a consequence on positive empirical processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Park%2C+J">Jinyoung Park</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pham%2C+H+T">Huy Tuan Pham</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Final version, 22 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item660>[660]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.11209 title=Abstract>arXiv:2204.11209</a> (replaced) [<a href=https://arxiv.org/pdf/2204.11209 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2204.11209 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2204.11209 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Locality Sensitive Hashing for Structured Data: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item661>[661]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.02422 title=Abstract>arXiv:2205.02422</a> (replaced) [<a href=https://arxiv.org/pdf/2205.02422 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2205.02422 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2205.02422 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Semantic Communications for Resource-Efficient Quantum Networking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chehimi%2C+M">Mahdi Chehimi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaccour%2C+C">Christina Chaccour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item662>[662]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.05173 title=Abstract>arXiv:2205.05173</a> (replaced) [<a href=https://arxiv.org/pdf/2205.05173 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.05173 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Supervised Anomaly Detection: A Survey and Outlook
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hojjati%2C+H">Hadi Hojjati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ho%2C+T+K+K">Thi Kieu Khanh Ho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Armanfard%2C+N">Narges Armanfard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 4 figures, 5 tables
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Neural Networks, Volume 172, April 2024, 106106
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item663>[663]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.11359 title=Abstract>arXiv:2205.11359</a> (replaced) [<a href=https://arxiv.org/pdf/2205.11359 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.11359 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Size-Independent Generalization Bounds for Deep Operator Nets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopalani%2C+P">Pulkit Gopalani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karmakar%2C+S">Sayar Karmakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+D">Dibyakanti Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukherjee%2C+A">Anirbit Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 5 figures; Added theorem on generalization error indicating benefits of training DeepONets on the Huber loss and corresponding experiments
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item664>[664]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.14540 title=Abstract>arXiv:2205.14540</a> (replaced) [<a href=https://arxiv.org/pdf/2205.14540 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.14540 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+F">Feng Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yangguang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marculescu%2C+D">Diana Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Edge Intelligence Workshop Workshop at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item665>[665]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.15760 title=Abstract>arXiv:2205.15760</a> (replaced) [<a href=https://arxiv.org/pdf/2205.15760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.15760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimized Distortion and Proportional Fairness in Voting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ebadian%2C+S">Soroush Ebadian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kahng%2C+A">Anson Kahng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peters%2C+D">Dominik Peters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+N">Nisarg Shah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted version at ACM TEAC, 36 pages including appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)
</div>
</div>
</dd>
<dt><a name=item666>[666]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.04300 title=Abstract>arXiv:2206.04300</a> (replaced) [<a href=https://arxiv.org/pdf/2206.04300 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.04300 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cone-Restricted Information Theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=George%2C+I">Ian George</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Chitambar%2C+E">Eric Chitambar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Updated formatting, terminology, and some of the presentation for clarity. Some typos fixed as well
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item667>[667]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.09542 title=Abstract>arXiv:2206.09542</a> (replaced) [<a href=https://arxiv.org/pdf/2206.09542 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.09542 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual Guidance for User Placement in Avatar-Mediated Telepresence between Dissimilar Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+D">Dongseok Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiho Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+T">Taehei Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Sung-Hee Lee</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Visualization and Computer Graphics, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item668>[668]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.10078 title=Abstract>arXiv:2206.10078</a> (replaced) [<a href=https://arxiv.org/pdf/2206.10078 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.10078 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Manifold Scattering Transform for High-Dimensional Point Cloud Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chew%2C+J">Joyce Chew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steach%2C+H+R">Holly R. Steach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viswanath%2C+S">Siddharth Viswanath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Hau-Tieng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirn%2C+M">Matthew Hirn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Needell%2C+D">Deanna Needell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnaswamy%2C+S">Smita Krishnaswamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perlmutter%2C+M">Michael Perlmutter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in the TAG in DS Workshop at ICML. For subsequent theoretical guarantees, please see Section 6 of <a href=https://arxiv.org/abs/2208.08561>arXiv:2208.08561</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Numerical Analysis (math.NA); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item669>[669]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.13082 title=Abstract>arXiv:2206.13082</a> (replaced) [<a href=https://arxiv.org/pdf/2206.13082 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2206.13082 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2206.13082 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PST: Plant segmentation transformer for 3D point clouds of rapeseed plants at the podding stage
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+R">Ruiming Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhihong Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+P">Pengyao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cen%2C+H">Haiyan Cen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 46 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item670>[670]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.14358 title=Abstract>arXiv:2206.14358</a> (replaced) [<a href=https://arxiv.org/pdf/2206.14358 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2206.14358 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2206.14358 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using Twitter Data to Understand Public Perceptions of Approved versus Off-label Use for COVID-19-related Medications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+Y">Yining Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+H">Hang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shixu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plasek%2C+J+M">Joseph M. Plasek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bates%2C+D+W">David W. Bates</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Li Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Full paper published in JAMIA
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> amiajnl-2022-012337.R1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Applications (stat.AP)
</div>
</div>
</dd>
<dt><a name=item671>[671]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.15269 title=Abstract>arXiv:2206.15269</a> (replaced) [<a href=https://arxiv.org/pdf/2206.15269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.15269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Reinforcement Learning with Swin Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+L">Li Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goodwin%2C+M">Morten Goodwin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yazidi%2C+A">Anis Yazidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Engelstad%2C+P">Paal Engelstad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item672>[672]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.15414 title=Abstract>arXiv:2206.15414</a> (replaced) [<a href=https://arxiv.org/pdf/2206.15414 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.15414 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bounding and computing obstacle numbers of graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balko%2C+M">Martin Balko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaplick%2C+S">Steven Chaplick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganian%2C+R">Robert Ganian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+S">Siddharth Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoffmann%2C+M">Michael Hoffmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valtr%2C+P">Pavel Valtr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolff%2C+A">Alexander Wolff</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item673>[673]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.00067 title=Abstract>arXiv:2207.00067</a> (replaced) [<a href=https://arxiv.org/pdf/2207.00067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.00067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rethinking Unsupervised Domain Adaptation for Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhijie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suganuma%2C+M">Masanori Suganuma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Okatani%2C+T">Takayuki Okatani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review in Pattern Recognition Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item674>[674]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.07143 title=Abstract>arXiv:2207.07143</a> (replaced) [<a href=https://arxiv.org/pdf/2207.07143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.07143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Node Replication: Theory And Practice
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kesner%2C+D">Delia Kesner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peyrot%2C+L">Loïc Peyrot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ventura%2C+D">Daniel Ventura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item675>[675]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.11456 title=Abstract>arXiv:2207.11456</a> (replaced) [<a href=https://arxiv.org/pdf/2207.11456 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.11456 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Vertical Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+D">Dongqi Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+T">Tao Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+Y">Yan Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+L">Lixin Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengwei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shangguang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item676>[676]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.03784 title=Abstract>arXiv:2208.03784</a> (replaced) [<a href=https://arxiv.org/pdf/2208.03784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.03784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CoVault: A Secure Analytics Platform
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Viti%2C+R">Roberta De Viti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheff%2C+I">Isaac Sheff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Glaeser%2C+N">Noemi Glaeser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dinis%2C+B">Baltasar Dinis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodrigues%2C+R">Rodrigo Rodrigues</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+B">Bobby Bhattacharjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hithnawi%2C+A">Anwar Hithnawi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garg%2C+D">Deepak Garg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Druschel%2C+P">Peter Druschel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item677>[677]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.04957 title=Abstract>arXiv:2208.04957</a> (replaced) [<a href=https://arxiv.org/pdf/2208.04957 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.04957 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+K">Ke Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yutong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+C">Cong Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+L">Lei Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+H">Haobo Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Q">Qiang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+C">Chao Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
</div>
</dd>
<dt><a name=item678>[678]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.05481 title=Abstract>arXiv:2208.05481</a> (replaced) [<a href=https://arxiv.org/pdf/2208.05481 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.05481 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-Frequency Space Diffusion Models for Accelerated MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cao%2C+C">Chentao Cao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cui%2C+Z">Zhuo-Xu Cui</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yue Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+S">Shaonan Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+T">Taijin Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zheng%2C+H">Hairong Zheng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+D">Dong Liang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhu%2C+Y">Yanjie Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted for IEEE TMI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item679>[679]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.12302 title=Abstract>arXiv:2208.12302</a> (replaced) [<a href=https://arxiv.org/pdf/2208.12302 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.12302 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uniform error estimate of an asymptotic preserving scheme for the Lévy-Fokker-Planck equation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sun%2C+W">Weiran Sun</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+L">Li Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
</div>
</div>
</dd>
<dt><a name=item680>[680]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.14701 title=Abstract>arXiv:2208.14701</a> (replaced) [<a href=https://arxiv.org/pdf/2208.14701 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2208.14701 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2208.14701 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Duality analysis of interior penalty discontinuous Galerkin methods under minimal regularity and application to the a priori and a posteriori error analysis of Helmholtz problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chaumont-Frelet%2C+T">T. Chaumont-Frelet</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
</div>
</div>
</dd>
<dt><a name=item681>[681]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.00368 title=Abstract>arXiv:2209.00368</a> (replaced) [<a href=https://arxiv.org/pdf/2209.00368 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.00368 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bribery Can Get Harder in Structured Multiwinner Approval Election
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kusek%2C+B">Bartosz Kusek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bredereck%2C+R">Robert Bredereck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faliszewski%2C+P">Piotr Faliszewski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaczmarczyk%2C+A">Andrzej Kaczmarczyk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knop%2C+D">Dušan Knop</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 1 figure, 1 table, published in the Proceedings of AAMAS-23
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item682>[682]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.01136 title=Abstract>arXiv:2209.01136</a> (replaced) [<a href=https://arxiv.org/pdf/2209.01136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.01136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Syncline Model -- Analyzing the Impact of Time Synchronization in Sensor Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jellum%2C+E+R">Erling Rennemo Jellum</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bryne%2C+T+H">Torleiv Håland Bryne</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Johansen%2C+T+A">Tor Arne Johansen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Orland%C3%ADc%2C+M">Milica Orlandíc</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published in IEEE CCTA2022 Proceedings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item683>[683]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.03825 title=Abstract>arXiv:2209.03825</a> (replaced) [<a href=https://arxiv.org/pdf/2209.03825 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.03825 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Eigenvalue Mapping-based Discretization of the Generalized Super-Twisting Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ding%2C+N">Ningning Ding</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item684>[684]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.04554 title=Abstract>arXiv:2209.04554</a> (replaced) [<a href=https://arxiv.org/pdf/2209.04554 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.04554 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diagnosis-guided Attack Recovery for Securing Robotic Vehicles from Sensor Deception Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dash%2C+P">Pritam Dash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guanpeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karimibiuki%2C+M">Mehdi Karimibiuki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pattabiraman%2C+K">Karthik Pattabiraman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item685>[685]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.07517 title=Abstract>arXiv:2209.07517</a> (replaced) [<a href=https://arxiv.org/pdf/2209.07517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.07517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spectral Total-Variation Processing of Shapes -- Theory and Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brokman%2C+J">Jonathan Brokman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burger%2C+M">Martin Burger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gilboa%2C+G">Guy Gilboa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 20 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
</div>
</dd>
<dt><a name=item686>[686]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.00044 title=Abstract>arXiv:2210.00044</a> (replaced) [<a href=https://arxiv.org/pdf/2210.00044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.00044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Task Formulation Matters When Learning Continually: A Case Study in Visual Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nikandrou%2C+M">Mavina Nikandrou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lu Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suglia%2C+A">Alessandro Suglia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konstas%2C+I">Ioannis Konstas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rieser%2C+V">Verena Rieser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item687>[687]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.00108 title=Abstract>arXiv:2210.00108</a> (replaced) [<a href=https://arxiv.org/pdf/2210.00108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.00108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clifford%2C+T">Tim Clifford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yiren Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anderson%2C+R">Ross Anderson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mullins%2C+R">Robert Mullins</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 7 figures, to be published in IEEE Secure and Trustworthy Machine Learning 2024. For website see <a href=https://ml.backdoors.uk/>this https URL</a> . For source code, see <a href=https://git.sr.ht/~tim-clifford/impnet_source>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item688>[688]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.00240 title=Abstract>arXiv:2210.00240</a> (replaced) [<a href=https://arxiv.org/pdf/2210.00240 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.00240 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Executable First-Order Queries in the Logic of Information Flows
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aamer%2C+H">Heba Aamer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Surinx%2C+D">Dimitri Surinx</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ternovska%2C+E">Eugenia Ternovska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+den+Bussche%2C+J">Jan Van den Bussche</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is the extended version of the two papers presented at ICDT 2020 and ICDT 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item689>[689]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.01751 title=Abstract>arXiv:2210.01751</a> (replaced) [<a href=https://arxiv.org/pdf/2210.01751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2210.01751 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2210.01751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proportional structures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anti%C4%87%2C+C">Christian Antić</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item690>[690]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.02428 title=Abstract>arXiv:2210.02428</a> (replaced) [<a href=https://arxiv.org/pdf/2210.02428 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.02428 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gradual C0: Symbolic Execution for Gradual Verification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DiVincenzo%2C+J">Jenna DiVincenzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McCormack%2C+I">Ian McCormack</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gouni%2C+H">Hemant Gouni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorenburg%2C+J">Jacob Gorenburg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramos-D%C3%A1vila%2C+J">Jan-Paul Ramos-Dávila</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mona Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmerman%2C+C">Conrad Zimmerman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sunshine%2C+J">Joshua Sunshine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanter%2C+%C3%89">Éric Tanter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aldrich%2C+J">Jonathan Aldrich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages without appendix supplement, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item691>[691]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.09745 title=Abstract>arXiv:2210.09745</a> (replaced) [<a href=https://arxiv.org/pdf/2210.09745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.09745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transfer learning with affine model transformation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Minami%2C+S">Shunya Minami</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Fukumizu%2C+K">Kenji Fukumizu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hayashi%2C+Y">Yoshihiro Hayashi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Yoshida%2C+R">Ryo Yoshida</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item692>[692]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.14571 title=Abstract>arXiv:2210.14571</a> (replaced) [<a href=https://arxiv.org/pdf/2210.14571 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.14571 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards the Detection of Diffusion Model Deepfakes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricker%2C+J">Jonas Ricker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damm%2C+S">Simon Damm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holz%2C+T">Thorsten Holz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+A">Asja Fischer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at VISAPP 2024. This is the extended version with additional experiments and supplemental material. Code and data: <a href=https://github.com/jonasricker/diffusion-model-deepfake-detection>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item693>[693]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.16349 title=Abstract>arXiv:2210.16349</a> (replaced) [<a href=https://arxiv.org/pdf/2210.16349 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.16349 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Numerical analysis of a time-stepping method for the Westervelt equation with time-fractional damping
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Baker%2C+K">Katherine Baker</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Banjai%2C+L">Lehel Banjai</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ptashnyk%2C+M">Mariya Ptashnyk</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
</div>
</div>
</dd>
<dt><a name=item694>[694]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.00652 title=Abstract>arXiv:2211.00652</a> (replaced) [<a href=https://arxiv.org/pdf/2211.00652 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.00652 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Persistent Tensors and Multiqudit Entanglement Transformation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gharahi%2C+M">Masoud Gharahi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Lysikov%2C+V">Vladimir Lysikov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages. Your comments are more than welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Mathematical Physics (math-ph); Commutative Algebra (math.AC)
</div>
</div>
</dd>
<dt><a name=item695>[695]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.02915 title=Abstract>arXiv:2211.02915</a> (replaced) [<a href=https://arxiv.org/pdf/2211.02915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.02915 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.02915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ESKNet-An enhanced adaptive selection kernel convolution for breast tumors segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+G">Gongping Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou%2C+L">Lu Zhou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+J">Jianxun Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yin%2C+X">Xiaotao Yin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cui%2C+L">Liang Cui</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+Y">Yu Dai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item696>[696]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.03324 title=Abstract>arXiv:2211.03324</a> (replaced) [<a href=https://arxiv.org/e-print/2211.03324 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decoding Neural Signals with Computational Models: A Systematic Review of Invasive BMI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Firuzi%2C+R">Rezwan Firuzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmadyani%2C+H">Hamed Ahmadyani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdi%2C+M+F">Mohammad Foad Abdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naderi%2C+D">Dana Naderi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassan%2C+J">Jahan Hassan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bokani%2C+A">Ayub Bokani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> We have made significant changes to this article
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item697>[697]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.06411 title=Abstract>arXiv:2211.06411</a> (replaced) [<a href=https://arxiv.org/pdf/2211.06411 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.06411 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Qafny: A Quantum-Program Verifier
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Li%2C+L">Liyi Li</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhu%2C+M">Mingwei Zhu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Cleaveland%2C+R">Rance Cleaveland</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Nicolellis%2C+A">Alexander Nicolellis</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Lee%2C+Y">Yi Lee</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Chang%2C+L">Le Chang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wu%2C+X">Xiaodi Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Version 4
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item698>[698]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.07394 title=Abstract>arXiv:2211.07394</a> (replaced) [<a href=https://arxiv.org/pdf/2211.07394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.07394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiyang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Zhedong Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+W">Wei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+L">Leigang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item699>[699]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.08594 title=Abstract>arXiv:2211.08594</a> (replaced) [<a href=https://arxiv.org/pdf/2211.08594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.08594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Orthogonal Polynomials Approximation Algorithm (OPAA):a functional analytic approach to estimating probability densities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bialokozowicz%2C+L+W">Lilian W. Bialokozowicz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Neurips 2023 Workshop "The Symbiosis of Deep Learning and Differential Equations (DLDE III)"
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item700>[700]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.08824 title=Abstract>arXiv:2211.08824</a> (replaced) [<a href=https://arxiv.org/pdf/2211.08824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.08824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SMILEtrack: SiMIlarity LEarning for Occlusion-Aware Multiple Object Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu-Hsiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsieh%2C+J">Jun-Wei Hsieh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Ping-Yang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+M">Ming-Ching Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=So%2C+H+H">Hung Hin So</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xin Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Our paper was accepted by AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item701>[701]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.09480 title=Abstract>arXiv:2211.09480</a> (replaced) [<a href=https://arxiv.org/pdf/2211.09480 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.09480 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ArcAid: Analysis of Archaeological Artifacts using Drawings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayon%2C+O">Offry Hayon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCnger%2C+S">Stefan Münger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shimshoni%2C+I">Ilan Shimshoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tal%2C+A">Ayellet Tal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item702>[702]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.09634 title=Abstract>arXiv:2211.09634</a> (replaced) [<a href=https://arxiv.org/pdf/2211.09634 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.09634 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.09634 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Sample Complexity of Two-Layer Networks: Lipschitz vs. Element-Wise Lipschitz Activation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daniely%2C+A">Amit Daniely</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Granot%2C+E">Elad Granot</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 35th International Conference on Algorithmic Learning Theory, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item703>[703]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.10540 title=Abstract>arXiv:2211.10540</a> (replaced) [<a href=https://arxiv.org/pdf/2211.10540 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.10540 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.10540 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Waiting Nets: State Classes and Taxonomy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%A9lou%C3%ABt%2C+L">Loïc Hélouët</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawal%2C+P">Pranay Agrawal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
</div>
</dd>
<dt><a name=item704>[704]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.11174 title=Abstract>arXiv:2211.11174</a> (replaced) [<a href=https://arxiv.org/pdf/2211.11174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.11174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unveiling the Tapestry: the Interplay of Generalization and Forgetting in Continual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zenglin Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jie%2C+J">Jing Jie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Ying Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+J+H">Joo Hwee Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mengmi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item705>[705]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.14082 title=Abstract>arXiv:2211.14082</a> (replaced) [<a href=https://arxiv.org/pdf/2211.14082 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.14082 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.14082 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simple Algorithms for Stochastic Score Classification with Small Approximation Ratios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plank%2C+B+M">Benedikt M. Plank</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schewior%2C+K">Kevin Schewior</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item706>[706]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.14835 title=Abstract>arXiv:2211.14835</a> (replaced) [<a href=https://arxiv.org/pdf/2211.14835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2211.14835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CLID: Controlled-Length Image Descriptions with Limited Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirsch%2C+E">Elad Hirsch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tal%2C+A">Ayellet Tal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item707>[707]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.00325 title=Abstract>arXiv:2212.00325</a> (replaced) [<a href=https://arxiv.org/pdf/2212.00325 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.00325 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HashVFL: Defending Against Data Reconstruction Attacks in Vertical Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+P">Pengyu Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+S">Shouling Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+C">Chong Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xing Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Ting Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item708>[708]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.01168 title=Abstract>arXiv:2212.01168</a> (replaced) [<a href=https://arxiv.org/pdf/2212.01168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.01168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yeongwoo Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+H">Hawoong Jeong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Conference paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)
</div>
</div>
</dd>
<dt><a name=item709>[709]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.03369 title=Abstract>arXiv:2212.03369</a> (replaced) [<a href=https://arxiv.org/pdf/2212.03369 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.03369 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Randomly Wired Neural Networks for Climate Model Emulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yik%2C+W">William Yik</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Silva%2C+S+J">Sam J. Silva</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Geiss%2C+A">Andrew Geiss</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Watson-Parris%2C+D">Duncan Watson-Parris</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in AIES
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item710>[710]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.05758 title=Abstract>arXiv:2212.05758</a> (replaced) [<a href=https://arxiv.org/pdf/2212.05758 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.05758 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BEV-MAE: Bird's Eye View Masked Autoencoders for Point Cloud Pre-training in Autonomous Driving Scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhiwei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yongtao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+S">Shengxiang Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+N">Nan Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item711>[711]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.11047 title=Abstract>arXiv:2212.11047</a> (replaced) [<a href=https://arxiv.org/pdf/2212.11047 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.11047 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discovering Process Models With Long-Term Dependencies While Providing Guarantees and Filtering Infrequent Behavior Patterns
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mannel%2C+L+L">Lisa Luise Mannel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+der+Aalst%2C+W+M+P">Wil M. P. van der Aalst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fundamenta Informaticae, Petri Nets Special Issue 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
</div>
</dd>
<dt><a name=item712>[712]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.11969 title=Abstract>arXiv:2212.11969</a> (replaced) [<a href=https://arxiv.org/pdf/2212.11969 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2212.11969 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2212.11969 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Invertibility of digraphs and tournaments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Alon%2C+N">Noga Alon</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Powierski%2C+E">Emil Powierski</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Savery%2C+M">Michael Savery</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scott%2C+A">Alex Scott</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wilmer%2C+E">Elizabeth Wilmer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages; v3: corrected abstract formatting; v2: minor changes incorporating referees' comments, and addition of Conjecture 3
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> SIAM Journal on Discrete Mathematics, 38: 327-347 (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
</div>
</dd>
<dt><a name=item713>[713]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.08898 title=Abstract>arXiv:2301.08898</a> (replaced) [<a href=https://arxiv.org/pdf/2301.08898 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.08898 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recurrent Generic Contour-based Instance Segmentation with Progressive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+H">Hao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+K">Keyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yufei Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+J">Jiajun Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Houqiang Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item714>[714]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.13181 title=Abstract>arXiv:2301.13181</a> (replaced) [<a href=https://arxiv.org/pdf/2301.13181 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2301.13181 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2301.13181 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Partitioned Matching Games for International Kidney Exchange
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benedek%2C+M">Márton Benedek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bir%C3%B3%2C+P">Péter Biró</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kern%2C+W">Walter Kern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A1lv%C3%B6lgyi%2C+D">Dömötör Pálvölgyi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paulusma%2C+D">Daniël Paulusma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item715>[715]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06419 title=Abstract>arXiv:2302.06419</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06419 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06419 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lian%2C+J">Jiachen Lian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Baevski%2C+A">Alexei Baevski</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hsu%2C+W">Wei-Ning Hsu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Auli%2C+M">Michael Auli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2023 ASRU
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item716>[716]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06726 title=Abstract>arXiv:2302.06726</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06726 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06726 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Swap Agnostic Learning, or Characterizing Omniprediction via Multicalibration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopalan%2C+P">Parikshit Gopalan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+M+P">Michael P. Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reingold%2C+O">Omer Reingold</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item717>[717]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.08577 title=Abstract>arXiv:2302.08577</a> (replaced) [<a href=https://arxiv.org/pdf/2302.08577 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.08577 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> For Generated Text, Is NLI-Neutral Text the Best Text?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mersinias%2C+M">Michail Mersinias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahowald%2C+K">Kyle Mahowald</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item718>[718]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.11337 title=Abstract>arXiv:2302.11337</a> (replaced) [<a href=https://arxiv.org/pdf/2302.11337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.11337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Matrix Decomposition and Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lu%2C+J">Jun Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item719>[719]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.12584 title=Abstract>arXiv:2302.12584</a> (replaced) [<a href=https://arxiv.org/pdf/2302.12584 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.12584 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruiz-Dolz%2C+R">Ramon Ruiz-Dolz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iranzo-S%C3%A1nchez%2C+J">Javier Iranzo-Sánchez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages; EMNLP 2023 Accepted Version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item720>[720]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.13113 title=Abstract>arXiv:2302.13113</a> (replaced) [<a href=https://arxiv.org/pdf/2302.13113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.13113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Self-Adjusting k-ary Search Tree Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feder%2C+E">Evgenii Feder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paramonov%2C+A">Anton Paramonov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salem%2C+I">Iosif Salem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmid%2C+S">Stefan Schmid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aksenov%2C+V">Vitaly Aksenov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item721>[721]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.03906 title=Abstract>arXiv:2303.03906</a> (replaced) [<a href=https://arxiv.org/pdf/2303.03906 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.03906 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compositional Confluence Criteria
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shintani%2C+K">Kiraku Shintani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirokawa%2C+N">Nao Hirokawa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item722>[722]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.05105 title=Abstract>arXiv:2303.05105</a> (replaced) [<a href=https://arxiv.org/pdf/2303.05105 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.05105 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MaskDiff: Modeling Mask Distribution with Diffusion Probabilistic Model for Few-Shot Instance Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+M">Minh-Quan Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T+V">Tam V. Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+T">Trung-Nghia Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+T">Thanh-Toan Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+M+N">Minh N. Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+M">Minh-Triet Tran</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI 2024 (oral presentation)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item723>[723]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.05123 title=Abstract>arXiv:2303.05123</a> (replaced) [<a href=https://arxiv.org/pdf/2303.05123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.05123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dominating Set Database Selection for Visual Place Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kornilova%2C+A">Anastasiia Kornilova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moskalenko%2C+I">Ivan Moskalenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pushkin%2C+T">Timofei Pushkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tojiboev%2C+F">Fakhriddin Tojiboev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tariverdizadeh%2C+R">Rahim Tariverdizadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+G">Gonzalo Ferrer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item724>[724]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.05479 title=Abstract>arXiv:2303.05479</a> (replaced) [<a href=https://arxiv.org/pdf/2303.05479 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.05479 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakamoto%2C+M">Mitsuhiko Nakamoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+A">Anikait Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mark%2C+M+S">Max Sobol Mark</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yi Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Finn%2C+C">Chelsea Finn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2023. project page: <a href=https://nakamotoo.github.io/Cal-QL>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item725>[725]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.07064 title=Abstract>arXiv:2303.07064</a> (replaced) [<a href=https://arxiv.org/pdf/2303.07064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.07064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Generalized Multi-Modal Fusion Detection Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Leichao Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiuxian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+M">Min Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+X">Xiaoyu Mo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item726>[726]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.07287 title=Abstract>arXiv:2303.07287</a> (replaced) [<a href=https://arxiv.org/pdf/2303.07287 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.07287 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tight Non-asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhang%2C+H">Huiming Zhang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wei%2C+H">Haoyu Wei</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cheng%2C+G">Guang Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)
</div>
</div>
</dd>
<dt><a name=item727>[727]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.11249 title=Abstract>arXiv:2303.11249</a> (replaced) [<a href=https://arxiv.org/pdf/2303.11249 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.11249 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexander%2C+Y">Yotam Alexander</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+La+Vega%2C+N">Nimrod De La Vega</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razin%2C+N">Noam Razin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+N">Nadav Cohen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item728>[728]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.11681 title=Abstract>arXiv:2303.11681</a> (replaced) [<a href=https://arxiv.org/pdf/2303.11681 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.11681 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Weijia Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hong Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> ICCV 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item729>[729]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.13472 title=Abstract>arXiv:2303.13472</a> (replaced) [<a href=https://arxiv.org/pdf/2303.13472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.13472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Promptable Game Models: Text-Guided Game Simulation via Masked Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menapace%2C+W">Willi Menapace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lathuili%C3%A8re%2C+S">Stéphane Lathuilière</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Achlioptas%2C+P">Panos Achlioptas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ACM Transactions on Graphics \c{opyright} Copyright is held by the owner/author(s) 2023. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in ACM Transactions on Graphics, <a href=http://dx.doi.org/10.1145/3635705>this http URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item730>[730]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.16180 title=Abstract>arXiv:2303.16180</a> (replaced) [<a href=https://arxiv.org/pdf/2303.16180 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.16180 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Coating by 3D Hybrid Programmable Matter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kostitsyna%2C+I">Irina Kostitsyna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liedtke%2C+D">David Liedtke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scheideler%2C+C">Christian Scheideler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Emerging Technologies (cs.ET)
</div>
</div>
</dd>
<dt><a name=item731>[731]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.17063 title=Abstract>arXiv:2303.17063</a> (replaced) [<a href=https://arxiv.org/pdf/2303.17063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.17063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Colosseum as a Digital Twin: Bridging Real-World Experimentation and Wireless Network Emulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Villa%2C+D">Davide Villa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tehrani-Moayyed%2C+M">Miead Tehrani-Moayyed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+C+P">Clifton Paul Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johari%2C+P">Pedram Johari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polese%2C+M">Michele Polese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 25 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item732>[732]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.01225 title=Abstract>arXiv:2304.01225</a> (replaced) [<a href=https://arxiv.org/pdf/2304.01225 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.01225 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A greedy approach for increased vehicle utilization in ridesharing networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Makhdomi%2C+A+A">Aqsa Ashraf Makhdomi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gillani%2C+I+A">Iqra Altaf Gillani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item733>[733]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.02981 title=Abstract>arXiv:2304.02981</a> (replaced) [<a href=https://arxiv.org/pdf/2304.02981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.02981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smart Contract and DeFi Security Tools: Do They Meet the Needs of Practitioners?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaliasos%2C+S">Stefanos Chaliasos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Charalambous%2C+M+A">Marcos Antonios Charalambous</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Liyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galanopoulou%2C+R">Rafaila Galanopoulou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gervais%2C+A">Arthur Gervais</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitropoulos%2C+D">Dimitris Mitropoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Livshits%2C+B">Ben Livshits</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item734>[734]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.03047 title=Abstract>arXiv:2304.03047</a> (replaced) [<a href=https://arxiv.org/pdf/2304.03047 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.03047 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+D">Dong An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hanqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenguan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K">Keji He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://github.com/MarSaKi/ETPNav>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item735>[735]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.04036 title=Abstract>arXiv:2304.04036</a> (replaced) [<a href=https://arxiv.org/pdf/2304.04036 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.04036 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized State Estimation: An Approach using Pseudomeasurements and Preintegration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cossette%2C+C+C">Charles Champagne Cossette</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shalaby%2C+M+A">Mohammed Ayman Shalaby</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saussi%C3%A9%2C+D">David Saussié</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 13 figures, submitted to IJRR
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item736>[736]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.04083 title=Abstract>arXiv:2304.04083</a> (replaced) [<a href=https://arxiv.org/pdf/2304.04083 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.04083 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VOICE: Visual Oracle for Interaction, Conversation, and Explanation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+D">Donggang Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Irger%2C+A">Alexandra Irger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Besancon%2C+L">Lonni Besancon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strnad%2C+O">Ondrej Strnad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+D">Deng Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bjorklund%2C+J">Johanna Bjorklund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ynnerman%2C+A">Anders Ynnerman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viola%2C+I">Ivan Viola</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item737>[737]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.05482 title=Abstract>arXiv:2304.05482</a> (replaced) [<a href=https://arxiv.org/pdf/2304.05482 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.05482 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computational Pathology: A Survey Review and The Way Forward
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hosseini%2C+M+S">Mahdi S. Hosseini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bejnordi%2C+B+E">Babak Ehteshami Bejnordi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Trinh%2C+V+Q">Vincent Quoc-Huy Trinh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hasan%2C+D">Danial Hasan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+X">Xingwen Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+T">Taehyo Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+H">Haochen Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wu%2C+T">Theodore Wu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chinniah%2C+K">Kajanan Chinniah</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Maghsoudlou%2C+S">Sina Maghsoudlou</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+R">Ryan Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+S">Stephen Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhu%2C+J">Jiadai Zhu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chan%2C+L">Lyndon Chan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khaki%2C+S">Samir Khaki</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Buin%2C+A">Andrei Buin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chaji%2C+F">Fatemeh Chaji</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Salehi%2C+A">Ala Salehi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+B+N">Bich Ngoc Nguyen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Samaras%2C+D">Dimitris Samaras</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in Elsevier Journal of Pathology Informatics (JPI) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item738>[738]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.06662 title=Abstract>arXiv:2304.06662</a> (replaced) [<a href=https://arxiv.org/pdf/2304.06662 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.06662 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning in Breast Cancer Imaging: A Decade of Progress and Future Directions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Luo%2C+L">Luyang Luo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+X">Xi Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lin%2C+Y">Yi Lin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ma%2C+X">Xiaoqi Ma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tan%2C+A">Andong Tan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chan%2C+R">Ronald Chan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vardhanabhuti%2C+V">Varut Vardhanabhuti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chu%2C+W+C">Winnie CW Chu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE RBME 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item739>[739]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.07042 title=Abstract>arXiv:2304.07042</a> (replaced) [<a href=https://arxiv.org/pdf/2304.07042 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.07042 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Graph ODE for Continuous-Time Sequential Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yifang Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+W">Wei Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Hongjun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+X">Xiao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by EEE Transactions on Knowledge and Data Engineering (TKDE 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item740>[740]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.07366 title=Abstract>arXiv:2304.07366</a> (replaced) [<a href=https://arxiv.org/pdf/2304.07366 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.07366 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jie Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yuchen Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+G">Gionnieve Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianqin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perrault%2C+S+T">Simon Tangi Perrault</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Will be published at the ACM CHI Conference on Human Factors in Computing Systems (CHI'24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item741>[741]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.07444 title=Abstract>arXiv:2304.07444</a> (replaced) [<a href=https://arxiv.org/pdf/2304.07444 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.07444 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Art of Camouflage: Few-shot Learning for Animal Detection and Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Thanh-Danh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+A+N">Anh-Khoa Nguyen Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+N">Nhat-Duy Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+V">Vinh-Tiep Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ngo%2C+T+D">Thanh Duc Ngo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+T">Thanh-Toan Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T+V">Tam V. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under-review Journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item742>[742]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14317 title=Abstract>arXiv:2304.14317</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14317 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.14317 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ICE-Score: Instructing Large Language Models to Evaluate Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Findings of EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item743>[743]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14811 title=Abstract>arXiv:2304.14811</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14811 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.14811 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junge Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+F">Feihu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuang%2C+S">Shaochen Kuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item744>[744]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14964 title=Abstract>arXiv:2304.14964</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14964 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.14964 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Exponential Capacity of Dense Associative Memories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Lucibello%2C+C">Carlo Lucibello</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=M%C3%A9zard%2C+M">Marc Mézard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Version accepted on Physics Review Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item745>[745]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.00418 title=Abstract>arXiv:2305.00418</a> (replaced) [<a href=https://arxiv.org/pdf/2305.00418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.00418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Empirical Study of Using Large Language Models for Unit Test Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siddiq%2C+M+L">Mohammed Latif Siddiq</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santos%2C+J+C+S">Joanna C. S. Santos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanvir%2C+R+H">Ridwanul Hasan Tanvir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulfat%2C+N">Noshin Ulfat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rifat%2C+F+A">Fahmid Al Rifat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lopes%2C+V+C">Vinicius Carvalho Lopes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item746>[746]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.01135 title=Abstract>arXiv:2305.01135</a> (replaced) [<a href=https://arxiv.org/pdf/2305.01135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.01135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Wave in Robotics: Survey on Recent mmWave Radar Applications in Robotics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harlow%2C+K">Kyle Harlow</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+H">Hyesu Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barfoot%2C+T+D">Timothy D. Barfoot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+A">Ayoung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heckman%2C+C">Christoffer Heckman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 Pages, 7 Figures, 2 Tables, TRO Submission pending
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item747>[747]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04073 title=Abstract>arXiv:2305.04073</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04073 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.04073 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explaining RL Decisions with Trajectories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshmukh%2C+S+V">Shripad Vilasrao Deshmukh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dasgupta%2C+A">Arpan Dasgupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+B">Balaji Krishnamurthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+N">Nan Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theocharous%2C+G">Georgios Theocharous</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramanian%2C+J">Jayakumar Subramanian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at International Conference on Learning Representations (ICLR), 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item748>[748]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08404 title=Abstract>arXiv:2305.08404</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Theoretical Analysis of Inductive Biases in Deep Convolutional Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zihao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 57 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item749>[749]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.08891 title=Abstract>arXiv:2305.08891</a> (replaced) [<a href=https://arxiv.org/pdf/2305.08891 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.08891 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Common Diffusion Noise Schedules and Sample Steps are Flawed
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bingchen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiashi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiao Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item750>[750]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.10124 title=Abstract>arXiv:2305.10124</a> (replaced) [<a href=https://arxiv.org/pdf/2305.10124 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.10124 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Principal Uncertainty Quantification with Spatial Correlation for Image Restoration Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belhasin%2C+O">Omer Belhasin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Romano%2C+Y">Yaniv Romano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freedman%2C+D">Daniel Freedman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivlin%2C+E">Ehud Rivlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elad%2C+M">Michael Elad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item751>[751]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.12997 title=Abstract>arXiv:2305.12997</a> (replaced) [<a href=https://arxiv.org/pdf/2305.12997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.12997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating Privacy Leakage in Split Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xinchi Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leontiadis%2C+I">Ilias Leontiadis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Melis%2C+L">Luca Melis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sablayrolles%2C+A">Alex Sablayrolles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stock%2C+P">Pierre Stock</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item752>[752]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14189 title=Abstract>arXiv:2305.14189</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14189 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14189 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+D">Di Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monz%2C+C">Christof Monz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item753>[753]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14578 title=Abstract>arXiv:2305.14578</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14578 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14578 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification Using Graph Neural Networks?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bugue%C3%B1o%2C+M">Margarita Bugueño</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Melo%2C+G">Gerard de Melo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Findings of the Association for Computational Linguistics: EMNLP 2023 (Long Paper). 17 pages, 2 figures, 15 tables. The Appendix starts on page 12
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Findings of the Association for Computational Linguistics: EMNLP
 2023, pages 8943-8960
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item754>[754]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15586 title=Abstract>arXiv:2305.15586</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15586 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15586 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Manifold Diffusion Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elhag%2C+A+A">Ahmed A. Elhag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Susskind%2C+J+M">Joshua M. Susskind</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bautista%2C+M+A">Miguel Angel Bautista</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR24 paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item755>[755]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15791 title=Abstract>arXiv:2305.15791</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15791 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15791 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Residual Dynamics Learning for Trajectory Tracking for Multi-rotor Aerial Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulathunga%2C+G">Geesara Kulathunga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamed%2C+H">Hany Hamed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klimchik%2C+A">Alexandr Klimchik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item756>[756]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16326 title=Abstract>arXiv:2305.16326</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16326 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.16326 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.16326 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+J">Jingcheng Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keloth%2C+V+K">Vipina Kuttichi Keloth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X">Xueqing Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raja%2C+K">Kalpana Raja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hua Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item757>[757]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16789 title=Abstract>arXiv:2305.16789</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.16789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modulate Your Spectrum in Self-Supervised Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weng%2C+X">Xi Weng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+Y">Yunhao Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+T">Tengwei Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jie Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anwer%2C+R+M">Rao Muhammad Anwer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+S">Salman Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Lei Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024. The code is available at <a href=https://github.com/winci-ai/intl>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item758>[758]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16943 title=Abstract>arXiv:2305.16943</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16943 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.16943 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+S">Sohyun An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hayeon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jo%2C+J">Jaehyeong Jo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seanie Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item759>[759]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.17028 title=Abstract>arXiv:2305.17028</a> (replaced) [<a href=https://arxiv.org/pdf/2305.17028 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.17028 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Better Batch for Deep Probabilistic Time Series Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zheng%2C+V+Z">Vincent Zhihao Zheng</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Choi%2C+S">Seongjin Choi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sun%2C+L">Lijun Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 3 figures, camera-ready version, The 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item760>[760]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.17734 title=Abstract>arXiv:2305.17734</a> (replaced) [<a href=https://arxiv.org/pdf/2305.17734 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.17734 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.17734 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design, Actuation, and Functionalization of Untethered Soft Magnetic Robots with Life-Like Motions: A Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+J">Jiaqi Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S">Siqi Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 36 pages, 11 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. Magn. Magn. Mater. 586, 171160 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Soft Condensed Matter (cond-mat.soft)
</div>
</div>
</dd>
<dt><a name=item761>[761]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.18394 title=Abstract>arXiv:2305.18394</a> (replaced) [<a href=https://arxiv.org/pdf/2305.18394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.18394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Optimal Regularization Parameters via Bilevel Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ehrhardt%2C+M+J">Matthias J. Ehrhardt</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gazzola%2C+S">Silvia Gazzola</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scott%2C+S+J">Sebastian J. Scott</a> (Department of Mathematical Sciences, University of Bath, Bath, UK)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 11 figures. Version for publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item762>[762]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.19604 title=Abstract>arXiv:2305.19604</a> (replaced) [<a href=https://arxiv.org/pdf/2305.19604 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.19604 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Medication Recommendation via Domain Knowledge Informed Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Sicen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xianbing Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item763>[763]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.00824 title=Abstract>arXiv:2306.00824</a> (replaced) [<a href=https://arxiv.org/pdf/2306.00824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.00824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero and Few-shot Semantic Parsing with Ambiguous Inputs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stengel-Eskin%2C+E">Elias Stengel-Eskin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rawlins%2C+K">Kyle Rawlins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 Camera Ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item764>[764]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01589 title=Abstract>arXiv:2306.01589</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01589 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01589 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transfer learning for atomistic simulations using GNNs and kernel mean embeddings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Falk%2C+J">John Falk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bonati%2C+L">Luigi Bonati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parrinello%2C+M">Michele Parrinello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 4 figures, 7 tables, published in NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)
</div>
</div>
</dd>
<dt><a name=item765>[765]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01631 title=Abstract>arXiv:2306.01631</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01631 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01631 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+P">Pengcheng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Cao Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+T">Tianfan Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)
</div>
</div>
</dd>
<dt><a name=item766>[766]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.02869 title=Abstract>arXiv:2306.02869</a> (replaced) [<a href=https://arxiv.org/pdf/2306.02869 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.02869 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Driven Regret Balancing for Online Model Selection in Bandits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pacchiano%2C+A">Aldo Pacchiano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dann%2C+C">Christoph Dann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gentile%2C+C">Claudio Gentile</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item767>[767]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.03740 title=Abstract>arXiv:2306.03740</a> (replaced) [<a href=https://arxiv.org/pdf/2306.03740 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.03740 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GMMap: Memory-Efficient Continuous Occupancy Map Using Gaussian Mixture Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P+Z+X">Peter Zhi Xuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karaman%2C+S">Sertac Karaman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sze%2C+V">Vivienne Sze</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 12 figures, 3 tables
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Robotics 40 (2024) 1339-1355
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item768>[768]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.05023 title=Abstract>arXiv:2306.05023</a> (replaced) [<a href=https://arxiv.org/pdf/2306.05023 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.05023 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Dang%2C+H">Hien Dang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tran%2C+T">Tho Tran</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nguyen%2C+T">Tan Nguyen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Conference on Learning Representations (ICLR) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item769>[769]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.06064 title=Abstract>arXiv:2306.06064</a> (replaced) [<a href=https://arxiv.org/pdf/2306.06064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.06064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Algorithmic Reasoning for Combinatorial Optimisation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Georgiev%2C+D">Dobrik Georgiev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Numeroso%2C+D">Danilo Numeroso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bacciu%2C+D">Davide Bacciu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%C3%B2%2C+P">Pietro Liò</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item770>[770]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.06071 title=Abstract>arXiv:2306.06071</a> (replaced) [<a href=https://arxiv.org/pdf/2306.06071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.06071 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.06071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Attack On Yolov5 For Traffic And Road Sign Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+S">Sanyam Jain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item771>[771]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.06347 title=Abstract>arXiv:2306.06347</a> (replaced) [<a href=https://arxiv.org/pdf/2306.06347 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.06347 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DocChecker: Bootstrapping Code Large Language Model for Detecting and Resolving Code-Comment Inconsistencies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dau%2C+A+T+V">Anh T. V. Dau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J+L+C">Jin L. C. Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bui%2C+N+D+Q">Nghi D. Q. Bui</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> EACL 2024 - Demonstration track
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item772>[772]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08623 title=Abstract>arXiv:2306.08623</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parallel Algorithms for Hierarchical Nucleus Decomposition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jessica Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shun%2C+J">Julian Shun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item773>[773]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08727 title=Abstract>arXiv:2306.08727</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08727 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08727 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gauss Newton method for solving variational problems of PDEs with neural network discretizaitons
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hao%2C+W">Wenrui Hao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hong%2C+Q">Qingguo Hong</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jin%2C+X">Xianlin Jin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item774>[774]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09136 title=Abstract>arXiv:2306.09136</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finite-Time Logarithmic Bayes Regret Upper Bounds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atsidakou%2C+A">Alexia Atsidakou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kveton%2C+B">Branislav Kveton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katariya%2C+S">Sumeet Katariya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caramanis%2C+C">Constantine Caramanis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanghavi%2C+S">Sujay Sanghavi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item775>[775]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09432 title=Abstract>arXiv:2306.09432</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum State Tomography for Matrix Product Density Operators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Qin%2C+Z">Zhen Qin</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Jameson%2C+C">Casey Jameson</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gong%2C+Z">Zhexuan Gong</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wakin%2C+M+B">Michael B. Wakin</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhu%2C+Z">Zhihui Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item776>[776]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.13301 title=Abstract>arXiv:2306.13301</a> (replaced) [<a href=https://arxiv.org/pdf/2306.13301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.13301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chai%2C+Z">Zhizhong Chai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Luyang Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Huangjing Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heng%2C+P">Pheng-Ann Heng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> TMI 2024. Zhizhong Chai and Luyang Luo contributed equally. Code is available via: <a href=https://github.com/zhizhongchai/ORF-Net/tree/main>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item777>[777]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.16001 title=Abstract>arXiv:2306.16001</a> (replaced) [<a href=https://arxiv.org/pdf/2306.16001 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.16001 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.16001 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Streamlining Social Media Information Extraction for Public Health Research with Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+Y">Yining Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Shixu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Minghui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yujie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foer%2C+D">Dinah Foer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Siwen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Li Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Updated full paper. Abstract presented at IEEE ICHI 2023 and AMIA Annual Symposium 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item778>[778]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.16761 title=Abstract>arXiv:2306.16761</a> (replaced) [<a href=https://arxiv.org/pdf/2306.16761 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.16761 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Moreau Envelope Based Difference-of-weakly-Convex Reformulation and Algorithm for Bilevel Programs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gao%2C+L+L">Lucy L. Gao</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ye%2C+J+J">Jane J. Ye</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yin%2C+H">Haian Yin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zeng%2C+S">Shangzhi Zeng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhang%2C+J">Jin Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item779>[779]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.17269 title=Abstract>arXiv:2306.17269</a> (replaced) [<a href=https://arxiv.org/pdf/2306.17269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.17269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Micro-Macro Parareal Implementation for the Ocean-Circulation Model FESOM2
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Philippi%2C+B">B. Philippi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Slawig%2C+T">T. Slawig</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 65 pages, 107 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item780>[780]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.17778 title=Abstract>arXiv:2306.17778</a> (replaced) [<a href=https://arxiv.org/pdf/2306.17778 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.17778 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Look, Remember and Reason: Grounded reasoning in videos with language models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharyya%2C+A">Apratim Bhattacharyya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panchal%2C+S">Sunny Panchal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+M">Mingu Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pourreza%2C+R">Reza Pourreza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madan%2C+P">Pulkit Madan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Memisevic%2C+R">Roland Memisevic</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item781>[781]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.17808 title=Abstract>arXiv:2306.17808</a> (replaced) [<a href=https://arxiv.org/pdf/2306.17808 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.17808 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Circular Systems Engineering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=David%2C+I">Istvan David</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bork%2C+D">Dominik Bork</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kappel%2C+G">Gerti Kappel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Software Engineering (cs.SE); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item782>[782]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00581 title=Abstract>arXiv:2307.00581</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00581 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.00581 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.00581 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A new approach to integrals of discretizations by polarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/nlin?searchtype=author&amp;query=Suris%2C+Y+B">Yuri B. Suris</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> v2 re-formatted for the journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Exactly Solvable and Integrable Systems (nlin.SI)</span>; Mathematical Physics (math-ph); Dynamical Systems (math.DS); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item783>[783]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.02273 title=Abstract>arXiv:2307.02273</a> (replaced) [<a href=https://arxiv.org/pdf/2307.02273 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.02273 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient Neural Image Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghorbel%2C+A">Ahmed Ghorbel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamidouche%2C+W">Wassim Hamidouche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morin%2C+L">Luce Morin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item784>[784]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.04408 title=Abstract>arXiv:2307.04408</a> (replaced) [<a href=https://arxiv.org/pdf/2307.04408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.04408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TIM: Teaching Large Language Models to Translate with Comparison
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jiali Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+F">Fandong Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yongjing Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item785>[785]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.04417 title=Abstract>arXiv:2307.04417</a> (replaced) [<a href=https://arxiv.org/pdf/2307.04417 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.04417 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fairness-aware Federated Minimax Optimization with Convergence Guarantee
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dunda%2C+G+W+M">Gerry Windiarto Mohamad Dunda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S">Shenghui Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> At the time of uploading, it is currently under review in IEEE CAI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item786>[786]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.06564 title=Abstract>arXiv:2307.06564</a> (replaced) [<a href=https://arxiv.org/pdf/2307.06564 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.06564 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shoush%2C+M">Mahmoud Shoush</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dumas%2C+M">Marlon Dumas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item787>[787]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.06706 title=Abstract>arXiv:2307.06706</a> (replaced) [<a href=https://arxiv.org/pdf/2307.06706 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.06706 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cost Allocation for Inertia and Frequency Response Ancillary Services
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Matamala%2C+C">Carlos Matamala</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Badesa%2C+L">Luis Badesa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Moreno%2C+R">Rodrigo Moreno</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Strbac%2C+G">Goran Strbac</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE Transactions on Energy Markets, Policy and Regulation
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item788>[788]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.08097 title=Abstract>arXiv:2307.08097</a> (replaced) [<a href=https://arxiv.org/pdf/2307.08097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.08097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EasyTPP: Towards Open Benchmarking Temporal Point Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+S">Siqiao Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaoming Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+H">Hongyan Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+F">Fan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+C">Caigao Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+C">Chen Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J+Y">James Y. Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+H">Hongyuan Mei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 camera ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item789>[789]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.08279 title=Abstract>arXiv:2307.08279</a> (replaced) [<a href=https://arxiv.org/pdf/2307.08279 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.08279 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combiner and HyperCombiner Networks: Rules to Combine Multimodality MR Images for Prostate Cancer Localisation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yan%2C+W">Wen Yan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chiu%2C+B">Bernard Chiu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shen%2C+Z">Ziyi Shen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Q">Qianye Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Syer%2C+T">Tom Syer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Min%2C+Z">Zhe Min</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Punwani%2C+S">Shonit Punwani</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Emberton%2C+M">Mark Emberton</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Atkinson%2C+D">David Atkinson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Barratt%2C+D+C">Dean C. Barratt</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+Y">Yipeng Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 6 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> journal={Medical Image Analysis}, volume={91}, pages={103030},
 year={2024}, publisher={Elsevier}
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item790>[790]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.09997 title=Abstract>arXiv:2307.09997</a> (replaced) [<a href=https://arxiv.org/pdf/2307.09997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.09997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical Phase Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Funke%2C+I">Isabel Funke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivoir%2C+D">Dominik Rivoir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krell%2C+S">Stefanie Krell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Speidel%2C+S">Stefanie Speidel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Major revision: additional experiments, re-activated Dropout
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item791>[791]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.10266 title=Abstract>arXiv:2307.10266</a> (replaced) [<a href=https://arxiv.org/pdf/2307.10266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.10266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A DPLL(T) Framework for Verifying Deep Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duong%2C+H">Hai Duong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">ThanhVu Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dwyer%2C+M">Matthew Dwyer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeuralSAT is avaliable at: <a href=https://github.com/dynaroars/neuralsat>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item792>[792]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.12620 title=Abstract>arXiv:2307.12620</a> (replaced) [<a href=https://arxiv.org/pdf/2307.12620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.12620 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.12620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Past-present temporal programs over finite traces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cabalar%2C+P">Pedro Cabalar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di%C3%A9guez%2C+M">Martín Diéguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laferri%C3%A8re%2C+F">François Laferrière</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaub%2C+T">Torsten Schaub</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item793>[793]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.13158 title=Abstract>arXiv:2307.13158</a> (replaced) [<a href=https://arxiv.org/pdf/2307.13158 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.13158 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-UAV Speed Control with Collision Avoidance and Handover-aware Cell Association: DRL with Action Branching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Z">Zijiang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaafar%2C+W">Wael Jaafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Selim%2C+B">Bassant Selim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabassum%2C+H">Hina Tabassum</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE Globecom 2023 Accepted
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Robotics (cs.RO); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item794>[794]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.13716 title=Abstract>arXiv:2307.13716</a> (replaced) [<a href=https://arxiv.org/pdf/2307.13716 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.13716 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Leiming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Cihao Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+S">Sibo Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Ziling Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+Y">Yuming Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+Z">Zhaoxiang Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+C+W">Chee Wei Tan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item795>[795]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.13858 title=Abstract>arXiv:2307.13858</a> (replaced) [<a href=https://arxiv.org/pdf/2307.13858 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.13858 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.13858 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EmphasisChecker: A Tool for Guiding Chart and Caption Emphasis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D+H">Dae Hyun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+S">Seulgi Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Juho Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Setlur%2C+V">Vidya Setlur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> IEEE VIS 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Visualization and Computer Graphics, vol. 30,
 no. 1, pp. 120-130, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item796>[796]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.15567 title=Abstract>arXiv:2307.15567</a> (replaced) [<a href=https://arxiv.org/pdf/2307.15567 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.15567 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Panoptic Scene Graph Generation with Semantics-Prototype Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Li Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+W">Wei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yiming Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mengze Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">You Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+L">Lina Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item797>[797]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.15844 title=Abstract>arXiv:2307.15844</a> (replaced) [<a href=https://arxiv.org/pdf/2307.15844 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.15844 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shared Information for a Markov Chain on a Tree
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+S">Sagnik Bhattacharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayan%2C+P">Prakash Narayan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 4 figures, submitted to IEEE Transactions on Information Theory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item798>[798]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.00783 title=Abstract>arXiv:2308.00783</a> (replaced) [<a href=https://arxiv.org/pdf/2308.00783 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.00783 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+M">Mingzhan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+G">Guangxin Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Bin Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenhua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+J">Jinqing Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+H">Huchuan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item799>[799]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.01738 title=Abstract>arXiv:2308.01738</a> (replaced) [<a href=https://arxiv.org/pdf/2308.01738 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.01738 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yeying Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+B">Beibei Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+W">Wending Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+W">Wei Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ACM'MM2023, <a href=https://github.com/jinyeying/nighttime_dehaze>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Published in ACM'MM2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item800>[800]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.02453 title=Abstract>arXiv:2308.02453</a> (replaced) [<a href=https://arxiv.org/pdf/2308.02453 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.02453 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Getting the Ball Rolling: Learning a Dexterous Policy for a Biomimetic Tendon-Driven Hand with Rolling Contact Joints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toshimitsu%2C+Y">Yasunori Toshimitsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forrai%2C+B">Benedek Forrai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steger%2C+U">Ulrich Steger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knecht%2C+M">Manuel Knecht</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weirich%2C+S">Stefan Weirich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> for project website, see <a href=https://srl-ethz.github.io/get-ball-rolling/>this https URL</a> . for video, see <a href=https://youtu.be/YahsMhqNU8o>this https URL</a> . for code, see <a href=https://github.com/srl-ethz/faive_gym_oss>this https URL</a> . Published to the 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE-RAS 22nd International Conference on Humanoid Robots
 (Humanoids), Austin, TX, USA, 2023, pp. 1-7
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item801>[801]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.04292 title=Abstract>arXiv:2308.04292</a> (replaced) [<a href=https://arxiv.org/pdf/2308.04292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.04292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Engineering LaCAM<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-264-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1469 style=width:0.512em;display:inline-block><span style=display:inline-block;position:relative;width:0.419em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.188em,1000.42em,1.16em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-1470><span class=msubsup id=MathJax-Span-1471><span style=display:inline-block;position:relative;width:0.419em;height:0px><span style=position:absolute;clip:rect(3.845em,1000em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mi id=MathJax-Span-1472></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.35em;left:0em><span class=mo id=MathJax-Span-1473 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Okumura%2C+K">Keisuke Okumura</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> to be presented at AAMAS-24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item802>[802]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.04620 title=Abstract>arXiv:2308.04620</a> (replaced) [<a href=https://arxiv.org/pdf/2308.04620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.04620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiclass Online Learnability under Bandit Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raman%2C+A">Ananth Raman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raman%2C+V">Vinod Raman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subedi%2C+U">Unique Subedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehalel%2C+I">Idan Mehalel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, ALT 2024 Camera Ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item803>[803]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.04942 title=Abstract>arXiv:2308.04942</a> (replaced) [<a href=https://arxiv.org/pdf/2308.04942 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.04942 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guangyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+H">Hongyang Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D+I">Dong In Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xuemin">Xuemin</a> (Sherman)
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen">Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages,5figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item804>[804]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.06981 title=Abstract>arXiv:2308.06981</a> (replaced) [<a href=https://arxiv.org/pdf/2308.06981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.06981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Sound Demixing Challenge 2023 <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-265-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1474 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.762em,1000.51em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-1475><span class=mtext id=MathJax-Span-1476 style=font-family:MathJax_Main>–</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.447em"></span></span></nobr></span> Cinematic Demixing Track
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Uhlich%2C+S">Stefan Uhlich</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fabbro%2C+G">Giorgio Fabbro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hirano%2C+M">Masato Hirano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Takahashi%2C+S">Shusuke Takahashi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Roux%2C+J+L">Jonathan Le Roux</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chakraborty%2C+D">Dipam Chakraborty</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mohanty%2C+S">Sharada Mohanty</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+K">Kai Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Luo%2C+Y">Yi Luo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yu%2C+J">Jianwei Yu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gu%2C+R">Rongzhi Gu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Solovyev%2C+R">Roman Solovyev</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Stempkovskiy%2C+A">Alexander Stempkovskiy</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Habruseva%2C+T">Tatiana Habruseva</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sukhovei%2C+M">Mikhail Sukhovei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item805>[805]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.07314 title=Abstract>arXiv:2308.07314</a> (replaced) [<a href=https://arxiv.org/pdf/2308.07314 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.07314 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual Associated Encoder for Face Restoration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yu-Ju Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yu-Lun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+L">Lu Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024, Project page: <a href=https://liagm.github.io/DAEFR/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item806>[806]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09400 title=Abstract>arXiv:2308.09400</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GIPC: Fast and stable Gauss-Newton optimization of IPC barrier energy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kemeng Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chitalu%2C+F">Floyd Chitalu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Huancheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Komura%2C+T">Taku Komura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
</div>
</dd>
<dt><a name=item807>[807]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09543 title=Abstract>arXiv:2308.09543</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Latent State Models of Training Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+M+Y">Michael Y. Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+A">Angelica Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at TMLR 2023. Updated Jan 19, 2024 with erratum
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item808>[808]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09647 title=Abstract>arXiv:2308.09647</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Uncertainty Quantification Using Conformalised Monte Carlo Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bethell%2C+D">Daniel Bethell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerasimou%2C+S">Simos Gerasimou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calinescu%2C+R">Radu Calinescu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item809>[809]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.10610 title=Abstract>arXiv:2308.10610</a> (replaced) [<a href=https://arxiv.org/pdf/2308.10610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.10610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ultrafast and Ultralight Network-Based Intelligent System for Real-time Diagnosis of Ear diseases in Any Devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue%2C+Y">Yubiao Yue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaoqiang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Meiping Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+H">Haihua Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+F">Fan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yanmei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zefeng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Wenrui Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenzhang Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item810>[810]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.11737 title=Abstract>arXiv:2308.11737</a> (replaced) [<a href=https://arxiv.org/pdf/2308.11737 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.11737 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiacong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+J">Jiawei Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+W">Wufei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jesslen%2C+A">Artur Jesslen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+P">Pengliang Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Q">Qixin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiehua Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qihao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiahao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+W">Wei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+X">Xiaoding Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaushik%2C+P">Prakhar Kaushik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yushan Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yawen Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuille%2C+A">Alan Yuille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kortylewski%2C+A">Adam Kortylewski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 5 figures, link to the dataset: <a href=https://xujiacong.github.io/Animal3D/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item811>[811]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13507 title=Abstract>arXiv:2308.13507</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13507 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13507 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Models Should Ask Clarifying Questions to Increase Confidence in Generated Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J+J">Jie JW Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 2 figures, 1 table. Accepted and presented at the 7th Annual Symposium on Machine Programming (MAPS 2023 Workshop, see <a href=https://mapsworkshop.github.io/>this https URL</a>). Reference: "Wu, Jie JW. Large Language Models Should Ask Clarifying Questions to Increase Confidence in Generated Code. The 7th Annual Symposium on Machine Programming (MAPS 23), December 3, 2023, San Francisco, CA, USA"
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item812>[812]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13894 title=Abstract>arXiv:2308.13894</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13894 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13894 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FwdLLM: Efficient FedLLM using Forward Gradient
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengwei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+D">Dongqi Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yaozong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shangguang Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item813>[813]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.15997 title=Abstract>arXiv:2308.15997</a> (replaced) [<a href=https://arxiv.org/pdf/2308.15997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.15997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the entropy and information of Gaussian mixtures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eskenazis%2C+A">Alexandros Eskenazis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gavalakis%2C+L">Lampros Gavalakis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, no figures. Funding information updated and a minor typo fixed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item814>[814]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00733 title=Abstract>arXiv:2309.00733</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00733 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.00733 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TExplain: Explaining Learned Visual Features via Pre-trained (Frozen) Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taghanaki%2C+S+A">Saeid Asgari Taghanaki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khani%2C+A">Aliasghar Khani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khasahmadi%2C+A">Amir Khasahmadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item815>[815]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01115 title=Abstract>arXiv:2309.01115</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.01115 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.01115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multicollinearity Resolution Based on Machine Learning: A Case Study of Carbon Emissions in Sichuan Province
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoxue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yonghang Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages,19 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item816>[816]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01409 title=Abstract>arXiv:2309.01409</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01409 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01409 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Implicit Neural Image Stitching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+M">Minsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaewon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+B">Byeonghun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Im%2C+S">Sunghoon Im</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+K+H">Kyong Hwan Jin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item817>[817]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01538 title=Abstract>arXiv:2309.01538</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Linhao Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+J">Jiaxin Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+B">Bo Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haffari%2C+G">Gholamreza Haffari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item818>[818]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02592 title=Abstract>arXiv:2309.02592</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02592 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02592 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BWSNet: Automatic Perceptual Assessment of Audio Signals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Veillon%2C+C+L+M">Clément Le Moine Veillon</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rosi%2C+V">Victor Rosi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sarah%2C+P+A">Pablo Arias Sarah</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Salais%2C+L">Léane Salais</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Obin%2C+N">Nicolas Obin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item819>[819]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02773 title=Abstract>arXiv:2309.02773</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02773 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02773 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion Model is Secretly a Training-free Open Vocabulary Semantic Segmenter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jinglong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiawei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qingyuan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qian Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+L">Lu Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+D">Dong Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item820>[820]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03020 title=Abstract>arXiv:2309.03020</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03020 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.03020 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenlong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaohui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiao-Ming Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024, Spotlight. The source code is available at <a href=https://github.com/XPixelGroup/SEAL>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item821>[821]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03202 title=Abstract>arXiv:2309.03202</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.03202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of Reinforcement Learning Techniques for Trading on a Diverse Portfolio
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Khare%2C+I+S">Ishan S. Khare</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Martheswaran%2C+T+K">Tarun K. Martheswaran</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Dassanaike-Perera%2C+A">Akshana Dassanaike-Perera</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> fixed minor typos
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item822>[822]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.04089 title=Abstract>arXiv:2309.04089</a> (replaced) [<a href=https://arxiv.org/pdf/2309.04089 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.04089 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward Sufficient Spatial-Frequency Interaction for Gradient-aware Underwater Image Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chen Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+W">Weiling Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Chenyu Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Ziqi Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item823>[823]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05030 title=Abstract>arXiv:2309.05030</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05030 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05030 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decolonial AI Alignment: Openness, Viśe\d{s}a-Dharma, and Including Excluded Knowledges
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varshney%2C+K+R">Kush R. Varshney</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item824>[824]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05173 title=Abstract>arXiv:2309.05173</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05173 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05173 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhengxiang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lipani%2C+A">Aldo Lipani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. Code is available at <a href=https://github.com/ZhengxiangShi/DePT>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item825>[825]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06186 title=Abstract>arXiv:2309.06186</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06186 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06186 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Bregman-Kaczmarz: An Approach to Solve Linear Inverse Problems with Independent Noise Exactly
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tondji%2C+L">Lionel Tondji</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tondji%2C+I">Idriss Tondji</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lorenz%2C+D+A">Dirk A. Lorenz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item826>[826]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06207 title=Abstract>arXiv:2309.06207</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06207 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06207 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SGNet: Salient Geometric Network for Point Cloud Registration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Q">Qianliang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yaqing Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+L">Lei Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+S">Shuo Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chuanwei Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jin Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item827>[827]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06629 title=Abstract>arXiv:2309.06629</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06629 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06629 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Relational Bottleneck as an Inductive Bias for Efficient Abstraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Webb%2C+T+W">Taylor W. Webb</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frankland%2C+S+M">Steven M. Frankland</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altabaa%2C+A">Awni Altabaa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+K">Kamesh Krishnamurthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Campbell%2C+D">Declan Campbell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Russin%2C+J">Jacob Russin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=O%27Reilly%2C+R">Randall O'Reilly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafferty%2C+J">John Lafferty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+J+D">Jonathan D. Cohen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item828>[828]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07525 title=Abstract>arXiv:2309.07525</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07525 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07525 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SingFake: Singing Voice Deepfake Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zang%2C+Y">Yongyi Zang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">You Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heydari%2C+M">Mojtaba Heydari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+Z">Zhiyao Duan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item829>[829]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08361 title=Abstract>arXiv:2309.08361</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jhaver%2C+S">Shagun Jhaver</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rathi%2C+H">Himanshu Rathi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+K">Koustuv Saha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item830>[830]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.09627 title=Abstract>arXiv:2309.09627</a> (replaced) [<a href=https://arxiv.org/pdf/2309.09627 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.09627 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Electrolaryngeal Speech Intelligibility Enhancement Through Robust Linguistic Encoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Violeta%2C+L+P">Lester Phillip Violeta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Wen-Chin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+D">Ding Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamamoto%2C+R">Ryuichi Yamamoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+K">Kazuhiro Kobayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024. Demo page: lesterphillip.github.io/icassp2024_el_sie
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item831>[831]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.10245 title=Abstract>arXiv:2309.10245</a> (replaced) [<a href=https://arxiv.org/pdf/2309.10245 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.10245 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%2C+H">Hyung-Kwon Ko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon%2C+H">Hyeon Jeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+G">Gwanmo Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D+H">Dae Hyun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+N+W">Nam Wook Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Juho Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seo%2C+J">Jinwook Seo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 5 figures
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> In Proceedings of the CHI Conference on Human Factors in Computing
 Systems (CHI '24), May 11-16, 2024, Honolulu, HI, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item832>[832]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.10688 title=Abstract>arXiv:2309.10688</a> (replaced) [<a href=https://arxiv.org/pdf/2309.10688 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.10688 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the different regimes of Stochastic Gradient Descent
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sclocchi%2C+A">Antonio Sclocchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wyart%2C+M">Matthieu Wyart</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Main: 8 pages, 4 figures; Appendix: 20 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item833>[833]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.11680 title=Abstract>arXiv:2309.11680</a> (replaced) [<a href=https://arxiv.org/pdf/2309.11680 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.11680 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Federated Learning with Neural Graphical Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chajewska%2C+U">Urszula Chajewska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shrivastava%2C+H">Harsh Shrivastava</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item834>[834]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.11759 title=Abstract>arXiv:2309.11759</a> (replaced) [<a href=https://arxiv.org/pdf/2309.11759 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.11759 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Symbol Detection for Coarsely Quantized OTFS
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junwei He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haochuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Huimin Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item835>[835]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12244 title=Abstract>arXiv:2309.12244</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12244 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12244 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seo%2C+W">Woosuk Seo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Chanmo Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Young-Ho Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 5 figures, 2 tables; Accepted at ACM CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item836>[836]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12247 title=Abstract>arXiv:2309.12247</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12247 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12247 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Beizhe Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+Q">Qiang Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+J">Juan Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Danding Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+P">Peng Qi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 5 figures, and 9 tables. To appear at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item837>[837]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12701 title=Abstract>arXiv:2309.12701</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12701 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12701 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decision Tree Search as a Markov Decision Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kohler%2C+H">Hector Kohler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akrour%2C+R">Riad Akrour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Preux%2C+P">Philippe Preux</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item838>[838]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.13365 title=Abstract>arXiv:2309.13365</a> (replaced) [<a href=https://arxiv.org/pdf/2309.13365 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.13365 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kohler%2C+H">Hector Kohler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akrour%2C+R">Riad Akrour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Preux%2C+P">Philippe Preux</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be included in an other submission. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2304.05839>arXiv:2304.05839</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item839>[839]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.14590 title=Abstract>arXiv:2309.14590</a> (replaced) [<a href=https://arxiv.org/pdf/2309.14590 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.14590 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HeLiPR: Heterogeneous LiDAR Dataset for inter-LiDAR Place Recognition under Spatiotemporal Variations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+M">Minwoo Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wooseong Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dongjae Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gil%2C+H">Hyeonjae Gil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+G">Giseop Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 9 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item840>[840]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15462 title=Abstract>arXiv:2309.15462</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15462 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15462 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DTC: Deep Tracking Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jenelten%2C+F">Fabian Jenelten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junzhe He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farshidian%2C+F">Farbod Farshidian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item841>[841]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.16034 title=Abstract>arXiv:2309.16034</a> (replaced) [<a href=https://arxiv.org/pdf/2309.16034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.16034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale Localization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pascual%2C+G">Guillem Pascual</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lemic%2C+F">Filip Lemic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa-Perez%2C+X">Xavier Costa-Perez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 7 figures, 4 tables, 16 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item842>[842]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.16301 title=Abstract>arXiv:2309.16301</a> (replaced) [<a href=https://arxiv.org/pdf/2309.16301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.16301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gated Cross-Attention Network for Depth Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+X">Xiaogang Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jian%2C+S">Songlei Jian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+Y">Yusong Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Che%2C+Y">Yonggang Che</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Z">Zhengfa Liang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item843>[843]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.16952 title=Abstract>arXiv:2309.16952</a> (replaced) [<a href=https://arxiv.org/pdf/2309.16952 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.16952 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Optimization for Adaptive Attacks on Image Watermarks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lukas%2C+N">Nils Lukas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaa%2C+A">Abdulrahman Diaa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fenaux%2C+L">Lucas Fenaux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item844>[844]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00106 title=Abstract>arXiv:2310.00106</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00106 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00106 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+T">Tasin Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miron%2C+A">Alina Miron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">XiaoHui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongmin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item845>[845]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00454 title=Abstract>arXiv:2310.00454</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00454 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00454 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UniLVSeg: Unified Left Ventricular Segmentation with Sparsely Annotated Echocardiogram Videos through Self-Supervised Temporal Masking and Weakly Supervised Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maani%2C+F">Fadillah Maani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ukaye%2C+A">Asim Ukaye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saadi%2C+N">Nada Saadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeed%2C+N">Numan Saeed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yaqub%2C+M">Mohammad Yaqub</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item846>[846]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00647 title=Abstract>arXiv:2310.00647</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shukor%2C+M">Mustafa Shukor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rame%2C+A">Alexandre Rame</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dancette%2C+C">Corentin Dancette</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cord%2C+M">Matthieu Cord</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. Project Page: <a href=https://evalign-icl.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item847>[847]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00731 title=Abstract>arXiv:2310.00731</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ranked Enumeration for MSO on Trees via Knowledge Compilation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bourhis%2C+P">Pierre Bourhis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Capelli%2C+F">Florent Capelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monet%2C+M">Mikaël Monet</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages; this is the authors version of the corresponding ICDT'24 article
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item848>[848]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01361 title=Abstract>arXiv:2310.01361</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01361 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01361 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GenSim: Generating Robotic Simulation Tasks via Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lirui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+Y">Yiyang Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zhecheng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shridhar%2C+M">Mohit Shridhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+C">Chen Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bailin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Huazhe Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> See our project website (<a href=https://liruiw.github.io/gensim>this https URL</a>), demo and datasets (<a href=https://huggingface.co/spaces/Gen-Sim/Gen-Sim>this https URL</a>), and code (<a href=https://github.com/liruiw/GenSim>this https URL</a>) for more details
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Conference on Learning Representations (ICLR), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item849>[849]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01386 title=Abstract>arXiv:2310.01386</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01386 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01386 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+E+J">Eric John Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lam%2C+M+H">Man Ho Lam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+S">Shujie Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Youliang Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for ICLR 2024 Oral Presentation. 15 pages (main text) and 5 pages (appendix)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item850>[850]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02118 title=Abstract>arXiv:2310.02118</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02118 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02118 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+R">Rafael Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tavares%2C+D">Diogo Tavares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+D">Diogo Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Val%C3%A9rio%2C+R">Rodrigo Valério</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bordalo%2C+J">João Bordalo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%C3%B5es%2C+I">Inês Simões</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramos%2C+V">Vasco Ramos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Semedo%2C+D">David Semedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magalh%C3%A3es%2C+J">João Magalhães</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item851>[851]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02138 title=Abstract>arXiv:2310.02138</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02138 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02138 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discrete anisotropic curve shortening flow in higher codimension
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Deckelnick%2C+K">Klaus Deckelnick</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=N%C3%BCrnberg%2C+R">Robert Nürnberg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item852>[852]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02255 title=Abstract>arXiv:2310.02255</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02255 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02255 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+P">Pan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+T">Tony Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiacheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+H">Hao Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galley%2C+M">Michel Galley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 116 pages, 120 figures. Accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item853>[853]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.03298 title=Abstract>arXiv:2310.03298</a> (replaced) [<a href=https://arxiv.org/pdf/2310.03298 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.03298 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.03298 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chen%2C+Y">Yi-Ping Chen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wang%2C+L">Liwei Wang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Comlek%2C+Y">Yigitcan Comlek</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item854>[854]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04691 title=Abstract>arXiv:2310.04691</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04691 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04691 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+S">Siyu Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item855>[855]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05916 title=Abstract>arXiv:2310.05916</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05916 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.05916 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpreting CLIP's Image Representation via Text-Based Decomposition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gandelsman%2C+Y">Yossi Gandelsman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efros%2C+A+A">Alexei A. Efros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page and code: <a href=https://yossigandelsman.github.io/clip_decomposition/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item856>[856]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.06333 title=Abstract>arXiv:2310.06333</a> (replaced) [<a href=https://arxiv.org/pdf/2310.06333 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.06333 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.06333 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning bounded-degree polytrees with known skeleton
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choo%2C+D">Davin Choo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J+Q">Joy Qiping Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharyya%2C+A">Arnab Bhattacharyya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Canonne%2C+C+L">Clément L. Canonne</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fixed some typos. Added some discussions. Accepted to ALT 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item857>[857]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08147 title=Abstract>arXiv:2310.08147</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08147 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08147 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimization of Federated Learning's Client Selection for Non-IID data Based on Gray Relational Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuaijun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tavallaie%2C+O">Omid Tavallaie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hambali%2C+M+H">Michael Henri Hambali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zandavi%2C+S+M">Seid Miad Zandavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddadi%2C+H">Hamed Haddadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lane%2C+N">Nicholas Lane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Song Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zomaya%2C+A+Y">Albert Y. Zomaya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item858>[858]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08445 title=Abstract>arXiv:2310.08445</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08445 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08445 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Risk-informed Resilience Planning of Transmission Systems Against Ice Storms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hu%2C+C">Chenxi Hu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+Y">Yujia Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hou%2C+Y">Yunhe Hou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item859>[859]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09126 title=Abstract>arXiv:2310.09126</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09126 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09126 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Physics-guided Noise Neural Proxy for Practical Low-light Raw Image Denoising
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Feng%2C+H">Hansen Feng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+L">Lizhi Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+Y">Yiqi Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuzhi Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhu%2C+L">Lin Zhu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+H">Hua Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item860>[860]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09177 title=Abstract>arXiv:2310.09177</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09177 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.09177 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.09177 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Future Industrial Applications: Exploring LPWAN-Driven IoT Protocols
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+M">Mahbubul Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jamil%2C+H+M+M">Hossain Md. Mubashshir Jamil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pranto%2C+S+A">Samiul Ahsan Pranto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+R+K">Rupak Kumar Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amin%2C+A">Al Amin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Arshia Khan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item861>[861]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09221 title=Abstract>arXiv:2310.09221</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09221 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09221 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ultrasound Image Segmentation of Thyroid Nodule via Latent Semantic Feature Co-Registration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+X">Xuewei Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhu%2C+Y">Yaqiao Zhu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gao%2C+J">Jie Gao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wei%2C+X">Xi Wei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+R">Ruixuan Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tian%2C+Y">Yuan Tian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+Z">ZhiQiang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item862>[862]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.10873 title=Abstract>arXiv:2310.10873</a> (replaced) [<a href=https://arxiv.org/pdf/2310.10873 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.10873 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shaokun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhaoqing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Ling-Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiale Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Q">Qingyun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item863>[863]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.11036 title=Abstract>arXiv:2310.11036</a> (replaced) [<a href=https://arxiv.org/pdf/2310.11036 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.11036 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Radio Map Estimation: Empirical Validation and Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shrestha%2C+R">Raju Shrestha</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ha%2C+T+N">Tien Ngoc Ha</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Viet%2C+P+Q">Pham Q. Viet</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Romero%2C+D">Daniel Romero</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, Journal version, submitted to the IEEE Transactions on Wireless Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Applied Physics (physics.app-ph)
</div>
</div>
</dd>
<dt><a name=item864>[864]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.12817 title=Abstract>arXiv:2310.12817</a> (replaced) [<a href=https://arxiv.org/pdf/2310.12817 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.12817 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Cheng-Kun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Min-Hung Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chuang%2C+Y">Yung-Yu Chuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yen-Yu Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICCV 2023 (main + supp). Website: <a href=https://jimmy15923.github.io/mit_web/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item865>[865]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14281 title=Abstract>arXiv:2310.14281</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14281 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.14281 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.14281 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Infinite series of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-266-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1477 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1000.47em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-1478><span class=mn id=MathJax-Span-1479 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-designs in the extended quadratic residue code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Awada%2C+M">Madoka Awada</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2309.03206>arXiv:2309.03206</a>; text overlap with <a href=https://arxiv.org/abs/2305.03285>arXiv:2305.03285</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Information Theory (cs.IT); Group Theory (math.GR); Number Theory (math.NT)
</div>
</div>
</dd>
<dt><a name=item866>[866]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15642 title=Abstract>arXiv:2310.15642</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15642 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15642 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GitBug-Actions: Building Reproducible Bug-Fix Benchmarks with GitHub Actions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saavedra%2C+N">Nuno Saavedra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+A">André Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICSE 2024 Demo
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item867>[867]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15823 title=Abstract>arXiv:2310.15823</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=ElBakry%2C+A">Ahmed ElBakry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabr%2C+M">Mohamed Gabr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=ElNokrashy%2C+M">Muhammad ElNokrashy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlKhamissi%2C+B">Badr AlKhamissi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of ArabicNLP 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item868>[868]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.16908 title=Abstract>arXiv:2310.16908</a> (replaced) [<a href=https://arxiv.org/pdf/2310.16908 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.16908 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.16908 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SequenceLab: A Comprehensive Benchmark of Computational Methods for Comparing Genomic Sequences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Rumpf%2C+M">Maximilian-David Rumpf</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Alser%2C+M">Mohammed Alser</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Gollwitzer%2C+A+E">Arvid E. Gollwitzer</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Lindegger%2C+J">Joel Lindegger</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Almadhoun%2C+N">Nour Almadhoun</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Firtina%2C+C">Can Firtina</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Mangul%2C+S">Serghei Mangul</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Genomics (q-bio.GN)</span>; Hardware Architecture (cs.AR); Quantitative Methods (q-bio.QM)
</div>
</div>
</dd>
<dt><a name=item869>[869]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.17168 title=Abstract>arXiv:2310.17168</a> (replaced) [<a href=https://arxiv.org/pdf/2310.17168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.17168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning an Inventory Control Policy with General Inventory Arrival Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andaz%2C+S">Sohrab Andaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eisenach%2C+C">Carson Eisenach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madeka%2C+D">Dhruv Madeka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torkkola%2C+K">Kari Torkkola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+R">Randy Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Foster%2C+D">Dean Foster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kakade%2C+S">Sham Kakade</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item870>[870]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.17544 title=Abstract>arXiv:2310.17544</a> (replaced) [<a href=https://arxiv.org/pdf/2310.17544 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.17544 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Ensemble-Based Feature Selection for Time Series Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tumay%2C+A">Aysin Tumay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aydin%2C+M+E">Mustafa E. Aydin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koc%2C+A+T">Ali T. Koc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozat%2C+S+S">Suleyman S. Kozat</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item871>[871]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.19491 title=Abstract>arXiv:2310.19491</a> (replaced) [<a href=https://arxiv.org/pdf/2310.19491 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.19491 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.19491 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generator Identification for Linear SDEs with Additive and Multiplicative Noise
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Y">Yuanyuan Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Geng%2C+X">Xi Geng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Huang%2C+W">Wei Huang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Huang%2C+B">Biwei Huang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gong%2C+M">Mingming Gong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item872>[872]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.19699 title=Abstract>arXiv:2310.19699</a> (replaced) [<a href=https://arxiv.org/pdf/2310.19699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.19699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimizing Logical Execution Time Model for Both Determinism and Low Latency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Sen Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+D">Dong Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sifat%2C+A+H">Ashrarul H. Sifat</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+S">Shao-Yu Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Deng%2C+X">Xuanliang Deng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+C">Changhee Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Williams%2C+R">Ryan Williams</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zeng%2C+H">Haibo Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Operating Systems (cs.OS); Symbolic Computation (cs.SC)
</div>
</div>
</dd>
<dt><a name=item873>[873]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20381 title=Abstract>arXiv:2310.20381</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20381 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.20381 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Systematic Evaluation of GPT-4V's Multimodal Capability for Medical Image Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yingshu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yunyi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+X">Xinyu Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Leyang Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Longyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item874>[874]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.00928 title=Abstract>arXiv:2311.00928</a> (replaced) [<a href=https://arxiv.org/pdf/2311.00928 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.00928 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quatro++: Robust Global Registration Exploiting Ground Segmentation for Loop Closing in LiDAR SLAM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+H">Hyungtae Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+B">Beomsoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Daebeom Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+E+M">Eungchang Mason Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 23 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item875>[875]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.00931 title=Abstract>arXiv:2311.00931</a> (replaced) [<a href=https://arxiv.org/pdf/2311.00931 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.00931 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Defect Prediction from Unrealistic Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alrashedy%2C+K">Kamel Alrashedy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hellendoorn%2C+V+J">Vincent J. Hellendoorn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item876>[876]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.01431 title=Abstract>arXiv:2311.01431</a> (replaced) [<a href=https://arxiv.org/pdf/2311.01431 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.01431 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.01431 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Empirical Lossless Compression Bound of a Data Sequence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L+M">Lei M Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item877>[877]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02189 title=Abstract>arXiv:2311.02189</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02189 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02189 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Harvard FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yu Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+M">Min Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kouhana%2C+A">Ava Kouhana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elze%2C+T">Tobias Elze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Mengyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item878>[878]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02332 title=Abstract>arXiv:2311.02332</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02332 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02332 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Machine Learning in Image-Based and Clinical Biomedicine: Survey and Prospects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Warner%2C+E">Elisa Warner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Joonsang Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+W">William Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kahn%2C+C">Charles Kahn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gevaert%2C+O">Olivier Gevaert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+A">Arvind Rao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item879>[879]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02348 title=Abstract>arXiv:2311.02348</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02348 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02348 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Geometrically Higher Order Unfitted Space-Time Methods for PDEs on Moving Domains: Geometry Error Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Heimann%2C+F">Fabian Heimann</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lehrenfeld%2C+C">Christoph Lehrenfeld</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item880>[880]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.02959 title=Abstract>arXiv:2311.02959</a> (replaced) [<a href=https://arxiv.org/pdf/2311.02959 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.02959 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Manageable to unmanageable transition in a fractal model of project networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Vazquez%2C+A">Alexei Vazquez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 5 figures, changes of notation and wording
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item881>[881]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.03242 title=Abstract>arXiv:2311.03242</a> (replaced) [<a href=https://arxiv.org/pdf/2311.03242 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.03242 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miranda%2C+C">Charles Miranda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%BCtte%2C+J">Janina Schütte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sommer%2C+D">David Sommer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eigel%2C+M">Martin Eigel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item882>[882]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.03500 title=Abstract>arXiv:2311.03500</a> (replaced) [<a href=https://arxiv.org/pdf/2311.03500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.03500 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.03500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting Age from White Matter Diffusivity with Residual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gao%2C+C">Chenyu Gao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+M+E">Michael E. Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Q">Qi Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khairi%2C+N+M">Nazirah Mohd Khairi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kanakaraj%2C+P">Praitayini Kanakaraj</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Newlin%2C+N+R">Nancy R. Newlin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Archer%2C+D+B">Derek B. Archer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jefferson%2C+A+L">Angela L. Jefferson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Taylor%2C+W+D">Warren D. Taylor</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Boyd%2C+B+D">Brian D. Boyd</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Beason-Held%2C+L+L">Lori L. Beason-Held</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Resnick%2C+S+M">Susan M. Resnick</a>, 
The <a href="https://arxiv.org/search/eess?searchtype=author&amp;query=BIOCARD+Study+Team">BIOCARD Study Team</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huo%2C+Y">Yuankai Huo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Van+Schaik%2C+K+D">Katherine D. Van Schaik</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schilling%2C+K+G">Kurt G. Schilling</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=I%C5%A1gum%2C+I">Ivana Išgum</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Landman%2C+B+A">Bennett A. Landman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> SPIE Medical Imaging: Image Processing. San Diego, CA. February 2024 (accepted as poster presentation)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)
</div>
</div>
</dd>
<dt><a name=item883>[883]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.03782 title=Abstract>arXiv:2311.03782</a> (replaced) [<a href=https://arxiv.org/e-print/2311.03782 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CapST: An Enhanced and Lightweight Model Attribution Approach for Synthetic Videos
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmad%2C+W">Wasim Ahmad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yuan-Hao Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganfure%2C+G+O">Gaddisa Olani Ganfure</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+S">Sarwar Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahzad%2C+S+A">Sahibzada Adil Shahzad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Rejected from jounal and will have to conduct several more experiments
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item884>[884]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04881 title=Abstract>arXiv:2311.04881</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04881 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.04881 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.04881 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Transmit Signal and Beamforming Design for Integrated Sensing and Power Transfer Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+K+M">Kenneth MacSporran Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shanin%2C+N">Nikita Shanin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+Z">Zhenlong You</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lotter%2C+S">Sebastian Lotter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Br%C3%BCckner%2C+S">Stefan Brückner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vossiek%2C+M">Martin Vossiek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cottatellucci%2C+L">Laura Cottatellucci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 2 figures, six page version of this paper has been submitted to IEEE ICC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item885>[885]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.05587 title=Abstract>arXiv:2311.05587</a> (replaced) [<a href=https://arxiv.org/pdf/2311.05587 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.05587 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.05587 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Methods for Media Mix Modelling with shape and funnel effects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marin%2C+J">Javier Marin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Rev. 5, Jan 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item886>[886]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06101 title=Abstract>arXiv:2311.06101</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06101 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06101 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zecchin%2C+M">Matteo Zecchin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simeone%2C+O">Osvaldo Simeone</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item887>[887]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06558 title=Abstract>arXiv:2311.06558</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convolve and Conquer: Data Comparison with Wiener Filters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cruz%2C+D+P">Deborah Pelacani Cruz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strong%2C+G">George Strong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bates%2C+O">Oscar Bates</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cueto%2C+C">Carlos Cueto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+J">Jiashun Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guasch%2C+L">Lluis Guasch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 5 figures, Medical Imaging Meets Neurips Workshop
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item888>[888]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06979 title=Abstract>arXiv:2311.06979</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.06979 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.06979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessing the Interpretability of Programmatic Policies with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bashir%2C+Z">Zahra Bashir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bowling%2C+M">Michael Bowling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lelis%2C+L+H+S">Levi H. S. Lelis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is under-review for IJCAI. The main file is arxiv.tex and I have a supplementary_materials.tex file as well
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item889>[889]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07789 title=Abstract>arXiv:2311.07789</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Level-k Thinking in the Extensive Form
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schipper%2C+B+C">Burkhard C. Schipper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 51 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item890>[890]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.07989 title=Abstract>arXiv:2311.07989</a> (replaced) [<a href=https://arxiv.org/pdf/2311.07989 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.07989 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chaoyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bingchang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+C">Cong Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+Z">Zi Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianguo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Repo is available at <a href=https://github.com/codefuse-ai/Awesome-Code-LLM.>this https URL</a> 8 figures, 10 tables, and 713 references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item891>[891]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09018 title=Abstract>arXiv:2311.09018</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.09018 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.09018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Foundation of Distributionally Robust Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shengbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+N">Nian Si</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanchet%2C+J">Jose Blanchet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item892>[892]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09127 title=Abstract>arXiv:2311.09127</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09127 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.09127 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuanwei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yixin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+P">Pan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item893>[893]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11205 title=Abstract>arXiv:2311.11205</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shape-Sensitive Loss for Catheter and Guidewire Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kongtongvattana%2C+C">Chayun Kongtongvattana</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+B">Baoru Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kang%2C+J">Jingxuan Kang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+H">Hoan Nguyen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Olufemi%2C+O">Olajide Olufemi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+A">Anh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item894>[894]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11990 title=Abstract>arXiv:2311.11990</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11990 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.11990 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.11990 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine-Learned Atomic Cluster Expansion Potentials for Fast and Quantum-Accurate Thermal Simulations of Wurtzite AlN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Yang%2C+G">Guang Yang</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Liu%2C+Y">Yuan-Bin Liu</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Yang%2C+L">Lei Yang</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Cao%2C+B">Bing-Yang Cao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
</div>
</div>
</dd>
<dt><a name=item895>[895]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13057 title=Abstract>arXiv:2311.13057</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.13057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoque%2C+M+N">Md Naimul Hoque</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mashiat%2C+T">Tasfia Mashiat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghai%2C+B">Bhavya Ghai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shelton%2C+C">Cecilia Shelton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chevalier%2C+F">Fanny Chevalier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kraus%2C+K">Kari Kraus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elmqvist%2C+N">Niklas Elmqvist</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item896>[896]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13373 title=Abstract>arXiv:2311.13373</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.13373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Bin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Pu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item897>[897]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.13416 title=Abstract>arXiv:2311.13416</a> (replaced) [<a href=https://arxiv.org/pdf/2311.13416 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.13416 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.13416 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comprehensive Survey: Biometric User Authentication Application, Evaluation, and Discussion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alrawili%2C+R">Reem Alrawili</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlQahtani%2C+A+A+S">Ali Abdullah S. AlQahtani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+M+K">Muhammad Khurram Khan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item898>[898]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14212 title=Abstract>arXiv:2311.14212</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Annotation Sensitivity: Training Data Collection Methods Affect Model Performance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kern%2C+C">Christoph Kern</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Eckman%2C+S">Stephanie Eckman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Beck%2C+J">Jacob Beck</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chew%2C+R">Rob Chew</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ma%2C+B">Bolei Ma</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kreuter%2C+F">Frauke Kreuter</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EMNLP 2023 Findings: <a href=https://aclanthology.org/2023.findings-emnlp.992/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item899>[899]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14616 title=Abstract>arXiv:2311.14616</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14616 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14616 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using MultiPrecisonArrays.jl: Iterative Refinement in Julia
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kelley%2C+C+T">C. T. Kelley</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item900>[900]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16141 title=Abstract>arXiv:2311.16141</a> (replaced) [<a href=https://arxiv.org/pdf/2311.16141 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.16141 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Criticality-Guided Efficient Pruning in Spiking Neural Networks Inspired by Critical Brain Hypothesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shuo Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Boxiao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=You%2C+H">Haihang You</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item901>[901]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17005 title=Abstract>arXiv:2311.17005</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17005 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17005 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MVBench: A Comprehensive Multi-modal Video Understanding Benchmark
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Kunchang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yali Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yinan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yizhuo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jilan Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guo Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+P">Ping Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Limin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 7 figures, 19 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item902>[902]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17841 title=Abstract>arXiv:2311.17841</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.17841 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.17841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast list-decoding of univariate multiplicity and folded Reed-Solomon codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+R">Rohan Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harsha%2C+P">Prahladh Harsha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shankar%2C+A">Ashutosh Shankar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Computational Complexity (cs.CC)
</div>
</div>
</dd>
<dt><a name=item903>[903]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.18484 title=Abstract>arXiv:2311.18484</a> (replaced) [<a href=https://arxiv.org/pdf/2311.18484 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.18484 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nigerian Schizophrenia EEG Dataset (NSzED) Towards Data-Driven Psychiatry in Africa
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olateju%2C+E+O">E.O. Olateju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayodele%2C+K+P">K.P. Ayodele</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mosaku%2C+S+K">S.K. Mosaku</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Manuscript being updated as more data-acquisition proceeds. Link to dataset will be added on next update
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)
</div>
</div>
</dd>
<dt><a name=item904>[904]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00157 title=Abstract>arXiv:2312.00157</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00157 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.00157 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Backdoor Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+B">Benjamin Schneider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lukas%2C+N">Nils Lukas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item905>[905]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00339 title=Abstract>arXiv:2312.00339</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00339 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.00339 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.00339 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Propagation of chaos in path spaces via information theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+L">Lei Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Y">Yuelin Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Y">Yuliang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item906>[906]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.01632 title=Abstract>arXiv:2312.01632</a> (replaced) [<a href=https://arxiv.org/pdf/2312.01632 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.01632 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GaussianHead: High-fidelity Head Avatars with Learnable Gaussian Derivation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jiu-Cheng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xianyan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pun%2C+C">Chi-Man Pun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+H">Hao Gao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item907>[907]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.01963 title=Abstract>arXiv:2312.01963</a> (replaced) [<a href=https://arxiv.org/pdf/2312.01963 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.01963 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model reduction on manifolds: A differential geometric framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Buchfink%2C+P">Patrick Buchfink</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Glas%2C+S">Silke Glas</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Haasdonk%2C+B">Bernard Haasdonk</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Unger%2C+B">Benjamin Unger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 3 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item908>[908]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.02063 title=Abstract>arXiv:2312.02063</a> (replaced) [<a href=https://arxiv.org/pdf/2312.02063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.02063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The GPU Phase Folding and Deep Learning Method for Detecting Exoplanet Transits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Wang%2C+K">Kaitlyn Wang</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Ge%2C+J">Jian Ge</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Willis%2C+K">Kevin Willis</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Wang%2C+K">Kevin Wang</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Zhao%2C+Y">Yinan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 19 figures; Accepted for publication in the peer-reviewed journal, Monthly Notices of the Royal Astronomical Society (MNRAS), on January 20, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item909>[909]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.02277 title=Abstract>arXiv:2312.02277</a> (replaced) [<a href=https://arxiv.org/pdf/2312.02277 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.02277 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled Compositional Stochastic Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+B">Bokun Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fixed several typos; Added some numerical experiments
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item910>[910]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.02317 title=Abstract>arXiv:2312.02317</a> (replaced) [<a href=https://arxiv.org/pdf/2312.02317 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.02317 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruijie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rossetto%2C+L">Luca Rossetto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cochez%2C+M">Michael Cochez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernstein%2C+A">Abraham Bernstein</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item911>[911]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.02471 title=Abstract>arXiv:2312.02471</a> (replaced) [<a href=https://arxiv.org/pdf/2312.02471 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.02471 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Congestion-aware Distributed Task Offloading in Wireless Multi-hop Networks Using Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perazzone%2C+J">Jake Perazzone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verma%2C+G">Gunjan Verma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 5 figures, accepted to IEEE ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item912>[912]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03122 title=Abstract>arXiv:2312.03122</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03122 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.03122 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.03122 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assertion Enhanced Few-Shot Learning: Instructive Technique for Large Language Models to Generate Educational Explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahriar%2C+T">Tasmia Shahriar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramos%2C+K">Kelly Ramos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matsuda%2C+N">Noboru Matsuda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item913>[913]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03311 title=Abstract>arXiv:2312.03311</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03311 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03311 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Nystrom Approximation for Preconditioning in Kernel Machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Abedsoltan%2C+A">Amirhesam Abedsoltan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Belkin%2C+M">Mikhail Belkin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Pandit%2C+P">Parthe Pandit</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Rademacher%2C+L">Luis Rademacher</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item914>[914]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03686 title=Abstract>arXiv:2312.03686</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03686 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.03686 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.03686 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Canonization of a random graph by two matrix-vector multiplications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verbitsky%2C+O">Oleg Verbitsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhukovskii%2C+M">Maksim Zhukovskii</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages, 3 Figures. The proof of Part 2 of Theorem 1 is given in this version in more detail. The proof of Theorem 3 is also revised
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Complexity (cs.CC)</span>
</div>
</div>
</dd>
<dt><a name=item915>[915]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05058 title=Abstract>arXiv:2312.05058</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05058 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05058 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spatial and Temporal Hierarchy for Autonomous Navigation using Active Inference in Minigrid Environment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Tinguy%2C+D">Daria de Tinguy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+de+Maele%2C+T">Toon van de Maele</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhoedt%2C+B">Bart Dhoedt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2309.09864>arXiv:2309.09864</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Entropy 2024, 26, 83, Special Issue From Functional Imaging to
 Free Energy Dedicated to Professor Karl Friston on the Occasion of His 65th
 Birthday
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item916>[916]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05134 title=Abstract>arXiv:2312.05134</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05134 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05134 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Multi-Distribution Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan%2C+W">Wenhao Zhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+S+S">Simon S. Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J+D">Jason D. Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item917>[917]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06261 title=Abstract>arXiv:2312.06261</a> (replaced) [<a href=https://arxiv.org/e-print/2312.06261 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruonan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Quanhu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+T">Te Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Authors of the paper to be re-established
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item918>[918]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07178 title=Abstract>arXiv:2312.07178</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07178 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07178 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Expected Return: Accounting for Policy Reproducibility when Evaluating Reinforcement Learning Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Flageat%2C+M">Manon Flageat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lim%2C+B">Bryan Lim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cully%2C+A">Antoine Cully</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item919>[919]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07343 title=Abstract>arXiv:2312.07343</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.07343 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.07343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anishka">Anishka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta%2C+A">Atharva Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+N">Nipun Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balachandran%2C+A">Aarav Balachandran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jalote%2C+P">Pankaj Jalote</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item920>[920]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07930 title=Abstract>arXiv:2312.07930</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07930 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.07930 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Optimal Statistical Watermarking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+B">Baihe Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jiantao Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item921>[921]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10049 title=Abstract>arXiv:2312.10049</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10049 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.10049 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.10049 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Graph Reasoning Based on Attention GCN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+M">Meera Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khanna%2C+R">Ravi Khanna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choudhary%2C+D">Divya Choudhary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+N">Nandini Rao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item922>[922]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10105 title=Abstract>arXiv:2312.10105</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10105 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10105 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Forging Tokens for Improved Storage-efficient Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+M">Minhyun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Song Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heo%2C+B">Byeongho Heo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+D">Dongyoon Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> First two authors contributed equally
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item923>[923]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10269 title=Abstract>arXiv:2312.10269</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trujillo%2C+A">Amaury Trujillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fagni%2C+T">Tiziano Fagni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cresci%2C+S">Stefano Cresci</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item924>[924]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10301 title=Abstract>arXiv:2312.10301</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10301 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10301 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FCBench: Cross-Domain Benchmarking of Lossless Compression for Floating-Point Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+J">Jiannan Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beaver%2C+I">Ian Beaver</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freeman%2C+C">Cynthia Freeman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yan Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianguo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 11 figures, 11 tables, accepted by VLDB '24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
</div>
</dd>
<dt><a name=item925>[925]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10305 title=Abstract>arXiv:2312.10305</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+Z">Zhaoxi Mu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S">Sining Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qing Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item926>[926]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11413 title=Abstract>arXiv:2312.11413</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11413 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11413 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DeRDaVa: Deletion-Robust Data Valuation for Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+X">Xiao Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%2C+R+H+L">Rachael Hwee Ling Sim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+J">Jue Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item927>[927]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11532 title=Abstract>arXiv:2312.11532</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11532 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11532 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo%2C+Y">YoungJoon Yoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jongwon Choi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in the 38th annual AAAI conference on Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item928>[928]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11835 title=Abstract>arXiv:2312.11835</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Provably Convergent Federated Trilevel Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kai Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tiancheng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jian%2C+C">Chengtao Jian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item929>[929]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11841 title=Abstract>arXiv:2312.11841</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MixRT: Mixed Neural Representations For Real-Time NeRF Rendering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chaojian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+B">Bichen Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vajda%2C+P">Peter Vajda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yingyan">Yingyan</a> (Celine)Lin
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by 3DV'24. Project Page: <a href=https://licj15.github.io/MixRT/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item930>[930]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11976 title=Abstract>arXiv:2312.11976</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11976 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11976 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Dongmin Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Sunghyun Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI 2024, 17 pages, <a href=https://github.com/carrtesy/M2N2>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item931>[931]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.13118 title=Abstract>arXiv:2312.13118</a> (replaced) [<a href=https://arxiv.org/pdf/2312.13118 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.13118 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Tao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+T">Tie Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wunsch%2C+D+C">Donald C. Wunsch</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024 main track. Code available on Github (see abstract). Appendix is included in this updated version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item932>[932]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.13141 title=Abstract>arXiv:2312.13141</a> (replaced) [<a href=https://arxiv.org/pdf/2312.13141 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.13141 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Augment on Manifold: Mixup Regularization with UMAP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Laham%2C+Y">Yousef El-Laham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fons%2C+E">Elizabeth Fons</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daudert%2C+D">Dillon Daudert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted paper to be published in the proceedings of ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item933>[933]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.13152 title=Abstract>arXiv:2312.13152</a> (replaced) [<a href=https://arxiv.org/pdf/2312.13152 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.13152 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Stochastic Differential Equations with Change Points: A Generative Adversarial Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhongchang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Laham%2C+Y">Yousef El-Laham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted paper to be published in the proceedings of ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item934>[934]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.14971 title=Abstract>arXiv:2312.14971</a> (replaced) [<a href=https://arxiv.org/pdf/2312.14971 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.14971 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Designing Electricity Distribution Networks: The Impact of Demand Coincidence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Gust%2C+G">Gunther Gust</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Schl%C3%BCter%2C+A">Alexander Schlüter</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=%C3%9Abeda%2C+I">Ignacio Úbeda</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lee%2C+J+T">Jonathan T Lee</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Neumann%2C+D">Dirk Neumann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted manuscript, to appear in European Journal of Operational Research (EJOR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item935>[935]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15407 title=Abstract>arXiv:2312.15407</a> (replaced) [<a href=https://arxiv.org/pdf/2312.15407 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.15407 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Haro%2C+L+F">Luis Fernando D'Haro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Malu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> An extended version of AAAI-2024 camera-ready paper (appendix included, 16 pages)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item936>[936]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16113 title=Abstract>arXiv:2312.16113</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+M">Mengxuan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Q">Qing Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Longfei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of the 2024 AAAI Conference on Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item937>[937]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16244 title=Abstract>arXiv:2312.16244</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16244 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16244 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modality-missing RGBT Tracking via Invertible Prompt Learning and A High-quality Data Simulation Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+A">Andong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jiacong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenglong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jin Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+B">Bin Luo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item938>[938]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16313 title=Abstract>arXiv:2312.16313</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unraveling the Key Components of OOD Generalization via Diversification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benoit%2C+H">Harold Benoit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+L">Liangze Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atanov%2C+A">Andrei Atanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kar%2C+O+F">Oğuzhan Fatih Kar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zamir%2C+A">Amir Zamir</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item939>[939]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17004 title=Abstract>arXiv:2312.17004</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17004 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17004 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Continual Learning in Medical Image Analysis: A Comprehensive Review of Recent Advancements and Future Prospects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kumari%2C+P">Pratibha Kumari</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chauhan%2C+J">Joohi Chauhan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bozorgpour%2C+A">Afshin Bozorgpour</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+B">Boqiang Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Azad%2C+R">Reza Azad</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item940>[940]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17045 title=Abstract>arXiv:2312.17045</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.17045 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.17045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Properties of Immersions for Systems with Multiple Limit Sets with Implications to Learning Koopman Embeddings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+Z">Zexiang Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ozay%2C+N">Necmiye Ozay</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sontag%2C+E+D">Eduardo D. Sontag</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)
</div>
</div>
</dd>
<dt><a name=item941>[941]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17080 title=Abstract>arXiv:2312.17080</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17080 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17080 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zhongshen Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pengguang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code: <a href=https://github.com/dvlab-research/MR-GSM8K>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item942>[942]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17240 title=Abstract>arXiv:2312.17240</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17240 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17240 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LISA++: An Improved Baseline for Reasoning Segmentation with Large Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Senqiao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+T">Tianyuan Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+X">Xin Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+Z">Zhuotao Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+B">Bohao Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Typo fixed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item943>[943]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00313 title=Abstract>arXiv:2401.00313</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Matching of Users and Creators in Two-Sided Markets with Departures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huttenlocher%2C+D">Daniel Huttenlocher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hannah Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+L">Liang Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozdaglar%2C+A">Asuman Ozdaglar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siderius%2C+J">James Siderius</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); General Economics (econ.GN)
</div>
</div>
</dd>
<dt><a name=item944>[944]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00334 title=Abstract>arXiv:2401.00334</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00334 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00334 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explainability-Driven Leaf Disease Classification using Adversarial Training and Knowledge Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Echim%2C+S">Sebastian-Vasile Echim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C4%83iatu%2C+I">Iulian-Marius Tăiatu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cercel%2C+D">Dumitru-Clementin Cercel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pop%2C+F">Florin Pop</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 8 figures, Accepted by ICAART 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item945>[945]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00733 title=Abstract>arXiv:2401.00733</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00733 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.00733 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.00733 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximate generalized Steiner systems and near-optimal constant weight codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+M">Miao Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shangguan%2C+C">Chong Shangguan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, introduction revised
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item946>[946]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.01084 title=Abstract>arXiv:2401.01084</a> (replaced) [<a href=https://arxiv.org/pdf/2401.01084 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.01084 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Global Convergence of Natural Policy Gradient with Hessian-aided Momentum Variance Reduction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+J">Jie Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+K">Ke Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jinchi Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item947>[947]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.01841 title=Abstract>arXiv:2401.01841</a> (replaced) [<a href=https://arxiv.org/pdf/2401.01841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.01841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+B">Baiting Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunuo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubey%2C+A">Abhishek Dubey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication at the International Conference on Autonomous Agents and MultiAgent Systems (AAMAS), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item948>[948]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02436 title=Abstract>arXiv:2401.02436</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02436 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02436 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compressed 3D Gaussian Splatting for Accelerated Novel View Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niedermayr%2C+S">Simon Niedermayr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stumpfegger%2C+J">Josef Stumpfegger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Westermann%2C+R">Rüdiger Westermann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item949>[949]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02500 title=Abstract>arXiv:2401.02500</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pallagani%2C+V">Vishal Pallagani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muppasani%2C+B">Bharath Muppasani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fabiano%2C+F">Francesco Fabiano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Loreggia%2C+A">Andrea Loreggia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murugesan%2C+K">Keerthiram Murugesan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rossi%2C+F">Francesca Rossi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horesh%2C+L">Lior Horesh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheth%2C+A">Amit Sheth</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item950>[950]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02610 title=Abstract>arXiv:2401.02610</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DHGCN: Dynamic Hop Graph Convolution Network for Self-Supervised Point Cloud Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jincen Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lizhi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+X">Xuequan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+W">Wei Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razzak%2C+I">Imran Razzak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Meili Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item951>[951]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.03197 title=Abstract>arXiv:2401.03197</a> (replaced) [<a href=https://arxiv.org/pdf/2401.03197 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.03197 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decision Making in Non-Stationary Environments with Policy-Augmented Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pettet%2C+A">Ava Pettet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunuo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+B">Baiting Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wray%2C+K">Kyle Wray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baier%2C+H">Hendrik Baier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laszka%2C+A">Aron Laszka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dubey%2C+A">Abhishek Dubey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended Abstract accepted for presentation at AAMAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item952>[952]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.03506 title=Abstract>arXiv:2401.03506</a> (replaced) [<a href=https://arxiv.org/pdf/2401.03506 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.03506 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiarizationLM: Speaker Diarization Post-Processing with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Q">Quan Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+Y">Yiling Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Clark%2C+E">Evan Clark</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xia%2C+W">Wei Xia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liao%2C+H">Hank Liao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item953>[953]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04614 title=Abstract>arXiv:2401.04614</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generic Knowledge Boosted Pre-training For Remote Sensing Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Ziyue Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mingming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+Y">Yuan Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item954>[954]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04620 title=Abstract>arXiv:2401.04620</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Agent Alignment in Evolving Social Norms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shimin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item955>[955]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04846 title=Abstract>arXiv:2401.04846</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04846 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04846 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The inherent goodness of well educated intelligence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Glinsky%2C+M+E">Michael E. Glinsky</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Sievert%2C+S">Sharon Sievert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 10 figures, 15 equations, to be submitted to Nature
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item956>[956]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04925 title=Abstract>arXiv:2401.04925</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04925 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04925 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Impact of Reasoning Step Length on Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+M">Mingyu Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qinkai Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+D">Dong Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Haiyan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+W">Wenyue Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+Y">Yanda Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+M">Mengnan Du</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item957>[957]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05949 title=Abstract>arXiv:2401.05949</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+M">Meihuizi Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tuan%2C+L+A">Luu Anh Tuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+J">Jinming Wen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item958>[958]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06144 title=Abstract>arXiv:2401.06144</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06144 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06144 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DFU: scale-robust diffusion model for zero-shot super-resolution image generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Havrilla%2C+A">Alex Havrilla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rojas%2C+K">Kevin Rojas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+W">Wenjing Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+M">Molei Tao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item959>[959]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06256 title=Abstract>arXiv:2401.06256</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.06256 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.06256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sukhobokov%2C+A">Artem Sukhobokov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belousov%2C+E">Evgeny Belousov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gromozdov%2C+D">Danila Gromozdov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zenger%2C+A">Anna Zenger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popov%2C+I">Ilya Popov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item960>[960]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06328 title=Abstract>arXiv:2401.06328</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06328 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06328 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Non-Euclidean Erdős-Anning Theorems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eppstein%2C+D">David Eppstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 13 figures. This version adds a connection to equilateral dimension
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Metric Geometry (math.MG)</span>; Computational Geometry (cs.CG)
</div>
</div>
</dd>
<dt><a name=item961>[961]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06391 title=Abstract>arXiv:2401.06391</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yebo Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+T">Tianlin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Weisong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X">Xin Peng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item962>[962]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06547 title=Abstract>arXiv:2401.06547</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.06547 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.06547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Are We Still Missing an Item?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magen%2C+R">Roey Magen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item963>[963]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06766 title=Abstract>arXiv:2401.06766</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06766 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06766 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voronov%2C+A">Anton Voronov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+L">Lena Wolf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ryabinin%2C+M">Max Ryabinin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 10 figures. Code: <a href=https://github.com/yandex-research/mind-your-format>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item964>[964]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07278 title=Abstract>arXiv:2401.07278</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07278 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07278 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luu%2C+V+Q">Vinh Quoc Luu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+D+K">Duy Khanh Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+H+T">Huy Thanh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+M+T">Minh Thanh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T+T">Thinh Tien Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dinh%2C+V+Q">Vinh Quang Dinh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item965>[965]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07356 title=Abstract>arXiv:2401.07356</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07356 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07356 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BUGSPHP: A dataset for Automated Program Repair in PHP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pramod%2C+K+D">K.D. Pramod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Silva%2C+W+T+N">W.T.N. De Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thabrew%2C+W+U+K">W.U.K. Thabrew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shariffdeen%2C+R">Ridwan Shariffdeen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wickramanayake%2C+S">Sandareka Wickramanayake</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item966>[966]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07364 title=Abstract>arXiv:2401.07364</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07364 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07364 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Liu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item967>[967]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07378 title=Abstract>arXiv:2401.07378</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07378 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07378 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+G">Guangyu Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+R">Ruyu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Liu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+P">Peixian Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Danny Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niemier%2C+M">Michael Niemier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X+S">X.Sharon Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item968>[968]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07450 title=Abstract>arXiv:2401.07450</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07450 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07450 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Fashion Design with Multi-stage Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+H">Huiming Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mengtian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Y">Ying Cao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item969>[969]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07510 title=Abstract>arXiv:2401.07510</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07510 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.07510 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.07510 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 50 pages, 3 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item970>[970]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07656 title=Abstract>arXiv:2401.07656</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.07656 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.07656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Explainable and Better Performing Representations of POMDP Strategies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bork%2C+A">Alexander Bork</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakraborty%2C+D">Debraj Chakraborty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grover%2C+K">Kush Grover</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kretinsky%2C+J">Jan Kretinsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohr%2C+S">Stefanie Mohr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Technical report for the submission to TACAS 24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item971>[971]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07890 title=Abstract>arXiv:2401.07890</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07890 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07890 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahbazi%2C+A">Alireza Shahbazi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirsanei%2C+S+A">Seyyed Ahmad Mirsanei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarraf%2C+M+H+K+M">Malikeh Haj Khan Mirzaye Sarraf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bidgoli%2C+B+M">Behrouz Minaei Bidgoli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item972>[972]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07991 title=Abstract>arXiv:2401.07991</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robustness Against Adversarial Attacks via Learning Confined Adversarial Polytopes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamidi%2C+S+M">Shayan Mohajer Hamidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+L">Linfeng Ye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper has been accepted in ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item973>[973]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08503 title=Abstract>arXiv:2401.08503</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08503 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08503 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Z">Zhenhui Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+T">Tianyun Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Y">Yi Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiaqi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Weichuang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiawei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Ziyue Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Jinzheng He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+R">Rongjie Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinglin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+X">Xiang Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zejun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024 (Spotlight). Project page: <a href=https://real3dportrait.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item974>[974]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08573 title=Abstract>arXiv:2401.08573</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08573 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08573 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking the Robustness of Image Watermarks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+B">Bang An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+M">Mucong Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rabbani%2C+T">Tahseen Rabbani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawal%2C+A">Aakriti Agrawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuancheng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+C">Chenghao Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+S">Sicheng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohamed%2C+A">Abdirisak Mohamed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Y">Yuxin Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F">Furong Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item975>[975]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08586 title=Abstract>arXiv:2401.08586</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08586 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08586 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08586 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A GPU accelerated mixed-precision Smoothed Particle Hydrodynamics framework with cell-based relative coordinates
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+Z">Zirui Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shenyang Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+A">Ang Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item976>[976]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08668 title=Abstract>arXiv:2401.08668</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08668 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Thermodynamic Perspectives on Computational Complexity: Exploring the P vs. NP Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neukart%2C+F">Florian Neukart</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 52 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item977>[977]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08738 title=Abstract>arXiv:2401.08738</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08738 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08738 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08738 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine Learning-Based Analysis of Ebola Virus' Impact on Gene Expression in Nonhuman Primates
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Rezapour%2C+M">Mostafa Rezapour</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Niazi%2C+M+K+K">Muhammad Khalid Khan Niazi</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Lu%2C+H">Hao Lu</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Narayanan%2C+A">Aarthi Narayanan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Gurcan%2C+M+N">Metin Nafi Gurcan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 8 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item978>[978]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08865 title=Abstract>arXiv:2401.08865</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konz%2C+N">Nicholas Konz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mazurowski%2C+M+A">Maciej A. Mazurowski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024. Code: <a href=https://github.com/mazurowski-lab/intrinsic-properties>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item979>[979]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08947 title=Abstract>arXiv:2401.08947</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08947 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08947 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08947 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AntiPhishStack: LSTM-based Stacked Generalization Model for Optimized Phishing URL Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aslam%2C+S">Saba Aslam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aslam%2C+H">Hafsa Aslam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manzoor%2C+A">Arslan Manzoor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hui%2C+C">Chen Hui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rasool%2C+A">Abdur Rasool</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item980>[980]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08981 title=Abstract>arXiv:2401.08981</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Real-time generative design of diverse, "truly" optimized structures with controllable structural complexities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Z">Zongliang Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xinyu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+W">Wenyu Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yuan Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+H">Hongzhi Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xu Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
</div>
</dd>
<dt><a name=item981>[981]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09003 title=Abstract>arXiv:2401.09003</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09003 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09003 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Augmenting Math Word Problems via Iterative Question Composing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoxiong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+A+C">Andrew Chi-Chih Yao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item982>[982]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09031 title=Abstract>arXiv:2401.09031</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09031 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09031 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+T">Tong Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haoyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+A">Andrew Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsieh%2C+C">Cho-Jui Hsieh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item983>[983]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09059 title=Abstract>arXiv:2401.09059</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09059 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09059 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Autonomous Catheterization with Open-source Simulator and Expert Trajectory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jianu%2C+T">Tudor Jianu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+B">Baoru Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vo%2C+T">Tuan Vo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+M+N">Minh Nhat Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jingxuan Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+H">Hoan Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omisore%2C+O">Olatunji Omisore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berthet-Rayne%2C+P">Pierre Berthet-Rayne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fichera%2C+S">Sebastiano Fichera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+A">Anh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code: <a href=https://github.com/airvlab/cathsim>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item984>[984]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09074 title=Abstract>arXiv:2401.09074</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09074 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09074 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Code Simulation Challenges for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=La+Malfa%2C+E">Emanuele La Malfa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weinhuber%2C+C">Christoph Weinhuber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Torre%2C+O">Orazio Torre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+F">Fangru Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohn%2C+A">Anthony Cohn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shadbolt%2C+N">Nigel Shadbolt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wooldridge%2C+M">Michael Wooldridge</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> main paper (10 pages) + Appendix (11 pages)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item985>[985]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09102 title=Abstract>arXiv:2401.09102</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09102 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09102 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SendingNetwork: Advancing the Future of Decentralized Messaging Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeung%2C+M">Mason Yeung</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
</div>
</dd>
<dt><a name=item986>[986]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09149 title=Abstract>arXiv:2401.09149</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09149 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09149 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qiaoling Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+D">Diandian Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoteng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">YingTong Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+T">Ting Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Q">Qinghao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+X">Xin Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Y">Yonggang Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+P">Peng Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item987>[987]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09221 title=Abstract>arXiv:2401.09221</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09221 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09221 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09221 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiple Subset Problem as an encryption scheme for communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zadok%2C+Y">Yair Zadok</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voloch%2C+N">Nadav Voloch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voloch-Bloch%2C+N">Noa Voloch-Bloch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajaj%2C+M+M">Maor Meir Hajaj</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item988>[988]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09333 title=Abstract>arXiv:2401.09333</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09333 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09333 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gordillo%2C+D+D">Diana Davila Gordillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timoneda%2C+J">Joan Timoneda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vera%2C+S+V">Sebastian Vallejo Vera</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 5 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item989>[989]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09451 title=Abstract>arXiv:2401.09451</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion-Driven Generative Framework for Molecular Conformation Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Yang%2C+B">Bobin Yang</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Deng%2C+J">Jie Deng</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Wu%2C+R">Ruoxue Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2105.07246>arXiv:2105.07246</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)
</div>
</div>
</dd>
<dt><a name=item990>[990]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09495 title=Abstract>arXiv:2401.09495</a> (replaced) [<a href=https://arxiv.org/e-print/2401.09495 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IPR-NeRF: Ownership Verification meets Neural Radiance Field
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ong%2C+W+K">Win Kent Ong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+K+W">Kam Woh Ng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y+Z">Yi Zhe Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Error on result tabulation for the state of the art method which might cause misleading to the readers
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item991>[991]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09496 title=Abstract>arXiv:2401.09496</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Generalize over Subpartitions for Heterogeneity-aware Domain Adaptive Nuclei Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+J">Jianan Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+D">Dongnan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+H">Hang Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+W">Weidong Cai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item992>[992]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09671 title=Abstract>arXiv:2401.09671</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09671 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09671 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shrestha%2C+S">Sagar Shrestha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+X">Xiao Fu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item993>[993]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09767 title=Abstract>arXiv:2401.09767</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09767 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09767 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Effectiveness of Function-Level Vulnerability Detectors for Inter-Procedural Vulnerabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Ning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+D">Deqing Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yating Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruqian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shouhuai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures. To appear in the Proceedings of the 46th International Conference on Software Engineering (ICSE'24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item994>[994]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09793 title=Abstract>arXiv:2401.09793</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09793 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09793 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhijie Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weizheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaixiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 16 figures, IJCAI 2024 under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item995>[995]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09798 title=Abstract>arXiv:2401.09798</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09798 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09798 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09798 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takemoto%2C+K">Kazuhiro Takemoto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item996>[996]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09826 title=Abstract>arXiv:2401.09826</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09826 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09826 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Boosting Few-Shot Semantic Segmentation Via Segment Anything Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chen-Bin Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+Q">Qi Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kangdao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+H">Houcheng Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vong%2C+C">Chi-Man Vong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item997>[997]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09953 title=Abstract>arXiv:2401.09953</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09953 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09953 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yutong Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+R">Runpeng Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinchao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item998>[998]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09957 title=Abstract>arXiv:2401.09957</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09957 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.09957 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.09957 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Most General Winning Secure Equilibria Synthesis in Graph Games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nayak%2C+S+P">Satya Prakash Nayak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmuck%2C+A">Anne-Kathrin Schmuck</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> TACAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item999>[999]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10015 title=Abstract>arXiv:2401.10015</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10015 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10015 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Hierarchical Spoken Language Dysfluency Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+J">Jiachen Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anumanchipalli%2C+G">Gopala Anumanchipalli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 EACL. Hierarchical extension of our previous workshop paper <a href=https://arxiv.org/abs/2312.12810>arXiv:2312.12810</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item1000>[1000]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10074 title=Abstract>arXiv:2401.10074</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10074 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10074 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10074 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lower Bounds for Maximum Weight Bisections of Graphs with Bounded Degrees
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gerke%2C+S">Stefanie Gerke</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gutin%2C+G">Gregory Gutin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yeo%2C+A">Anders Yeo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhou%2C+Y">Yacong Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
</div>
</dd>
<dt><a name=item1001>[1001]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10107 title=Abstract>arXiv:2401.10107</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10107 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Palo%2C+G">Gianpaolo Palo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fiorillo%2C+L">Luigi Fiorillo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Monachino%2C+G">Giuliana Monachino</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bechny%2C+M">Michal Bechny</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Melnykowycz%2C+M">Mark Melnykowycz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tzovara%2C+A">Athina Tzovara</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Agostini%2C+V">Valentina Agostini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Faraci%2C+F+D">Francesca Dalia Faraci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 12 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)
</div>
</div>
</dd>
<dt><a name=item1002>[1002]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10150 title=Abstract>arXiv:2401.10150</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10150 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10150 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Changgu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+J">Junwei Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lianggangxu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+G">Gaoqi He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Changbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item1003>[1003]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10155 title=Abstract>arXiv:2401.10155</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10155 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10155 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A novel hybrid time-varying graph neural network for traffic flow forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+B+A">Ben Ao Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+B">Bao-Lin Ye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages 1figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item1004>[1004]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10189 title=Abstract>arXiv:2401.10189</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10189 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10189 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qingyun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zixuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongxiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J">Jiawei Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+H">Heng Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Huimin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages. Accepted by Findings of the Association for Computational Linguistics: EACL 2024. Code and resources are available at <a href=https://github.com/EagleW/Chem-FINESE>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item1005>[1005]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10230 title=Abstract>arXiv:2401.10230</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10230 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10230 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TEXterity: Tactile Extrinsic deXterity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bronars%2C+A">Antonia Bronars</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sangwoon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patre%2C+P">Parag Patre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodriguez%2C+A">Alberto Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 5 figures, submitted to ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item1006>[1006]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10273 title=Abstract>arXiv:2401.10273</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10273 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10273 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10273 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revolutionizing Pharma: Unveiling the AI and LLM Trends in the Pharmaceutical Industry
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yu Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+J">Jingwen Tao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item1007>[1007]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10305 title=Abstract>arXiv:2401.10305</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10305 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10305 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Personality Trait Inference Via Mobile Phone Sensors: A Machine Learning Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sze%2C+W+Y+S">Wun Yung Shaney Sze</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Herrero%2C+M+P">Maryglen Pearl Herrero</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Garriga%2C+R">Roger Garriga</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item1008>[1008]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10337 title=Abstract>arXiv:2401.10337</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Tu Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srndic%2C+N">Nedim Srndic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neth%2C+A">Alexander Neth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at EACL 2024, in ARR October 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item1009>[1009]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10371 title=Abstract>arXiv:2401.10371</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10371 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10371 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chien%2C+E">Eli Chien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Ziang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Pan Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item1010>[1010]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10393 title=Abstract>arXiv:2401.10393</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10393 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10393 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Catastrophic Interference is Mitigated in Naturalistic Power-Law Learning Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gandhi%2C+A">Atith Gandhi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marupudi%2C+V">Vijay Marupudi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varma%2C+S">Sashank Varma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item1011>[1011]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10451 title=Abstract>arXiv:2401.10451</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Brenner%2C+A">Aron Brenner</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khorramfar%2C+R">Rahman Khorramfar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mallapragada%2C+D">Dharik Mallapragada</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Amin%2C+S">Saurabh Amin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item1012>[1012]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10491 title=Abstract>arXiv:2401.10491</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10491 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10491 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Fusion of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+F">Fanqi Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xinting Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+D">Deng Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+W">Wei Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item1013>[1013]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10739 title=Abstract>arXiv:2401.10739</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10739 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10739 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10739 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> In-IDE Human-AI Experience in the Era of Large Language Models; A Literature Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sergeyuk%2C+A">Agnia Sergeyuk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Titov%2C+S">Sergey Titov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Izadi%2C+M">Maliheh Izadi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper accepted for presentation at the IDE Workshop, co-located with ICSE'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item1014>[1014]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10765 title=Abstract>arXiv:2401.10765</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10765 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10765 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abadi%2C+A">Aydin Abadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doyle%2C+B">Bradley Doyle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gini%2C+F">Francesco Gini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guinamard%2C+K">Kieron Guinamard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murakonda%2C+S+K">Sasi Kumar Murakonda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liddell%2C+J">Jack Liddell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mellor%2C+P">Paul Mellor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murdoch%2C+S+J">Steven J. Murdoch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naseri%2C+M">Mohammad Naseri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Page%2C+H">Hector Page</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theodorakopoulos%2C+G">George Theodorakopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weller%2C+S">Suzanne Weller</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item1015>[1015]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10845 title=Abstract>arXiv:2401.10845</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10845 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10845 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Emotion Classification In Software Engineering Texts: A Comparative Analysis of Pre-trained Transformers Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Imran%2C+M+M">Mia Mohammad Imran</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item573>Cross-lists</a></li>
<li><a href=#item634>Replacements</a></li>
</ul>
<small>[ total of 1015 entries: <b>1-1015</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2401>2401</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_SansSerif,sans-serif class=sf-hidden></div></div>