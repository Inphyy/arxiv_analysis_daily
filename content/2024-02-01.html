<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Thu Feb 01 2024 10:38:45 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}.MathJax .noError{text-align:left;color:black;padding:1px 3px}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,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 aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Tue 30 Jan 24 to Wed 31 Jan 24, announced Thu, 1 Feb 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item291>Cross-lists</a></li>
<li><a href=#item333>Replacements</a></li>
</ul>
<small>[ total of 530 entries: <b>1-530</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Thu, 1 Feb 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17313 title=Abstract>arXiv:2401.17313</a> [<a href=https://arxiv.org/pdf/2401.17313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized control methodology for multi-machine/multi-converter power systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhetessov%2C+A">Aidar Zhetessov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 38 pages, Semester Thesis at ETH Zurich
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this project we evaluate a framework for synchronization of mixed
machine-converter power grids. Synchronous machines are assumed to be actuated
by mechanical torque injections, while the converters by DC-side current
injections. As this approach is based on model-matching, the converter's
modulation angle is driven by the DC-side voltage measurement, while its
modulation amplitude is assigned analogously to the electrical machine's
excitation current. In this way we provide extensions to the swing-equations
model, retaining physical interpretation, and design controllers that achieve
various objectives: frequency synchronization while stabilizing an angle
configuration and a bus voltage magnitude prescribed by an optimal power flow
(OPF) set-point. We further discuss decentralization issues related to clock
drifts, loopy graphs, model reduction, energy function selection and
characterizations of operating points. Finally, a numerical evaluation is based
on experiments from three- and two-bus systems.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17314 title=Abstract>arXiv:2401.17314</a> [<a href=https://arxiv.org/pdf/2401.17314 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17314 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17314 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Labeled random finite sets vs. trajectory random finite sets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mahler%2C+R">Ronald Mahler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figur4e
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Computation (stat.CO)
</div>
<p class=mathjax>The paper [12] discussed two approaches for multitarget tracking (MTT): the
generalized labeled multi-Bernoulli (GLMB) filter and three Poisson
multi-Bernoulli mixture (PMBM) filters. The paper [13] discussed two frameworks
for multitarget trajectory representation--labeled random finite set (LRFS) and
set of trajectories (SoT)--and the merging of SoT and PMBM into trajectory PMBM
(TPMBM) theory. This paper summarizes and augments the main findings of [12],
[13]--specifcally, why SoT, PMBM, and TPMBM are physically and mathematically
erroneous.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17316 title=Abstract>arXiv:2401.17316</a> [<a href=https://arxiv.org/pdf/2401.17316 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17316 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Queueing Model for the Ambulance Ramping Problem with an Offload Zone
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zuk%2C+J">Josef Zuk</a> (Defence Science and Technology Group, Australia), 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kirszenblat%2C+D">David Kirszenblat</a> (Defence Science and Technology Group, Australia)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Probability (math.PR)
</div>
<p class=mathjax>This work develops a methodology for studying the effect of an offload zone
on the ambulance ramping problem using a multi-server, multi-class
non-preemptive priority queueing model that can be treated analytically. A
prototype model for the ambulance/emergency-department interface is
constructed, which is then implemented as a formal discrete event simulation,
and is run as a regenerative steady-state simulation for empirical estimation
of the ambulance queue-length and waiting-time distributions. The model is also
solved by analytical means for explicit and exact representations of these
distributions, which are subsequently tested against simulation results. A
number of measures of performance is extracted, including the mean and 90th
percentiles of the ambulance queue length and waiting time, as well as the
average number of ambulance days lost per month due to offload delay (offload
delay rate). Various easily computable approximations are proposed and tested.
In particular, a closed-form, purely algebraic expression that approximates the
dependence of the offload delay rate on the capacity of the offload zone is
proposed. It can be evaluated directly from model input parameters and is found
to be, for all practical purposes, indistinguishable from the exact result.
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17319 title=Abstract>arXiv:2401.17319</a> [<a href=https://arxiv.org/pdf/2401.17319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decentralized Federated Learning: A Survey on Security and Privacy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hallaji%2C+E">Ehsan Hallaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razavi-Far%2C+R">Roozbeh Razavi-Far</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saif%2C+M">Mehrdad Saif</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Boyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in IEEE Transactions on Big Data
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Federated learning has been rapidly evolving and gaining popularity in recent
years due to its privacy-preserving features, among other advantages.
Nevertheless, the exchange of model updates and gradients in this architecture
provides new attack surfaces for malicious users of the network which may
jeopardize the model performance and user and data privacy. For this reason,
one of the main motivations for decentralized federated learning is to
eliminate server-related threats by removing the server from the network and
compensating for it through technologies such as blockchain. However, this
advantage comes at the cost of challenging the system with new privacy threats.
Thus, performing a thorough security analysis in this new paradigm is
necessary. This survey studies possible variations of threats and adversaries
in decentralized federated learning and overviews the potential defense
mechanisms. Trustability and verifiability of decentralized federated learning
are also considered in this study.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17337 title=Abstract>arXiv:2401.17337</a> [<a href=https://arxiv.org/pdf/2401.17337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sharing delay costs in stochastic scheduling problems with delays
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">J.C. Gonalves-Dosantos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Jurado%2C+I">I. Garca-Jurado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+J">J. Costa</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 4OR, 2020, 18(4), 457-476
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>An important problem in project management is determining ways to distribute
amongst activities the costs that are incurred when a project is delayed
because some activities end later than expected. In this study, we address this
problem in stochastic projects, where the durations of activities are unknown
but their corresponding probability distributions are known. We propose and
characterise an allocation rule based on the Shapley value, illustrate its
behaviour by using examples, and analyse features of its calculation for large
problems.
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17338 title=Abstract>arXiv:2401.17338</a> [<a href=https://arxiv.org/pdf/2401.17338 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17338 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17338 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New results on egalitarian values for games with a priori unions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">J.C. Gonalves-Dosantos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alonso-Meijide%2C+J+M">J.M. Alonso-Meijide</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Optimization, 2023, 72(3), 861-881
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>Several extensions of the equal division value and the equal surplus division
value to the family of games with a priori unions are proposed in
Alonso-Meijide et al. (2020) ``On egalitarian values for cooperative games with
a priori unions.'' TOP 28: 672-688. In this paper we provide new axiomatic
characterizations of these values. Furthermore, using the equal surplus
division value in two steps, we propose a new coalitional value. The balanced
contributions and quotient game properties give rise to a different
modification of the equal surplus division value.
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17342 title=Abstract>arXiv:2401.17342</a> [<a href=https://arxiv.org/pdf/2401.17342 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17342 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pitsiorlas%2C+I">Ioannis Pitsiorlas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsantalidou%2C+A">Argyro Tsantalidou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arvanitakis%2C+G">George Arvanitakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kountouris%2C+M">Marios Kountouris</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kontoes%2C+C">Charalambos Kontoes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This study presents a new approach for estimating confidence in machine
learning model predictions, specifically in regression tasks utilizing Earth
Observation (EO) data, with a particular focus on mosquito abundance (MA)
estimation. We take advantage of a Variational AutoEncoder architecture, to
derive a confidence metric by the latent space representations of EO datasets.
This methodology is pivotal in establishing a correlation between the Euclidean
distance in latent representations and the Absolute Error (AE) in individual MA
predictions. Our research focuses on EO datasets from the Veneto region in
Italy and the Upper Rhine Valley in Germany, targeting areas significantly
affected by mosquito populations. A key finding is a notable correlation of
0.46 between the AE of MA predictions and the proposed confidence metric. This
correlation signifies a robust, new metric for quantifying the reliability and
enhancing the trustworthiness of the AI model's predictions in the context of
both EO data analysis and mosquito abundance studies.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17343 title=Abstract>arXiv:2401.17343</a> [<a href=https://arxiv.org/pdf/2401.17343 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17343 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> YTCommentQA: Video Question Answerability in Instructional Videos
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Saelyne Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Sunghyun Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+Y">Yunseok Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+M">Moontae Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Instructional videos provide detailed how-to guides for various tasks, with
viewers often posing questions regarding the content. Addressing these
questions is vital for comprehending the content, yet receiving immediate
answers is difficult. While numerous computational models have been developed
for Video Question Answering (Video QA) tasks, they are primarily trained on
questions generated based on video content, aiming to produce answers from
within the content. However, in real-world situations, users may pose questions
that go beyond the video's informational boundaries, highlighting the necessity
to determine if a video can provide the answer. Discerning whether a question
can be answered by video content is challenging due to the multi-modal nature
of videos, where visual and verbal information are intertwined. To bridge this
gap, we present the YTCommentQA dataset, which contains naturally-generated
questions from YouTube, categorized by their answerability and required
modality to answer -- visual, script, or both. Experiments with answerability
classification tasks demonstrate the complexity of YTCommentQA and emphasize
the need to comprehend the combined role of visual and script information in
video reasoning. The dataset is available at
https://github.com/lgresearch/YTCommentQA.
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17345 title=Abstract>arXiv:2401.17345</a> [<a href=https://arxiv.org/pdf/2401.17345 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17345 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17345 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reproducibility, energy efficiency and performance of pseudorandom number generators in machine learning: a comparative study of python, numpy, tensorflow, and pytorch implementations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antunes%2C+B">Benjamin Antunes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hill%2C+D+R+C">David R.C Hill</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 10 tables, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Pseudo-Random Number Generators (PRNGs) have become ubiquitous in machine
learning technologies because they are interesting for numerous methods. The
field of machine learning holds the potential for substantial advancements
across various domains, as exemplified by recent breakthroughs in Large
Language Models (LLMs). However, despite the growing interest, persistent
concerns include issues related to reproducibility and energy consumption.
Reproducibility is crucial for robust scientific inquiry and explainability,
while energy efficiency underscores the imperative to conserve finite global
resources. This study delves into the investigation of whether the leading
Pseudo-Random Number Generators (PRNGs) employed in machine learning languages,
libraries, and frameworks uphold statistical quality and numerical
reproducibility when compared to the original C implementation of the
respective PRNG algorithms. Additionally, we aim to evaluate the time
efficiency and energy consumption of various implementations. Our experiments
encompass Python, NumPy, TensorFlow, and PyTorch, utilizing the Mersenne
Twister, PCG, and Philox algorithms. Remarkably, we verified that the temporal
performance of machine learning technologies closely aligns with that of
C-based implementations, with instances of achieving even superior
performances. On the other hand, it is noteworthy that ML technologies consumed
only 10% more energy than their C-implementation counterparts. However, while
statistical quality was found to be comparable, achieving numerical
reproducibility across different platforms for identical seeds and algorithms
was not achieved.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17350 title=Abstract>arXiv:2401.17350</a> [<a href=https://arxiv.org/pdf/2401.17350 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17350 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Timeseries Suppliers Allocation Risk Optimization via Deep Black Litterman Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jiayuan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiaowei Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xinke Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> version 1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We introduce the BL model and the Perspective Matrix to optimize supplier
selection and order allocation, focusing on both temporal and spatial dynamics.
Our development of a Supplier Relationship Network, using a Spatio-Temporal
Graph Neural Network, enhances the understanding of complex supplier
interdependencies. Additionally, we address credibility issues in zero-order
scenarios with a Masked Ranking Mechanism, improving supplier ranking
efficiency. Our model demonstrates superior results on two datasets compared to
the traditional models. Our evaluations using real-world datasets highlight
DBLM's superiority in providing accurate predictions and precise confidence
intervals, particularly in high-resolution scenarios.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17351 title=Abstract>arXiv:2401.17351</a> [<a href=https://arxiv.org/pdf/2401.17351 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17351 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supporting Meta-model-based Language Evolution and Rapid Prototyping with Automated Grammar Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weixing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holtmann%2C+J">Jrg Holtmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Str%C3%BCber%2C+D">Daniel Strber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hebig%2C+R">Regina Hebig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stegh%C3%B6fer%2C+J">Jan-Philipp Steghfer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)
</div>
<p class=mathjax>In model-driven engineering, developing a textual domain-specific language
(DSL) involves constructing a meta-model, which defines an underlying abstract
syntax, and a grammar, which defines the concrete syntax for the DSL. Language
workbenches such as Xtext allow the grammar to be automatically generated from
the meta-model, yet the generated grammar usually needs to be manually
optimized to improve its usability. When the meta-model changes during rapid
prototyping or language evolution, it can become necessary to re-generate the
grammar and optimize it again, causing repeated effort and potential for
errors. In this paper, we present GrammarOptimizer, an approach for optimizing
generated grammars in the context of meta-model-based language evolution. To
reduce the effort for language engineers during rapid prototyping and language
evolution, it offers a catalog of configurable grammar optimization rules. Once
configured, these rules can be automatically applied and re-applied after
future evolution steps, greatly reducing redundant manual effort. In addition,
some of the supported optimizations can globally change the style of concrete
syntax elements, further significantly reducing the effort for manual
optimizations. The grammar optimization rules were extracted from a comparison
of generated and existing, expert-created grammars, based on seven available
DSLs.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17373 title=Abstract>arXiv:2401.17373</a> [<a href=https://arxiv.org/pdf/2401.17373 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17373 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17373 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for Classifying Arabic Speech Acts on Twitter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alshehri%2C+K">Khadejaa Alshehri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alhothali%2C+A">Areej Alhothali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alowidi%2C+N">Nahed Alowidi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Speech acts are a speakers actions when performing an utterance within a
conversation, such as asking, recommending, greeting, or thanking someone,
expressing a thought, or making a suggestion. Understanding speech acts helps
interpret the intended meaning and actions behind a speakers or writers words.
This paper proposes a Twitter dialectal Arabic speech act classification
approach based on a transformer deep learning neural network. Twitter and
social media, are becoming more and more integrated into daily life. As a
result, they have evolved into a vital source of information that represents
the views and attitudes of their users. We proposed a BERT based weighted
ensemble learning approach to integrate the advantages of various BERT models
in dialectal Arabic speech acts classification. We compared the proposed model
against several variants of Arabic BERT models and sequence-based models. We
developed a dialectal Arabic tweet act dataset by annotating a subset of a
large existing Arabic sentiment analysis dataset (ASAD) based on six speech act
categories. We also evaluated the models on a previously developed Arabic Tweet
Act dataset (ArSAS). To overcome the class imbalance issue commonly observed in
speech act problems, a transformer-based data augmentation model was
implemented to generate an equal proportion of speech act categories. The
results show that the best BERT model is araBERTv2-Twitter models with a
macro-averaged F1 score and an accuracy of 0.73 and 0.84, respectively. The
performance improved using a BERT-based ensemble method with a 0.74 and 0.85
averaged F1 score and accuracy on our dataset, respectively.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17377 title=Abstract>arXiv:2401.17377</a> [<a href=https://arxiv.org/pdf/2401.17377 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17377 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiacheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+S">Sewon Min</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yejin Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>Are n-gram language models still relevant in this era of neural large
language models (LLMs)? Our answer is yes, and we show their values in both
text analysis and improving neural LLMs. Yet this necessitates modernizing
n-gram models in two aspects. First, we train them at the same data scale as
neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever
built. Second, existing n-gram models use small n which hinders their
performance; we instead allow n to be arbitrarily large, by introducing a new
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-2><span class=mi id=MathJax-Span-3 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram LM with backoff. Instead of pre-computing n-gram count tables
(which would be very expensive), we develop an engine named infini-gram --
powered by suffix arrays -- that can compute <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-4 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-5><span class=mi id=MathJax-Span-6 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram (as well as n-gram
with arbitrary n) probabilities with millisecond-level latency. The
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-7 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-8><span class=mi id=MathJax-Span-9 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram framework and infini-gram engine enable us to conduct many novel
and interesting analyses of human-written and machine-generated text: we find
that the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-10 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-11><span class=mi id=MathJax-Span-12 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram LM has fairly high accuracy for next-token prediction
(47%), and can complement neural LLMs to greatly reduce their language modeling
perplexities. When analyzing machine-generated text, we also observe
irregularities in the machine--<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-13 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-14><span class=mi id=MathJax-Span-15 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-gram agreement level with respect to
the suffix length, which indicates deficiencies in neural LLM pretraining and
the positional embeddings of Transformers. We open-source our infini-gram
engine in the hopes of enabling more study on how to best use verbatim
information retrieved from large text corpora.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17390 title=Abstract>arXiv:2401.17390</a> [<a href=https://arxiv.org/pdf/2401.17390 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17390 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Customizing Language Model Responses with Contrastive In-Context Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+K">Kamalika Das</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to appear at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large language models (LLMs) are becoming increasingly important for machine
learning applications. However, it can be challenging to align LLMs with our
intent, particularly when we want to generate content that is preferable over
others or when we want the LLM to respond in a certain style or tone that is
hard to describe. To address this challenge, we propose an approach that uses
contrastive examples to better describe our intent. This involves providing
positive examples that illustrate the true intent, along with negative examples
that show what characteristics we want LLMs to avoid. The negative examples can
be retrieved from labeled data, written by a human, or generated by the LLM
itself. Before generating an answer, we ask the model to analyze the examples
to teach itself what to avoid. This reasoning step provides the model with the
appropriate articulation of the user's need and guides it towards generting a
better answer. We tested our approach on both synthesized and real-world
datasets, including StackExchange and Reddit, and found that it significantly
improves performance compared to standard few-shot prompting
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17396 title=Abstract>arXiv:2401.17396</a> [<a href=https://arxiv.org/pdf/2401.17396 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17396 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17396 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yildirim%2C+S">Savas Yildirim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Deep learning-based and lately Transformer-based language models have been
dominating the studies of natural language processing in the last years. Thanks
to their accurate and fast fine-tuning characteristics, they have outperformed
traditional machine learning-based approaches and achieved state-of-the-art
results for many challenging natural language understanding (NLU) problems.
Recent studies showed that the Transformer-based models such as BERT, which is
Bidirectional Encoder Representations from Transformers, have reached
impressive achievements on many tasks. Moreover, thanks to their transfer
learning capacity, these architectures allow us to transfer pre-built models
and fine-tune them to specific NLU tasks such as question answering. In this
study, we provide a Transformer-based model and a baseline benchmark for the
Turkish Language. We successfully fine-tuned a Turkish BERT model, namely
BERTurk that is trained with base settings, to many downstream tasks and
evaluated with a the Turkish Benchmark dataset. We showed that our studies
significantly outperformed other existing baseline approaches for Named-Entity
Recognition, Sentiment Analysis, Question Answering and Text Classification in
Turkish Language. We publicly released these four fine-tuned models and
resources in reproducibility and with the view of supporting other Turkish
researchers and applications.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17399 title=Abstract>arXiv:2401.17399</a> [<a href=https://arxiv.org/pdf/2401.17399 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17399 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ATPPNet: Attention based Temporal Point cloud Prediction Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pal%2C+K">Kaustab Pal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+A">Aditya Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+A">Avinash Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishna%2C+K+M">K. Madhava Krishna</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for presentation at the 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Point cloud prediction is an important yet challenging task in the field of
autonomous driving. The goal is to predict future point cloud sequences that
maintain object structures while accurately representing their temporal motion.
These predicted point clouds help in other subsequent tasks like object
trajectory estimation for collision avoidance or estimating locations with the
least odometry drift. In this work, we present ATPPNet, a novel architecture
that predicts future point cloud sequences given a sequence of previous time
step point clouds obtained with LiDAR sensor. ATPPNet leverages Conv-LSTM along
with channel-wise and spatial attention dually complemented by a 3D-CNN branch
for extracting an enhanced spatio-temporal context to recover high quality
fidel predictions of future point clouds. We conduct extensive experiments on
publicly available datasets and report impressive performance outperforming the
existing methods. We also conduct a thorough ablative study of the proposed
architecture and provide an application study that highlights the potential of
our model for tasks like odometry estimation.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17400 title=Abstract>arXiv:2401.17400</a> [<a href=https://arxiv.org/pdf/2401.17400 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17400 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CALM: Convolution As Local Mixture
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+L">Lifan Liang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we showed that the feature map of a convolution layer is
equivalent to the unnormalized log posterior of a special kind of Gaussian
mixture for image modeling. Then we expanded the model to drive diverse
features and proposed a corresponding EM algorithm to learn the model. Learning
convolution weights using this approach is efficient, guaranteed to converge,
and does not need supervised information. Code is available at:
https://github.com/LifanLiang/CALM.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17401 title=Abstract>arXiv:2401.17401</a> [<a href=https://arxiv.org/pdf/2401.17401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Step-size Optimization for Continual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Degris%2C+T">Thomas Degris</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Javed%2C+K">Khurram Javed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharifnassab%2C+A">Arsalan Sharifnassab</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuxin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sutton%2C+R">Richard Sutton</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In continual learning, a learner has to keep learning from the data over its
whole life time. A key issue is to decide what knowledge to keep and what
knowledge to let go. In a neural network, this can be implemented by using a
step-size vector to scale how much gradient samples change network weights.
Common algorithms, like RMSProp and Adam, use heuristics, specifically
normalization, to adapt this step-size vector. In this paper, we show that
those heuristics ignore the effect of their adaptation on the overall objective
function, for example by moving the step-size vector away from better step-size
vectors. On the other hand, stochastic meta-gradient descent algorithms, like
IDBD (Sutton, 1992), explicitly optimize the step-size vector with respect to
the overall objective function. On simple problems, we show that IDBD is able
to consistently improve step-size vectors, where RMSProp and Adam do not. We
explain the differences between the two approaches and their respective
limitations. We conclude by suggesting that combining both approaches could be
a promising future direction to improve the performance of neural networks in
continual learning.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17403 title=Abstract>arXiv:2401.17403</a> [<a href=https://arxiv.org/pdf/2401.17403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ozone: Fully Out-of-Order Choreographies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plyukhin%2C+D">Dan Plyukhin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peressotti%2C+M">Marco Peressotti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montesi%2C+F">Fabrizio Montesi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
<p class=mathjax>Choreographic programming is a paradigm for writing distributed applications.
It allows programmers to write a single program, called a choreography, that
can be compiled to generate correct implementations of each process in the
application. Although choreographies provide good static guarantees, they can
exhibit high latency when messages or processes are delayed. This is because
processes in a choreography typically execute in a fixed, deterministic order,
and cannot adapt to the order that messages arrive at runtime. In
non-choreographic code, programmers can address this problem by allowing
processes to execute out of order -- for instance by using futures or reactive
programming. However, in choreographic code, out-of-order process execution can
lead to serious and subtle bugs, called communication integrity violations
(CIVs).
<br>In this paper, we develop a model of choreographic programming for
out-of-order processes that guarantees absence of CIVs and deadlocks. As an
application of our approach, we also introduce an API for safe non-blocking
communication via futures in the choreographic programming language Choral. The
API allows processes to execute out of order, participate in multiple
choreographies concurrently, and to handle unordered or dropped messages as in
the UDP transport protocol. We provide an illustrative evaluation of our API,
showing that out-of-order execution can reduce latency by overlapping
communication with computation.
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17404 title=Abstract>arXiv:2401.17404</a> [<a href=https://arxiv.org/pdf/2401.17404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ROAMER: Robust Offroad Autonomy using Multimodal State Estimation with Radar Velocity Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nissov%2C+M">Morten Nissov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khattak%2C+S">Shehryar Khattak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edlund%2C+J+A">Jeffrey A. Edlund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padgett%2C+C">Curtis Padgett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexis%2C+K">Kostas Alexis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spieler%2C+P">Patrick Spieler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Reliable offroad autonomy requires low-latency, high-accuracy state estimates
of pose as well as velocity, which remain viable throughout environments with
sub-optimal operating conditions for the utilized perception modalities. As
state estimation remains a single point of failure system in the majority of
aspiring autonomous systems, failing to address the environmental degradation
the perception sensors could potentially experience given the operating
conditions, can be a mission-critical shortcoming. In this work, a method for
integration of radar velocity information in a LiDAR-inertial odometry solution
is proposed, enabling consistent estimation performance even with degraded
LiDAR-inertial odometry. The proposed method utilizes the direct
velocity-measuring capabilities of an Frequency Modulated Continuous Wave
(FMCW) radar sensor to enhance the LiDAR-inertial smoother solution onboard the
vehicle through integration of the forward velocity measurement into the
graph-based smoother. This leads to increased robustness in the overall
estimation solution, even in the absence of LiDAR data. This method was
validated by hardware experiments conducted onboard an all-terrain vehicle
traveling at high speed, ~12 m/s, in demanding offroad environments.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17405 title=Abstract>arXiv:2401.17405</a> [<a href=https://arxiv.org/pdf/2401.17405 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17405 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Camouflage Adversarial Attacks on Multiple Agent Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Ziqing Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+G">Guanlin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+L">Lifeng Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiyu Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.00859>arXiv:2311.00859</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>
</div>
<p class=mathjax>The multi-agent reinforcement learning systems (MARL) based on the Markov
decision process (MDP) have emerged in many critical applications. To improve
the robustness/defense of MARL systems against adversarial attacks, the study
of various adversarial attacks on reinforcement learning systems is very
important. Previous works on adversarial attacks considered some possible
features to attack in MDP, such as the action poisoning attacks, the reward
poisoning attacks, and the state perception attacks. In this paper, we propose
a brand-new form of attack called the camouflage attack in the MARL systems. In
the camouflage attack, the attackers change the appearances of some objects
without changing the actual objects themselves; and the camouflaged appearances
may look the same to all the targeted recipient (victim) agents. The
camouflaged appearances can mislead the recipient agents to misguided actions.
We design algorithms that give the optimal camouflage attacks minimizing the
rewards of recipient agents. Our numerical and theoretical results show that
camouflage attacks can rival the more conventional, but likely more difficult
state perception attacks. We also investigate cost-constrained camouflage
attacks and showed numerically how cost budgets affect the attack performance.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17408 title=Abstract>arXiv:2401.17408</a> [<a href=https://arxiv.org/pdf/2401.17408 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17408 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving Boltzmann Optimization Problems with Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knoll%2C+F">Fiona Knoll</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daly%2C+J+T">John T. Daly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meyer%2C+J+J">Jess J. Meyer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Emerging Technologies (cs.ET); Optimization and Control (math.OC)
</div>
<p class=mathjax>Decades of exponential scaling in high performance computing (HPC) efficiency
is coming to an end. Transistor based logic in complementary metal-oxide
semiconductor (CMOS) technology is approaching physical limits beyond which
further miniaturization will be impossible. Future HPC efficiency gains will
necessarily rely on new technologies and paradigms of compute. The Ising model
shows particular promise as a future framework for highly energy efficient
computation. Ising systems are able to operate at energies approaching
thermodynamic limits for energy consumption of computation. Ising systems can
function as both logic and memory. Thus, they have the potential to
significantly reduce energy costs inherent to CMOS computing by eliminating
costly data movement. The challenge in creating Ising-based hardware is in
optimizing useful circuits that produce correct results on fundamentally
nondeterministic hardware. The contribution of this paper is a novel machine
learning approach, a combination of deep neural networks and random forests,
for efficiently solving optimization problems that minimize sources of error in
the Ising model. In addition, we provide a process to express a Boltzmann
probability optimization problem as a supervised machine learning problem.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17409 title=Abstract>arXiv:2401.17409</a> [<a href=https://arxiv.org/pdf/2401.17409 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17409 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+C">Chi-Jung Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruidong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal%2C+D">Devansh Agarwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+T+C">Tianhong Catherine Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gunda%2C+V">Vipin Gunda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lopez%2C+O">Oliver Lopez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">James Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+S">Sicheng Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+B">Boao Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Ke Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sakashita%2C+M">Mose Sakashita</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guimbretiere%2C+F">Francois Guimbretiere</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cheng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Our hands serve as a fundamental means of interaction with the world around
us. Therefore, understanding hand poses and interaction context is critical for
human-computer interaction. We present EchoWrist, a low-power wristband that
continuously estimates 3D hand pose and recognizes hand-object interactions
using active acoustic sensing. EchoWrist is equipped with two speakers emitting
inaudible sound waves toward the hand. These sound waves interact with the hand
and its surroundings through reflections and diffractions, carrying rich
information about the hand's shape and the objects it interacts with. The
information captured by the two microphones goes through a deep learning
inference system that recovers hand poses and identifies various everyday hand
activities. Results from the two 12-participant user studies show that
EchoWrist is effective and efficient at tracking 3D hand poses and recognizing
hand-object interactions. Operating at 57.9mW, EchoWrist is able to
continuously reconstruct 20 3D hand joints with MJEDE of 4.81mm and recognize
12 naturalistic hand-object interactions with 97.6% accuracy.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17417 title=Abstract>arXiv:2401.17417</a> [<a href=https://arxiv.org/pdf/2401.17417 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17417 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Through-Wall Imaging based on WiFi Channel State Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strohmayer%2C+J">Julian Strohmayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sterzinger%2C+R">Rafael Sterzinger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stippel%2C+C">Christian Stippel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kampel%2C+M">Martin Kampel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This work presents a seminal approach for synthesizing images from WiFi
Channel State Information (CSI) in through-wall scenarios. Leveraging the
strengths of WiFi, such as cost-effectiveness, illumination invariance, and
wall-penetrating capabilities, our approach enables visual monitoring of indoor
environments beyond room boundaries and without the need for cameras. More
generally, it improves the interpretability of WiFi CSI by unlocking the option
to perform image-based downstream tasks, e.g., visual activity recognition. In
order to achieve this crossmodal translation from WiFi CSI to images, we rely
on a multimodal Variational Autoencoder (VAE) adapted to our problem specifics.
We extensively evaluate our proposed methodology through an ablation study on
architecture configuration and a quantitative/qualitative assessment of
reconstructed images. Our results demonstrate the viability of our method and
highlight its potential for practical applications.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17418 title=Abstract>arXiv:2401.17418</a> [<a href=https://arxiv.org/pdf/2401.17418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Model Predictive Control for Acrobatic Quadrotor Flights
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+S">Saransh Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shethwala%2C+Y">Yash Shethwala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+J">Jnaneshwar Das</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This study explores modeling and control for quadrotor acrobatics, focusing
on executing flip maneuvers. Flips are an elegant way to deliver sensor probes
into no-fly or hazardous zones, like volcanic vents. Successful flips require
feasible trajectories and precise control, influenced by rotor dynamics, thrust
allocation, and control methodologies. The research introduces a novel approach
using Model Predictive Control (MPC) for real-time trajectory planning. The MPC
considers dynamic constraints and environmental variables, ensuring system
stability during maneuvers. The proposed methodology's effectiveness is
examined through simulation studies in ROS and Gazebo, providing insights into
quadrotor behavior, response time, and trajectory accuracy. Real-time flight
experiments on a custom agile quadrotor using PixHawk 4 and Hardkernel Odroid
validate MPC-designed controllers. Experiments confirm successful execution and
adaptability to real-world scenarios. Outcomes contribute to autonomous aerial
robotics, especially aerial acrobatics, enhancing mission capabilities. MPC
controllers find applications in probe throws and optimal image capture views
through efficient flight paths, e.g., full roll maneuvers. This research paves
the way for quadrotors in demanding scenarios, showcasing groundbreaking
applications. Video Link: \url{ https://www.youtube.com/watch?v=UzR0PWjy9W4}
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17419 title=Abstract>arXiv:2401.17419</a> [<a href=https://arxiv.org/pdf/2401.17419 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17419 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Few-Shot Channel-Agnostic Analog Coding: A Near-Optimal Scheme
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maddah-Ali%2C+M+A">Mohammad Ali Maddah-Ali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohajer%2C+S">Soheil Mohajer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we investigate the problem of transmitting an analog source to
a destination over <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-16 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-17><span class=mi id=MathJax-Span-18 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> uses of an additive-white-Gaussian-noise (AWGN) channel,
where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-19 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-20><span class=mi id=MathJax-Span-21 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is very small (in the order of 10 or even less). The proposed coding
scheme is based on representing the source symbol using a novel progressive
expansion technique, partitioning the digits of expansion into <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-22 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-23><span class=mi id=MathJax-Span-24 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> ordered
sets, and finally mapping the symbols in each set to a real number by applying
the reverse progressive expansion. In the last step, we introduce some gaps
between the signal levels to prevent the carry-over of the additive noise from
propagation to other levels. This shields the most significant levels of the
signal from an additive noise, hitting the signal at a less significant level.
The parameters of the progressive expansion and the shielding procedure are
opportunistically independent of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><span class=math id=MathJax-Span-25><span class=noError id=MathJax-Span-26>$\SNR$</span></span></span> so that the proposed scheme
achieves a distortion <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-27 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-28><span class=mi id=MathJax-Span-29 style=font-family:MathJax_Math-italic>D</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-30 style=width:4.633em;display:inline-block><span style=display:inline-block;position:relative;width:3.822em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.71em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-31><span class=mo id=MathJax-Span-32 style=font-family:MathJax_Main></span><span class=mi id=MathJax-Span-33 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-34></span><span class=mo id=MathJax-Span-35 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-36 style=font-family:MathJax_Math-italic>D</span><span class=mo id=MathJax-Span-37 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is within <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><span class=math id=MathJax-Span-38><span class=noError id=MathJax-Span-39>$O(\log\log(\SNR))$</span></span></span> of
the optimal performance for all values of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><span class=math id=MathJax-Span-40><span class=noError id=MathJax-Span-41>$\SNR$</span></span></span>, leading to a channel-agnostic
scheme.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17426 title=Abstract>arXiv:2401.17426</a> [<a href=https://arxiv.org/pdf/2401.17426 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17426 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Superiority of Multi-Head Attention in In-Context Linear Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yingqian Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+J">Jie Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+P">Pengfei He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiliang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Y">Yue Xing</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>We present a theoretical analysis of the performance of transformer with
softmax attention in in-context learning with linear regression tasks. While
the existing literature predominantly focuses on the convergence of
transformers with single-/multi-head attention, our research centers on
comparing their performance. We conduct an exact theoretical analysis to
demonstrate that multi-head attention with a substantial embedding dimension
performs better than single-head attention. When the number of in-context
examples D increases, the prediction loss using single-/multi-head attention is
in O(1/D), and the one for multi-head attention has a smaller multiplicative
constant. In addition to the simplest data distribution setting, we consider
more scenarios, e.g., noisy labels, local examples, correlated features, and
prior knowledge. We observe that, in general, multi-head attention is preferred
over single-head attention. Our results verify the effectiveness of the design
of multi-head attention in the transformer architecture.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17428 title=Abstract>arXiv:2401.17428</a> [<a href=https://arxiv.org/pdf/2401.17428 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17428 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Metaverse Perspectives from Japan: A Participatory Speculative Design Case Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hohendanner%2C+M">Michel Hohendanner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ullstein%2C+C">Chiara Ullstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miyamoto%2C+D">Dohjin Miyamoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huffman%2C+E+F">Emma Fukuwatari Huffman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Socher%2C+G">Gudrun Socher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossklags%2C+J">Jens Grossklags</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Osawa%2C+H">Hirotaka Osawa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Currently, the development of the metaverse lies in the hands of industry.
Citizens have little influence on this process. Instead, to do justice to the
pluralism of (digital) societies, we should strive for an open discourse
including many different perspectives on the metaverse and its core
technologies such as AI. We utilize a participatory speculative design (PSD)
approach to explore Japanese citizens' perspectives on future metaverse
societies, as well as social and ethical implications. Our contributions are
twofold. Firstly, we demonstrate the effectiveness of PSD in engaging citizens
in critical discourse on emerging technologies like the metaverse, offering our
workshop framework as a methodological contribution. Secondly, we identify key
themes from participants' perspectives, providing insights for culturally
sensitive design and development of virtual environments. Our analysis shows
that participants imagine the metaverse to have the potential to solve a
variety of societal issues; for example, breaking down barriers of physical
environments for communication, social interaction, crisis preparation, and
political participation, or tackling identity-related issues. Regarding future
metaverse societies, participants' imaginations raise critical questions about
human-AI relations, technical solutionism, politics and technology,
globalization and local cultures, and immersive technologies. We discuss
implications and contribute to expanding conversations on metaverse
developments.
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17432 title=Abstract>arXiv:2401.17432</a> [<a href=https://arxiv.org/pdf/2401.17432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decapodes: A Diagrammatic Tool for Representing, Composing, and Computing Spatialized Partial Differential Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Morris%2C+L">Luke Morris</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Baas%2C+A">Andrew Baas</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Arias%2C+J">Jesus Arias</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gatlin%2C+M">Maia Gatlin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Patterson%2C+E">Evan Patterson</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fairbanks%2C+J+P">James P. Fairbanks</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present Decapodes, a diagrammatic tool for representing, composing, and
solving partial differential equations. Decapodes provides an intuitive
diagrammatic representation of the relationships between variables in a system
of equations, a method for composing systems of partial differential equations
using an operad of wiring diagrams, and an algorithm for deriving solvers using
hypergraphs and string diagrams. The string diagrams are in turn compiled into
executable programs using the techniques of categorical data migration, graph
traversal, and the discrete exterior calculus. The generated solvers produce
numerical solutions consistent with state-of-the-art open source tools as
demonstrated by benchmark comparisons with SU2. These numerical experiments
demonstrate the feasibility of this approach to multiphysics simulation and
identify areas requiring further development.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17434 title=Abstract>arXiv:2401.17434</a> [<a href=https://arxiv.org/pdf/2401.17434 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17434 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17434 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sajja%2C+R">Ramteja Sajja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erazo%2C+C">Carlos Erazo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhouyayan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demiray%2C+B+Z">Bekir Z. Demiray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sermet%2C+Y">Yusuf Sermet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Demir%2C+I">Ibrahim Demir</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8491 words, 23 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Hackathons and software competitions, increasingly pivotal in the software
industry, serve as vital catalysts for innovation and skill development for
both organizations and students. These platforms enable companies to prototype
ideas swiftly, while students gain enriched learning experiences, enhancing
their practical skills. Over the years, hackathons have transitioned from mere
competitive events to significant educational tools, fusing theoretical
knowledge with real-world problem-solving. The integration of hackathons into
computer science and software engineering curricula aims to align educational
proficiencies within a collaborative context, promoting peer connectivity and
enriched learning via industry-academia collaborations. However, the infusion
of advanced technologies, notably artificial intelligence (AI), and machine
learning, into hackathons is revolutionizing their structure and outcomes. This
evolution brings forth both opportunities, like enhanced learning experiences,
and challenges, such as ethical concerns. This study delves into the impact of
generative AI, examining its influence on student's technological choices based
on a case study on the University of Iowa 2023 event. The exploration provides
insights into AI's role in hackathons, and its educational implications, and
offers a roadmap for the integration of such technologies in future events,
ensuring innovation is balanced with ethical and educational considerations.
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17435 title=Abstract>arXiv:2401.17435</a> [<a href=https://arxiv.org/pdf/2401.17435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Large Language Models Replace Economic Choice Prediction Labs?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shapira%2C+E">Eilam Shapira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madmon%2C+O">Omer Madmon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reichart%2C+R">Roi Reichart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Economic choice prediction is an essential challenging task, often
constrained by the difficulties in acquiring human choice data. Indeed,
experimental economics studies had focused mostly on simple choice settings.
The AI community has recently contributed to that effort in two ways:
considering whether LLMs can substitute for humans in the above-mentioned
simple choice prediction settings, and the study through ML lens of more
elaborated but still rigorous experimental economics settings, employing
incomplete information, repetitive play, and natural language communication,
notably language-based persuasion games. This leaves us with a major
inspiration: can LLMs be used to fully simulate the economic environment and
generate data for efficient human choice prediction, substituting for the
elaborated economic lab studies? We pioneer the study of this subject,
demonstrating its feasibility. In particular, we show that a model trained
solely on LLM-generated data can effectively predict human behavior in a
language-based persuasion game, and can even outperform models trained on
actual human data.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17436 title=Abstract>arXiv:2401.17436</a> [<a href=https://arxiv.org/pdf/2401.17436 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17436 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Difficulty Modelling in Mobile Puzzle Games: An Empirical Study on Different Methods to Combine Player Analytics and Simulated Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kristensen%2C+J+T">Jeppe Theiss Kristensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burelli%2C+P">Paolo Burelli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Difficulty is one of the key drivers of player engagement and it is often one
of the aspects that designers tweak most to optimise the player experience;
operationalising it is, therefore, a crucial task for game development studios.
A common practice consists of creating metrics out of data collected by player
interactions with the content; however, this allows for estimation only after
the content is released and does not consider the characteristics of potential
future players.
<br>In this article, we present a number of potential solutions for the
estimation of difficulty under such conditions, and we showcase the results of
a comparative study intended to understand which method and which types of data
perform better in different scenarios.
<br>The results reveal that models trained on a combination of cohort statistics
and simulated data produce the most accurate estimations of difficulty in all
scenarios. Furthermore, among these models, artificial neural networks show the
most consistent results.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17441 title=Abstract>arXiv:2401.17441</a> [<a href=https://arxiv.org/pdf/2401.17441 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17441 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explaining Predictive Uncertainty by Exposing Second-Order Effects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bley%2C+F">Florian Bley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samek%2C+W">Wojciech Samek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montavon%2C+G">Grgoire Montavon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages + supplement
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Explainable AI has brought transparency into complex ML blackboxes, enabling,
in particular, to identify which features these models use for their
predictions. So far, the question of explaining predictive uncertainty, i.e.
why a model 'doubts', has been scarcely studied. Our investigation reveals that
predictive uncertainty is dominated by second-order effects, involving single
features or product interactions between them. We contribute a new method for
explaining predictive uncertainty based on these second-order effects.
Computationally, our method reduces to a simple covariance computation over a
collection of first-order explanations. Our method is generally applicable,
allowing for turning common attribution techniques (LRP, Gradient x Input,
etc.) into powerful second-order uncertainty explainers, which we call CovLRP,
CovGI, etc. The accuracy of the explanations our method produces is
demonstrated through systematic quantitative evaluations, and the overall
usefulness of our method is demonstrated via two practical showcases.
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17443 title=Abstract>arXiv:2401.17443</a> [<a href=https://arxiv.org/pdf/2401.17443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Liquid Democracy for Low-Cost Ensemble Pruning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Armstrong%2C+B">Ben Armstrong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larson%2C+K">Kate Larson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 20 figures. Extended abstract to appear at AAMAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>We argue that there is a strong connection between ensemble learning and a
delegative voting paradigm -- liquid democracy -- that can be leveraged to
reduce ensemble training costs. We present an incremental training procedure
that identifies and removes redundant classifiers from an ensemble via
delegation mechanisms inspired by liquid democracy. Through both analysis and
extensive experiments we show that this process greatly reduces the
computational cost of training compared to training a full ensemble. By
carefully selecting the underlying delegation mechanism, weight centralization
in the classifier population is avoided, leading to higher accuracy than some
boosting methods. Furthermore, this work serves as an exemplar of how
frameworks from computational social choice literature can be applied to
problems in nontraditional domains.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17444 title=Abstract>arXiv:2401.17444</a> [<a href=https://arxiv.org/pdf/2401.17444 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17444 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17444 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Languages of Higher-Dimensional Timed Automata
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amrane%2C+A">Amazigh Amrane</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bazille%2C+H">Hugo Bazille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clement%2C+E">Emily Clement</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fahrenberg%2C+U">Uli Fahrenberg</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>We present a new language semantics for real-time concurrency. Its
operational models are higher-dimensional timed automata (HDTAs), a
generalization of both higher-dimensional automata and timed automata. We
define languages of HDTAs as sets of interval-timed pomsets with interfaces. As
an application, we show that language inclusion of HDTAs is undecidable. On the
other hand, using a region construction we can show that untimings of HDTA
languages have enough regularity so that untimed language inclusion is
decidable.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17451 title=Abstract>arXiv:2401.17451</a> [<a href=https://arxiv.org/pdf/2401.17451 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17451 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> URLLC-Aware Proactive UAV Placement in Internet of Vehicles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chen-Feng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wickramasinghe%2C+N+D">Nirmal D. Wickramasinghe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suraweera%2C+H+A">Himal A. Suraweera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bennis%2C+M">Mehdi Bennis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in the IEEE Transactions on Intelligent Transportation Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Unmanned aerial vehicles (UAVs) are envisioned to provide diverse services
from the air. The service quality may rely on the wireless performance which is
affected by the UAV's position. In this paper, we focus on the UAV placement
problem in the Internet of Vehicles, where the UAV is deployed to monitor the
road traffic and sends the monitored videos to vehicles. The studied problem is
formulated as video resolution maximization by optimizing over the UAV's
position. Moreover, we take into account the maximal transmission delay and
impose a probabilistic constraint. To solve the formulated problem, we first
leverage the techniques in extreme value theory (EVT) and Gaussian process
regression (GPR) to characterize the influence of the UAV's position on the
delay performance. Based on this characterization, we subsequently propose a
proactive resolution selection and UAV placement approach, which adaptively
places the UAV according to the geographic distribution of vehicles. Numerical
results justify the joint usage of EVT and GPR for maximal delay
characterization. Through investigating the maximal transmission delay, the
proposed approach nearly achieves the optimal performance when vehicles are
evenly distributed, and reduces 10% and 19% of the 999-th 1000-quantile over
two baselines when vehicles are biased distributed.
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17457 title=Abstract>arXiv:2401.17457</a> [<a href=https://arxiv.org/pdf/2401.17457 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17457 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Socially Aware V2X Localized QoS
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaliski%2C+R">Rafael Kaliski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yue-hua Han</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Under review by IEEE Internet of Things journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Vehicle-to-everything (V2X) is a core 5G technology. V2X and its enabler,
Device-to-Device (D2D), are essential for the Internet of Things (IoT) and the
Internet of Vehicles (IoV). V2X enables vehicles to communicate with other
vehicles (V2V), networks (V2N), and infrastructure (V2I). While V2X enables
ubiquitous vehicular connectivity, the impact of bursty data on the network's
overall Quality of Service (QoS), such as when a vehicle accident occurs, is
often ignored. In this work, we study both 4G and 5G V2X utilizing Evolved
Universal Terrestrial Radio Access New Radio (E-UTRA-NR) and propose the use of
socially aware 5G NR Dual Connectivity (en-DC) for traffic differentiation. We
also propose localized QoS, wherein high-priority QoS flows traverse 5G road
side units (RSUs) and normal-priority QoS flows traverse 4G Base Station (BS).
<br>We formulate a max-min fair QoS-aware Non-Orthogonal Multiple Access (NOMA)
resource allocation scheme, QoS reclassify. QoS reclassify enables localized
QoS and traffic steering to mitigate bursty network traffic's impact on the
network's overall QoS. We then solve QoS reclassify via Integer Linear
Programming (ILP) and derive its approximation. We demonstrate that both
optimal and approximation QoS reclassify resource allocation schemes in our
socially aware QoS management methodology outperform socially unaware legacy 4G
V2X algorithms (no localized QoS support, no traffic steering) and socially
aware 5G V2X (no localized QoS support, yet utilizes traffic steering). Our
proposed QoS reclassify scheme's QoS flow end-to-end latency requires only
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-42 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.13em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-43><span class=mo id=MathJax-Span-44 style=font-family:MathJax_Main></span><span class=mtext id=MathJax-Span-45 style=font-family:MathJax_Main;padding-left:0.292em>&nbsp;</span><span class=mn id=MathJax-Span-46 style=font-family:MathJax_Main>15</span><span class=mi id=MathJax-Span-47 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of the time legacy 4G V2X requires.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17459 title=Abstract>arXiv:2401.17459</a> [<a href=https://arxiv.org/pdf/2401.17459 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17459 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17459 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Preliminary Study on Using Large Language Models in Software Pentesting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shashwat%2C+K">Kumar Shashwat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hahn%2C+F">Francis Hahn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+X">Xinming Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldgof%2C+D">Dmitry Goldgof</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hall%2C+L">Lawrence Hall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ligatti%2C+J">Jay Ligatti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajgopalan%2C+S+R">S. Raj Rajgopalan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabari%2C+A+Z">Armin Ziaie Tabari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large language models (LLM) are perceived to offer promising potentials for
automating security tasks, such as those found in security operation centers
(SOCs). As a first step towards evaluating this perceived potential, we
investigate the use of LLMs in software pentesting, where the main task is to
automatically identify software security vulnerabilities in source code. We
hypothesize that an LLM-based AI agent can be improved over time for a specific
security task as human operators interact with it. Such improvement can be
made, as a first step, by engineering prompts fed to the LLM based on the
responses produced, to include relevant contexts and structures so that the
model provides more accurate results. Such engineering efforts become
sustainable if the prompts that are engineered to produce better results on
current tasks, also produce better results on future unknown tasks. To examine
this hypothesis, we utilize the OWASP Benchmark Project 1.2 which contains
2,740 hand-crafted source code test cases containing various types of
vulnerabilities. We divide the test cases into training and testing data, where
we engineer the prompts based on the training data (only), and evaluate the
final system on the testing data. We compare the AI agent's performance on the
testing data against the performance of the agent without the prompt
engineering. We also compare the AI agent's results against those from
SonarQube, a widely used static code analyzer for security testing. We built
and tested multiple versions of the AI agent using different off-the-shelf LLMs
-- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with
both chat completion and assistant APIs). The results show that using LLMs is a
viable approach to build an AI agent for software pentesting that can improve
through repeated use and prompt engineering.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17460 title=Abstract>arXiv:2401.17460</a> [<a href=https://arxiv.org/pdf/2401.17460 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17460 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rendering Wireless Environments Useful for Gradient Estimators: A Zero-Order Stochastic Federated Learning Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mhanna%2C+E">Elissa Mhanna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Assaad%2C+M">Mohamad Assaad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Optimization and Control (math.OC)
</div>
<p class=mathjax>Federated learning (FL) is a novel approach to machine learning that allows
multiple edge devices to collaboratively train a model without disclosing their
raw data. However, several challenges hinder the practical implementation of
this approach, especially when devices and the server communicate over wireless
channels, as it suffers from communication and computation bottlenecks in this
case. By utilizing a communication-efficient framework, we propose a novel
zero-order (ZO) method with a one-point gradient estimator that harnesses the
nature of the wireless communication channel without requiring the knowledge of
the channel state coefficient. It is the first method that includes the
wireless channel in the learning algorithm itself instead of wasting resources
to analyze it and remove its impact. The two main difficulties of this work are
that in FL, the objective function is usually not convex, which makes the
extension of FL to ZO methods challenging, and that including the impact of
wireless channels requires extra attention. However, we overcome these
difficulties and comprehensively analyze the proposed zero-order federated
learning (ZOFL) framework. We establish its convergence theoretically, and we
prove a convergence rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-48 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.01em,3.07em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-49><span class=mi id=MathJax-Span-50 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-51 style=font-family:MathJax_Main>(</span><span class=mfrac id=MathJax-Span-52><span style=display:inline-block;position:relative;width:1.334em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-53 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.186em,1001.22em,4.285em,-999.997em);top:-3.411em;left:50%;margin-left:-0.634em><span class=mroot id=MathJax-Span-54><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0.582em><span class=mi id=MathJax-Span-55 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.987em,1000.64em,1.334em,-999.997em);top:-1.733em;left:0.582em><span style="display:inline-block;overflow:hidden;vertical-align:-0.055em;border-top:1.3px solid;width:0.639em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span><span style=position:absolute;clip:rect(3.244em,1000.58em,4.285em,-999.997em);top:-3.99em;left:0em><span><span style=font-size:70.7%;font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-4.337em;left:0.177em><span class=mn id=MathJax-Span-56 style=font-size:50%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.33em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.334em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-57 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.899em;border-left:0px solid;width:0px;height:2.087em"></span></span></nobr></span> in the nonconvex
setting. We further demonstrate the potential of our algorithm with
experimental results, taking into account independent and identically
distributed (IID) and non-IID device data distributions.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17461 title=Abstract>arXiv:2401.17461</a> [<a href=https://arxiv.org/pdf/2401.17461 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17461 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Synthetic Dialogue Dataset Generation using LLM Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdullin%2C+Y">Yelaman Abdullin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molla-Aliod%2C+D">Diego Molla-Aliod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ofoghi%2C+B">Bahadorreza Ofoghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yearwood%2C+J">John Yearwood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qingyang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> GEM Workshop @ EMNLP 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Linear programming (LP) problems are pervasive in real-life applications.
However, despite their apparent simplicity, an untrained user may find it
difficult to determine the linear model of their specific problem. We envisage
the creation of a goal-oriented conversational agent that will engage in
conversation with the user to elicit all information required so that a
subsequent agent can generate the linear model. In this paper, we present an
approach for the generation of sample dialogues that can be used to develop and
train such a conversational agent. Using prompt engineering, we develop two
agents that "talk" to each other, one acting as the conversational agent, and
the other acting as the user. Using a set of text descriptions of linear
problems from NL4Opt available to the user only, the agent and the user engage
in conversation until the agent has retrieved all key information from the
original problem description. We also propose an extrinsic evaluation of the
dialogues by assessing how well the summaries generated by the dialogues match
the original problem descriptions. We conduct human and automatic evaluations,
including an evaluation approach that uses GPT-4 to mimic the human evaluation
metrics. The evaluation results show an overall good quality of the dialogues,
though research is still needed to improve the quality of the GPT-4 evaluation
metrics. The resulting dialogues, including the human annotations of a subset,
are available to the research community. The conversational agent used for the
generation of the dialogues can be used as a baseline.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17463 title=Abstract>arXiv:2401.17463</a> [<a href=https://arxiv.org/pdf/2401.17463 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17463 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Group Theoretic Metric for Robot State Estimation Leveraging Chebyshev Interpolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawal%2C+V">Varun Agrawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dellaert%2C+F">Frank Dellaert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>We propose a new metric for robot state estimation based on the recently
introduced <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-58 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-59><span class=msubsup id=MathJax-Span-60><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.22em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mtext id=MathJax-Span-61 style=font-family:MathJax_Main>SE</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:1.218em><span class=mn id=MathJax-Span-62 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-63 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-64 style=font-family:MathJax_Main>3</span><span class=mo id=MathJax-Span-65 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> Lie group definition. Our metric is related to
prior metrics for SLAM but explicitly takes into account the linear velocity of
the state estimate, improving over current pose-based trajectory analysis. This
has the benefit of providing a single, quantitative metric to evaluate state
estimation algorithms against, while being compatible with existing tools and
libraries. Since ground truth data generally consists of pose data from motion
capture systems, we also propose an approach to compute the ground truth linear
velocity based on polynomial interpolation. Using Chebyshev interpolation and a
pseudospectral parameterization, we can accurately estimate the ground truth
linear velocity of the trajectory in an optimal fashion with best approximation
error. We demonstrate how this approach performs on multiple robotic platforms
where accurate state estimation is vital, and compare it to alternative
approaches such as finite differences. The pseudospectral parameterization also
provides a means of trajectory data compression as an additional benefit.
Experimental results show our method provides a valid and accurate means of
comparing state estimation systems, which is also easy to interpret and report.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17464 title=Abstract>arXiv:2401.17464</a> [<a href=https://arxiv.org/pdf/2401.17464 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17464 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Tool Use with Chain-of-Abstraction Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Silin Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dwivedi-Yu%2C+J">Jane Dwivedi-Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+P">Ping Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+X+E">Xiaoqing Ellen Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasunuru%2C+R">Ramakanth Pasunuru</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golovneva%2C+O">Olga Golovneva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+K">Koustuv Sinha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosselut%2C+A">Antoine Bosselut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianlu Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>To achieve faithful reasoning that aligns with human expectations, large
language models (LLMs) need to ground their reasoning to real-world knowledge
(e.g., web facts, math and physical rules). Tools help LLMs access this
external knowledge, but there remains challenges for fine-tuning LLM agents
(e.g., Toolformer) to invoke tools in multi-step reasoning problems, where
inter-connected tool calls require holistic and efficient tool usage planning.
<br>In this work, we propose a new method for LLMs to better leverage tools in
multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to
first decode reasoning chains with abstract placeholders, and then call domain
tools to reify each reasoning chain by filling in specific knowledge. This
planning with abstract chains enables LLMs to learn more general reasoning
strategies, which are robust to shifts of domain knowledge (e.g., math results)
relevant to different reasoning questions. It also allows LLMs to perform
decoding and calling of external tools in parallel, which avoids the inference
delay caused by waiting for tool responses. In mathematical reasoning and Wiki
QA domains, we show that our method consistently outperforms previous
chain-of-thought and tool-augmented baselines on both in-distribution and
out-of-distribution test sets, with an average ~6% absolute QA accuracy
improvement. LLM agents trained with our method also show more efficient tool
use, with inference speed being on average ~1.4x faster than baseline
tool-augmented LLMs.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17474 title=Abstract>arXiv:2401.17474</a> [<a href=https://arxiv.org/pdf/2401.17474 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17474 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parallelization Strategies for the Randomized Kaczmarz Algorithm on Large-Scale Dense Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+I">Ins Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acebr%C3%B3n%2C+J+A">Juan A. Acebrn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monteiro%2C+J">Jos Monteiro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>The Kaczmarz algorithm is an iterative technique designed to solve consistent
linear systems of equations. It falls within the category of row-action
methods, focusing on handling one equation per iteration. This characteristic
makes it especially useful in solving very large systems. The recent
introduction of a randomized version, the Randomized Kaczmarz method, renewed
interest in the algorithm, leading to the development of numerous variations.
Subsequently, parallel implementations for both the original and Randomized
Kaczmarz method have since then been proposed. However, previous work has
addressed sparse linear systems, whereas we focus on solving dense systems. In
this paper, we explore in detail approaches to parallelizing the Kaczmarz
method for both shared and distributed memory for large dense systems. In
particular, we implemented the Randomized Kaczmarz with Averaging (RKA) method
that, for inconsistent systems, unlike the standard Randomized Kaczmarz
algorithm, reduces the final error of the solution. While efficient
parallelization of this algorithm is not achievable, we introduce a block
version of the averaging method that can outperform the RKA method.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17477 title=Abstract>arXiv:2401.17477</a> [<a href=https://arxiv.org/pdf/2401.17477 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17477 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17477 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting mental disorder on social media: a ChatGPT-augmented explainable approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belcastro%2C+L">Loris Belcastro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cantini%2C+R">Riccardo Cantini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marozzo%2C+F">Fabrizio Marozzo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talia%2C+D">Domenico Talia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trunfio%2C+P">Paolo Trunfio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>In the digital era, the prevalence of depressive symptoms expressed on social
media has raised serious concerns, necessitating advanced methodologies for
timely detection. This paper addresses the challenge of interpretable
depression detection by proposing a novel methodology that effectively combines
Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and
conversational agents like ChatGPT. In our methodology, explanations are
achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a
novel self-explanatory model, namely BERT-XDD, capable of providing both
classification and explanations via masked attention. The interpretability is
further enhanced using ChatGPT to transform technical explanations into
human-readable commentaries. By introducing an effective and modular approach
for interpretable depression detection, our methodology can contribute to the
development of socially responsible digital platforms, fostering early
intervention and support for mental health challenges under the guidance of
qualified healthcare professionals.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17480 title=Abstract>arXiv:2401.17480</a> [<a href=https://arxiv.org/pdf/2401.17480 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17480 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Colony-Enhanced Recurrent Neural Architecture Search: Collaborative Ant-Based Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elsaid%2C+A">Abdelrahman Elsaid</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>Crafting neural network architectures manually is a formidable challenge
often leading to suboptimal and inefficient structures. The pursuit of the
perfect neural configuration is a complex task, prompting the need for a
metaheuristic approach such as Neural Architecture Search (NAS). Drawing
inspiration from the ingenious mechanisms of nature, this paper introduces
Collaborative Ant-based Neural Topology Search (CANTS-N), pushing the
boundaries of NAS and Neural Evolution (NE). In this innovative approach,
ant-inspired agents meticulously construct neural network structures,
dynamically adapting within a dynamic environment, much like their natural
counterparts. Guided by Particle Swarm Optimization (PSO), CANTS-N's colonies
optimize architecture searches, achieving remarkable improvements in mean
squared error (MSE) over established methods, including BP-free CANTS, BP
CANTS, and ANTS. Scalable, adaptable, and forward-looking, CANTS-N has the
potential to reshape the landscape of NAS and NE. This paper provides detailed
insights into its methodology, results, and far-reaching implications.
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17481 title=Abstract>arXiv:2401.17481</a> [<a href=https://arxiv.org/pdf/2401.17481 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17481 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating the Unknown: Uncertainty-Aware Compute-in-Memory Autonomy of Edge Robotics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Darabi%2C+N">Nastaran Darabi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shukla%2C+P">Priyesh Shukla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayasuriya%2C+D">Dinithi Jayasuriya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+D">Divake Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stutts%2C+A+C">Alex C. Stutts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trivedi%2C+A+R">Amit Ranjan Trivedi</a> (AEON Lab, University of Illinois Chicago (UIC), Chicago, IL)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper addresses the challenging problem of energy-efficient and
uncertainty-aware pose estimation in insect-scale drones, which is crucial for
tasks such as surveillance in constricted spaces and for enabling non-intrusive
spatial intelligence in smart homes. Since tiny drones operate in highly
dynamic environments, where factors like lighting and human movement impact
their predictive accuracy, it is crucial to deploy uncertainty-aware prediction
algorithms that can account for environmental variations and express not only
the prediction but also confidence in the prediction. We address both of these
challenges with Compute-in-Memory (CIM) which has become a pivotal technology
for deep learning acceleration at the edge. While traditional CIM techniques
are promising for energy-efficient deep learning, to bring in the robustness of
uncertainty-aware predictions at the edge, we introduce a suite of novel
techniques: First, we discuss CIM-based acceleration of Bayesian filtering
methods uniquely by leveraging the Gaussian-like switching current of CMOS
inverters along with co-design of kernel functions to operate with extreme
parallelism and with extreme energy efficiency. Secondly, we discuss the
CIM-based acceleration of variational inference of deep learning models through
probabilistic processing while unfolding iterative computations of the method
with a compute reuse strategy to significantly minimize the workload. Overall,
our co-design methodologies demonstrate the potential of CIM to improve the
processing efficiency of uncertainty-aware algorithms by orders of magnitude,
thereby enabling edge robotics to access the robustness of sophisticated
prediction frameworks within their extremely stringent area/power resources.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17482 title=Abstract>arXiv:2401.17482</a> [<a href=https://arxiv.org/pdf/2401.17482 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17482 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17482 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Comparison Analysis of ArangoDB, MySQL, and Neo4j: An Experimental Study of Querying Connected Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandell%2C+J">Johan Sandell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asplund%2C+E">Einar Asplund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayele%2C+W+Y">Workneh Yilma Ayele</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duneld%2C+M">Martin Duneld</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> <a href=https://hdl.handle.net/10125/107319>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2024, Proceedings of the 57th Hawaii International Conference on
 System Sciences
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>Choosing and developing performant database solutions helps organizations
optimize their operational practices and decision-making. Since graph data is
becoming more common, it is crucial to develop and use them in big data with
complex relationships with high and consistent performance. However, legacy
database technologies such as MySQL are tailored to store relational databases
and need to perform more complex queries to retrieve graph data. Previous
research has dealt with performance aspects such as CPU and memory usage. In
contrast, energy usage and temperature of the servers are lacking. Thus, this
paper evaluates and compares state-of-the-art graphs and relational databases
from the performance aspects to allow a more informed selection of
technologies. Graph-based big data applications benefit from informed selection
database technologies for data retrieval and analytics problems. The results
show that Neo4j performs faster in querying connected data than MySQL and
ArangoDB, and energy, CPU, and memory usage performances are reported in this
paper.
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17483 title=Abstract>arXiv:2401.17483</a> [<a href=https://arxiv.org/pdf/2401.17483 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17483 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17483 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Analysis of Symmetry in Quantitative Semantics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clairambault%2C+P">Pierre Clairambault</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forest%2C+S">Simon Forest</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)
</div>
<p class=mathjax>In this paper, we build on a recent bicategorical model called thin spans of
groupoids, introduced by Clairambault and Forest. Notably, thin spans feature a
decomposition of symmetry into two sub-groupoids of polarized -- positive and
negative -- symmetries. We first construct a variation of the original
exponential of thin spans, based on sequences rather than families. Then we
give a syntactic characterisation of the interpretation of simply-typed
lambda-terms in thin spans, in terms of rigid intersection types and rigid
resource terms. Finally, we formally relate thin spans with the weighted
relational model and generalized species of structure. This allows us to show
how some quantities in those models reflect polarized symmetries: in particular
we show that the weighted relational model counts witnesses from generalized
species of structure, divided by the cardinal of a group of positive
symmetries.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17484 title=Abstract>arXiv:2401.17484</a> [<a href=https://arxiv.org/pdf/2401.17484 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17484 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung%2C+C">Chanyoung Chung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Georgakis%2C+G">Georgios Georgakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spieler%2C+P">Patrick Spieler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padgett%2C+C">Curtis Padgett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khattak%2C+S">Shehryar Khattak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures, Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>Understanding terrain topology at long-range is crucial for the success of
off-road robotic missions, especially when navigating at high-speeds. LiDAR
sensors, which are currently heavily relied upon for geometric mapping, provide
sparse measurements when mapping at greater distances. To address this
challenge, we present a novel learning-based approach capable of predicting
terrain elevation maps at long-range using only onboard egocentric images in
real-time. Our proposed method is comprised of three main elements. First, a
transformer-based encoder is introduced that learns cross-view associations
between the egocentric views and prior bird-eye-view elevation map predictions.
Second, an orientation-aware positional encoding is proposed to incorporate the
3D vehicle pose information over complex unstructured terrain with multi-view
visual image features. Lastly, a history-augmented learn-able map embedding is
proposed to achieve better temporal consistency between elevation map
predictions to facilitate the downstream navigational tasks. We experimentally
validate the applicability of our proposed approach for autonomous offroad
robotic navigation in complex and unstructured terrain using real-world offroad
driving data. Furthermore, the method is qualitatively and quantitatively
compared against the current state-of-the-art methods. Extensive field
experiments demonstrate that our method surpasses baseline models in accurately
predicting terrain elevation while effectively capturing the overall terrain
topology at long-ranges. Finally, ablation studies are conducted to highlight
and understand the effect of key components of the proposed approach and
validate their suitability to improve offroad robotic navigation capabilities.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17486 title=Abstract>arXiv:2401.17486</a> [<a href=https://arxiv.org/pdf/2401.17486 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17486 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17486 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berman%2C+G">Glen Berman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+N">Nitesh Goyal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madaio%2C+M">Michael Madaio</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Responsible design of AI systems is a shared goal across HCI and AI
communities. Responsible AI (RAI) tools have been developed to support
practitioners to identify, assess, and mitigate ethical issues during AI
development. These tools take many forms (e.g., design playbooks, software
toolkits, documentation protocols). However, research suggests that use of RAI
tools is shaped by organizational contexts, raising questions about how
effective such tools are in practice. To better understand how RAI tools are --
and might be -- evaluated, we conducted a qualitative analysis of 37
publications that discuss evaluations of RAI tools. We find that most
evaluations focus on usability, while questions of tools' effectiveness in
changing AI development are sidelined. While usability evaluations are an
important approach to evaluate RAI tools, we draw on evaluation approaches from
other fields to highlight developer- and community-level steps to support
evaluations of RAI tools' effectiveness in shaping AI development practices and
outcomes.
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17497 title=Abstract>arXiv:2401.17497</a> [<a href=https://arxiv.org/pdf/2401.17497 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17497 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Visual Syntactical Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+S+S">Sayeed Shafayet Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandra%2C+S">Soumyadeep Chandra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Syntax is usually studied in the realm of linguistics and refers to the
arrangement of words in a sentence. Similarly, an image can be considered as a
visual 'sentence', with the semantic parts of the image acting as 'words'.
While visual syntactic understanding occurs naturally to humans, it is
interesting to explore whether deep neural networks (DNNs) are equipped with
such reasoning. To that end, we alter the syntax of natural images (e.g.
swapping the eye and nose of a face), referred to as 'incorrect' images, to
investigate the sensitivity of DNNs to such syntactic anomaly. Through our
experiments, we discover an intriguing property of DNNs where we observe that
state-of-the-art convolutional neural networks, as well as vision transformers,
fail to discriminate between syntactically correct and incorrect images when
trained on only correct ones. To counter this issue and enable visual syntactic
understanding with DNNs, we propose a three-stage framework- (i) the 'words'
(or the sub-features) in the image are detected, (ii) the detected words are
sequentially masked and reconstructed using an autoencoder, (iii) the original
and reconstructed parts are compared at each location to determine syntactic
correctness. The reconstruction module is trained with BERT-like masked
autoencoding for images, with the motivation to leverage language model
inspired training to better capture the syntax. Note, our proposed approach is
unsupervised in the sense that the incorrect images are only used during
testing and the correct versus incorrect labels are never used for training. We
perform experiments on CelebA, and AFHQ datasets and obtain classification
accuracy of 92.10%, and 90.89%, respectively. Notably, the approach generalizes
well to ImageNet samples which share common classes with CelebA and AFHQ
without explicitly training on them.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17498 title=Abstract>arXiv:2401.17498</a> [<a href=https://arxiv.org/pdf/2401.17498 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17498 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving QA Model Performance with Cartographic Inoculation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+A">Allen Chen</a> (UT Austin), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tankirulu%2C+O">Okan Tankirulu</a> (UT Austin)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>QA models are faced with complex and open-ended contextual reasoning
problems, but can often learn well-performing solution heuristics by exploiting
dataset-specific patterns in their training data. These patterns, or "dataset
artifacts", reduce the model's ability to generalize to real-world QA problems.
Utilizing an ElectraSmallDiscriminator model trained for QA, we analyze the
impacts and incidence of dataset artifacts using an adversarial challenge set
designed to confuse models reliant on artifacts for prediction. Extending
existing work on methods for mitigating artifact impacts, we propose
cartographic inoculation, a novel method that fine-tunes models on an optimized
subset of the challenge data to reduce model reliance on dataset artifacts. We
show that by selectively fine-tuning a model on ambiguous adversarial examples
from a challenge set, significant performance improvements can be made on the
full challenge dataset with minimal loss of model generalizability to other
challenging environments and QA datasets.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17499 title=Abstract>arXiv:2401.17499</a> [<a href=https://arxiv.org/pdf/2401.17499 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17499 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AdvGPS: Adversarial GPS for Multi-Agent Perception Attack
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinlong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Baolu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xinyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+J">Jianwu Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qing Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hongkai Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The multi-agent perception system collects visual data from sensors located
on various agents and leverages their relative poses determined by GPS signals
to effectively fuse information, mitigating the limitations of single-agent
sensing, such as occlusion. However, the precision of GPS signals can be
influenced by a range of factors, including wireless transmission and
obstructions like buildings. Given the pivotal role of GPS signals in
perception fusion and the potential for various interference, it becomes
imperative to investigate whether specific GPS signals can easily mislead the
multi-agent perception system. To address this concern, we frame the task as an
adversarial attack challenge and introduce \textsc{AdvGPS}, a method capable of
generating adversarial GPS signals which are also stealthy for individual
agents within the system, significantly reducing object detection accuracy. To
enhance the success rates of these attacks in a black-box scenario, we
introduce three types of statistically sensitive natural discrepancies:
appearance-based discrepancy, distribution-based discrepancy, and task-aware
discrepancy. Our extensive experiments on the OPV2V dataset demonstrate that
these attacks substantially undermine the performance of state-of-the-art
methods, showcasing remarkable transferability across different point cloud
based 3D detection systems. This alarming revelation underscores the pressing
need to address security implications within multi-agent perception systems,
thereby underscoring a critical area of research.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17500 title=Abstract>arXiv:2401.17500</a> [<a href=https://arxiv.org/pdf/2401.17500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhengtong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=She%2C+Y">Yu She</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper introduces LeTO, a method for learning constrained visuomotor
policy via differentiable trajectory optimization. Our approach uniquely
integrates a differentiable optimization layer into the neural network. By
formulating the optimization layer as a trajectory optimization problem, we
enable the model to end-to-end generate actions in a safe and controlled
fashion without extra modules. Our method allows for the introduction of
constraints information during the training process, thereby balancing the
training objectives of satisfying constraints, smoothing the trajectories, and
minimizing errors with demonstrations. This "gray box" method marries the
optimization-based safety and interpretability with the powerful
representational abilities of neural networks. We quantitatively evaluate LeTO
in simulation and on the real robot. In simulation, LeTO achieves a success
rate comparable to state-of-the-art imitation learning methods, but the
generated trajectories are of less uncertainty, higher quality, and smoother.
In real-world experiments, we deployed LeTO to handle constraints-critical
tasks. The results show the effectiveness of LeTO comparing with
state-of-the-art imitation learning approaches. We release our code at
https://github.com/ZhengtongXu/LeTO.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17504 title=Abstract>arXiv:2401.17504</a> [<a href=https://arxiv.org/pdf/2401.17504 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17504 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CaMU: Disentangling Causal Effects in Deep Model Unlearning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+S">Shaofei Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chenhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bialkowski%2C+A">Alina Bialkowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Weitong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Miao Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Full version of the paper accepted for the SDM 24 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Methodology (stat.ME)
</div>
<p class=mathjax>Machine unlearning requires removing the information of forgetting data while
keeping the necessary information of remaining data. Despite recent
advancements in this area, existing methodologies mainly focus on the effect of
removing forgetting data without considering the negative impact this can have
on the information of the remaining data, resulting in significant performance
degradation after data removal. Although some methods try to repair the
performance of remaining data after removal, the forgotten information can also
return after repair. Such an issue is due to the intricate intertwining of the
forgetting and remaining data. Without adequately differentiating the influence
of these two kinds of data on the model, existing algorithms take the risk of
either inadequate removal of the forgetting data or unnecessary loss of
valuable information from the remaining data. To address this shortcoming, the
present study undertakes a causal analysis of the unlearning and introduces a
novel framework termed Causal Machine Unlearning (CaMU). This framework adds
intervention on the information of remaining data to disentangle the causal
effects between forgetting data and remaining data. Then CaMU eliminates the
causal impact associated with forgetting data while concurrently preserving the
causal relevance of the remaining data. Comprehensive empirical results on
various datasets and models suggest that CaMU enhances performance on the
remaining data and effectively minimizes the influences of forgetting data.
Notably, this work is the first to interpret deep model unlearning tasks from a
new perspective of causality and provide a solution based on causal analysis,
which opens up new possibilities for future research in deep model unlearning.
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17505 title=Abstract>arXiv:2401.17505</a> [<a href=https://arxiv.org/pdf/2401.17505 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17505 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arrows of Time for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Papadopoulos%2C+V">Vassilis Papadopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wenger%2C+J">Jrmie Wenger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hongler%2C+C">Clment Hongler</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>We study the probabilistic modeling performed by Autoregressive Large
Language Models through the angle of time directionality. We empirically find a
time asymmetry exhibited by such models in their ability to model natural
language: a difference in the average log-perplexity when trying to predict the
next token versus when trying to predict the previous one. This difference is
at the same time subtle and very consistent across various modalities
(language, model size, training time, ...). Theoretically, this is surprising:
from an information-theoretic point of view, there should be no such
difference. We provide a theoretical framework to explain how such an asymmetry
can appear from sparsity and computational complexity considerations, and
outline a number of perspectives opened by our results.
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17509 title=Abstract>arXiv:2401.17509</a> [<a href=https://arxiv.org/pdf/2401.17509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Anything in Any Scene: Photorealistic Video Object Insertion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+C">Chen Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Z">Zeman Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guoxiang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+D">Di Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhuorui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yujian Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+C">Chengzhang Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Y">Yiqiao Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhendong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+Y">Yichen Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xiaoyin Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+C">Cheng Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Realistic video simulation has shown significant potential across diverse
applications, from virtual reality to film production. This is particularly
true for scenarios where capturing videos in real-world settings is either
impractical or expensive. Existing approaches in video simulation often fail to
accurately model the lighting environment, represent the object geometry, or
achieve high levels of photorealism. In this paper, we propose Anything in Any
Scene, a novel and generic framework for realistic video simulation that
seamlessly inserts any object into an existing dynamic video with a strong
emphasis on physical realism. Our proposed general framework encompasses three
key processes: 1) integrating a realistic object into a given scene video with
proper placement to ensure geometric realism; 2) estimating the sky and
environmental lighting distribution and simulating realistic shadows to enhance
the light realism; 3) employing a style transfer network that refines the final
video output to maximize photorealism. We experimentally demonstrate that
Anything in Any Scene framework produces simulated videos of great geometric
realism, lighting realism, and photorealism. By significantly mitigating the
challenges associated with video data generation, our framework offers an
efficient and cost-effective solution for acquiring high-quality videos.
Furthermore, its applications extend well beyond video data augmentation,
showing promising potential in virtual reality, video editing, and various
other video-centric applications. Please check our project website
https://anythinginanyscene.github.io for access to our project code and more
high-resolution video results.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17511 title=Abstract>arXiv:2401.17511</a> [<a href=https://arxiv.org/pdf/2401.17511 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17511 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Linguistically Communicating Uncertainty in Patient-Facing Risk Prediction Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sivaprasad%2C+A">Adarsa Sivaprasad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reiter%2C+E">Ehud Reiter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>This paper addresses the unique challenges associated with uncertainty
quantification in AI models when applied to patient-facing contexts within
healthcare. Unlike traditional eXplainable Artificial Intelligence (XAI)
methods tailored for model developers or domain experts, additional
considerations of communicating in natural language, its presentation and
evaluating understandability are necessary. We identify the challenges in
communication model performance, confidence, reasoning and unknown knowns using
natural language in the context of risk prediction. We propose a design aimed
at addressing these challenges, focusing on the specific application of
in-vitro fertilisation outcome prediction.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17512 title=Abstract>arXiv:2401.17512</a> [<a href=https://arxiv.org/pdf/2401.17512 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17512 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Cradle-to-Gate Life Cycle Analysis of Bitcoin Mining Equipment Using Sphera LCA and ecoinvent Databases
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Courtillat--Piazza%2C+L">Ludmila Courtillat--Piazza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pirson%2C+T">Thibault Pirson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golard%2C+L">Louis Golard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bol%2C+D">David Bol</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures, 2 tables. Supplementary Information not available
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Bitcoin mining is regularly pointed out for its massive energy consumption
and associated greenhouse gas emissions, hence contributing significantly to
climate change. However, most studies ignore the environmental impacts of
producing mining equipment, which is problematic given the short lifespan of
such highly specific hardware. In this study, we perform a cradle-to-gate life
cycle assessment (LCA) of dedicated Bitcoin mining equipment, considering their
specific architecture. Our results show that the application-specific
integrated circuit designed for Bitcoin mining is the main contributor to
production-related impacts. This observation applies to most impact categories,
including the global warming potential. In addition, this finding stresses out
the necessity to carefully consider the specificity of the hardware. By
comparing these results with several usage scenarios, we also demonstrate that
the impacts of producing this type of equipment can be significant (up to 80%
of the total life cycle impacts), depending on the sources of electricity
supply for the use phase. Therefore, we highlight the need to consider the
production phase when assessing the environmental impacts of Bitcoin mining
hardware. To test the validity of our results, we use the Sphera LCA and
ecoinvent databases for the background modeling of our system. Surprisingly, it
leads to results with variations of up to 4 orders of magnitude for
toxicity-related indicators, despite using the same foreground modeling. This
database mismatch phenomenon, already identified in previous studies, calls for
better understanding, consideration and discussion of environmental impacts in
the field of electronics, going well beyond climate change indicators.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17514 title=Abstract>arXiv:2401.17514</a> [<a href=https://arxiv.org/pdf/2401.17514 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17514 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FEUDA: Frustratingly Easy Prompt Based Unsupervised Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uppaal%2C+R">Rheeya Uppaal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yixuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Junjie Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>A major thread of unsupervised domain adaptation (UDA) methods uses unlabeled
data from both source and target domains to learn domain-invariant
representations for adaptation. However, these methods showcase certain
limitations, encouraging the use of self-supervised learning through continued
pre-training. The necessity of continued pre-training or learning
domain-invariant representations is still unclear in the prompt-based
classification framework, where an input example is modified by a template and
then fed into a language model (LM) to generate a label string. To examine this
new paradigm of UDA in the prompt-based setup, we propose a frustratingly easy
UDA method (FEUDA) that trains an autoregressive LM on both unlabeled and
labeled examples using two different instruction-tuning tasks. Specifically,
the first task trains the LM on unlabeled texts from both domains via masked
language modeling (MLM), and the other uses supervised instruction-tuning on
source-labeled data for classification. We conduct extensive experiments on 24
real-world domain pairs to show the effectiveness of our method over strong
domain-invariant learning methods. Our analysis sheds light on why masked
language modeling improves target-domain classification performance in
prompt-based UDA. We discover that MLM helps the model learn both semantic and
background knowledge of a domain, which are both beneficial for downstream
classification.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17515 title=Abstract>arXiv:2401.17515</a> [<a href=https://arxiv.org/pdf/2401.17515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Image Semantics and Syntax Sequence Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+C">Chun Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ibrayev%2C+T">Timur Ibrayev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 22 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Convolutional neural networks and vision transformers have achieved
outstanding performance in machine perception, particularly for image
classification. Although these image classifiers excel at predicting
image-level class labels, they may not discriminate missing or shifted parts
within an object. As a result, they may fail to detect corrupted images that
involve missing or disarrayed semantic information in the object composition.
On the contrary, human perception easily distinguishes such corruptions. To
mitigate this gap, we introduce the concept of "image grammar", consisting of
"image semantics" and "image syntax", to denote the semantics of parts or
patches of an image and the order in which these parts are arranged to create a
meaningful object. To learn the image grammar relative to a class of visual
objects/scenes, we propose a weakly supervised two-stage approach. In the first
stage, we use a deep clustering framework that relies on iterative clustering
and feature refinement to produce part-semantic segmentation. In the second
stage, we incorporate a recurrent bi-LSTM module to process a sequence of
semantic segmentation patches to capture the image syntax. Our framework is
trained to reason over patch semantics and detect faulty syntax. We benchmark
the performance of several grammar learning models in detecting patch
corruptions. Finally, we verify the capabilities of our framework in Celeb and
SUNRGBD datasets and demonstrate that it can achieve a grammar validation
accuracy of 70 to 90% in a wide variety of semantic and syntactical corruption
scenarios.
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17517 title=Abstract>arXiv:2401.17517</a> [<a href=https://arxiv.org/pdf/2401.17517 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17517 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Force Push: Robust Single-Point Pushing with Force Feedback
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heins%2C+A">Adam Heins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE Robotics and Automation Letters (RA-L). arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.11048>arXiv:2305.11048</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>We present the first controller for quasistatic robotic planar pushing with
single-point contact using only force feedback. We consider an omnidirectional
mobile robot pushing an object (the "slider") along a given path, where the
robot is equipped with a force-torque sensor to measure the force at the
contact point with the slider. The geometric, inertial, and frictional
parameters of the slider are not known to the controller, nor are measurements
of the slider's pose. We assume that the robot can be localized so that the
global position of the contact point is always known and that the approximate
initial position of the slider is provided. Simulations and real-world
experiments show that our controller yields stable pushes that are robust to a
wide range of slider parameters and state perturbations along both straight and
curved paths. Furthermore, we use an admittance controller to adjust the
pushing velocity based on the measured force when the slider contacts obstacles
like walls.
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17519 title=Abstract>arXiv:2401.17519</a> [<a href=https://arxiv.org/pdf/2401.17519 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17519 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Modeling and analysis of a flexible spinning Euler-Bernoulli beam with centrifugal stiffening and softening: A Linear Fractional Representation approach with application to spinning spacecraft
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rodrigues%2C+R">Ricardo Rodrigues</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alazard%2C+D">Daniel Alazard</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanfedino%2C+F">Francesco Sanfedino</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mauriello%2C+T">Tommaso Mauriello</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Iannelli%2C+P">Paolo Iannelli</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Space Physics (physics.space-ph)
</div>
<p class=mathjax>The derivation of a linear fractional representation (LFR) model for a
flexible, spinning and uniform Euler-Bernoulli beam is accomplished using the
{Lagrange} technique, fully capturing the centrifugal force generated by the
spinning motion and accounting for its dependence on the angular velocity. This
six degrees of freedom (DOF) model accounts for the behavior of deflection in
the moving body frame, encompassing the bending, traction and torsion dynamics.
The model is also designed to be compliant with the Two-Input-Two-Output Port
(TITOP) approach, which offers the possibility to model complex multibody
mechanical systems, while keeping the uncertain nature of the plant and
condensing all the possible mechanical configurations in a single LFR. To
evaluate the effectiveness of the model, various scenarios are considered and
their results are tabulated. These scenarios include uniform beams with fixed
root boundary conditions for different values of tip mass, root offset and
angular velocity. The results from the analysis of the uniform cantilever beam
are compared with solutions found in the literature and obtained from a
commercial finite element software. Ultimately, this paper presents a multibody
model for a spinning spacecraft mission scenario. A comprehensive analysis of
the system dynamics is conducted, providing insights into the behavior of the
spacecraft under spinning conditions.
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17522 title=Abstract>arXiv:2401.17522</a> [<a href=https://arxiv.org/pdf/2401.17522 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17522 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17522 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Sum Secrecy Rate Maximisation for Wireless Vehicular Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Farooq%2C+M">Muhammad Farooq</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tran%2C+L">Le-Nam Tran</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Golpayegani%2C+F">Fatemeh Golpayegani</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Afraz%2C+N">Nima Afraz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Wireless communications form the backbone of future vehicular networks,
playing a critical role in applications ranging from traffic control to
vehicular road safety. However, the dynamic structure of these networks creates
security vulnerabilities, making security considerations an integral part of
network design. We address these security concerns from a physical layer
security aspect by investigating achievable secrecy rates in wireless vehicular
networks. Specifically, we aim to maximize the sum secrecy rate from all
vehicular pairs subject to bandwidth and power resource constraints. For the
considered problem, we first propose a solution based on the successive convex
approximation (SCA) method, which has not been applied in this context before.
To further reduce the complexity of the SCA-based method, we also propose a
low-complexity solution based on a fast iterative shrinkage-thresholding
algorithm (FISTA). Our simulation results for SCA and FISTA show a trade-off
between convergence and runtime. While the SCA method achieves better
convergence, the FISTA-based approach is at least 300 times faster than the SCA
method.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17523 title=Abstract>arXiv:2401.17523</a> [<a href=https://arxiv.org/pdf/2401.17523 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17523 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Game-Theoretic Unlearnable Example Generator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yihan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiao-Shan Gao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)
</div>
<p class=mathjax>Unlearnable example attacks are data poisoning attacks aiming to degrade the
clean test accuracy of deep learning by adding imperceptible perturbations to
the training samples, which can be formulated as a bi-level optimization
problem. However, directly solving this optimization problem is intractable for
deep neural networks. In this paper, we investigate unlearnable example attacks
from a game-theoretic perspective, by formulating the attack as a nonzero sum
Stackelberg game. First, the existence of game equilibria is proved under the
normal setting and the adversarial training setting. It is shown that the game
equilibrium gives the most powerful poison attack in that the victim has the
lowest test accuracy among all networks within the same hypothesis space, when
certain loss functions are used. Second, we propose a novel attack method,
called the Game Unlearnable Example (GUE), which has three main gradients. (1)
The poisons are obtained by directly solving the equilibrium of the Stackelberg
game with a first-order algorithm. (2) We employ an autoencoder-like generative
network model as the poison attacker. (3) A novel payoff function is introduced
to evaluate the performance of the poison. Comprehensive experiments
demonstrate that GUE can effectively poison the model in various scenarios.
Furthermore, the GUE still works by using a relatively small percentage of the
training data to train the generator, and the poison generator can generalize
to unseen data well. Our implementation code can be found at
https://github.com/hong-xian/gue.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17527 title=Abstract>arXiv:2401.17527</a> [<a href=https://arxiv.org/pdf/2401.17527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+H">Haotian Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhihai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jie Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Cutting planes (cuts) play an important role in solving mixed-integer linear
programs (MILPs), as they significantly tighten the dual bounds and improve the
solving performance. A key problem for cuts is when to stop cuts generation,
which is important for the efficiency of solving MILPs. However, many modern
MILP solvers employ hard-coded heuristics to tackle this problem, which tends
to neglect underlying patterns among MILPs from certain applications. To
address this challenge, we formulate the cuts generation stopping problem as a
reinforcement learning problem and propose a novel hybrid graph representation
model (HYGRO) to learn effective stopping strategies. An appealing feature of
HYGRO is that it can effectively capture both the dynamic and static features
of MILPs, enabling dynamic decision-making for the stopping strategies. To the
best of our knowledge, HYGRO is the first data-driven method to tackle the cuts
generation stopping problem. By integrating our approach with modern solvers,
experiments demonstrate that HYGRO significantly improves the efficiency of
solving MILPs compared to competitive baselines, achieving up to 31%
improvement.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17536 title=Abstract>arXiv:2401.17536</a> [<a href=https://arxiv.org/pdf/2401.17536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PipeNet: Question Answering with Semantic Pruning over Knowledge Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Ying Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jipeng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yangqiu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>It is well acknowledged that incorporating explicit knowledge graphs (KGs)
can benefit question answering. Existing approaches typically follow a
grounding-reasoning pipeline in which entity nodes are first grounded for the
query (question and candidate answers), and then a reasoning module reasons
over the matched multi-hop subgraph for answer prediction. Although the
pipeline largely alleviates the issue of extracting essential information from
giant KGs, efficiency is still an open challenge when scaling up hops in
grounding the subgraphs. In this paper, we target at finding semantically
related entity nodes in the subgraph to improve the efficiency of graph
reasoning with KG. We propose a grounding-pruning-reasoning pipeline to prune
noisy nodes, remarkably reducing the computation cost and memory usage while
also obtaining decent subgraph representation. In detail, the pruning module
first scores concept nodes based on the dependency distance between matched
spans and then prunes the nodes according to score ranks. To facilitate the
evaluation of pruned subgraphs, we also propose a graph attention network (GAT)
based module to reason with the subgraph data. Experimental results on
CommonsenseQA and OpenBookQA demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17538 title=Abstract>arXiv:2401.17538</a> [<a href=https://arxiv.org/pdf/2401.17538 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17538 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Post-Quantum Cryptography for Internet of Things: A Survey on Performance and Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramachandran%2C+G">Gowri Ramachandran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jurdak%2C+R">Raja Jurdak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 3 figures and 7 tables. Formatted version submitted to ACM Computer Surveys
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Due to recent development in quantum computing, the invention of a large
quantum computer is no longer a distant future. Quantum computing severely
threatens modern cryptography, as the hard mathematical problems beneath
classic public-key cryptosystems can be solved easily by a sufficiently large
quantum computer. As such, researchers have proposed PQC based on problems that
even quantum computers cannot efficiently solve. Generally, post-quantum
encryption and signatures can be hard to compute. This could potentially be a
problem for IoT, which usually consist lightweight devices with limited
computational power. In this paper, we survey existing literature on the
performance for PQC in resource-constrained devices to understand the
severeness of this problem. We also review recent proposals to optimize PQC
algorithms for resource-constrained devices. Overall, we find that whilst PQC
may be feasible for reasonably lightweight IoT, proposals for their
optimization seem to lack standardization. As such, we suggest future research
to seek coordination, in order to ensure an efficient and safe migration toward
IoT for the post-quantum era.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17539 title=Abstract>arXiv:2401.17539</a> [<a href=https://arxiv.org/pdf/2401.17539 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17539 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Score-Based Sampling Methods with Ensembles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bischoff%2C+T">Tobias Bischoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riel%2C+B">Bryan Riel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation (stat.CO)
</div>
<p class=mathjax>We introduce ensembles within score-based sampling methods to develop
gradient-free approximate sampling techniques that leverage the collective
dynamics of particle ensembles to compute approximate reverse diffusion drifts.
We introduce the underlying methodology, emphasizing its relationship with
generative diffusion models and the previously introduced F\"ollmer sampler. We
demonstrate the efficacy of ensemble strategies through various examples,
ranging from low- to medium-dimensionality sampling problems, including
multi-modal and highly non-Gaussian probability distributions, and provide
comparisons to traditional methods like NUTS. Our findings highlight the
potential of ensemble strategies for modeling complex probability distributions
in situations where gradients are unavailable. Finally, we showcase its
application in the context of Bayesian inversion problems within the
geophysical sciences.
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17541 title=Abstract>arXiv:2401.17541</a> [<a href=https://arxiv.org/pdf/2401.17541 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17541 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Understanding Variants of Invariant Risk Minimization through the Lens of Calibration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoshida%2C+K">Kotaro Yoshida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naganuma%2C+H">Hiroki Naganuma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Machine learning models traditionally assume that training and test data are
independently and identically distributed. However, in real-world applications,
the test distribution often differs from training. This problem, known as
out-of-distribution generalization, challenges conventional models. Invariant
Risk Minimization (IRM) emerges as a solution, aiming to identify features
invariant across different environments to enhance out-of-distribution
robustness. However, IRM's complexity, particularly its bi-level optimization,
has led to the development of various approximate methods. Our study
investigates these approximate IRM techniques, employing the Expected
Calibration Error (ECE) as a key metric. ECE, which measures the reliability of
model prediction, serves as an indicator of whether models effectively capture
environment-invariant features. Through a comparative analysis of datasets with
distributional shifts, we observe that Information Bottleneck-based IRM, which
condenses representational information, achieves a balance in improving ECE
while preserving accuracy relatively. This finding is pivotal, as it
demonstrates a feasible path to maintaining robustness without compromising
accuracy. Nonetheless, our experiments also caution against
over-regularization, which can diminish accuracy. This underscores the
necessity for a systematic approach in evaluating out-of-distribution
generalization metrics, one that beyond mere accuracy to address the nuanced
interplay between accuracy and calibration.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17542 title=Abstract>arXiv:2401.17542</a> [<a href=https://arxiv.org/pdf/2401.17542 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17542 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Effective Learning: A Comprehensive Medical Benchmark
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenxuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+W">Weimin Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuqi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Bo Yan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Data-effective learning aims to use data in the most impactful way to train
AI models, which involves strategies that focus on data quality rather than
quantity, ensuring the data used for training has high informational value.
Data-effective learning plays a profound role in accelerating AI training,
reducing computational costs, and saving data storage, which is very important
as the volume of medical data in recent years has grown beyond many people's
expectations. However, due to the lack of standards and comprehensive
benchmark, research on medical data-effective learning is poorly studied. To
address this gap, our paper introduces a comprehensive benchmark specifically
for evaluating data-effective learning in the medical field. This benchmark
includes a dataset with millions of data samples from 31 medical centers
(DataDEL), a baseline method for comparison (MedDEL), and a new evaluation
metric (NormDEL) to objectively measure data-effective learning performance.
Our extensive experimental results show the baseline MedDEL can achieve
performance comparable to the original large dataset with only 5% of the data.
Establishing such an open data-effective learning benchmark is crucial for the
medical AI research community because it facilitates efficient data use,
promotes collaborative breakthroughs, and fosters the development of
cost-effective, scalable, and impactful healthcare solutions. The project can
be accessed at
https://github.com/shadow2469/Data-Effective-Learning-A-Comprehensive-Medical-Benchmark.git.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17543 title=Abstract>arXiv:2401.17543</a> [<a href=https://arxiv.org/pdf/2401.17543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Frchet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arabzadeh%2C+N">Negar Arabzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clarke%2C+C+L+A">Charles L. A. Clarke</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>The rapid advancement of natural language processing, information retrieval
(IR), computer vision, and other technologies has presented significant
challenges in evaluating the performance of these systems. One of the main
challenges is the scarcity of human-labeled data, which hinders the fair and
accurate assessment of these systems. In this work, we specifically focus on
evaluating IR systems with sparse labels, borrowing from recent research on
evaluating computer vision tasks. taking inspiration from the success of using
Fr\'echet Inception Distance (FID) in assessing text-to-image generation
systems. We propose leveraging the Fr\'echet Distance to measure the distance
between the distributions of relevant judged items and retrieved results. Our
experimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks query
sets demonstrate the effectiveness of the Fr\'echet Distance as a metric for
evaluating IR systems, particularly in settings where a few labels are
available. This approach contributes to the advancement of evaluation
methodologies in real-world scenarios such as the assessment of generative IR
systems.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17544 title=Abstract>arXiv:2401.17544</a> [<a href=https://arxiv.org/pdf/2401.17544 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17544 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Trainable Fixed-Point Quantization for Deep Learning Acceleration on FPGAs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+D">Dingyi Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiahao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Z">Zhanqiu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yaohui Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qi Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiru Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Quantization is a crucial technique for deploying deep learning models on
resource-constrained devices, such as embedded FPGAs. Prior efforts mostly
focus on quantizing matrix multiplications, leaving other layers like BatchNorm
or shortcuts in floating-point form, even though fixed-point arithmetic is more
efficient on FPGAs. A common practice is to fine-tune a pre-trained model to
fixed-point for FPGA deployment, but potentially degrading accuracy.
<br>This work presents QFX, a novel trainable fixed-point quantization approach
that automatically learns the binary-point position during model training.
Additionally, we introduce a multiplier-free quantization strategy within QFX
to minimize DSP usage. QFX is implemented as a PyTorch-based library that
efficiently emulates fixed-point arithmetic, supported by FPGA HLS, in a
differentiable manner during backpropagation. With minimal effort, models
trained with QFX can readily be deployed through HLS, producing the same
numerical results as their software counterparts. Our evaluation shows that
compared to post-training quantization, QFX can quantize models trained with
element-wise layers quantized to fewer bits and achieve higher accuracy on both
CIFAR-10 and ImageNet datasets. We further demonstrate the efficacy of
multiplier-free quantization using a state-of-the-art binarized neural network
accelerator designed for an embedded FPGA (AMD Xilinx Ultra96 v2). We plan to
release QFX in open-source format.
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17545 title=Abstract>arXiv:2401.17545</a> [<a href=https://arxiv.org/pdf/2401.17545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17545 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Three-Stage Adjusted Regression Forecasting (TSARF) for Software Defect Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pritchard%2C+S">Shadow Pritchard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+B">Bhaskar Mitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagaraju%2C+V">Vidhyashree Nagaraju</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Software reliability growth models (SRGM) enable failure data collected
during testing. Specifically, nonhomogeneous Poisson process (NHPP) SRGM are
the most commonly employed models. While software reliability growth models are
important, efficient modeling of complex software systems increases the
complexity of models. Increased model complexity presents a challenge in
identifying robust and computationally efficient algorithms to identify model
parameters and reduces the generalizability of the models. Existing studies on
traditional software reliability growth models suggest that NHPP models
characterize defect data as a smooth continuous curve and fail to capture
changes in the defect discovery process. Therefore, the model fits well under
ideal conditions, but it is not adaptable and will only fit appropriately
shaped data. Neural networks and other machine learning methods have been
applied to greater effect [5], however limited due to lack of large samples of
defect data especially at earlier stages of testing.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17546 title=Abstract>arXiv:2401.17546</a> [<a href=https://arxiv.org/pdf/2401.17546 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17546 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17546 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Effective Multi-Stage Training Model For Edge Computing Devices In Intrusion Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trong%2C+T+H">Thua Huynh Trong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+T+N">Thanh Nguyen Hoang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Intrusion detection poses a significant challenge within expansive and
persistently interconnected environments. As malicious code continues to
advance and sophisticated attack methodologies proliferate, various advanced
deep learning-based detection approaches have been proposed. Nevertheless, the
complexity and accuracy of intrusion detection models still need further
enhancement to render them more adaptable to diverse system categories,
particularly within resource-constrained devices, such as those embedded in
edge computing systems. This research introduces a three-stage training
paradigm, augmented by an enhanced pruning methodology and model compression
techniques. The objective is to elevate the system's effectiveness,
concurrently maintaining a high level of accuracy for intrusion detection.
Empirical assessments conducted on the UNSW-NB15 dataset evince that this
solution notably reduces the model's dimensions, while upholding accuracy
levels equivalent to similar proposals.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17547 title=Abstract>arXiv:2401.17547</a> [<a href=https://arxiv.org/pdf/2401.17547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Task-Oriented Diffusion Model Compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+G">Geonung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+B">Beomsu Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+E">Eunhyeok Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+S">Sunghyun Cho</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>As recent advancements in large-scale Text-to-Image (T2I) diffusion models
have yielded remarkable high-quality image generation, diverse downstream
Image-to-Image (I2I) applications have emerged. Despite the impressive results
achieved by these I2I models, their practical utility is hampered by their
large model size and the computational burden of the iterative denoising
process. In this paper, we explore the compression potential of these I2I
models in a task-oriented manner and introduce a novel method for reducing both
model size and the number of timesteps. Through extensive experiments, we
observe key insights and use our empirical knowledge to develop practical
solutions that aim for near-optimal results with minimal exploration costs. We
validate the effectiveness of our method by applying it to InstructPix2Pix for
image editing and StableSR for image restoration. Our approach achieves
satisfactory output quality with 39.2% and 56.4% reduction in model footprint
and 81.4% and 68.7% decrease in latency to InstructPix2Pix and StableSR,
respectively.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17548 title=Abstract>arXiv:2401.17548</a> [<a href=https://arxiv.org/pdf/2401.17548 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17548 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lifan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yanyan Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR 2024. Preprint version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recently, channel-independent methods have achieved state-of-the-art
performance in multivariate time series (MTS) forecasting. Despite reducing
overfitting risks, these methods miss potential opportunities in utilizing
channel dependence for accurate predictions. We argue that there exist locally
stationary lead-lag relationships between variates, i.e., some lagged variates
may follow the leading indicators within a short time period. Exploiting such
channel dependence is beneficial since leading indicators offer advance
information that can be used to reduce the forecasting difficulty of the lagged
variates. In this paper, we propose a new method named LIFT that first
efficiently estimates leading indicators and their leading steps at each time
step and then judiciously allows the lagged variates to utilize the advance
information from leading indicators. LIFT plays as a plugin that can be
seamlessly collaborated with arbitrary time series forecasting methods.
Extensive experiments on six real-world datasets demonstrate that LIFT improves
the state-of-the-art methods by 5.5% in average forecasting performance.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17555 title=Abstract>arXiv:2401.17555</a> [<a href=https://arxiv.org/pdf/2401.17555 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17555 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> opML: Optimistic Machine Learning on Blockchain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conway%2C+K">KD Conway</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=So%2C+C">Cathie So</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiaohang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kartin Wong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The integration of machine learning with blockchain technology has witnessed
increasing interest, driven by the vision of decentralized, secure, and
transparent AI services. In this context, we introduce opML (Optimistic Machine
Learning on chain), an innovative approach that empowers blockchain systems to
conduct AI model inference. opML lies a interactive fraud proof protocol,
reminiscent of the optimistic rollup systems. This mechanism ensures
decentralized and verifiable consensus for ML services, enhancing trust and
transparency. Unlike zkML (Zero-Knowledge Machine Learning), opML offers
cost-efficient and highly efficient ML services, with minimal participation
requirements. Remarkably, opML enables the execution of extensive language
models, such as 7B-LLaMA, on standard PCs without GPUs, significantly expanding
accessibility.By combining the capabilities of blockchain and AI through opML,
we embark on a transformative journey toward accessible, secure, and efficient
on-chain machine learning.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17556 title=Abstract>arXiv:2401.17556</a> [<a href=https://arxiv.org/pdf/2401.17556 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17556 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17556 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model-Theoretic Logic for Mathematical Theory of Semantic Information and Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saz%2C+A+F">Ahmet Faruk Saz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+S">Siheng Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saidutta%2C+Y+M">Yashas Malur Saidutta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fekri%2C+F">Faramarz Fekri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we propose an advancement to Tarskian model-theoretic
semantics, leading to a unified quantitative theory of semantic information and
communication. We start with description of inductive logic and probabilities,
which serve as notable tools in development of the proposed theory. Then, we
identify two disparate kinds of uncertainty in semantic communication, that of
physical and content, present refined interpretations of semantic information
measures, and conclude with proposing a new measure for semantic
content-information and entropy. Our proposition standardizes semantic
information across different universes and systems, hence bringing
measurability and comparability into semantic communication. We then proceed
with introducing conditional and mutual semantic cont-information measures and
point out to their utility in formulating practical and optimizable lossless
and lossy semantic compression objectives. Finally, we experimentally
demonstrate the value of our theoretical propositions.
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17566 title=Abstract>arXiv:2401.17566</a> [<a href=https://arxiv.org/pdf/2401.17566 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17566 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IQ Skew and Imbalance Estimation for Coherent Point-to-Multi-Point Optical Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Ji Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jianrui Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haide Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+D">Dong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Liangchuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weiping Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C">Changyuan Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been submitted to the Journal of Lightwave Technology
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Coherent point-to-multi-point (PtMP) optical network based on digital
subcarrier multiplexing (DSCM) has been a promising technology for metro and
access networks to achieve cost savings, low latency, and high flexibility.
In-phase and quadrature (IQ) impairments of the coherent transceiver (e.g. IQ
skew and power imbalance) cause severe performance degradation. In the
DSCM-based coherent PtMP optical networks, it is hard to realize far-end
IQ-impairments estimation for the hub transmitter because the leaf on one
subcarrier cannot acquire the signal on the symmetrical subcarrier. In this
paper, we propose a far-end IQ-impairments estimation based on the specially
designed time-and-frequency interleaving tones (TFITs), which can
simultaneously estimate IQ skews and power imbalances of the hub transmitter
and leaf receiver at an individual leaf. The feasibility of the TFITs-based
IQ-impairments estimation has been experimentally verified by setting up
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-66 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-67><span class=mn id=MathJax-Span-68 style=font-family:MathJax_Main>8</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>Gbaud/SC<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-69 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-70><span class=mo id=MathJax-Span-71 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span><span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-72 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-73><span class=mn id=MathJax-Span-74 style=font-family:MathJax_Main>4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>SCs DSCM-based coherent PtMP optical network. The
experimental results depict that the absolute errors in the estimated IQ skew
and power imbalance are within <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-75 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.03em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-76><span class=mo id=MathJax-Span-77 style=font-family:MathJax_Main></span><span class=mn id=MathJax-Span-78 style=font-family:MathJax_Main>0.5</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>ps and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-79 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.03em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-80><span class=mo id=MathJax-Span-81 style=font-family:MathJax_Main></span><span class=mn id=MathJax-Span-82 style=font-family:MathJax_Main>0.2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>dB, respectively. In
conclusion, TFITs-based IQ-impairments estimation has great potential for
DSCM-based coherent PtMP optical networks.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17567 title=Abstract>arXiv:2401.17567</a> [<a href=https://arxiv.org/pdf/2401.17567 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17567 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error analysis of a collocation method on graded meshes for nonlocal diffusion problems with weakly singular kernels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+M">Minghua Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Min%2C+C">Chao Min</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shi%2C+J">Jiankang Shi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+J">Jizeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Can graded meshes yield more accurate numerical solution than uniform meshes?
A time-dependent nonlocal diffusion problem with a weakly singular kernel is
considered using collocation method. For its steady-state counterpart, under
the sufficiently smooth solution, we first clarify that the standard graded
meshes are worse than uniform meshes and may even lead to divergence; instead,
an optimal convergence rate arises in so-called anomalous graded meshes.
Furthermore, under low regularity solutions, it may suffer from a severe order
reduction in (Chen, Qi, Shi and Wu, IMA J. Numer. Anal., 41 (2021) 3145--3174).
In this case, conversely, a sharp error estimates appears in standard graded
meshes, but offering far less than first-order accuracy. For the time-dependent
case, however, second-order convergence can be achieved on graded meshes. The
related analysis are easily extended for certain multidimensional problems.
Numerical results are provided that confirm the sharpness of the error
estimates.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17574 title=Abstract>arXiv:2401.17574</a> [<a href=https://arxiv.org/pdf/2401.17574 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17574 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scavenging Hyena: Distilling Transformers into Long Convolution Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ralambomihanta%2C+T+R">Tokiniaina Raharison Ralambomihanta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadzadeh%2C+S">Shahrad Mohammadzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+M+S+N">Mohammad Sami Nur Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jabbour%2C+W">Wassim Jabbour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+L">Laurence Liang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The rapid evolution of Large Language Models (LLMs), epitomized by
architectures like GPT-4, has reshaped the landscape of natural language
processing. This paper introduces a pioneering approach to address the
efficiency concerns associated with LLM pre-training, proposing the use of
knowledge distillation for cross-architecture transfer. Leveraging insights
from the efficient Hyena mechanism, our method replaces attention heads in
transformer models by Hyena, offering a cost-effective alternative to
traditional pre-training while confronting the challenge of processing long
contextual information, inherent in quadratic attention mechanisms. Unlike
conventional compression-focused methods, our technique not only enhances
inference speed but also surpasses pre-training in terms of both accuracy and
efficiency. In the era of evolving LLMs, our work contributes to the pursuit of
sustainable AI solutions, striking a balance between computational power and
environmental impact.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17577 title=Abstract>arXiv:2401.17577</a> [<a href=https://arxiv.org/pdf/2401.17577 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17577 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robustness in Wireless Distributed Learning: An Information-Theoretic Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yangshuo He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+G">Guanding Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In this paper, we take an information-theoretic approach to understand the
robustness in wireless distributed learning. Upon measuring the difference in
loss functions, we provide an upper bound of the performance deterioration due
to imperfect wireless channels. Moreover, we characterize the transmission rate
under task performance guarantees and propose the channel capacity gain
resulting from the inherent robustness in wireless distributed learning. An
efficient algorithm for approximating the derived upper bound is established
for practical use. The effectiveness of our results is illustrated by the
numerical simulations.
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17580 title=Abstract>arXiv:2401.17580</a> [<a href=https://arxiv.org/pdf/2401.17580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Contrastive Learning with Cohesive Subgraph Awareness
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yucheng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Leye Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+X">Xiao Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+H">Han-Jia Ye</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Graph contrastive learning (GCL) has emerged as a state-of-the-art strategy
for learning representations of diverse graphs including social and biomedical
networks. GCL widely uses stochastic graph topology augmentation, such as
uniform node dropping, to generate augmented graphs. However, such stochastic
augmentations may severely damage the intrinsic properties of a graph and
deteriorate the following representation learning process. We argue that
incorporating an awareness of cohesive subgraphs during the graph augmentation
and learning processes has the potential to enhance GCL performance. To this
end, we propose a novel unified framework called CTAug, to seamlessly integrate
cohesion awareness into various existing GCL mechanisms. In particular, CTAug
comprises two specialized modules: topology augmentation enhancement and graph
learning enhancement. The former module generates augmented graphs that
carefully preserve cohesion properties, while the latter module bolsters the
graph encoder's ability to discern subgraph patterns. Theoretical analysis
shows that CTAug can strictly improve existing GCL mechanisms. Empirical
experiments verify that CTAug can achieve state-of-the-art performance for
graph representation learning, especially for graphs with high degrees. The
code is available at https://doi.org/10.5281/zenodo.10594093, or
https://github.com/wuyucheng2002/CTAug.
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17581 title=Abstract>arXiv:2401.17581</a> [<a href=https://arxiv.org/pdf/2401.17581 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17581 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bitcoin Inscriptions: Foundations and Beyond
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+N">Ningran Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+M">Minfeng Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shiping Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 6 figures, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Bitcoin inscription marks a pivotal moment in blockchain technology. This
report presents a primary exploration of Bitcoin inscriptions. We dive into the
technological underpinnings and offer a detailed comparative analysis between
Bitcoin inscriptions and NFTs on other blockchains. Further, we explore a wide
range of use cases and significant opportunities for future innovation,
including inscription derivative protocols, Bitcoin Layer2 solutions, and
interoperability techniques.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17582 title=Abstract>arXiv:2401.17582</a> [<a href=https://arxiv.org/pdf/2401.17582 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17582 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> STAR: An Efficient Softmax Engine for Attention Model with RRAM Crossbar
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+Y">Yifeng Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Bonan Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jing Wang</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 Design, Automation &amp; Test in Europe Conference &amp; Exhibition
 (DATE)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>RRAM crossbars have been studied to construct in-memory accelerators for
neural network applications due to their in-situ computing capability. However,
prior RRAM-based accelerators show efficiency degradation when executing the
popular attention models. We observed that the frequent softmax operations
arise as the efficiency bottleneck and also are insensitive to computing
precision. Thus, we propose STAR, which boosts the computing efficiency with an
efficient RRAM-based softmax engine and a fine-grained global pipeline for the
attention models. Specifically, STAR exploits the versatility and flexibility
of RRAM crossbars to trade off the model accuracy and hardware efficiency. The
experimental results evaluated on several datasets show STAR achieves up to
30.63x and 1.31x computing efficiency improvements over the GPU and the
state-of-the-art RRAM-based attention accelerators, respectively.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17583 title=Abstract>arXiv:2401.17583</a> [<a href=https://arxiv.org/pdf/2401.17583 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17583 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+T">Tairan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+W">Wenli Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+G">Guanqi He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Changliu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+G">Guanya Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project website: <a href=https://agile-but-safe.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>Legged robots navigating cluttered environments must be jointly agile for
efficient task execution and safe to avoid collisions with obstacles or humans.
Existing studies either develop conservative controllers (&lt; 1.0 m/s) to ensure
safety, or focus on agility without considering potentially fatal collisions.
This paper introduces Agile But Safe (ABS), a learning-based control framework
that enables agile and collision-free locomotion for quadrupedal robots. ABS
involves an agile policy to execute agile motor skills amidst obstacles and a
recovery policy to prevent failures, collaboratively achieving high-speed and
collision-free navigation. The policy switch in ABS is governed by a learned
control-theoretic reach-avoid value network, which also guides the recovery
policy as an objective function, thereby safeguarding the robot in a closed
loop. The training process involves the learning of the agile policy, the
reach-avoid value network, the recovery policy, and an exteroception
representation network, all in simulation. These trained modules can be
directly deployed in the real world with onboard sensing and computation,
leading to high-speed and collision-free navigation in confined indoor and
outdoor spaces with both static and dynamic obstacles.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17585 title=Abstract>arXiv:2401.17585</a> [<a href=https://arxiv.org/pdf/2401.17585 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17585 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+W">Wenyue Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jiang Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+M">Mingwen Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Henghui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+P">Patrick Ng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhiguo Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 14 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)
</div>
<p class=mathjax>Current approaches of knowledge editing struggle to effectively propagate
updates to interconnected facts. In this work, we delve into the barriers that
hinder the appropriate propagation of updated knowledge within these models for
accurate reasoning. To support our analysis, we introduce a novel
reasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing
dataset) -- which covers six common reasoning schemes in real world. We conduct
a thorough analysis of existing knowledge editing techniques, including input
augmentation, finetuning, and locate-and-edit. We found that all model editing
methods show notably low performance on this dataset, especially in certain
reasoning schemes. Our analysis over the chain-of-thought generation of edited
models further uncover key reasons behind the inadequacy of existing knowledge
editing methods from a reasoning standpoint, involving aspects on fact-wise
editing, fact recall ability, and coherence in generation. We will make our
benchmark publicly available.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17588 title=Abstract>arXiv:2401.17588</a> [<a href=https://arxiv.org/pdf/2401.17588 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17588 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local and Global Contexts for Conversation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zuoquan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+X">Xinyi Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The context in conversation is the dialog history crucial for multi-turn
dialogue. Learning from the relevant contexts in dialog history for grounded
conversation is a challenging problem. Local context is the most neighbor and
more sensitive to the subsequent response, and global context is relevant to a
whole conversation far beyond neighboring utterances. Currently, pretrained
transformer models for conversation challenge capturing the correlation and
connection between local and global contexts. We introduce a local and global
conversation model (LGCM) for general-purpose conversation in open domain. It
is a local-global hierarchical transformer model that excels at accurately
discerning and assimilating the relevant contexts necessary for generating
responses. It employs a local encoder to grasp the local context at the level
of individual utterances and a global encoder to understand the broader context
at the dialogue level. The seamless fusion of these locally and globally
contextualized encodings ensures a comprehensive comprehension of the
conversation. Experiments on popular datasets show that LGCM outperforms the
existing conversation models on the performance of automatic metrics with
significant margins.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17591 title=Abstract>arXiv:2401.17591</a> [<a href=https://arxiv.org/pdf/2401.17591 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17591 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Agent Phase-Balancing around Polar Curves with Bounded Trajectories: An Experimental Study using Crazyflies and MoCap System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bhati%2C+G+S">Gaurav Singh Bhati</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sathvik%2C+K+S">KKN Shyam Sathvik</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Patil%2C+A">Anuj Patil</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jain%2C+A">Anoop Jain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this experimental work, we implement the control design from our earlier
work on a swarm of Crazyflie 2.1 quad-copters by deriving the original control
in terms of variables that are available to the user in this practical system.
A suitable model is developed using the Crazyswarm2 package within ROS2 to
facilitate the execution of the control law. We also discuss various components
that are part of this experiment and the challenges we encountered during the
experimentation. Extensive experimental results, along with the links to the
YouTube videos for actual Crazyflie quad-copters, are provided.
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17592 title=Abstract>arXiv:2401.17592</a> [<a href=https://arxiv.org/pdf/2401.17592 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17592 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Feature Matching Using Deep Learning: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+S">Shibiao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shunpeng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Rongtao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Changwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+P">Peng Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+L">Li Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Local feature matching enjoys wide-ranging applications in the realm of
computer vision, encompassing domains such as image retrieval, 3D
reconstruction, and object recognition. However, challenges persist in
improving the accuracy and robustness of matching due to factors like viewpoint
and lighting variations. In recent years, the introduction of deep learning
models has sparked widespread exploration into local feature matching
techniques. The objective of this endeavor is to furnish a comprehensive
overview of local feature matching methods. These methods are categorized into
two key segments based on the presence of detectors. The Detector-based
category encompasses models inclusive of Detect-then-Describe, Joint Detection
and Description, Describe-then-Detect, as well as Graph Based techniques. In
contrast, the Detector-free category comprises CNN Based, Transformer Based,
and Patch Based methods. Our study extends beyond methodological analysis,
incorporating evaluations of prevalent datasets and metrics to facilitate a
quantitative comparison of state-of-the-art techniques. The paper also explores
the practical application of local feature matching in diverse domains such as
Structure from Motion, Remote Sensing Image Registration, and Medical Image
Registration, underscoring its versatility and significance across various
fields. Ultimately, we endeavor to outline the current challenges faced in this
domain and furnish future research directions, thereby serving as a reference
for researchers involved in local feature matching and its interconnected
domains.
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17594 title=Abstract>arXiv:2401.17594</a> [<a href=https://arxiv.org/pdf/2401.17594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 5G NR Positioning Enhancements in 3GPP Release-18
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cha%2C+H">Hyun-Su Cha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+G">Gilsoo Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+A">Amitava Ghosh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baker%2C+M">Matthew Baker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kelley%2C+S">Sean Kelley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hofmann%2C+J">Juergen Hofmann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>New radio (NR) positioning in the Third Generation Partnership Project (3GPP)
Release 18 (Rel-18) enables 5G-advanced networks to achieve ultra-high accuracy
positioning without dependence on global navigation satellite systems (GNSS)
with key enablers such as the carrier phase positioning technique, standardized
for the first time in a cellular communications standard and setting a new
baseline for future generations. In addition, Rel-18 NR supports positioning
functionalities for reduced capability (RedCap) user equipment and bandwidth
aggregation for positioning measurements. Moreover, the low power solutions are
designed for low power high accuracy positioning use cases. Lastly,
sidelink-based positioning is introduced in Rel-18. This article constitutes a
comprehensive treatment of the Rel-18 NR positioning enhancements crucial for
the development of next-generation networks.
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17596 title=Abstract>arXiv:2401.17596</a> [<a href=https://arxiv.org/pdf/2401.17596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17596 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Interactive Empirical Approach to the Validation of Software Package Specifications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fraser%2C+S+D">S.D. Fraser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silvester%2C+P+P">P.P. Silvester</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>The objective of this research is the development of a practical system to
manipulate and validate software package specifications. The validation process
developed is based on consistency checks. Furthermore, by means of scenarios,
the customer will be able to interactively experience the specified system
prior to its implementation. Functions, data, and data types constitute the
framework of our validation system. The specification of the Graphical Kernel
System (GKS) is a typical example of the target software package specifications
to be manipulated.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17597 title=Abstract>arXiv:2401.17597</a> [<a href=https://arxiv.org/pdf/2401.17597 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17597 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+S">Sangwoo Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+K">Kaiqiang Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chao Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Multi-turn dialogues are characterized by their extended length and the
presence of turn-taking conversations. Traditional language models often
overlook the distinct features of these dialogues by treating them as regular
text. In this paper, we propose a speaker-enhanced pre-training method for long
dialogue summarization, which leverages the inherent structure of multiple-turn
dialogues. To support our study, we curate a diverse dataset that includes
transcripts from real-world scenarios, movie or TV show transcripts, and
dialogues generated by a Large Language Model. We then perform a pre-training,
which encompasses the detection of speaker changes, and masked utterance
generation. Experimental results of fine-tuned models demonstrate that our
model achieves state-of-the-art performance on downstream benchmarks with long
context, surpassing baseline models and highlighting the effectiveness of our
approach. Our findings highlight the importance of curating pre-training
datasets that exhibit diversity and variations in length distribution to ensure
effective alignment with downstream datasets.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17599 title=Abstract>arXiv:2401.17599</a> [<a href=https://arxiv.org/pdf/2401.17599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17599 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Graphics Function Standard Specification Validator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fraser%2C+S+D">Steven D. Fraser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silvester%2C+P+P">Peter P. Silvester</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>A validation methodology is proposed and implemented for natural language
software specifications of standard graphics functions. Checks are made for
consistency, completeness, and lack of ambiguity in data element and function
descriptions. Functions and data elements are maintained in a relational
database representation. The appropriate checks are performed by sequences of
database operations. The relational database manager INGRES was used to support
a prototype implementation of the proposed technique. The methodology supports
the development of a scenario-based prototype from the information available in
the specification. This permits various function sequences to be checked
without implementation of the environment specified. The application of a
prototype implementation of the proposed methodology to the specification of
the Graphics Kernel System (GKS) software package demonstrates the
practicability of the method. Several inconsistencies in GKS related to the
definition of data elements have been identified.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17600 title=Abstract>arXiv:2401.17600</a> [<a href=https://arxiv.org/pdf/2401.17600 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17600 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chenhui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sherrie Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 62 pages; work in progress
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Large Vision-Language Models (VLMs) have demonstrated impressive performance
on complex tasks involving visual input with natural language instructions.
However, it remains unclear to what extent capabilities on natural images
transfer to Earth observation (EO) data, which are predominantly satellite and
aerial images less common in VLM training data. In this work, we propose a
comprehensive benchmark to gauge the progress of VLMs toward being useful tools
for EO data by assessing their abilities on scene understanding, localization
and counting, and change detection tasks. Motivated by real-world applications,
our benchmark includes scenarios like urban monitoring, disaster relief, land
use, and conservation. We discover that, although state-of-the-art VLMs like
GPT-4V possess extensive world knowledge that leads to strong performance on
open-ended tasks like location understanding and image captioning, their poor
spatial reasoning limits usefulness on object localization and counting tasks.
Our benchmark will be made publicly available at https://vleo.danielz.ch/ and
on Hugging Face at
https://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70
for easy model evaluation.
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17602 title=Abstract>arXiv:2401.17602</a> [<a href=https://arxiv.org/pdf/2401.17602 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17602 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yuelyu Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zeshui Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In this study, we aim to address the task of assertion detection when
extracting medical concepts from clinical notes, a key process in clinical
natural language processing (NLP). Assertion detection in clinical NLP usually
involves identifying assertion types for medical concepts in the clinical text,
namely certainty (whether the medical concept is positive, negated, possible,
or hypothetical), temporality (whether the medical concept is for present or
the past history), and experiencer (whether the medical concept is described
for the patient or a family member). These assertion types are essential for
healthcare professionals to quickly and clearly understand the context of
medical conditions from unstructured clinical texts, directly influencing the
quality and outcomes of patient care. Although widely used, traditional
methods, particularly rule-based NLP systems and machine learning or deep
learning models, demand intensive manual efforts to create patterns and tend to
overlook less common assertion types, leading to an incomplete understanding of
the context. To address this challenge, our research introduces a novel
methodology that utilizes Large Language Models (LLMs) pre-trained on a vast
array of medical data for assertion detection. We enhanced the current method
with advanced reasoning techniques, including Tree of Thought (ToT), Chain of
Thought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank
Adaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010
assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11
improvements over the previous works. To further assess the generalizability of
our approach, we extended our evaluation to a local dataset that focused on
sleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31
higher than the previous method.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17603 title=Abstract>arXiv:2401.17603</a> [<a href=https://arxiv.org/pdf/2401.17603 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17603 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Topology-Aware Latent Diffusion for 3D Shape Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiangbei Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fei%2C+B">Ben Fei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+B">Baixin Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+F">Fei Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Weidong Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shengfa Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+N">Na Lei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+C">Chen Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Ying He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We introduce a new generative model that combines latent diffusion with
persistent homology to create 3D shapes with high diversity, with a special
emphasis on their topological characteristics. Our method involves representing
3D shapes as implicit fields, then employing persistent homology to extract
topological features, including Betti numbers and persistence diagrams. The
shape generation process consists of two steps. Initially, we employ a
transformer-based autoencoding module to embed the implicit representation of
each 3D shape into a set of latent vectors. Subsequently, we navigate through
the learned latent space via a diffusion model. By strategically incorporating
topological features into the diffusion process, our generative module is able
to produce a richer variety of 3D shapes with different topological structures.
Furthermore, our framework is flexible, supporting generation tasks constrained
by a variety of inputs, including sparse and partial point clouds, as well as
sketches. By modifying the persistence diagrams, we can alter the topology of
the shapes generated from these input modalities.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17604 title=Abstract>arXiv:2401.17604</a> [<a href=https://arxiv.org/pdf/2401.17604 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17604 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computation and Parameter Efficient Multi-Modal Fusion Transformer for Cued Speech Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by TASLP
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Cued Speech (CS) is a pure visual coding method used by hearing-impaired
people that combines lip reading with several specific hand shapes to make the
spoken language visible. Automatic CS recognition (ACSR) seeks to transcribe
visual cues of speech into text, which can help hearing-impaired people to
communicate effectively. The visual information of CS contains lip reading and
hand cueing, thus the fusion of them plays an important role in ACSR. However,
most previous fusion methods struggle to capture the global dependency present
in long sequence inputs of multi-modal CS data. As a result, these methods
generally fail to learn the effective cross-modal relationships that contribute
to the fusion. Recently, attention-based transformers have been a prevalent
idea for capturing the global dependency over the long sequence in multi-modal
fusion, but existing multi-modal fusion transformers suffer from both poor
recognition accuracy and inefficient computation for the ACSR task. To address
these problems, we develop a novel computation and parameter efficient
multi-modal fusion transformer by proposing a novel Token-Importance-Aware
Attention mechanism (TIAA), where a token utilization rate (TUR) is formulated
to select the important tokens from the multi-modal streams. More precisely,
TIAA firstly models the modality-specific fine-grained temporal dependencies
over all tokens of each modality, and then learns the efficient cross-modal
interaction for the modality-shared coarse-grained temporal dependencies over
the important tokens of different modalities. Besides, a light-weight gated
hidden projection is designed to control the feature flows of TIAA. The
resulting model, named Economical Cued Speech Fusion Transformer (EcoCued),
achieves state-of-the-art performance on all existing CS datasets, compared
with existing transformer-based fusion methods and ACSR fusion methods.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17605 title=Abstract>arXiv:2401.17605</a> [<a href=https://arxiv.org/pdf/2401.17605 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17605 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring Uni-manual Around Ear Off-Device Gestures for Earables
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shimon%2C+S+S+A">Shaikh Shawon Arefin Shimon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neshati%2C+A">Ali Neshati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J">Junwei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qiang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 15 figures, to be published in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Volume 8, Issue 1 (March 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Small form factor limits physical input space in earable (i.e., ear-mounted
wearable) devices. Off-device earable inputs in alternate mid-air and on-skin
around-ear interaction spaces using uni-manual gestures can address this input
space limitation. Segmenting these alternate interaction spaces to create
multiple gesture regions for reusing off-device gestures can expand earable
input vocabulary by a large margin. Although prior earable interaction research
has explored off-device gesture preferences and recognition techniques in such
interaction spaces, supporting gesture reuse over multiple gesture regions
needs further exploration. We collected and analyzed 7560 uni-manual gesture
motion data from 18 participants to explore earable gesture reuse by
segmentation of on-skin and mid-air spaces around the ear. Our results show
that gesture performance degrades significantly beyond 3 mid-air and 5 on-skin
around-ear gesture regions for different uni-manual gesture classes (e.g.,
swipe, pinch, tap). We also present qualitative findings on most and least
preferred regions (and associated boundaries) by end-users for different
uni-manual gesture shapes across both interaction spaces for earable devices.
Our results complement earlier elicitation studies and interaction technologies
for earables to help expand the gestural input vocabulary and potentially drive
future commercialization of such devices.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17606 title=Abstract>arXiv:2401.17606</a> [<a href=https://arxiv.org/pdf/2401.17606 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17606 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ambush from All Sides: Understanding Security Threats in Open-Source Software CI/CD Pipelines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+Z">Ziyue Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+W">Wenbo Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xingkai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yutian Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+R">Rui Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chengwei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+K">Kui Ren</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Dependable and Secure Computing (Volume: 21,
 Issue: 1, Jan.-Feb. 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The continuous integration and continuous deployment (CI/CD) pipelines are
widely adopted on Internet hosting platforms, such as GitHub. With the
popularity, the CI/CD pipeline faces various security threats. However, current
CI/CD pipelines suffer from malicious code and severe vulnerabilities. Even
worse, people have not been fully aware of its attack surfaces and the
corresponding impacts.
<br>Therefore, in this paper, we conduct a large-scale measurement and a
systematic analysis to reveal the attack surfaces of the CI/CD pipeline and
quantify their security impacts. Specifically, for the measurement, we collect
a data set of 320,000+ CI/CD pipeline-configured GitHub repositories and build
an analysis tool to parse the CI/CD pipelines and extract security-critical
usages. Besides, current CI/CD ecosystem heavily relies on several core
scripts, which may lead to a single point of failure. While the CI/CD pipelines
contain sensitive information/operations, making them the attacker's favorite
targets.
<br>Inspired by the measurement findings, we abstract the threat model and the
attack approach toward CI/CD pipelines, followed by a systematic analysis of
attack surfaces, attack strategies, and the corresponding impacts. We further
launch case studies on five attacks in real-world CI/CD environments to
validate the revealed attack surfaces. Finally, we give suggestions on
mitigating attacks on CI/CD scripts, including securing CI/CD configurations,
securing CI/CD scripts, and improving CI/CD infrastructure.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17609 title=Abstract>arXiv:2401.17609</a> [<a href=https://arxiv.org/pdf/2401.17609 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17609 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+R">Renyuan Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+X">Xinyue Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiachen Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+F">Feng Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Understanding road structures is crucial for autonomous driving. Intricate
road structures are often depicted using lane graphs, which include centerline
curves and connections forming a Directed Acyclic Graph (DAG). Accurate
extraction of lane graphs relies on precisely estimating vertex and edge
information within the DAG. Recent research highlights Transformer-based
language models' impressive sequence prediction abilities, making them
effective for learning graph representations when graph data are encoded as
sequences. However, existing studies focus mainly on modeling vertices
explicitly, leaving edge information simply embedded in the network.
Consequently, these approaches fall short in the task of lane graph extraction.
To address this, we introduce LaneGraph2Seq, a novel approach for lane graph
extraction. It leverages a language model with vertex-edge encoding and
connectivity enhancement. Our serialization strategy includes a vertex-centric
depth-first traversal and a concise edge-based partition sequence.
Additionally, we use classifier-free guidance combined with nucleus sampling to
improve lane connectivity. We validate our method on prominent datasets,
nuScenes and Argoverse 2, showcasing consistent and compelling results. Our
LaneGraph2Seq approach demonstrates superior performance compared to
state-of-the-art techniques in lane graph extraction.
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17611 title=Abstract>arXiv:2401.17611</a> [<a href=https://arxiv.org/pdf/2401.17611 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17611 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Estimating Diffusion Degree on Graph Streams
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gore%2C+V+R">Vinit Ramesh Gore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kundu%2C+S">Suman Kundu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pratiwi%2C+A+E">Anggy Eka Pratiwi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>The challenges of graph stream algorithms are twofold. First, each edge needs
to be processed only once, and second, it needs to work on highly constrained
memory. Diffusion degree is a measure of node centrality that can be calculated
(for all nodes) trivially for static graphs using a single Breadth-First Search
(BFS). However, keeping track of the Diffusion Degree in a graph stream is
nontrivial. The memory requirement for exact calculation is equivalent to
keeping the whole graph in memory. The present paper proposes an estimator (or
sketch) of diffusion degree for graph streams. We prove the correctness of the
proposed sketch and the upper bound of the estimated error. Given <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-83 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.69em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-84><span class=mi id=MathJax-Span-85 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-86 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-87 style=font-family:MathJax_Math-italic;padding-left:0.177em><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-88 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mo id=MathJax-Span-89 style=font-family:MathJax_Main;padding-left:0.292em>(</span><span class=mn id=MathJax-Span-90 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-91 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-92 style=font-family:MathJax_Main;padding-left:0.177em>1</span><span class=mo id=MathJax-Span-93 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, we achieve error below <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-94 style=width:7.121em;display:inline-block><span style=display:inline-block;position:relative;width:5.906em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1005.91em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-95><span class=mi id=MathJax-Span-96 style=font-family:MathJax_Math-italic></span><span class=mo id=MathJax-Span-97 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-98><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-99 style=font-family:MathJax_Math-italic>b</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mi id=MathJax-Span-100 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-101 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=msubsup id=MathJax-Span-102 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-103 style=font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-104 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-105 style=font-family:MathJax_Main>)</span><span class=msubsup id=MathJax-Span-106><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-107 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-108 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-109 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> in node
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-110 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-111><span class=mi id=MathJax-Span-112 style=font-family:MathJax_Math-italic>u</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> with probability <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-113 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-114><span class=mn id=MathJax-Span-115 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-116 style=font-family:MathJax_Main;padding-left:0.234em></span><span class=mi id=MathJax-Span-117 style=font-family:MathJax_Math-italic;padding-left:0.234em><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> by utilizing
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-118 style=width:6.253em;display:inline-block><span style=display:inline-block;position:relative;width:5.211em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1005.1em,2.839em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-119><span class=mi id=MathJax-Span-120 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-121 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-122 style=font-family:MathJax_Math-italic>n</span><span class=mfrac id=MathJax-Span-123><span style=display:inline-block;position:relative;width:0.697em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-124 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1000.58em,4.17em,-999.997em);top:-3.527em;left:50%;margin-left:-0.286em><span class=msubsup id=MathJax-Span-125><span style=display:inline-block;position:relative;width:0.582em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-126 style=font-size:70.7%;font-family:MathJax_Math-italic></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.222em;left:0.292em><span class=mn id=MathJax-Span-127 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.7em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.697em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mi id=MathJax-Span-128 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-129></span><span class=texatom id=MathJax-Span-130 style=padding-left:0.177em><span class=mrow id=MathJax-Span-131><span class=mfrac id=MathJax-Span-132><span style=display:inline-block;position:relative;width:0.466em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.29em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-133 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mi id=MathJax-Span-134 style=font-size:70.7%;font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.47em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.466em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span></span><span class=mo id=MathJax-Span-135 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.622em;border-left:0px solid;width:0px;height:1.74em"></span></span></nobr></span> space, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-136 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.93em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-137><span class=msubsup id=MathJax-Span-138><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-139 style=font-family:MathJax_Math-italic>b</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.408em><span class=mi id=MathJax-Span-140 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-141 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-142><span class=msubsup id=MathJax-Span-143><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-144 style=font-family:MathJax_Math-italic>a</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-145 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span> are
the maximum and minimum degrees of neighbors of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-146 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-147><span class=mi id=MathJax-Span-148 style=font-family:MathJax_Math-italic>u</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-149 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-150><span class=mi id=MathJax-Span-151 style=font-family:MathJax_Math-italic></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is diffusion
probability, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-152 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-153><span class=msubsup id=MathJax-Span-154><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-155 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-156 style=font-size:70.7%;font-family:MathJax_Math-italic>u</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> is the degree of node <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-157 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-158><span class=mi id=MathJax-Span-159 style=font-family:MathJax_Math-italic>u</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. With the help of this sketch,
we propose an algorithm to extract the top-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-160 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-161><span class=mi id=MathJax-Span-162 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> influencing nodes in the graph
stream. Comparative experiments show that the spread of top-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-163 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-164><span class=mi id=MathJax-Span-165 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> nodes by the
proposed graph stream algorithm is equivalent to or better than the spread of
top-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-166 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-167><span class=mi id=MathJax-Span-168 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> nodes extracted by the exact algorithm.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17612 title=Abstract>arXiv:2401.17612</a> [<a href=https://arxiv.org/pdf/2401.17612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IGCN: Integrative Graph Convolutional Networks for Multi-modal Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ozdemir%2C+C">Cagri Ozdemir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olaimat%2C+M+A">Mohammad Al Olaimat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vashishath%2C+Y">Yashu Vashishath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bozdag%2C+S">Serdar Bozdag</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Initiative%2C+A+D+N">Alzheimer's Disease Neuroimaging Initiative</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recent advances in Graph Neural Networks (GNN) have led to a considerable
growth in graph data modeling for multi-modal data which contains various types
of nodes and edges. Although some integrative prediction solutions have been
developed recently for network-structured data, these methods have some
restrictions. For a node classification task involving multi-modal data,
certain data modalities may perform better when predicting one class, while
others might excel in predicting a different class. Thus, to obtain a better
learning representation, advanced computational methodologies are required for
the integrative analysis of multi-modal data. Moreover, existing integrative
tools lack a comprehensive and cohesive understanding of the rationale behind
their specific predictions, making them unsuitable for enhancing model
interpretability. Addressing these restrictions, we introduce a novel
integrative neural network approach for multi-modal data networks, named
Integrative Graph Convolutional Networks (IGCN). IGCN learns node embeddings
from multiple topologies and fuses the multiple node embeddings into a weighted
form by assigning attention coefficients to the node embeddings. Our proposed
attention mechanism helps identify which types of data receive more emphasis
for each sample to predict a certain class. Therefore, IGCN has the potential
to unravel previously unknown characteristics within different node
classification tasks. We benchmarked IGCN on several datasets from different
domains, including a multi-omics dataset to predict cancer subtypes and a
multi-modal clinical dataset to predict the progression of Alzheimer's disease.
Experimental results show that IGCN outperforms or is on par with the
state-of-the-art and baseline methods.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17615 title=Abstract>arXiv:2401.17615</a> [<a href=https://arxiv.org/pdf/2401.17615 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17615 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Multi-Similarity Learning for Molecular Property Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+H">Hao Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>Effective molecular representation learning is essential for molecular
property prediction. Contrastive learning, a prominent self-supervised approach
for molecular representation learning, relies on establishing positive and
negative pairs. However, this binary similarity categorization oversimplifies
the nature of complex molecular relationships and overlooks the degree of
relative similarities among molecules, posing challenges to the effectiveness
and generality of representation learning. In response to this challenge, we
propose the Graph Multi-Similarity Learning for Molecular Property Prediction
(GraphMSL) framework. GraphMSL incorporates a generalized multi-similarity
metric in a continuous scale, capturing self-similarity and relative
similarities. The unimodal multi-similarity metrics are derived from various
chemical modalities, and the fusion of these metrics into a multimodal form
significantly enhances the effectiveness of GraphMSL. In addition, the
flexibility of fusion function can reshape the focus of the model to convey
different chemical semantics. GraphMSL proves effective in drug discovery
evaluations through various downstream tasks and post-hoc analysis of learnt
representations. Its notable performance suggests significant potential for the
exploration of new drug candidates.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17617 title=Abstract>arXiv:2401.17617</a> [<a href=https://arxiv.org/pdf/2401.17617 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17617 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unveiling the Power of Self-supervision for Multi-view Multi-human Association and Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+W">Wei Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Feifan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+R">Ruize Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Z">Zekun Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Multi-view multi-human association and tracking (MvMHAT), is a new but
important problem for multi-person scene video surveillance, aiming to track a
group of people over time in each view, as well as to identify the same person
across different views at the same time, which is different from previous MOT
and multi-camera MOT tasks only considering the over-time human tracking. This
way, the videos for MvMHAT require more complex annotations while containing
more information for self learning. In this work, we tackle this problem with a
self-supervised learning aware end-to-end network. Specifically, we propose to
take advantage of the spatial-temporal self-consistency rationale by
considering three properties of reflexivity, symmetry and transitivity. Besides
the reflexivity property that naturally holds, we design the self-supervised
learning losses based on the properties of symmetry and transitivity, for both
appearance feature learning and assignment matrix optimization, to associate
the multiple humans over time and across views. Furthermore, to promote the
research on MvMHAT, we build two new large-scale benchmarks for the network
training and testing of different algorithms. Extensive experiments on the
proposed benchmarks verify the effectiveness of our method. We have released
the benchmark and code to the public.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17618 title=Abstract>arXiv:2401.17618</a> [<a href=https://arxiv.org/pdf/2401.17618 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17618 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Control: Exploring Novel File System Objects for Data-Only Attacks on Linux Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jinmeng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiayi Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+Z">Ziyue Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jiaxun Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guoren Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+W">Wenbo Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sui%2C+Y">Yulei Sui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Z">Zhiyun Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, in submission of the 31th ACM Conference on Computer and Communications Security (CCS), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS)
</div>
<p class=mathjax>The widespread deployment of control-flow integrity has propelled non-control
data attacks into the mainstream. In the domain of OS kernel exploits, by
corrupting critical non-control data, local attackers can directly gain root
access or privilege escalation without hijacking the control flow. As a result,
OS kernels have been restricting the availability of such non-control data.
This forces attackers to continue to search for more exploitable non-control
data in OS kernels. However, discovering unknown non-control data can be
daunting because they are often tied heavily to semantics and lack universal
patterns.
<br>We make two contributions in this paper: (1) discover critical non-control
objects in the file subsystem and (2) analyze their exploitability. This work
represents the first study, with minimal domain knowledge, to
semi-automatically discover and evaluate exploitable non-control data within
the file subsystem of the Linux kernel. Our solution utilizes a custom analysis
and testing framework that statically and dynamically identifies promising
candidate objects. Furthermore, we categorize these discovered objects into
types that are suitable for various exploit strategies, including a novel
strategy necessary to overcome the defense that isolates many of these objects.
These objects have the advantage of being exploitable without requiring KASLR,
thus making the exploits simpler and more reliable. We use 18 real-world CVEs
to evaluate the exploitability of the file system objects using various exploit
strategies. We develop 10 end-to-end exploits using a subset of CVEs against
the kernel with all state-of-the-art mitigations enabled.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17619 title=Abstract>arXiv:2401.17619</a> [<a href=https://arxiv.org/pdf/2401.17619 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17619 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and KiSing-v2
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiatong Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+X">Xinyi Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Keyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuning Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yuxun Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yifeng Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qin Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>In singing voice synthesis (SVS), generating singing voices from musical
scores faces challenges due to limited data availability, a constraint less
common in text-to-speech (TTS). This study proposes a new approach to address
this data scarcity. We utilize an existing singing voice synthesizer for data
augmentation and apply precise manual tuning to reduce unnatural voice
synthesis. Our development of two extensive singing voice corpora, ACE-Opencpop
and KiSing-v2, facilitates large-scale, multi-singer voice synthesis. Utilizing
pre-trained models derived from these corpora, we achieve notable improvements
in voice quality, evident in both in-domain and out-of-domain scenarios. The
corpora, pre-trained models, and their related training recipes are publicly
available at Muskits-ESPnet (https://github.com/espnet/espnet).
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17622 title=Abstract>arXiv:2401.17622</a> [<a href=https://arxiv.org/pdf/2401.17622 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17622 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Commit Messages in the Age of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lopes%2C+C+V">Cristina V. Lopes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klotzman%2C+V+I">Vanessa I. Klotzman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+I">Iris Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+I">Iftekar Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to FSE 23 on Feb 6 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Commit messages are explanations of changes made to a codebase that are
stored in version control systems. They help developers understand the codebase
as it evolves. However, writing commit messages can be tedious and inconsistent
among developers. To address this issue, researchers have tried using different
methods to automatically generate commit messages, including rule-based,
retrieval-based, and learning-based approaches. Advances in large language
models offer new possibilities for generating commit messages. In this study,
we evaluate the performance of OpenAI's ChatGPT for generating commit messages
based on code changes. We compare the results obtained with ChatGPT to previous
automatic commit message generation methods that have been trained specifically
on commit data. Our goal is to assess the extent to which large pre-trained
language models can generate commit messages that are both quantitatively and
qualitatively acceptable. We found that ChatGPT was able to outperform previous
Automatic Commit Message Generation (ACMG) methods by orders of magnitude, and
that, generally, the messages it generates are both accurate and of
high-quality. We also provide insights, and a categorization, for the cases
where it fails.
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17623 title=Abstract>arXiv:2401.17623</a> [<a href=https://arxiv.org/pdf/2401.17623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neighboring Perturbations of Knowledge Editing on Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jun-Yu Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+J">Jia-Chen Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+Z">Zhen-Hua Ling</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Despite their exceptional capabilities, large language models (LLMs) are
prone to generating unintended text due to false or outdated knowledge. Given
the resource-intensive nature of retraining LLMs, there has been a notable
increase in the development of knowledge editing. However, current approaches
and evaluations rarely explore the perturbation of editing on neighboring
knowledge. This paper studies whether updating new knowledge to LLMs perturbs
the neighboring knowledge encapsulated within them. Specifically, we seek to
figure out whether appending a new answer into an answer list to a factual
question leads to catastrophic forgetting of original correct answers in this
list, as well as unintentional inclusion of incorrect answers. A metric of
additivity is introduced and a benchmark dubbed as Perturbation Evaluation of
Appending Knowledge (PEAK) is constructed to evaluate the degree of
perturbation to neighboring knowledge when appending new knowledge. Besides, a
plug-and-play framework termed Appending via Preservation and Prevention (APP)
is proposed to mitigate the neighboring perturbation by maintaining the
integrity of the answer list. Experiments demonstrate the effectiveness of APP
coupling with four editing methods on three LLMs.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17626 title=Abstract>arXiv:2401.17626</a> [<a href=https://arxiv.org/pdf/2401.17626 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17626 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17626 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI to Generate Test Data Generators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baudry%2C+B">Benoit Baudry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Etemadi%2C+K">Khashayar Etemadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+S">Sen Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gamage%2C+Y">Yogya Gamage</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuxin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Monperrus%2C+M">Martin Monperrus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ron%2C+J">Javier Ron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+A">Andr Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiwari%2C+D">Deepika Tiwari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Generating fake data is an essential dimension of modern software testing, as
demonstrated by the number and significance of data faking libraries. Yet,
developers of faking libraries cannot keep up with the wide range of data to be
generated for different natural languages and domains. In this paper, we assess
the ability of generative AI for generating test data in different domains. We
design three types of prompts for Large Language Models (LLMs), which perform
test data generation tasks at different levels of integrability: 1) raw test
data generation, 2) synthesizing programs in a specific language that generate
useful test data, and 3) producing programs that use state-of-the-art faker
libraries. We evaluate our approach by prompting LLMs to generate test data for
11 domains. The results show that LLMs can successfully generate realistic test
data generators in a wide range of domains at all three levels of
integrability.
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17628 title=Abstract>arXiv:2401.17628</a> [<a href=https://arxiv.org/pdf/2401.17628 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17628 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+J">Jiankai Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chuengsatiansup%2C+C">Chitchanok Chuengsatiansup</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murray%2C+T">Toby Murray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rubinstein%2C+B+I+P">Benjamin I. P. Rubinstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yarom%2C+Y">Yuval Yarom</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohrimenko%2C+O">Olga Ohrimenko</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Current implementations of differentially-private (DP) systems either lack
support to track the global privacy budget consumed on a dataset, or fail to
faithfully maintain the state continuity of this budget. We show that failure
to maintain a privacy budget enables an adversary to mount replay, rollback and
fork attacks - obtaining answers to many more queries than what a secure system
would allow. As a result the attacker can reconstruct secret data that DP aims
to protect - even if DP code runs in a Trusted Execution Environment (TEE). We
propose ElephantDP, a system that aims to provide the same guarantees as a
trusted curator in the global DP model would, albeit set in an untrusted
environment. Our system relies on a state continuity module to provide
protection for the privacy budget and a TEE to faithfully execute DP code and
update the budget. To provide security, our protocol makes several design
choices including the content of the persistent state and the order between
budget updates and query answers. We prove that ElephantDP provides liveness
(i.e., the protocol can restart from a correct state and respond to queries as
long as the budget is not exceeded) and DP confidentiality (i.e., an attacker
learns about a dataset as much as it would from interacting with a trusted
curator). Our implementation and evaluation of the protocol use Intel SGX as a
TEE to run the DP code and a network of TEEs to maintain state continuity.
Compared to an insecure baseline, we observe only 1.1-2<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-169 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-170><span class=mo id=MathJax-Span-171 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> overheads and
lower relative overheads for larger datasets and complex DP queries.
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17629 title=Abstract>arXiv:2401.17629</a> [<a href=https://arxiv.org/pdf/2401.17629 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17629 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spatial-and-Frequency-aware Restoration method for Images based on Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K">Kyungsung Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Donggyu Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+M">Myungjoo Kang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Diffusion models have recently emerged as a promising framework for Image
Restoration (IR), owing to their ability to produce high-quality
reconstructions and their compatibility with established methods. Existing
methods for solving noisy inverse problems in IR, considers the pixel-wise
data-fidelity. In this paper, we propose SaFaRI, a spatial-and-frequency-aware
diffusion model for IR with Gaussian noise. Our model encourages images to
preserve data-fidelity in both the spatial and frequency domains, resulting in
enhanced reconstruction quality. We comprehensively evaluate the performance of
our model on a variety of noisy inverse problems, including inpainting,
denoising, and super-resolution. Our thorough evaluation demonstrates that
SaFaRI achieves state-of-the-art performance on both the ImageNet datasets and
FFHQ datasets, outperforming existing zero-shot IR methods in terms of LPIPS
and FID metrics.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17630 title=Abstract>arXiv:2401.17630</a> [<a href=https://arxiv.org/pdf/2401.17630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Personalized Privacy: User-Governed Data Contribution for Federated Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+L">Liang Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+W">Wei Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Ruiqi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Lizhen Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Federated recommender systems (FedRecs) have gained significant attention for
their potential to protect user's privacy by keeping user privacy data locally
and only communicating model parameters/gradients to the server. Nevertheless,
the currently existing architecture of FedRecs assumes that all users have the
same 0-privacy budget, i.e., they do not upload any data to the server, thus
overlooking those users who are less concerned about privacy and are willing to
upload data to get a better recommendation service. To bridge this gap, this
paper explores a user-governed data contribution federated recommendation
architecture where users are free to take control of whether they share data
and the proportion of data they share to the server. To this end, this paper
presents a cloud-device collaborative graph neural network federated
recommendation model, named CDCGNNFed. It trains user-centric ego graphs
locally, and high-order graphs based on user-shared data in the server in a
collaborative manner via contrastive learning. Furthermore, a graph mending
strategy is utilized to predict missing links in the graph on the server, thus
leveraging the capabilities of graph neural networks over high-order graphs.
Extensive experiments were conducted on two public datasets, and the results
demonstrate the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17632 title=Abstract>arXiv:2401.17632</a> [<a href=https://arxiv.org/pdf/2401.17632 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17632 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ashihara%2C+T">Takanori Ashihara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delcroix%2C+M">Marc Delcroix</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moriya%2C+T">Takafumi Moriya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matsuura%2C+K">Kohei Matsuura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asami%2C+T">Taichi Asami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ijima%2C+Y">Yusuke Ijima</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Self-supervised learning (SSL) has attracted increased attention for learning
meaningful speech representations. Speech SSL models, such as WavLM, employ
masked prediction training to encode general-purpose representations. In
contrast, speaker SSL models, exemplified by DINO-based models, adopt
utterance-level training objectives primarily for speaker representation.
Understanding how these models represent information is essential for refining
model efficiency and effectiveness. Unlike the various analyses of speech SSL,
there has been limited investigation into what information speaker SSL captures
and how its representation differs from speech SSL or other fully-supervised
speaker models. This paper addresses these fundamental questions. We explore
the capacity to capture various speech properties by applying SUPERB evaluation
probing tasks to speech and speaker SSL models. We also examine which layers
are predominantly utilized for each task to identify differences in how speech
is represented. Furthermore, we conduct direct comparisons to measure the
similarities between layers within and across models. Our analysis unveils that
1) the capacity to represent content information is somewhat unrelated to
enhanced speaker representation, 2) specific layers of speech SSL models would
be partly specialized in capturing linguistic information, and 3) speaker SSL
models tend to disregard linguistic information but exhibit more sophisticated
speaker representation.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17633 title=Abstract>arXiv:2401.17633</a> [<a href=https://arxiv.org/pdf/2401.17633 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17633 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Navigating the OverKill in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+C">Chenyu Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Q">Qiming Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Songyang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xianjun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gui%2C+T">Tao Gui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xun Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large language models are meticulously aligned to be both helpful and
harmless. However, recent research points to a potential overkill which means
models may refuse to answer benign queries. In this paper, we investigate the
factors for overkill by exploring how models handle and determine the safety of
queries. Our findings reveal the presence of shortcuts within models, leading
to an over-attention of harmful words like 'kill' and prompts emphasizing
safety will exacerbate overkill. Based on these insights, we introduce
Self-Contrastive Decoding (Self-CD), a training-free and model-agnostic
strategy, to alleviate this phenomenon. We first extract such over-attention by
amplifying the difference in the model's output distributions when responding
to system prompts that either include or omit an emphasis on safety. Then we
determine the final next-token predictions by downplaying the over-attention
from the model via contrastive decoding. Empirical results indicate that our
method has achieved an average reduction of the refusal rate by 20\% while
having almost no impact on safety.
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17642 title=Abstract>arXiv:2401.17642</a> [<a href=https://arxiv.org/pdf/2401.17642 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17642 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hanyu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoyue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+W">Wending Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+Y">Yuxing Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhiwei Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+L">Luxin Yan</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Conference on Learning Representations (ICLR), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We investigate a challenging task of nighttime optical flow, which suffers
from weakened texture and amplified noise. These degradations weaken
discriminative visual features, thus causing invalid motion feature matching.
Typically, existing methods employ domain adaptation to transfer knowledge from
auxiliary domain to nighttime domain in either input visual space or output
motion space. However, this direct adaptation is ineffective, since there
exists a large domain gap due to the intrinsic heterogeneous nature of the
feature representations between auxiliary and nighttime domains. To overcome
this issue, we explore a common-latent space as the intermediate bridge to
reinforce the feature alignment between auxiliary and nighttime domains. In
this work, we exploit two auxiliary daytime and event domains, and propose a
novel common appearance-boundary adaptation framework for nighttime optical
flow. In appearance adaptation, we employ the intrinsic image decomposition to
embed the auxiliary daytime image and the nighttime image into a
reflectance-aligned common space. We discover that motion distributions of the
two reflectance maps are very similar, benefiting us to consistently transfer
motion appearance knowledge from daytime to nighttime domain. In boundary
adaptation, we theoretically derive the motion correlation formula between
nighttime image and accumulated events within a spatiotemporal gradient-aligned
common space. We figure out that the correlation of the two spatiotemporal
gradient maps shares significant discrepancy, benefitting us to contrastively
transfer boundary knowledge from event to nighttime domain. Moreover,
appearance adaptation and boundary adaptation are complementary to each other,
since they could jointly transfer global motion and local boundary knowledge to
the nighttime domain.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17644 title=Abstract>arXiv:2401.17644</a> [<a href=https://arxiv.org/pdf/2401.17644 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17644 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Efficient and Reliable LLM Serving: A Real-World Workload Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zeyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zhenheng Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+R">Rui Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A+C">Amelie Chi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+X">Xiaowen Chu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Large language models (LLMs), especially Generative Pretrained Transformer
(GPT) models, have significantly advanced in the industry in recent years.
However, these models' broader development faces considerable challenges due to
high operational and deployment costs. This has led to active research in
improving the hardware efficiency of LLMs. Yet, the characteristics of
real-world LLM workloads are often overlooked in current optimizations of LLM
serving systems. In this work, we find that the absence of reliable workload
data for evaluating LLM serving systems impacts the quality of service (QoS)
and reliability in industrial deployments. This paper introduces the first
real-world trace dataset of LLM serving workloads, detailing user, system, and
LLM behaviors. We analyze this trace, highlighting burstiness, request and
response distributions, and focusing on the reliability of GPT services. Based
on this, we have developed a benchmark suite that reflects our dataset's
workload patterns, enabling performance evaluation of serving systems. This
suite captures the core patterns of workload distributions, allowing for
precise scaling of the workload dataset to match system sizes. Our evaluation
uncovers a previously unrecognized vulnerability of LLM serving systems to
short-term burstiness, particularly in common workload scenarios. We observe
that GPU memory limitations, caused by the fluctuating nature of burstiness,
lead to significant performance degradation in existing LLM serving systems.
Beyond benchmarking, understanding these patterns is valuable for optimizing
LLM workload management, enabling elastic hardware resource adjustments to
varying workloads. We will make the dataset and benchmark suite publicly
available to encourage further research.
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17645 title=Abstract>arXiv:2401.17645</a> [<a href=https://arxiv.org/pdf/2401.17645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+S">Shengyao Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Federated search, which involves integrating results from multiple
independent search engines, will become increasingly pivotal in the context of
Retrieval-Augmented Generation pipelines empowering LLM-based applications such
as chatbots. These systems often distribute queries among various search
engines, ranging from specialized (e.g., PubMed) to general (e.g., Google),
based on the nature of user utterances. A critical aspect of federated search
is resource selection - the selection of appropriate resources prior to issuing
the query to ensure high-quality and rapid responses, and contain costs
associated with calling the external search engines. However, current SOTA
resource selection methodologies primarily rely on feature-based learning
approaches. These methods often involve the labour intensive and expensive
creation of training labels for each resource. In contrast, LLMs have exhibited
strong effectiveness as zero-shot methods across NLP and IR tasks. We
hypothesise that in the context of federated search LLMs can assess the
relevance of resources without the need for extensive predefined labels or
features. In this paper, we propose ReSLLM. Our ReSLLM method exploits LLMs to
drive the selection of resources in federated search in a zero-shot setting. In
addition, we devise an unsupervised fine tuning protocol, the Synthetic Label
Augmentation Tuning (SLAT), where the relevance of previously logged queries
and snippets from resources is predicted using an off-the-shelf LLM and then in
turn used to fine-tune ReSLLM with respect to resource selection. Our empirical
evaluation and analysis details the factors influencing the effectiveness of
LLMs in this context. The results showcase the merits of ReSLLM for resource
selection: not only competitive effectiveness in the zero-shot setting, but
also obtaining large when fine-tuned using SLAT-protocol.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17649 title=Abstract>arXiv:2401.17649</a> [<a href=https://arxiv.org/pdf/2401.17649 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17649 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Covering All Bases: The Next Inning in DNA Sequencing Efficiency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abraham%2C+H">Hadas Abraham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabrys%2C+R">Rayn Gabrys</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>DNA emerges as a promising medium for the exponential growth of digital data
due to its density and durability. This study extends recent research by
addressing the \emph{coverage depth problem} in practical scenarios, exploring
optimal error-correcting code pairings with DNA storage systems to minimize
coverage depth. Conducted within random access settings, the study provides
theoretical analyses and experimental simulations to examine the expectation
and probability distribution of samples needed for files recovery. Structured
into sections covering definitions, analyses, lower bounds, and comparative
evaluations of coding schemes, the paper unveils insights into effective coding
schemes for optimizing DNA storage systems.
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17653 title=Abstract>arXiv:2401.17653</a> [<a href=https://arxiv.org/pdf/2401.17653 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17653 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17653 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A primer on synthetic health data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartell%2C+J+A">Jennifer Anne Bartell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valentin%2C+S+B">Sander Boisen Valentin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krogh%2C+A">Anders Krogh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langberg%2C+H">Henning Langberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%B8gsted%2C+M">Martin Bgsted</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recent advances in deep generative models have greatly expanded the potential
to create realistic synthetic health datasets. These synthetic datasets aim to
preserve the characteristics, patterns, and overall scientific conclusions
derived from sensitive health datasets without disclosing patient identity or
sensitive information. Thus, synthetic data can facilitate safe data sharing
that supports a range of initiatives including the development of new
predictive models, advanced health IT platforms, and general project ideation
and hypothesis development. However, many questions and challenges remain,
including how to consistently evaluate a synthetic dataset's similarity and
predictive utility in comparison to the original real dataset and risk to
privacy when shared. Additional regulatory and governance issues have not been
widely addressed. In this primer, we map the state of synthetic health data,
including generation and evaluation methods and tools, existing examples of
deployment, the regulatory and ethical landscape, access and governance
options, and opportunities for further development.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17654 title=Abstract>arXiv:2401.17654</a> [<a href=https://arxiv.org/pdf/2401.17654 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17654 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> All Beings Are Equal in Open Set Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chaohua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+E">Enhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+C">Chuanxing Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">SongCan Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by the main track The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In open-set recognition (OSR), a promising strategy is exploiting
pseudo-unknown data outside given <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-172 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-173><span class=mi id=MathJax-Span-174 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> known classes as an additional <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-175 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-176><span class=mi id=MathJax-Span-177 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>+<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-178 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-179><span class=mn id=MathJax-Span-180 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-th
class to explicitly model potential open space. However, treating unknown
classes without distinction is unequal for them relative to known classes due
to the category-agnostic and scale-agnostic of the unknowns. This inevitably
not only disrupts the inherent distributions of unknown classes but also incurs
both class-wise and instance-wise imbalances between known and unknown classes.
Ideally, the OSR problem should model the whole class space as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-181 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-182><span class=mi id=MathJax-Span-183 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>+<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-184 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-185><span class=mi id=MathJax-Span-186 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>,
but enumerating all unknowns is impractical. Since the core of OSR is to
effectively model the boundaries of known classes, this means just focusing on
the unknowns nearing the boundaries of targeted known classes seems sufficient.
Thus, as a compromise, we convert the open classes from infinite to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-187 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-188><span class=mi id=MathJax-Span-189 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, with a
novel concept Target-Aware Universum (TAU) and propose a simple yet effective
framework Dual Contrastive Learning with Target-Aware Universum (DCTAU). In
details, guided by the targeted known classes, TAU automatically expands the
unknown classes from the previous <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-190 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-191><span class=mn id=MathJax-Span-192 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-193 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-194><span class=mi id=MathJax-Span-195 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, effectively alleviating the
distribution disruption and the imbalance issues mentioned above. Then, a novel
Dual Contrastive (DC) loss is designed, where all instances irrespective of
known or TAU are considered as positives to contrast with their respective
negatives. Experimental results indicate DCTAU sets a new state-of-the-art.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17657 title=Abstract>arXiv:2401.17657</a> [<a href=https://arxiv.org/pdf/2401.17657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17657 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An attempt to generate new bridge types from latent space of energy-based model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Use energy-based model for bridge-type innovation. The loss function is
explained by the game theory, the logic is clear and the formula is simple and
clear. Thus avoid the use of maximum likelihood estimation to explain the loss
function and eliminate the need for Monte Carlo methods to solve the normalized
denominator. Assuming that the bridge-type population follows a Boltzmann
distribution, a neural network is constructed to represent the energy function.
Use Langevin dynamics technology to generate a new sample with low energy
value, thus a generative model of bridge-type based on energy is established.
Train energy function on symmetric structured image dataset of three span beam
bridge, arch bridge, cable-stayed bridge, and suspension bridge to accurately
calculate the energy values of real and fake samples. Sampling from latent
space, using gradient descent algorithm, the energy function transforms the
sampling points into low energy score samples, thereby generating new bridge
types different from the dataset. Due to unstable and slow training in this
attempt, the possibility of generating new bridge types is rare and the image
definition of generated images is low.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17658 title=Abstract>arXiv:2401.17658</a> [<a href=https://arxiv.org/pdf/2401.17658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Document Structure in Long Document Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buchmann%2C+J">Jan Buchmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eichler%2C+M">Max Eichler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bodensohn%2C+J">Jan-Micha Bodensohn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuznetsov%2C+I">Ilia Kuznetsov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at EACL 2024. Code and data: <a href=http://github.com/UKPLab/eacl2024-doc-structure>this http URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Long documents often exhibit structure with hierarchically organized elements
of different functions, such as section headers and paragraphs. Despite the
omnipresence of document structure, its role in natural language processing
(NLP) remains opaque. Do long-document Transformer models acquire an internal
representation of document structure during pre-training? How can structural
information be communicated to a model after pre-training, and how does it
influence downstream performance? To answer these questions, we develop a novel
suite of probing tasks to assess structure-awareness of long-document
Transformers, propose general-purpose structure infusion methods, and evaluate
the effects of structure infusion on QASPER and Evidence Inference, two
challenging long-document NLP tasks. Results on LED and LongT5 suggest that
they acquire implicit understanding of document structure during pre-training,
which can be further enhanced by structure infusion, leading to improved
end-task performance. To foster research on the role of document structure in
NLP modeling, we make our data and code publicly available.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17661 title=Abstract>arXiv:2401.17661</a> [<a href=https://arxiv.org/pdf/2401.17661 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17661 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ram%C3%ADrez-Dur%C3%A1n%2C+V+J">Vctor Julio Ramrez-Durn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berges%2C+I">Idoia Berges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted version of paper: V\'ictor Julio Ram\'irez-Dur\'an, Idoia Berges, Arantza Illarramendi: Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle. Comput. Ind. 126: 103403 (2021). DOI: 10.1016/j.compind.2021.103403
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Comput. Ind. 126: 103403 (2021)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Many different worldwide initiatives are promoting the transformation from
machine dominant manufacturing to digital manufacturing. Thus, to achieve a
successful transformation to Industry 4.0 standard, manufacturing enterprises
are required to implement a clear roadmap. However, Small and Medium
Manufacturing Enterprises (SMEs) encounter many barriers and difficulties
(economical, technical, cultural, etc.) in the implementation of Industry 4.0.
Although several works deal with the incorporation of Industry 4.0 technologies
in the area of the product and supply chain life cycles, which SMEs could use
as reference, this is not the case for the customer life cycle. Thus, we
present two contributions that can help the software engineers of those SMEs to
incorporate Industry 4.0 technologies in the context of the customer life
cycle. The first contribution is a methodology that can help those software
engineers in the task of creating new software services, aligned with Industry
4.0, that allow to change how customers interact with enterprises and the
experiences they have while interacting with them. The methodology details a
set of stages that are divided into phases which in turn are made up of
activities. It places special emphasis on the incorporation of semantics
descriptions and 3D visualization in the implementation of those new services.
The second contribution is a system developed for a real manufacturing
scenario, using the proposed methodology, which allows to observe the
possibilities that this kind of systems can offer to SMEs in two phases of the
customer life cycle: Discover &amp; Shop, and Use &amp; Service.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17663 title=Abstract>arXiv:2401.17663</a> [<a href=https://arxiv.org/pdf/2401.17663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Social Robot Navigation with Adaptive Proxemics Based on Emotions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilen%2C+B">Baris Bilen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uluer%2C+H+K+P">Hasan Kivrak Pinar Uluer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kose%2C+H">Hatice Kose</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, Proceeding of Towards Socially Intelligent Robots In Real World Applications: Challenges And Intricacies (SIRRW) Workshop, RO-MAN 2022, 3-7, August 2022, Naples, Italy
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>The primary aim of this paper is to investigate the integration of emotions
into the social navigation framework to analyse its effect on both navigation
and human physiological safety and comfort. The proposed framework uses leg
detection to find the whereabouts of people and computes adaptive proxemic
zones based on their emotional state. We designed several case studies in a
simulated environment and examined 3 different emotions; positive (happy),
neutral and negative (angry). A survey study was conducted with 70 participants
to explore their impressions about the navigation of the robot and compare the
human safety and comfort measurements results. Both survey and simulation
results showed that integrating emotions into proxemic zones has a significant
effect on the physical safety of a human. The results revealed that when a
person is angry, the robot is expected to navigate further than the standard
distance to support his/her physiological comfort and safety. The results also
showed that reducing the navigation distance is not preferred when a person is
happy.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17664 title=Abstract>arXiv:2401.17664</a> [<a href=https://arxiv.org/pdf/2401.17664 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17664 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image Anything: Towards Reasoning-coherent and Training-free Multi-modal Image Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+Y">Yuanhuiyi Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lin Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>The multifaceted nature of human perception and comprehension indicates that,
when we think, our body can naturally take any combination of senses, a.k.a.,
modalities and form a beautiful picture in our brain. For example, when we see
a cattery and simultaneously perceive the cat's purring sound, our brain can
construct a picture of a cat in the cattery. Intuitively, generative AI models
should hold the versatility of humans and be capable of generating images from
any combination of modalities efficiently and collaboratively. This paper
presents ImgAny, a novel end-to-end multi-modal generative model that can mimic
human reasoning and generate high-quality images. Our method serves as the
first attempt in its capacity of efficiently and flexibly taking any
combination of seven modalities, ranging from language, audio to vision
modalities, including image, point cloud, thermal, depth, and event data. Our
key idea is inspired by human-level cognitive processes and involves the
integration and harmonization of multiple input modalities at both the entity
and attribute levels without specific tuning across modalities. Accordingly,
our method brings two novel training-free technical branches: 1) Entity Fusion
Branch ensures the coherence between inputs and outputs. It extracts entity
features from the multi-modal representations powered by our specially
constructed entity knowledge graph; 2) Attribute Fusion Branch adeptly
preserves and processes the attributes. It efficiently amalgamates distinct
attributes from diverse input modalities via our proposed attribute knowledge
graph. Lastly, the entity and attribute features are adaptively fused as the
conditional inputs to the pre-trained Stable Diffusion model for image
generation. Extensive experiments under diverse modality combinations
demonstrate its exceptional capability for visual content creation.
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17671 title=Abstract>arXiv:2401.17671</a> [<a href=https://arxiv.org/pdf/2401.17671 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17671 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mischler%2C+G">Gavin Mischler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y+A">Yinghao Aaron Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bickel%2C+S">Stephan Bickel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta%2C+A+D">Ashesh D. Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mesgarani%2C+N">Nima Mesgarani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 5 figures and 4 supplementary figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)
</div>
<p class=mathjax>Recent advancements in artificial intelligence have sparked interest in the
parallels between large language models (LLMs) and human neural processing,
particularly in language comprehension. While prior research has established
similarities in the representation of LLMs and the brain, the underlying
computational principles that cause this convergence, especially in the context
of evolving LLMs, remain elusive. Here, we examined a diverse selection of
high-performance LLMs with similar parameter sizes to investigate the factors
contributing to their alignment with the brain's language processing
mechanisms. We find that as LLMs achieve higher performance on benchmark tasks,
they not only become more brain-like as measured by higher performance when
predicting neural responses from LLM embeddings, but also their hierarchical
feature extraction pathways map more closely onto the brain's while using fewer
layers to do the same encoding. We also compare the feature extraction pathways
of the LLMs to each other and identify new ways in which high-performing models
have converged toward similar hierarchical processing mechanisms. Finally, we
show the importance of contextual information in improving model performance
and brain similarity. Our findings reveal the converging aspects of language
processing in the brain and LLMs and offer new directions for developing models
that align more closely with human cognitive processing.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17676 title=Abstract>arXiv:2401.17676</a> [<a href=https://arxiv.org/pdf/2401.17676 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17676 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Observer-based Controller Design for Oscillation Damping of a Novel Suspended Underactuated Aerial Platform
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+H">Hemjyoti Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+M+N">Minh Nhat Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Egle%2C+T">Tobias Egle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ott%2C+C">Christian Ott</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 11 figures, Accepted for publication to ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this work, we present a novel actuation strategy for a suspended aerial
platform. By utilizing an underactuation approach, we demonstrate the
successful oscillation damping of the proposed platform, modeled as a spherical
double pendulum. A state estimator is designed in order to obtain the
deflection angles of the platform, which uses only onboard IMU measurements.
The state estimator is an extended Kalman filter (EKF) with intermittent
measurements obtained at different frequencies. An optimal state feedback
controller and a PD+ controller are designed in order to dampen the
oscillations of the platform in the joint space and task space respectively.
The proposed underactuated platform is found to be more energy-efficient than
an omnidirectional platform and requires fewer actuators. The effectiveness of
our proposed system is validated using both simulations and experimental
studies.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17681 title=Abstract>arXiv:2401.17681</a> [<a href=https://arxiv.org/pdf/2401.17681 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17681 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17681 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Transceiver Optimization for MmWave/THz MU-MIMO ISAC Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Peilan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+J">Jun Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xianlong Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongbin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In this paper, we consider the problem of joint transceiver design for
millimeter wave (mmWave)/Terahertz (THz) multi-user MIMO integrated sensing and
communication (ISAC) systems. Such a problem is formulated into a nonconvex
optimization problem, with the objective of maximizing a weighted sum of
communication users' rates and the passive radar's
signal-to-clutter-and-noise-ratio (SCNR). By exploring a low-dimensional
subspace property of the optimal precoder, a low-complexity
block-coordinate-descent (BCD)-based algorithm is proposed. Our analysis
reveals that the hybrid analog/digital beamforming structure can attain the
same performance as that of a fully digital precoder, provided that the number
of radio frequency (RF) chains is no less than the number of resolvable signal
paths. Also, through expressing the precoder as a sum of a
communication-precoder and a sensing-precoder, we develop an analytical
solution to the joint transceiver design problem by generalizing the idea of
block-diagonalization (BD) to the ISAC system. Simulation results show that
with a proper tradeoff parameter, the proposed methods can achieve a decent
compromise between communication and sensing, where the performance of each
communication/sensing task experiences only a mild performance loss as compared
with the performance attained by optimizing exclusively for a single task.
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17686 title=Abstract>arXiv:2401.17686</a> [<a href=https://arxiv.org/pdf/2401.17686 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17686 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tinghui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+J">Jian Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Yu Su</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recent advancements have significantly augmented the reasoning capabilities
of Large Language Models (LLMs) through various methodologies, especially
chain-of-thought (CoT) reasoning. However, previous methods fail to address
reasoning errors in intermediate steps, leading to accumulative errors.In this
paper, we propose Deductive Beam Search (DBS), which seamlessly integrates CoT
and deductive reasoning with step-wise beam search for LLMs. Our approach
deploys a verifier, verifying the deducibility of a reasoning step and its
premises, thus alleviating the error accumulation. Furthermore, we introduce a
scalable and labor-free data construction method to amplify our model's
verification capabilities. Extensive experiments demonstrate that our approach
significantly enhances the base performance of LLMs of various scales (7B, 13B,
70B, and ChatGPT) across 8 reasoning datasets from 3 diverse reasoning genres,
including arithmetic, commonsense, and symbolic. Moreover, our analysis proves
DBS's capability of detecting diverse and subtle reasoning errors and
robustness on different model scales.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17691 title=Abstract>arXiv:2401.17691</a> [<a href=https://arxiv.org/pdf/2401.17691 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17691 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17691 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Version Innovation Age and Age of Incorrect Version for Monitoring Markovian Sources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salimnejad%2C+M">Mehrdad Salimnejad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kountouris%2C+M">Marios Kountouris</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ephremides%2C+A">Anthony Ephremides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper, we propose two new performance metrics, coined the Version
Innovation Age (VIA) and the Age of Incorrect Version (AoIV) for real-time
monitoring of a two-state Markov process over an unreliable channel. We analyze
their performance under the change-aware, semantics-aware, and randomized
stationary sampling and transmission policies. We derive closed-form
expressions for the distribution and the average of VIA, AoIV, and AoII for
these policies. We then formulate and solve an optimization problem to minimize
the average VIA, subject to constraints on the time-averaged sampling cost and
time-averaged reconstruction error. Finally, we compare the performance of
various sampling and transmission policies and identify the conditions under
which each policy outperforms the others in optimizing the proposed metrics.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17692 title=Abstract>arXiv:2401.17692</a> [<a href=https://arxiv.org/pdf/2401.17692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating the Problem of Strong Priors in LMs with Context Extrapolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Douglas%2C+R">Raymond Douglas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Draguns%2C+A">Andis Draguns</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaven%C4%8Diak%2C+T">Tom Gaveniak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Language models (LMs) have become important tools in a variety of
applications, from data processing to the creation of instruction-following
assistants. But despite their advantages, LMs have certain idiosyncratic
limitations such as the problem of `strong priors', where a model learns to
output typical continuations in response to certain, usually local, portions of
the input regardless of any earlier instructions. For example, prompt injection
attacks can induce models to ignore explicit directives. In some cases, larger
models have been shown to be more susceptible to these problems than similar
smaller models, an example of the phenomenon of `inverse scaling'. We develop a
new technique for mitigating the problem of strong priors: we take the original
set of instructions, produce a weakened version of the original prompt that is
even more susceptible to the strong priors problem, and then extrapolate the
continuation away from the weakened prompt. This lets us infer how the model
would continue a hypothetical strengthened set of instructions. Our technique
conceptualises LMs as mixture models which combine a family of data generation
processes, reinforcing the desired elements of the mixture. Our approach works
at inference time, removing any need for retraining. We apply it to eleven
models including GPT-2, GPT-3, Llama 2, and Mistral on four tasks, and find
improvements in 41/44. Across all 44 combinations the median increase in
proportion of tasks completed is 40%.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17695 title=Abstract>arXiv:2401.17695</a> [<a href=https://arxiv.org/pdf/2401.17695 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17695 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Datacube segmentation via Deep Spectral Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bombini%2C+A">Alessandro Bombini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bof%C3%ADas%2C+F+G">Fernando Garca-Avello Bofas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bracci%2C+C">Caterina Bracci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ginolfi%2C+M">Michele Ginolfi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruberto%2C+C">Chiara Ruberto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 10 figures, doi for code repository, dataset and trained model available and reported in the paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Applied Physics (physics.app-ph)
</div>
<p class=mathjax>Extended Vision techniques are ubiquitous in physics. However, the data cubes
steaming from such analysis often pose a challenge in their interpretation, due
to the intrinsic difficulty in discerning the relevant information from the
spectra composing the data cube.
<br>Furthermore, the huge dimensionality of data cube spectra poses a complex
task in its statistical interpretation; nevertheless, this complexity contains
a massive amount of statistical information that can be exploited in an
unsupervised manner to outline some essential properties of the case study at
hand, e.g.~it is possible to obtain an image segmentation via (deep) clustering
of data-cube's spectra, performed in a suitably defined low-dimensional
embedding space.
<br>To tackle this topic, we explore the possibility of applying unsupervised
clustering methods in encoded space, i.e. perform deep clustering on the
spectral properties of datacube pixels. A statistical dimensional reduction is
performed by an ad hoc trained (Variational) AutoEncoder, in charge of mapping
spectra into lower dimensional metric spaces, while the clustering process is
performed by a (learnable) iterative K-Means clustering algorithm.
<br>We apply this technique to two different use cases, of different physical
origins: a set of Macro mapping X-Ray Fluorescence (MA-XRF) synthetic data on
pictorial artworks, and a dataset of simulated astrophysical observations.
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17698 title=Abstract>arXiv:2401.17698</a> [<a href=https://arxiv.org/pdf/2401.17698 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17698 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bi-ACT: Bilateral Control-Based Imitation Learning via Action Chunking with Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buamanee%2C+T">Thanpimon Buamanee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+M">Masato Kobayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uranishi%2C+Y">Yuki Uranishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takemura%2C+H">Haruo Takemura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Autonomous manipulation in robot arms is a complex and evolving field of
study in robotics. This paper proposes work stands at the intersection of two
innovative approaches in the field of robotics and machine learning. Inspired
by the Action Chunking with Transformer (ACT) model, which employs joint
location and image data to predict future movements, our work integrates
principles of Bilateral Control-Based Imitation Learning to enhance robotic
control. Our objective is to synergize these techniques, thereby creating a
more robust and efficient control mechanism. In our approach, the data
collected from the environment are images from the gripper and overhead
cameras, along with the joint angles, angular velocities, and forces of the
follower robot using bilateral control. The model is designed to predict the
subsequent steps for the joint angles, angular velocities, and forces of the
leader robot. This predictive capability is crucial for implementing effective
bilateral control in the follower robot, allowing for more nuanced and
responsive maneuvering.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17699 title=Abstract>arXiv:2401.17699</a> [<a href=https://arxiv.org/pdf/2401.17699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unified Physical-Digital Face Attack Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+H">Hao Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+A">Ajian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+H">Haocheng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+J">Junze Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+D">Dingheng Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yanhong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+J">Jiankang Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+J">Jun Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Face Recognition (FR) systems can suffer from physical (i.e., print photo)
and digital (i.e., DeepFake) attacks. However, previous related work rarely
considers both situations at the same time. This implies the deployment of
multiple models and thus more computational burden. The main reasons for this
lack of an integrated model are caused by two factors: (1) The lack of a
dataset including both physical and digital attacks with ID consistency which
means the same ID covers the real face and all attack types; (2) Given the
large intra-class variance between these two attacks, it is difficult to learn
a compact feature space to detect both attacks simultaneously. To address these
issues, we collect a Unified physical-digital Attack dataset, called
UniAttackData. The dataset consists of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-196 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.38em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-197><span class=mn id=MathJax-Span-198 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-199 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-200 style=font-family:MathJax_Main;padding-left:0.177em>800</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> participations of 2 and 12
physical and digital attacks, respectively, resulting in a total of 29,706
videos. Then, we propose a Unified Attack Detection framework based on
Vision-Language Models (VLMs), namely UniAttackDetection, which includes three
main modules: the Teacher-Student Prompts (TSP) module, focused on acquiring
unified and specific knowledge respectively; the Unified Knowledge Mining (UKM)
module, designed to capture a comprehensive feature space; and the Sample-Level
Prompt Interaction (SLPI) module, aimed at grasping sample-level semantics.
These three modules seamlessly form a robust unified attack detection
framework. Extensive experiments on UniAttackData and three other datasets
demonstrate the superiority of our approach for unified face attack detection.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17700 title=Abstract>arXiv:2401.17700</a> [<a href=https://arxiv.org/pdf/2401.17700 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17700 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17700 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Classification of executive functioning performance post-longitudinal tDCS using functional connectivity and machine learning methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+A+K">Akash K Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menon%2C+V+K">Vishnu K Menon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uttrani%2C+S">Shashank Uttrani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dixit%2C+A">Ayushman Dixit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verma%2C+D">Dipanshu Verma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutt%2C+V">Varun Dutt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, presented at the IEEE 20th India Council International Conference (INDICON 2023), Hyderabad, India, December 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Executive functioning is a cognitive process that enables humans to plan,
organize, and regulate their behavior in a goal-directed manner. Understanding
and classifying the changes in executive functioning after longitudinal
interventions (like transcranial direct current stimulation (tDCS)) has not
been explored in the literature. This study employs functional connectivity and
machine learning algorithms to classify executive functioning performance
post-tDCS. Fifty subjects were divided into experimental and placebo control
groups. EEG data was collected while subjects performed an executive
functioning task on Day 1. The experimental group received tDCS during task
training from Day 2 to Day 8, while the control group received sham tDCS. On
Day 10, subjects repeated the tasks specified on Day 1. Different functional
connectivity metrics were extracted from EEG data and eventually used for
classifying executive functioning performance using different machine learning
algorithms. Results revealed that a novel combination of partial directed
coherence and multi-layer perceptron (along with recursive feature elimination)
resulted in a high classification accuracy of 95.44%. We discuss the
implications of our results in developing real-time neurofeedback systems for
assessing and enhancing executive functioning performance post-tDCS
administration.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17701 title=Abstract>arXiv:2401.17701</a> [<a href=https://arxiv.org/pdf/2401.17701 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17701 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards a low-cost universal access cloud framework to assess STEM students
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merchante%2C+L+F+S">L.F.S Merchante</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vallez%2C+C+M">Carlos M. Vallez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szczerbik%2C+C">Carrie Szczerbik</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 8 figures, 1 appendix and 1 code repository
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>Government-imposed lockdowns have challenged academic institutions to
transition from traditional face-to-face education into hybrid or fully remote
learning models. This transition has focused on the technological challenge of
guaranteeing the continuity of sound pedagogy and granting safe access to
online digital university services. However, a key requisite involves adapting
the evaluation process as well. In response to this need, the authors of this
paper tailored and implemented a cloud deployment to provide universal access
to online summative assessment of university students in a computer programming
course that mirrored a traditional in-person monitored computer laboratory
under strictly controlled exam conditions. This deployment proved easy to
integrate with the university systems and many commercial proctoring tools.
This cloud deployment is not only a solution for extraordinary situations; it
can also be adapted daily for online collaborative coding assignments,
practical lab sessions, formative assessments, and masterclasses where the
students connect using their equipment. Connecting from home facilitates access
to education for students with physical disabilities. It also allows
participation with their students' own adapted equipment in the evaluation
processes, simplifying assessment for those with hearing or visual impairments.
In addition to these benefits and the evident commitment to the safety rules,
this solution has proven cheaper and more flexible than on-premise equivalent
installations.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17702 title=Abstract>arXiv:2401.17702</a> [<a href=https://arxiv.org/pdf/2401.17702 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17702 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supercloseness and asymptotic analysis of the Crouzeix-Raviart and enriched Crouzeix-Raviart elements for the Stokes problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Han%2C+H">Hao Han</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ma%2C+L">Limin Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>For the Crouzeix-Raviart and enriched Crouzeix-Raviart elements, asymptotic
expansions of eigenvalues of the Stokes operator are derived by establishing
two pseudostress interpolations, which admit a full one-order supercloseness
with respect to the numerical velocity and the pressure, respectively. The
design of these interpolations overcomes the difficulty caused by the lack of
supercloseness of the canonical interpolations for the two nonconforming
elements, and leads to an intrinsic and concise asymptotic analysis of
numerical eigenvalues, which proves an optimal superconvergence of eigenvalues
by the extrapolation algorithm. Meanwhile, an optimal superconvergence of
postprocessed approximations for the Stokes equation is proved by use of this
supercloseness. Finally, numerical experiments are tested to verify the
theoretical results.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17703 title=Abstract>arXiv:2401.17703</a> [<a href=https://arxiv.org/pdf/2401.17703 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17703 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zahraei%2C+P+S">Pardis Sadat Zahraei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Emami%2C+A">Ali Emami</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in main proceedings of EACL 2024 conference, 22 pages, 16 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The Winograd Schema Challenge (WSC) serves as a prominent benchmark for
evaluating machine understanding. While Large Language Models (LLMs) excel at
answering WSC questions, their ability to generate such questions remains less
explored. In this work, we propose Tree-of-Experts (ToE), a novel prompting
method which enhances the generation of WSC instances (50% valid cases vs. 10%
in recent methods). Using this approach, we introduce WSC+, a novel dataset
comprising 3,026 LLM-generated sentences. Notably, we extend the WSC framework
by incorporating new 'ambiguous' and 'offensive' categories, providing a deeper
insight into model overconfidence and bias. Our analysis reveals nuances in
generation-evaluation consistency, suggesting that LLMs may not always
outperform in evaluating their own generated questions when compared to those
crafted by other models. On WSC+, GPT-4, the top-performing LLM, achieves an
accuracy of 68.7%, significantly below the human benchmark of 95.1%.
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17704 title=Abstract>arXiv:2401.17704</a> [<a href=https://arxiv.org/pdf/2401.17704 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17704 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17704 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computing the forcing spectrum of outerplanar graphs in polynomial time
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorsky%2C+M">Maximilian Gorsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kre%C3%9Fin%2C+F">Fabian Krein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>The forcing number of a graph with a perfect matching <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-201 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-202><span class=mi id=MathJax-Span-203 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is the minimum
number of edges in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-204 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-205><span class=mi id=MathJax-Span-206 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> whose endpoints need to be deleted, such that the
remaining graph only has a single perfect matching. This number is of great
interest in theoretical chemistry, since it conveys information about the
structural properties of several interesting molecules. On the other hand, in
bipartite graphs the forcing number corresponds to the famous feedback vertex
set problem in digraphs.
<br>Determining the complexity of finding the smallest forcing number of a given
planar graph is still a widely open and important question in this area,
originally proposed by Afshani, Hatami, and Mahmoodian in 2004. We take a first
step towards the resolution of this question by providing an algorithm that
determines the set of all possible forcing numbers of an outerplanar graph in
polynomial time. This is the first polynomial-time algorithm concerning this
problem for a class of graphs of comparable or greater generality.
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17705 title=Abstract>arXiv:2401.17705</a> [<a href=https://arxiv.org/pdf/2401.17705 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17705 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17705 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting suicidal behavior among Indian adults using childhood trauma, mental health questionnaires and machine learning cascade ensembles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+A+K">Akash K Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trivedi%2C+G+Y">Gunjan Y Trivedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trivedi%2C+R+G">Riri G Trivedi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bajpai%2C+A">Anshika Bajpai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chauhan%2C+G+S">Gajraj Singh Chauhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menon%2C+V+K">Vishnu K Menon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soundappan%2C+K">Kathirvel Soundappan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramani%2C+H">Hemalatha Ramani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pandya%2C+N">Neha Pandya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutt%2C+V">Varun Dutt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, presnted at the 4th International Conference on Frontiers in Computing and Systems (COMSYS 2023), Himachal Pradesh, October 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Among young adults, suicide is India's leading cause of death, accounting for
an alarming national suicide rate of around 16%. In recent years, machine
learning algorithms have emerged to predict suicidal behavior using various
behavioral traits. But to date, the efficacy of machine learning algorithms in
predicting suicidal behavior in the Indian context has not been explored in
literature. In this study, different machine learning algorithms and ensembles
were developed to predict suicide behavior based on childhood trauma, different
mental health parameters, and other behavioral factors. The dataset was
acquired from 391 individuals from a wellness center in India. Information
regarding their childhood trauma, psychological wellness, and other mental
health issues was acquired through standardized questionnaires. Results
revealed that cascade ensemble learning methods using a support vector machine,
decision trees, and random forest were able to classify suicidal behavior with
an accuracy of 95.04% using data from childhood trauma and mental health
questionnaires. The study highlights the potential of using these machine
learning ensembles to identify individuals with suicidal tendencies so that
targeted interinterventions could be provided efficiently.
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17706 title=Abstract>arXiv:2401.17706</a> [<a href=https://arxiv.org/pdf/2401.17706 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17706 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Illusion of Performance: The Effect of Phantom Display Refresh Rates on User Expectations and Reaction Times
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosch%2C+E">Esther Bosch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Welsch%2C+R">Robin Welsch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayach%2C+T">Tamim Ayach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katins%2C+C">Christopher Katins</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kosch%2C+T">Thomas Kosch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>User expectations impact the evaluation of new interactive systems. Elevated
expectations may enhance the perceived effectiveness of interfaces in user
studies, similar to a placebo effect observed in medical studies. To showcase
the placebo effect, we executed a user study with 18 participants who conducted
a reaction time test with two different computer screen refresh rates.
Participants saw a stated screen refresh rate before every condition, which
corresponded to the true refresh rate only in half of the conditions and was
lower or higher in the other half. Results revealed successful priming, as
participants believed in superior or inferior performance based on the
narrative despite using the opposite refresh rate. Post-experiment
questionnaires confirmed participants still held onto the initial narrative.
Interestingly, the objective performance remained unchanged between both
refresh rates. We discuss how study narratives can influence subjective
measures and suggest strategies to mitigate placebo effects in user-centered
study designs.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17709 title=Abstract>arXiv:2401.17709</a> [<a href=https://arxiv.org/pdf/2401.17709 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17709 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Printed Sensing: Assessing 3D-Printed Electrodes for Measuring Electrodermal Activity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmitz%2C+M">Martin Schmitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6n%2C+D">Dominik Schn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klagemann%2C+H">Henning Klagemann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kosch%2C+T">Thomas Kosch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Electrodermal activity (EDA) reflects changes in skin conductance, closely
tied to human psychological states. EDA sensors can assess stress, cognitive
workload, arousal, and activity related to the parasympathetic nervous system
used in various human-computer interaction applications. Yet, current
limitations involve the complex attachment and proper skin contact with EDA
sensors. This paper explores the novel concept of 3D printing electrodes for
EDA measurements, potentially integrating sensors into arbitrary 3D printed
objects, alleviating the need for complex assembly and attachment. We examine
the adaptation of conventional EDA circuits for 3D-printed electrodes,
assessing different electrode shapes and their impact on the sensing accuracy.
A user study (N=6) revealed that 3D-printed electrodes can measure EDA with
similar accuracy while recommending larger contact areas for improved
precision. We discuss design implications to facilitate EDA sensor integration
into 3D-printed devices, fostering a diverse integration into everyday items
using consumer-grade 3D printers for physiological interface prototyping.
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17710 title=Abstract>arXiv:2401.17710</a> [<a href=https://arxiv.org/pdf/2401.17710 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17710 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Aesthetic Preference Prediction in Interior Design: Fuzzy Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adilova%2C+A">Ayana Adilova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shamoi%2C+P">Pakizar Shamoi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE conference for consideration
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Interior design is all about creating spaces that look and feel good.
However, the subjective nature of aesthetic preferences presents a significant
challenge in defining and quantifying what makes an interior design visually
appealing. The current paper addresses this gap by introducing a novel
methodology for quantifying and predicting aesthetic preferences in interior
design. Our study combines fuzzy logic with image processing techniques. We
collected a dataset of interior design images from social media platforms,
focusing on essential visual attributes such as color harmony, lightness, and
complexity. We integrate these features using weighted average to compute a
general aesthetic score. Our approach considers individual color preferences in
calculating the overall aesthetic preference. We initially gather user ratings
for primary colors like red, brown, and others to understand their preferences.
Then, we use the pixel count of the top five dominant colors in the image to
get the color scheme preference. The color scheme preference and the aesthetic
score are then passed as inputs to the fuzzy inference system to calculate an
overall preference score. This score represents a comprehensive measure of the
user's preference for a particular interior design, considering their color
choices and general aesthetic appeal. We used the 2AFC (Two-Alternative Forced
Choice) method to validate our methodology, achieving a notable hit rate of
0.7. This study can help designers and professionals better understand and meet
people's interior design preferences, especially in a world that relies heavily
on digital media.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17711 title=Abstract>arXiv:2401.17711</a> [<a href=https://arxiv.org/pdf/2401.17711 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17711 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17711 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prediction of multitasking performance post-longitudinal tDCS via EEG-based functional connectivity and machine learning methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+A+K">Akash K Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uttrani%2C+S">Shashank Uttrani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menon%2C+V+K">Vishnu K Menon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+D">Darshil Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhavsar%2C+A">Arnav Bhavsar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+S+R">Shubhajit Roy Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutt%2C+V">Varun Dutt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, presented at the 30th International Conference on Neural Information Processing (ICONIP2023), Changsha, China, November 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Predicting and understanding the changes in cognitive performance, especially
after a longitudinal intervention, is a fundamental goal in neuroscience.
Longitudinal brain stimulation-based interventions like transcranial direct
current stimulation (tDCS) induce short-term changes in the resting membrane
potential and influence cognitive processes. However, very little research has
been conducted on predicting these changes in cognitive performance
post-intervention. In this research, we intend to address this gap in the
literature by employing different EEG-based functional connectivity analyses
and machine learning algorithms to predict changes in cognitive performance in
a complex multitasking task. Forty subjects were divided into experimental and
active-control conditions. On Day 1, all subjects executed a multitasking task
with simultaneous 32-channel EEG being acquired. From Day 2 to Day 7, subjects
in the experimental condition undertook 15 minutes of 2mA anodal tDCS
stimulation during task training. Subjects in the active-control condition
undertook 15 minutes of sham stimulation during task training. On Day 10, all
subjects again executed the multitasking task with EEG acquisition.
Source-level functional connectivity metrics, namely phase lag index and
directed transfer function, were extracted from the EEG data on Day 1 and Day
10. Various machine learning models were employed to predict changes in
cognitive performance. Results revealed that the multi-layer perceptron and
directed transfer function recorded a cross-validation training RMSE of 5.11%
and a test RMSE of 4.97%. We discuss the implications of our results in
developing real-time cognitive state assessors for accurately predicting
cognitive performance in dynamic and complex tasks post-tDCS intervention
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17714 title=Abstract>arXiv:2401.17714</a> [<a href=https://arxiv.org/pdf/2401.17714 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17714 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D-Plotting Algorithm for Insects using YOLOv5
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mori%2C+D">Daisuke Mori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayami%2C+H">Hiroki Hayami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fujimoto%2C+Y">Yasufumi Fujimoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goto%2C+I">Isao Goto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In ecological research, accurately collecting spatiotemporal position data is
a fundamental task for understanding the behavior and ecology of insects and
other organisms. In recent years, advancements in computer vision techniques
have reached a stage of maturity where they can support, and in some cases,
replace manual observation. In this study, a simple and inexpensive method for
monitoring insects in three dimensions (3D) was developed so that their
behavior could be observed automatically in experimental environments. The main
achievements of this study have been to create a 3D monitoring algorithm using
inexpensive cameras and other equipment to design an adjusting algorithm for
depth error, and to validate how our plotting algorithm is quantitatively
precise, all of which had not been realized in conventional studies. By
offering detailed 3D visualizations of insects, the plotting algorithm aids
researchers in more effectively comprehending how insects interact within their
environments.
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17716 title=Abstract>arXiv:2401.17716</a> [<a href=https://arxiv.org/pdf/2401.17716 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17716 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Large Language Model with Decomposed Reasoning for Emotion Cause Pair Extraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jialiang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yi Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+L">Longjun Cai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Emotion-Cause Pair Extraction (ECPE) involves extracting clause pairs
representing emotions and their causes in a document. Existing methods tend to
overfit spurious correlations, such as positional bias in existing benchmark
datasets, rather than capturing semantic features. Inspired by recent work, we
explore leveraging large language model (LLM) to address ECPE task without
additional training. Despite strong capabilities, LLMs suffer from
uncontrollable outputs, resulting in mediocre performance. To address this, we
introduce chain-of-thought to mimic human cognitive process and propose the
Decomposed Emotion-Cause Chain (DECC) framework. Combining inducing inference
and logical pruning, DECC guides LLMs to tackle ECPE task. We further enhance
the framework by incorporating in-context learning. Experiment results
demonstrate the strength of DECC compared to state-of-the-art supervised
fine-tuning methods. Finally, we analyze the effectiveness of each component
and the robustness of the method in various scenarios, including different LLM
bases, rebalanced datasets, and multi-pair extraction.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17721 title=Abstract>arXiv:2401.17721</a> [<a href=https://arxiv.org/pdf/2401.17721 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17721 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Time Synchronization for 5G and TSN Integrated Networking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zixiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zonghui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+X">Xuan Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yiming Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ai%2C+B">Bo Ai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+X">Xiaoyu Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Emerging industrial applications involving robotic collaborative operations
and mobile robots require a more reliable and precise wireless network for
deterministic data transmission. To meet this demand, the 3rd Generation
Partnership Project (3GPP) is promoting the integration of 5th Generation
Mobile Communication Technology (5G) and Time-Sensitive Networking (TSN). Time
synchronization is essential for deterministic data transmission. Based on the
3GPP's vision of the 5G and TSN integrated networking with interoperability, we
improve the time synchronization of TSN to conquer the multi-gNB competition,
re-transmission, and mobility problems for the integrated 5G time
synchronization. We implemented the improvement mechanisms and systematically
validated the performance of 5G+TSN time synchronization. Based on the
simulation in 500m x 500m industrial environments, the improved time
synchronization achieved a precision of 1 microsecond with interoperability
between 5G nodes and TSN nodes.
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17723 title=Abstract>arXiv:2401.17723</a> [<a href=https://arxiv.org/pdf/2401.17723 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17723 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kaike Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Q">Qi Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yunfan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F">Fei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+H">Huawei Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Sequential recommender systems stand out for their ability to capture users'
dynamic interests and the patterns of item-to-item transitions. However, the
inherent openness of sequential recommender systems renders them vulnerable to
poisoning attacks, where fraudulent users are injected into the training data
to manipulate learned patterns. Traditional defense strategies predominantly
depend on predefined assumptions or rules extracted from specific known
attacks, limiting their generalizability to unknown attack types. To solve the
above problems, considering the rich open-world knowledge encapsulated in Large
Language Models (LLMs), our research initially focuses on the capabilities of
LLMs in the detection of unknown fraudulent activities within recommender
systems, a strategy we denote as LLM4Dec. Empirical evaluations demonstrate the
substantial capability of LLMs in identifying unknown fraudsters, leveraging
their expansive, open-world knowledge.
<br>Building upon this, we propose the integration of LLMs into defense
strategies to extend their effectiveness beyond the confines of known attacks.
We propose LoRec, an advanced framework that employs LLM-Enhanced Calibration
to strengthen the robustness of sequential recommender systems against
poisoning attacks. LoRec integrates an LLM-enhanced CalibraTor (LCT) that
refines the training process of sequential recommender systems with knowledge
derived from LLMs, applying a user-wise reweighting to diminish the impact of
fraudsters injected by attacks. By incorporating LLMs' open-world knowledge,
the LCT effectively converts the limited, specific priors or rules into a more
general pattern of fraudsters, offering improved defenses against poisoning
attacks. Our comprehensive experiments validate that LoRec, as a general
framework, significantly strengthens the robustness of sequential recommender
systems.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17724 title=Abstract>arXiv:2401.17724</a> [<a href=https://arxiv.org/pdf/2401.17724 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17724 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-Performance Data Mapping for BNNs on PCM-based Integrated Photonics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahroodi%2C+T">Taha Shahroodi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardoso%2C+R">Raphael Cardoso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+S">Stephan Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosio%2C+A">Alberto Bosio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=O%27Connor%2C+I">Ian O'Connor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamdioui%2C+S">Said Hamdioui</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in Design Automation and Test in Europe (DATE), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>State-of-the-Art (SotA) hardware implementations of Deep Neural Networks
(DNNs) incur high latencies and costs. Binary Neural Networks (BNNs) are
potential alternative solutions to realize faster implementations without
losing accuracy. In this paper, we first present a new data mapping, called
TacitMap, suited for BNNs implemented based on a Computation-In-Memory (CIM)
architecture. TacitMap maximizes the use of available parallelism, while CIM
architecture eliminates the data movement overhead. We then propose a hardware
accelerator based on optical phase change memory (oPCM) called EinsteinBarrier.
Ein-steinBarrier incorporates TacitMap and adds an extra dimension for
parallelism through wavelength division multiplexing, leading to extra latency
reduction. The simulation results show that, compared to the SotA CIM baseline,
TacitMap and EinsteinBarrier significantly improve execution time by up to
~154x and ~3113x, respectively, while also maintaining the energy consumption
within 60% of that in the CIM baseline.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17725 title=Abstract>arXiv:2401.17725</a> [<a href=https://arxiv.org/pdf/2401.17725 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17725 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Challenges in Understanding the Relationship between Teamwork Quality and Project Success in Large-Scale Agile Projects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dings%C3%B8yr%2C+T">Torgeir Dingsyr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+P">Phillip Schneider</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bergersen%2C+G+R">Gunnar Rye Bergersen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindsj%C3%B8rn%2C+Y">Yngve Lindsjrn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>A number of methods for large-scale agile development have recently been
suggested. Much of the advice in agile methods focuses on teamwork. Prior
research has established that teamwork quality influences project success both
for traditional software development teams and agile teams. Further, prior
studies have also suggested that teamwork quality may play out differently in
large projects compared to small. We investigated the relationship between
teamwork quality and project success with a survey of 196 project participants
across 34 teams in four projects, replicating a previous study on single teams.
The new data do not fit the previously established theoretical model, which
raises several concerns. The observed effect of teamwork quality on project
success operates differently across projects. We discuss possible reasons,
which include disagreements on what characterises success in large-scale agile
development, "concept drift" of teamwork quality factors, the possibility that
interteam factors might have more influence on project success than intrateam
factors, and finally, that our study design does not capture all relevant
levels and functions. We conclude with a call for more studies on the quality
and frequency of interaction between teams in addition to internal team factors
to further advance theory and practice within large-scale agile software
development.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17728 title=Abstract>arXiv:2401.17728</a> [<a href=https://arxiv.org/pdf/2401.17728 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17728 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain Adaptation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlachter%2C+P">Pascal Schlachter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In real-world applications, there is often a domain shift from training to
test data. This observation resulted in the development of test-time adaptation
(TTA). It aims to adapt a pre-trained source model to the test data without
requiring access to the source data. Thereby, most existing works are limited
to the closed-set assumption, i.e. there is no category shift between source
and target domain. We argue that in a realistic open-world setting a category
shift can appear in addition to a domain shift. This means, individual source
classes may not appear in the target domain anymore, samples of new classes may
be part of the target domain or even both at the same time. Moreover, in many
real-world scenarios the test data is not accessible all at once but arrives
sequentially as a stream of batches demanding an immediate prediction. Hence,
TTA must be applied in an online manner. To the best of our knowledge, the
combination of these aspects, i.e. online source-free universal domain
adaptation (online SF-UniDA), has not been studied yet. In this paper, we
introduce a Contrastive Mean Teacher (COMET) tailored to this novel scenario.
It applies a contrastive loss to rebuild a feature space where the samples of
known classes build distinct clusters and the samples of new classes separate
well from them. It is complemented by an entropy loss which ensures that the
classifier output has a small entropy for samples of known classes and a large
entropy for samples of new classes to be easily detected and rejected as
unknown. To provide the losses with reliable pseudo labels, they are embedded
into a mean teacher (MT) framework. We evaluate our method across two datasets
and all category shifts to set an initial benchmark for online SF-UniDA.
Thereby, COMET yields state-of-the-art performance and proves to be consistent
and robust across a variety of different scenarios.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17732 title=Abstract>arXiv:2401.17732</a> [<a href=https://arxiv.org/pdf/2401.17732 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17732 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-performance Racing on Unmapped Tracks using Local Maps
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evans%2C+B+D">Benjamin David Evans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jordaan%2C+H+W">Hendrik Willem Jordaan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Engelbrecht%2C+H+A">Herman Arnold Engelbrecht</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 14 figures. Submitted to IV 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Map-based methods for autonomous racing estimate the vehicle's location,
which is used to follow a high-level plan. While map-based optimisation methods
demonstrate high-performance results, they are limited by requiring a map of
the environment. In contrast, mapless methods can operate in unmapped contexts
since they directly process raw sensor data (often LiDAR) to calculate
commands. However, a major limitation in mapless methods is poor performance
due to a lack of optimisation. In response, we propose the local map framework
that uses easily extractable, low-level features to build local maps of the
visible region that form the input to optimisation-based controllers. Our local
map generation extracts the visible racetrack boundaries and calculates a
centreline and track widths used for planning. We evaluate our method for
simulated F1Tenth autonomous racing using a two-stage trajectory optimisation
and tracking strategy and a model predictive controller. Our method achieves
lap times that are 8.8% faster than the Follow-The-Gap method and 3.22% faster
than end-to-end neural networks due to the optimisation resulting in a faster
speed profile. The local map planner is 3.28% slower than global methods that
have access to an entire map of the track that can be used for planning.
Critically, our approach enables high-speed autonomous racing on unmapped
tracks, achieving performance similar to global methods without requiring a
track map.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17733 title=Abstract>arXiv:2401.17733</a> [<a href=https://arxiv.org/pdf/2401.17733 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17733 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17733 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Physical Plausibility in Neuroevolution Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cort%C3%AAs%2C+G">Gabriel Corts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Louren%C3%A7o%2C+N">Nuno Loureno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Machado%2C+P">Penousal Machado</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>The increasing usage of Artificial Intelligence (AI) models, especially Deep
Neural Networks (DNNs), is increasing the power consumption during training and
inference, posing environmental concerns and driving the need for more
energy-efficient algorithms and hardware solutions. This work addresses the
growing energy consumption problem in Machine Learning (ML), particularly
during the inference phase. Even a slight reduction in power usage can lead to
significant energy savings, benefiting users, companies, and the environment.
Our approach focuses on maximizing the accuracy of Artificial Neural Network
(ANN) models using a neuroevolutionary framework whilst minimizing their power
consumption. To do so, power consumption is considered in the fitness function.
We introduce a new mutation strategy that stochastically reintroduces modules
of layers, with power-efficient modules having a higher chance of being chosen.
We introduce a novel technique that allows training two separate models in a
single training step whilst promoting one of them to be more power efficient
than the other while maintaining similar accuracy. The results demonstrate a
reduction in power consumption of ANN models by up to 29.2% without a
significant decrease in predictive performance.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17734 title=Abstract>arXiv:2401.17734</a> [<a href=https://arxiv.org/pdf/2401.17734 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17734 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Shape Formation by 3D Hybrid Programmable Matter: An Algorithm for Low Diameter Intermediate Structures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hinnenthal%2C+K">Kristian Hinnenthal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liedtke%2C+D">David Liedtke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scheideler%2C+C">Christian Scheideler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>This paper considers the shape formation problem within the 3D hybrid model,
where a single agent with a strictly limited viewing range and the
computational capacity of a deterministic finite automaton manipulates passive
tiles through pick-up, movement, and placement actions. The goal is to
reconfigure a set of tiles into a specific shape termed an icicle. The icicle,
identified as a dense, hole-free structure, is strategically chosen to function
as an intermediate shape for more intricate shape formation tasks. It is
designed for easy exploration by a finite state agent, enabling the
identification of tiles that can be lifted without breaking connectivity.
Compared to the line shape, the icicle presents distinct advantages, including
a reduced diameter and the presence of multiple removable tiles. We propose an
algorithm that transforms an arbitrary initially connected tile structure into
an icicle in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-207 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.49em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-208><span class=texatom id=MathJax-Span-209><span class=mrow id=MathJax-Span-210><span class=mi id=MathJax-Span-211 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-212 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-213><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-214 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-215 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-216 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> steps, matching the runtime of the line
formation algorithm from prior work. Our theoretical contribution is
accompanied by an extensive experimental analysis, indicating that our
algorithm decreases the diameter of tile structures on average.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17736 title=Abstract>arXiv:2401.17736</a> [<a href=https://arxiv.org/pdf/2401.17736 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17736 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Human-Machine Interactions for Computer Vision Dataset Quality Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anzaku%2C+E+T">Esla Timothy Anzaku</a> (1,2,3), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+H">Hyesoo Hong</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jin-Woo Park</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wonjun Yang</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K">Kangmin Kim</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Won%2C+J">JongBum Won</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Herath%2C+D+V+K">Deshika Vinoshani Kumari Herath</a> (6), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Messem%2C+A">Arnout Van Messem</a> (5), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Neve%2C+W">Wesley De Neve</a> (1,2,3)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Large-scale datasets for single-label multi-class classification, such as
\emph{ImageNet-1k}, have been instrumental in advancing deep learning and
computer vision. However, a critical and often understudied aspect is the
comprehensive quality assessment of these datasets, especially regarding
potential multi-label annotation errors. In this paper, we introduce a
lightweight, user-friendly, and scalable framework that synergizes human and
machine intelligence for efficient dataset validation and quality enhancement.
We term this novel framework \emph{Multilabelfy}. Central to Multilabelfy is an
adaptable web-based platform that systematically guides annotators through the
re-evaluation process, effectively leveraging human-machine interactions to
enhance dataset quality. By using Multilabelfy on the ImageNetV2 dataset, we
found that approximately <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-217 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.07em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-218><span class=mn id=MathJax-Span-219 style=font-family:MathJax_Main>47.88</span><span class=mi id=MathJax-Span-220 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of the images contained at least two labels,
underscoring the need for more rigorous assessments of such influential
datasets. Furthermore, our analysis showed a negative correlation between the
number of potential labels per image and model top-1 accuracy, illuminating a
crucial factor in model evaluation and selection. Our open-source framework,
Multilabelfy, offers a convenient, lightweight solution for dataset
enhancement, emphasizing multi-label proportions. This study tackles major
challenges in dataset integrity and provides key insights into model
performance evaluation. Moreover, it underscores the advantages of integrating
human expertise with machine capabilities to produce more robust models and
trustworthy data development. The source code for Multilabelfy will be
available at https://github.com/esla/Multilabelfy.
<br>\keywords{Computer Vision \and Dataset Quality Enhancement \and Dataset
Validation \and Human-Computer Interaction \and Multi-label Annotation.}
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17738 title=Abstract>arXiv:2401.17738</a> [<a href=https://arxiv.org/pdf/2401.17738 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17738 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Harnessing Smartwatch Microphone Sensors for Cough Detection and Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal%2C+P">Pranay Jaiswal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lone%2C+H+R">Haroon R. Lone</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>This study investigates the potential of using smartwatches with built-in
microphone sensors for monitoring coughs and detecting various cough types. We
conducted a study involving 32 participants and collected 9 hours of audio data
in a controlled manner. Afterward, we processed this data using a structured
approach, resulting in 223 positive cough samples. We further improved the
dataset through augmentation techniques and employed a specialized 1D CNN
model. This model achieved an impressive accuracy rate of 98.49% while
non-walking and 98.2% while walking, showing smartwatches can detect cough.
Moreover, our research successfully identified four distinct types of coughs
using clustering techniques.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17739 title=Abstract>arXiv:2401.17739</a> [<a href=https://arxiv.org/pdf/2401.17739 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17739 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Operator learning without the adjoint
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Boull%C3%A9%2C+N">Nicolas Boull</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Halikias%2C+D">Diana Halikias</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Otto%2C+S+E">Samuel E. Otto</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 49 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>There is a mystery at the heart of operator learning: how can one recover a
non-self-adjoint operator from data without probing the adjoint? Current
practical approaches suggest that one can accurately recover an operator while
only using data generated by the forward action of the operator without access
to the adjoint. However, naively, it seems essential to sample the action of
the adjoint. In this paper, we partially explain this mystery by proving that
without querying the adjoint, one can approximate a family of non-self-adjoint
infinite-dimensional compact operators via projection onto a Fourier basis. We
then apply the result to recovering Green's functions of elliptic partial
differential operators and derive an adjoint-free sample complexity bound.
While existing theory justifies low sample complexity in operator learning,
ours is the first adjoint-free analysis that attempts to close the gap between
theory and practice.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17740 title=Abstract>arXiv:2401.17740</a> [<a href=https://arxiv.org/pdf/2401.17740 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17740 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gamifying a Software Testing Course with Continuous Integration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Straubinger%2C+P">Philipp Straubinger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fraser%2C+G">Gordon Fraser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Testing plays a crucial role in software development, and it is essential for
software engineering students to receive proper testing education. However,
motivating students to write tests and use automated testing during software
development can be challenging. To address this issue and enhance student
engagement in testing when they write code, we propose to incentivize students
to test more by gamifying continuous integration. For this we use Gamekins, a
tool that is seamlessly integrated into the Jenkins continuous integration
platform and uses game elements based on commits to the source code repository:
Developers can earn points by completing test challenges and quests generated
by Gamekins, compete with other developers or teams on a leaderboard, and
receive achievements for their test-related accomplishments. In this paper, we
present our integration of Gamekins into an undergraduate-level course on
software testing. We observe a correlation between how students test their code
and their use of Gamekins, as well as a significant improvement in the accuracy
of their results compared to a previous iteration of the course without
gamification. As a further indicator of how this approach improves testing
behavior, the students reported enjoyment in writing tests with Gamekins.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17741 title=Abstract>arXiv:2401.17741</a> [<a href=https://arxiv.org/pdf/2401.17741 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17741 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Haris: an Advanced Autonomous Mobile Robot for Smart Parking Assistance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamad%2C+L">Layth Hamad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+M+A">Muhammad Asif Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menouar%2C+H">Hamid Menouar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Filali%2C+F">Fethi Filali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohamed%2C+A">Amr Mohamed</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in 2024 IEEE International Conference on Consumer Electronics (ICCE), Las Vegas, NV, USA, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper presents Haris, an advanced autonomous mobile robot system for
tracking the location of vehicles in crowded car parks using license plate
recognition. The system employs simultaneous localization and mapping (SLAM)
for autonomous navigation and precise mapping of the parking area, eliminating
the need for GPS dependency. In addition, the system utilizes a sophisticated
framework using computer vision techniques for object detection and automatic
license plate recognition (ALPR) for reading and associating license plate
numbers with location data. This information is subsequently synchronized with
a back-end service and made accessible to users via a user-friendly mobile app,
offering effortless vehicle location and alleviating congestion within the
parking facility. The proposed system has the potential to improve the
management of short-term large outdoor parking areas in crowded places such as
sports stadiums. The demo of the robot can be found on
https://youtu.be/ZkTCM35fxa0?si=QjggJuN7M1o3oifx.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17743 title=Abstract>arXiv:2401.17743</a> [<a href=https://arxiv.org/pdf/2401.17743 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17743 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algorithmic Robust Forecast Aggregation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yongkang Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartline%2C+J+D">Jason D. Hartline</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhihuan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+Y">Yuqing Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+A">Anant Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+F">Fang-Yi Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)
</div>
<p class=mathjax>Forecast aggregation combines the predictions of multiple forecasters to
improve accuracy. However, the lack of knowledge about forecasters' information
structure hinders optimal aggregation. Given a family of information
structures, robust forecast aggregation aims to find the aggregator with
minimal worst-case regret compared to the omniscient aggregator. Previous
approaches for robust forecast aggregation rely on heuristic observations and
parameter tuning. We propose an algorithmic framework for robust forecast
aggregation. Our framework provides efficient approximation schemes for general
information aggregation with a finite family of possible information
structures. In the setting considered by Arieli et al. (2018) where two agents
receive independent signals conditioned on a binary state, our framework also
provides efficient approximation schemes by imposing Lipschitz conditions on
the aggregator or discrete conditions on agents' reports. Numerical experiments
demonstrate the effectiveness of our method by providing a nearly optimal
aggregator in the setting considered by Arieli et al. (2018).
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17745 title=Abstract>arXiv:2401.17745</a> [<a href=https://arxiv.org/pdf/2401.17745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17745 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gesture Controlled Robot For Human Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%2C+A+T">Athira T.S</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manoj%2C+H">Honey Manoj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Priya%2C+R+S+V">R S Vishnu Priya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menon%2C+V+K">Vishnu K Menon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%2C+S">Srilekshmi M</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, presented at the 2nd International Conference on IoT Based Control Networks and Intelligent Systems(ICICNIS 2021)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> proceedings of International Conference on IoT Based Control
 Networks &amp; Intelligent Systems - ICICNIS 2021, 6 pages,2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>It is very important to locate survivors from collapsed buildings so that
rescue operations can be arranged. Many lives are lost due to lack of competent
systems to detect people in these collapsed buildings at the right time. So
here we have designed a hand gesture controlled robot which is capable of
detecting humans under these collapsed building parts. The proposed work can be
used to access specific locations that are not humanly possible, and detect
those humans trapped under the rubble of collapsed buildings. This information
is then used to notify the rescue team to take adequate measures and initiate
rescue operations accordingly.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17746 title=Abstract>arXiv:2401.17746</a> [<a href=https://arxiv.org/pdf/2401.17746 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17746 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Logit Poisoning Attack in Distillation-based Federated Learning and its Countermeasures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yonghao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shunan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinglu Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Distillation-based federated learning has emerged as a promising
collaborative learning approach, where clients share the output logit vectors
of a public dataset rather than their private model parameters. This practice
reduces the risk of privacy invasion attacks and facilitates heterogeneous
learning. The landscape of poisoning attacks within distillation-based
federated learning is complex, with existing research employing traditional
data poisoning strategies targeting the models' parameters. However, these
attack schemes primarily have shortcomings rooted in their original designs,
which target the model parameters rather than the logit vectors. Furthermore,
they do not adequately consider the role of logit vectors in carrying
information during the knowledge transfer process. This misalignment results in
less efficiency in the context of distillation-based federated learning. Due to
the limitations of existing methodologies, our research delves into the
intrinsic properties of the logit vector, striving for a more nuanced
understanding. We introduce a two-stage scheme for logit poisoning attacks,
addressing previous shortcomings. Initially, we collect the local logits,
generate the representative vectors, categorize the logit elements within the
vector, and design a shuffling table to maximize information entropy. Then, we
intentionally scale the shuffled logit vectors to enhance the magnitude of the
target vectors. Concurrently, we propose an efficient defense algorithm to
counter this new poisoning scheme by calculating the distance between estimated
benign vectors and vectors uploaded by users. Through extensive experiments,
our study illustrates the significant threat posed by the proposed logit
poisoning attack and highlights the effectiveness of our defense algorithm.
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17747 title=Abstract>arXiv:2401.17747</a> [<a href=https://arxiv.org/pdf/2401.17747 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17747 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Model-driven development of data intensive applications over cloud resources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolosana-Calasanz%2C+R">Rafael Tolosana-Calasanz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ba%C3%B1ares%2C+J+%C3%81">Jos ngel Baares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colom%2C+J">Jos-Manuel Colom</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Future Generation Computer Systems, Volume 87, 2018, Pages
 888-909,
 (https://www.sciencedirect.com/science/article/pii/S0167739X17329473)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The proliferation of sensors over the last years has generated large amounts
of raw data, forming data streams that need to be processed. In many cases,
cloud resources are used for such processing, exploiting their flexibility, but
these sensor streaming applications often need to support operational and
control actions that have real-time and low-latency requirements that go beyond
the cost effective and flexible solutions supported by existing cloud
frameworks, such as Apache Kafka, Apache Spark Streaming, or Map-Reduce
Streams. In this paper, we describe a model-driven and stepwise refinement
methodological approach for streaming applications executed over clouds. The
central role is assigned to a set of Petri Net models for specifying functional
and non-functional requirements. They support model reuse, and a way to combine
formal analysis, simulation, and approximate computation of minimal and maximal
boundaries of non-functional requirements when the problem is either
mathematically or computationally intractable. We show how our proposal can
assist developers in their design and implementation decisions from a
performance perspective. Our methodology allows to conduct performance
analysis: The methodology is intended for all the engineering process stages,
and we can (i) analyse how it can be mapped onto cloud resources, and (ii)
obtain key performance indicators, including throughput or economic cost, so
that developers are assisted in their development tasks and in their decision
taking. In order to illustrate our approach, we make use of the pipelined
wavefront array.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17748 title=Abstract>arXiv:2401.17748</a> [<a href=https://arxiv.org/pdf/2401.17748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Dynamical Neural Galerkin Scheme for Filtering Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Aghili%2C+J">Joubine Aghili</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Atokple%2C+J+Z">Joy Zialesi Atokple</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Billaud-Friess%2C+M">Marie Billaud-Friess</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Garnier%2C+G">Guillaume Garnier</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mula%2C+O">Olga Mula</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tognon%2C+N">Norbert Tognon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>This paper considers the filtering problem which consists in reconstructing
the state of a dynamical system with partial observations coming from sensor
measurements, and the knowledge that the dynamics are governed by a physical
PDE model with unknown parameters. We present a filtering algorithm where the
reconstruction of the dynamics is done with neural network approximations whose
weights are dynamically updated using observational data. In addition to the
estimate of the state, we also obtain time-dependent parameter estimations of
the PDE parameters governing the observed evolution. We illustrate the behavior
of the method in a one-dimensional KdV equation involving the transport of
solutions with local support. Our numerical investigation reveals the
importance of the location and number of the observations. In particular, it
suggests to consider dynamical sensor placement.
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17749 title=Abstract>arXiv:2401.17749</a> [<a href=https://arxiv.org/pdf/2401.17749 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17749 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+X">Xiao Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+W">Weifu Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuo%2C+F">Fei Zuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Mengqing Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Large language models (LLMs) have recently garnered significant
accomplishments in various exploratory tasks, even surpassing the performance
of traditional reinforcement learning-based methods that have historically
dominated the agent-based field. The purpose of this paper is to investigate
the efficacy of LLMs in executing real-time strategy war tasks within the
StarCraft II gaming environment. In this paper, we introduce SwarmBrain, an
embodied agent leveraging LLM for real-time strategy implementation in the
StarCraft II game environment. The SwarmBrain comprises two key components: 1)
a Overmind Intelligence Matrix, powered by state-of-the-art LLMs, is designed
to orchestrate macro-level strategies from a high-level perspective. This
matrix emulates the overarching consciousness of the Zerg intelligence brain,
synthesizing strategic foresight with the aim of allocating resources,
directing expansion, and coordinating multi-pronged assaults. 2) a Swarm
ReflexNet, which is agile counterpart to the calculated deliberation of the
Overmind Intelligence Matrix. Due to the inherent latency in LLM reasoning, the
Swarm ReflexNet employs a condition-response state machine framework, enabling
expedited tactical responses for fundamental Zerg unit maneuvers. In the
experimental setup, SwarmBrain is in control of the Zerg race in confrontation
with an Computer-controlled Terran adversary. Experimental results show the
capacity of SwarmBrain to conduct economic augmentation, territorial expansion,
and tactical formulation, and it shows the SwarmBrain is capable of achieving
victory against Computer players set at different difficulty levels.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17751 title=Abstract>arXiv:2401.17751</a> [<a href=https://arxiv.org/pdf/2401.17751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design and Testbed Deployment of Frequency-Domain Equalization Full Duplex Radios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kohli%2C+M">Manav Kohli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dastjerdi%2C+M+B">Mahmood Baraani Dastjerdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jin Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seskar%2C+I">Ivan Seskar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krishnaswamy%2C+H">Harish Krishnaswamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zussman%2C+G">Gil Zussman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tingjun Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 22 figures. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/1812.01126>arXiv:1812.01126</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Full-duplex (FD) wireless can significantly enhance spectrum efficiency but
requires effective self-interference (SI) cancellers. RF SI cancellation (SIC)
via frequency-domain equalization (FDE), where bandpass filters channelize the
SI, is suited for integrated circuits (ICs). In this paper, we explore the
limits and higher layer challenges associated with using such cancellers. We
evaluate the performance of a custom FDE-based canceller using two testbeds;
one with mobile FD radios and the other with upgraded, static FD radios in the
PAWR COSMOS testbed. The latter is a lasting artifact for the research
community, alongside a dataset containing baseband waveforms captured on the
COSMOS FD radios, facilitating FD-related experimentation at the higher
networking layers. We evaluate the performance of the FDE-based FD radios in
both testbeds, with experiments showing 95 dB overall achieved SIC (52 dB from
RF SIC) across 20 MHz bandwidth, and an average link-level FD rate gain of
1.87x. We also conduct experiments in (i) uplink-downlink networks with
inter-user interference, and (ii) heterogeneous networks with half-duplex and
FD users. The experimental FD gains in the two types of networks depend on the
users' SNR values and the number of FD users, and are 1.14x-1.25x and
1.25x-1.73x, respectively, confirming previous analytical results.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17752 title=Abstract>arXiv:2401.17752</a> [<a href=https://arxiv.org/pdf/2401.17752 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17752 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PF-GNN: Differentiable particle filtering based approximation of universal graph representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dupty%2C+M+H">Mohammed Haroon Dupty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yanfei Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+W+S">Wee Sun Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published as a conference paper at ICLR 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Message passing Graph Neural Networks (GNNs) are known to be limited in
expressive power by the 1-WL color-refinement test for graph isomorphism. Other
more expressive models either are computationally expensive or need
preprocessing to extract structural features from the graph. In this work, we
propose to make GNNs universal by guiding the learning process with exact
isomorphism solver techniques which operate on the paradigm of
Individualization and Refinement (IR), a method to artificially introduce
asymmetry and further refine the coloring when 1-WL stops. Isomorphism solvers
generate a search tree of colorings whose leaves uniquely identify the graph.
However, the tree grows exponentially large and needs hand-crafted pruning
techniques which are not desirable from a learning perspective. We take a
probabilistic view and approximate the search tree of colorings (i.e.
embeddings) by sampling multiple paths from root to leaves of the search tree.
To learn more discriminative representations, we guide the sampling process
with particle filter updates, a principled approach for sequential state
estimation. Our algorithm is end-to-end differentiable, can be applied with any
GNN as backbone and learns richer graph representations with only linear
increase in runtime. Experimental evaluation shows that our approach
consistently outperforms leading GNN models on both synthetic benchmarks for
isomorphism detection as well as real-world datasets.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17755 title=Abstract>arXiv:2401.17755</a> [<a href=https://arxiv.org/pdf/2401.17755 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17755 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CauESC: A Causal Aware Model for Emotional Support Conversation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hengxu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+X">Xiang Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Emotional Support Conversation aims at reducing the seeker's emotional
distress through supportive response. Existing approaches have two limitations:
(1) They ignore the emotion causes of the distress, which is important for
fine-grained emotion understanding; (2) They focus on the seeker's own mental
state rather than the emotional dynamics during interaction between speakers.
To address these issues, we propose a novel framework CauESC, which firstly
recognizes the emotion causes of the distress, as well as the emotion effects
triggered by the causes, and then understands each strategy of verbal grooming
independently and integrates them skillfully. Experimental results on the
benchmark dataset demonstrate the effectiveness of our approach and show the
benefits of emotion understanding from cause to effect and
independent-integrated strategy modeling.
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17757 title=Abstract>arXiv:2401.17757</a> [<a href=https://arxiv.org/pdf/2401.17757 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17757 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17757 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Will Lanczos Iterations Generate Symmetric Quadrature Nodes?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+W">Wenhao Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Han%2C+Z">Zongyuan Han</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wathen%2C+A+J">Andrew J Wathen</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhu%2C+S">Shengxin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>The Golub-Welsch algorithm [Math. Comp., 23: 221-230 (1969)] for computing
Gaussian quadrature rules is of importance in estimating quadratic forms.
Quadrature rules based on this algorithm have long been assumed to be
symmetric. Recent research indicates that the presence of asymmetric quadrature
nodes may be more often. Such a divergence has led to varying error analyses of
the Lanczos quadrature method. Since symmetry often implies simplicity, it is
of great interest to ask when do Lanczos iterations generate symmetric
quadrature rules. This paper derives a sufficient condition that ensures
symmetric quadrature nodes which partially answers the question that when the
Ritz values of a symmetric matrix are symmetrically distributed. Additionally,
we establish both lower and upper bounds on the disparity between the minimum
Lanczos iterations required for symmetric and asymmetric quadrature.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17759 title=Abstract>arXiv:2401.17759</a> [<a href=https://arxiv.org/pdf/2401.17759 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17759 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17759 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tiered approach for rapid damage characterisation of infrastructure enabled by remote sensing and deep learning technologies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kopiika%2C+N">Nadiia Kopiika</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karavias%2C+A">Andreas Karavias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krassakis%2C+P">Pavlos Krassakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Z">Zehao Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ninic%2C+J">Jelena Ninic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shakhovska%2C+N">Nataliya Shakhovska</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koukouzas%2C+N">Nikolaos Koukouzas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Argyroudis%2C+S">Sotirios Argyroudis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitoulis%2C+S">Stergios-Aristoteles Mitoulis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Main text (34 pages,18 figures); Supplementary materials (13 pages)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Critical infrastructure such as bridges are systematically targeted during
wars and conflicts. This is because critical infrastructure is vital for
enabling connectivity and transportation of people and goods, and hence,
underpinning the national and international defence planning and economic
growth. Mass destruction of bridges, along with minimal or no accessibility to
these assets during natural and anthropogenic disasters, prevents us from
delivering rapid recovery. As a result, systemic resilience is drastically
reduced. A solution to this challenge is to use technology for stand-off
observations. Yet, no method exists to characterise damage at different scales,
i.e. regional, asset, and structural (component), and more so there is little
or no systematic correlation between assessments at scale. We propose an
integrated three-level tiered approach to fill this capability gap, and we
demonstrate the methods for damage characterisation enabled by fit-for-purpose
digital technologies. Next, this method is applied and validated to a case
study in Ukraine that includes 17 bridges. From macro to micro, we deploy
technology at scale, from Sentinel-1 SAR images, crowdsourced information, and
high-resolution images to deep learning for damaged infrastructure. For the
first time, the interferometric coherence difference and semantic segmentation
of images were deployed to improve the reliability of damage characterisations
from regional to infrastructure component level, when enhanced assessment
accuracy is required. This integrated method improves the speed of
decision-making, and thus, enhances resilience. Keywords: critical
infrastructure, damage characterisation, targeted attacks, restoration
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17766 title=Abstract>arXiv:2401.17766</a> [<a href=https://arxiv.org/pdf/2401.17766 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17766 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-Grained Zero-Shot Learning: Advances, Challenges, and Prospects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jingcai Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+Z">Zhijie Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+S">Song Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 1 figure, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent zero-shot learning (ZSL) approaches have integrated fine-grained
analysis, i.e., fine-grained ZSL, to mitigate the commonly known seen/unseen
domain bias and misaligned visual-semantics mapping problems, and have made
profound progress. Notably, this paradigm differs from existing close-set
fine-grained methods and, therefore, can pose unique and nontrivial challenges.
However, to the best of our knowledge, there remains a lack of systematic
summaries of this topic. To enrich the literature of this domain and provide a
sound basis for its future development, in this paper, we present a broad
review of recent advances for fine-grained analysis in ZSL. Concretely, we
first provide a taxonomy of existing methods and techniques with a thorough
analysis of each category. Then, we summarize the benchmark, covering publicly
available datasets, models, implementations, and some more details as a
library. Last, we sketch out some related applications. In addition, we discuss
vital challenges and suggest potential future directions.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17773 title=Abstract>arXiv:2401.17773</a> [<a href=https://arxiv.org/pdf/2401.17773 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17773 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+X">Xingning Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qingpei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gan%2C+T">Tian Gan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jianlong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xiangyuan Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+W">Wei Chu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by TCSVT (IEEE Transactions on Circuits and Systems for Video Technology)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)
</div>
<p class=mathjax>We present a framework for learning cross-modal video representations by
directly pre-training on raw data to facilitate various downstream video-text
tasks. Our main contributions lie in the pre-training framework and proxy
tasks. First, based on the shortcomings of two mainstream pixel-level
pre-training architectures (limited applications or less efficient), we propose
Shared Network Pre-training (SNP). By employing one shared BERT-type network to
refine textual and cross-modal features simultaneously, SNP is lightweight and
could support various downstream applications. Second, based on the intuition
that people always pay attention to several "significant words" when
understanding a sentence, we propose the Significant Semantic Strengthening
(S3) strategy, which includes a novel masking and matching proxy task to
promote the pre-training performance. Experiments conducted on three downstream
video-text tasks and six datasets demonstrate that, we establish a new
state-of-the-art in pixel-level video-text pre-training; we also achieve a
satisfactory balance between the pre-training efficiency and the fine-tuning
performance. The codebase are available at
https://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/snps3_vtp.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17776 title=Abstract>arXiv:2401.17776</a> [<a href=https://arxiv.org/pdf/2401.17776 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17776 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Double InfoGAN for Contrastive Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carton%2C+F">Florence Carton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Louiset%2C+R">Robin Louiset</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gori%2C+P">Pietro Gori</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)
</div>
<p class=mathjax>Contrastive Analysis (CA) deals with the discovery of what is common and what
is distinctive of a target domain compared to a background one. This is of
great interest in many applications, such as medical imaging. Current
state-of-the-art (SOTA) methods are latent variable models based on VAE
(CA-VAEs). However, they all either ignore important constraints or they don't
enforce fundamental assumptions. This may lead to sub-optimal solutions where
distinctive factors are mistaken for common ones (or viceversa). Furthermore,
the generated images have a rather poor quality, typical of VAEs, decreasing
their interpretability and usefulness. Here, we propose Double InfoGAN, the
first GAN based method for CA that leverages the high-quality synthesis of GAN
and the separation power of InfoGAN. Experimental results on four visual
datasets, from simple synthetic examples to complex medical images, show that
the proposed method outperforms SOTA CA-VAEs in terms of latent separation and
image quality. Datasets and code are available online.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17778 title=Abstract>arXiv:2401.17778</a> [<a href=https://arxiv.org/pdf/2401.17778 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17778 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parameter-robust full linear convergence and optimal complexity of adaptive iteratively linearized FEM for nonlinear PDEs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mira%C3%A7i%2C+A">Ani Mirai</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Praetorius%2C+D">Dirk Praetorius</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Streitberger%2C+J">Julian Streitberger</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We propose an adaptive iteratively linearized finite element method (AILFEM)
in the context of strongly monotone nonlinear operators in Hilbert spaces. The
approach combines adaptive mesh-refinement with an energy-contractive
linearization scheme (e.g., the Ka\v{c}anov method) and a norm-contractive
algebraic solver (e.g., an optimal geometric multigrid method). Crucially, a
novel parameter-free algebraic stopping criterion is designed and we prove that
it leads to a uniformly bounded number of algebraic solver steps. Unlike
available results requiring sufficiently small adaptivity parameters to ensure
even plain convergence, the new AILFEM algorithm guarantees full R-linear
convergence for arbitrary adaptivity parameters. Thus, parameter-robust
convergence is guaranteed. Moreover, for sufficiently small adaptivity
parameters, the new adaptive algorithm guarantees optimal complexity, i.e.,
optimal convergence rates with respect to the overall computational cost and,
hence, time.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17780 title=Abstract>arXiv:2401.17780</a> [<a href=https://arxiv.org/pdf/2401.17780 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17780 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Policy Gradient Primal-Dual Algorithm for Constrained MDPs with Uniform PAC Guarantees
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kitamura%2C+T">Toshinori Kitamura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kozuno%2C+T">Tadashi Kozuno</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kato%2C+M">Masahiro Kato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ichihara%2C+Y">Yuki Ichihara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nishimori%2C+S">Soichiro Nishimori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sannai%2C+A">Akiyoshi Sannai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sonoda%2C+S">Sho Sonoda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumagai%2C+W">Wataru Kumagai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matsuo%2C+Y">Yutaka Matsuo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We study a primal-dual reinforcement learning (RL) algorithm for the online
constrained Markov decision processes (CMDP) problem, wherein the agent
explores an optimal policy that maximizes return while satisfying constraints.
Despite its widespread practical use, the existing theoretical literature on
primal-dual RL algorithms for this problem only provides sublinear regret
guarantees and fails to ensure convergence to optimal policies. In this paper,
we introduce a novel policy gradient primal-dual algorithm with uniform
probably approximate correctness (Uniform-PAC) guarantees, simultaneously
ensuring convergence to optimal policies, sublinear regret, and polynomial
sample complexity for any target accuracy. Notably, this represents the first
Uniform-PAC algorithm for the online CMDP problem. In addition to the
theoretical guarantees, we empirically demonstrate in a simple CMDP that our
algorithm converges to optimal policies, while an existing algorithm exhibits
oscillatory performance and constraint violation.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17783 title=Abstract>arXiv:2401.17783</a> [<a href=https://arxiv.org/pdf/2401.17783 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17783 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SDRDPy: An application to graphically visualize the knowledge obtained with supervised descriptive rule algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padilla-Rascon%2C+M+A">M.A. Padilla-Rascon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+P">P. Gonzalez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmona%2C+C+J">C.J. Carmona</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>SDRDPy is a desktop application that allows experts an intuitive graphic and
tabular representation of the knowledge extracted by any supervised descriptive
rule discovery algorithm. The application is able to provide an analysis of the
data showing the relevant information of the data set and the relationship
between the rules, data and the quality measures associated for each rule
regardless of the tool where algorithm has been executed. All of the
information is presented in a user-friendly application in order to facilitate
expert analysis and also the exportation of reports in different formats.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17786 title=Abstract>arXiv:2401.17786</a> [<a href=https://arxiv.org/pdf/2401.17786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Graph-Native Query Optimization Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+B">Bingqing Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiaoli Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+L">Longbin Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yufan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lou%2C+Y">Yunkai Lou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+W">Wenyuan Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Graph queries that combine pattern matching with relational operations,
referred as PatRelQuery, are widely used in many real-world applications. It
allows users to identify arbitrary patterns in a graph and further perform
in-depth relational analysis on the results. To effectively support
PatRelQuery, two key challenges need to be addressed: (1) how to optimize
PatRelQuery in a unified framework, and (2) how to handle the arbitrary type
constraints in patterns in PatRelQuery. In this paper, we present a
graph-native query optimization framework named GOpt, to tackle these issues.
GOpt is built on top of a unified intermediate representation (IR) that is
capable of capturing both graph and relational operations, thereby streamlining
the optimization of PatRelQuery. To handle the arbitrary type constraints, GOpt
employs an automatic type inference approach to identify implicit type
constraints. Additionally, GOpt introduces a graph-native optimizer, which
encompasses an extensive collection of optimization rules along with cost-based
techniques tailored for arbitrary patterns, to optimize PatRelQuery. Through
comprehensive experiments, we demonstrate that GOpt can achieve significant
query performance improvements, in both crafted benchmarks and real-world
applications.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17789 title=Abstract>arXiv:2401.17789</a> [<a href=https://arxiv.org/pdf/2401.17789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robustly overfitting latents for flexible neural image compression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perugachi-Diaz%2C+Y">Yura Perugachi-Diaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gansekoele%2C+A">Arwin Gansekoele</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhulai%2C+S">Sandjai Bhulai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Neural image compression has made a great deal of progress. State-of-the-art
models are based on variational autoencoders and are outperforming classical
models. Neural compression models learn to encode an image into a quantized
latent representation that can be efficiently sent to the decoder, which
decodes the quantized latent into a reconstructed image. While these models
have proven successful in practice, they lead to sub-optimal results due to
imperfect optimization and limitations in the encoder and decoder capacity.
Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the
latents of pre-trained neural image compression models. We extend this idea by
introducing SGA+, which contains three different methods that build upon SGA.
Further, we give a detailed analysis of our proposed methods, show how they
improve performance, and show that they are less sensitive to hyperparameter
choices. Besides, we show how each method can be extended to three- instead of
two-class rounding. Finally, we show how refinement of the latents with our
best-performing method improves the compression performance on the Tecnick
dataset and how it can be deployed to partly move along the rate-distortion
curve.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17790 title=Abstract>arXiv:2401.17790</a> [<a href=https://arxiv.org/pdf/2401.17790 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17790 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RADIN: Souping on a Budget
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menes%2C+T">Thibaut Menes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Risser-Maroix%2C+O">Olivier Risser-Maroix</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Model Soups, extending Stochastic Weights Averaging (SWA), combine models
fine-tuned with different hyperparameters. Yet, their adoption is hindered by
computational challenges due to subset selection issues. In this paper, we
propose to speed up model soups by approximating soups performance using
averaged ensemble logits performances. Theoretical insights validate the
congruence between ensemble logits and weight averaging soups across any mixing
ratios. Our Resource ADjusted soups craftINg (RADIN) procedure stands out by
allowing flexible evaluation budgets, enabling users to adjust his budget of
exploration adapted to his resources while increasing performance at lower
budget compared to previous greedy approach (up to 4% on ImageNet).
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17791 title=Abstract>arXiv:2401.17791</a> [<a href=https://arxiv.org/pdf/2401.17791 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17791 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Transformers without Positional Encodings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garg%2C+A">Ayush Garg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Independent Research
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recently, Transformers for graph representation learning have become
increasingly popular, achieving state-of-the-art performance on a wide-variety
of datasets, either alone or in combination with message-passing graph neural
networks (MP-GNNs). Infusing graph inductive-biases in the innately
structure-agnostic transformer architecture in the form of structural or
positional encodings (PEs) is key to achieving these impressive results.
However, designing such encodings is tricky and disparate attempts have been
made to engineer such encodings including Laplacian eigenvectors, relative
random-walk probabilities (RRWP), spatial encodings, centrality encodings, edge
encodings etc. In this work, we argue that such encodings may not be required
at all, provided the attention mechanism itself incorporates information about
the graph structure. We introduce Eigenformer, which uses a novel
spectrum-aware attention mechanism cognizant of the Laplacian spectrum of the
graph, and empirically show that it achieves performance comparable to SOTA
MP-GNN architectures and Graph Transformers on a number of standard GNN
benchmark datasets, even surpassing the SOTA on some datasets. We also find
that our architecture is much faster to train in terms of number of epochs,
presumably due to the innate graph inductive biases.
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17793 title=Abstract>arXiv:2401.17793</a> [<a href=https://arxiv.org/pdf/2401.17793 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17793 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Dynamic Ancillary Services Provision Based on Local Power Grid Perception
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=H%C3%A4berle%2C+V">Verena Hberle</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=He%2C+X">Xiuqiang He</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+L">Linbin Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%C3%B6rfler%2C+F">Florian Drfler</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 18 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this paper, we propose a systematic closed-loop approach to provide
optimal dynamic ancillary services with converter-interfaced generation systems
based on local power grid perception. In particular, we structurally encode
dynamic ancillary services such as fast frequency and voltage regulation in the
form of a parametric transfer function matrix, which includes several
parameters to define a set of different feasible response behaviors, among
which we aim to find the optimal one to be realized by the converter system.
Our approach is based on a so-called "perceive-and-optimize" (P&amp;O) strategy:
First, we identify a grid dynamic equivalent at the interconnection terminals
of the converter system. Second, we consider the closed-loop interconnection of
the identified grid equivalent and the parametric transfer function matrix,
which we optimize for the set of transfer function parameters, resulting in a
stable and optimal closed-loop performance for ancillary services provision. In
the process, we ensure that grid-code and device-level requirements are
satisfied. Finally, we demonstrate the effectiveness of our approach in
different numerical case studies based on a modified Kundur two-area test
system.
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17796 title=Abstract>arXiv:2401.17796</a> [<a href=https://arxiv.org/pdf/2401.17796 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17796 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploiting Audio-Visual Features with Pretrained AV-HuBERT for Multi-Modal Dysarthric Speech Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xueyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuejiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xixin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Disong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xunying Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Dysarthric speech reconstruction (DSR) aims to transform dysarthric speech
into normal speech by improving the intelligibility and naturalness. This is a
challenging task especially for patients with severe dysarthria and speaking in
complex, noisy acoustic environments. To address these challenges, we propose a
novel multi-modal framework to utilize visual information, e.g., lip movements,
in DSR as extra clues for reconstructing the highly abnormal pronunciations.
The multi-modal framework consists of: (i) a multi-modal encoder to extract
robust phoneme embeddings from dysarthric speech with auxiliary visual
features; (ii) a variance adaptor to infer the normal phoneme duration and
pitch contour from the extracted phoneme embeddings; (iii) a speaker encoder to
encode the speaker's voice characteristics; and (iv) a mel-decoder to generate
the reconstructed mel-spectrogram based on the extracted phoneme embeddings,
prosodic features and speaker embeddings. Both objective and subjective
evaluations conducted on the commonly used UASpeech corpus show that our
proposed approach can achieve significant improvements over baseline systems in
terms of speech intelligibility and naturalness, especially for the speakers
with more severe symptoms. Compared with original dysarthric speech, the
reconstructed speech achieves 42.1\% absolute word error rate reduction for
patients with more severe dysarthria levels.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17797 title=Abstract>arXiv:2401.17797</a> [<a href=https://arxiv.org/pdf/2401.17797 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17797 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+X">Xingning Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zipeng Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chunluan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xuzheng Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qingpei Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We present a Multi-Modal Recipe for Advancing Adaptation-based Pre-training
towards effective and efficient zero-shot video-text retrieval, dubbed M2-RAAP.
Upon popular image-text models like CLIP, most current adaptation-based
video-text pre-training methods are confronted by three major issues, i.e.,
noisy data corpus, time-consuming pre-training, and limited performance gain.
Towards this end, we conduct a comprehensive study including four critical
steps in video-text pre-training. Specifically, we investigate 1) data
filtering and refinement, 2) video input type selection, 3) temporal modeling,
and 4) video feature enhancement. We then summarize this empirical study into
the M2-RAAP recipe, where our technical contributions lie in 1) the data
filtering and text re-writing pipeline resulting in 1M high-quality bilingual
video-text pairs, 2) the replacement of video inputs with key-frames to
accelerate pre-training, and 3) the Auxiliary-Caption-Guided (ACG) strategy to
enhance video features. We conduct extensive experiments by adapting three
image-text foundation models on two refined video-text datasets from different
languages, validating the robustness and reproducibility of M2-RAAP for
adaptation-based pre-training. Results demonstrate that M2-RAAP yields superior
performance with significantly reduced data (-90%) and time consumption (-95%),
establishing a new SOTA on four English zero-shot retrieval datasets and two
Chinese ones. We are preparing our refined bilingual data annotations and
codebase, which will be available at
https://github.com/alipay/Ant-Multi-Modal-Framework/tree/main/prj/M2_RAAP.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17799 title=Abstract>arXiv:2401.17799</a> [<a href=https://arxiv.org/pdf/2401.17799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI-enabled Cyber-Physical In-Orbit Factory -- AI approaches based on digital twin technology for robotic small satellite production
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leutert%2C+F">Florian Leutert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bohlig%2C+D">David Bohlig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kempf%2C+F">Florian Kempf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schilling%2C+K">Klaus Schilling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BChlbauer%2C+M">Maximilian Mhlbauer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayan%2C+B">Bengisu Ayan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hulin%2C+T">Thomas Hulin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stulp%2C+F">Freek Stulp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Schffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutscher%2C+V">Vladimir Kutscher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plesker%2C+C">Christian Plesker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dasbach%2C+T">Thomas Dasbach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damm%2C+S">Stephan Damm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anderl%2C+R">Reiner Anderl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schleich%2C+B">Benjamin Schleich</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Acta Astronautica (2024), vol. 217, page 1-17
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>With the ever increasing number of active satellites in space, the rising
demand for larger formations of small satellites and the commercialization of
the space industry (so-called New Space), the realization of manufacturing
processes in orbit comes closer to reality. Reducing launch costs and risks,
allowing for faster on-demand deployment of individually configured satellites
as well as the prospect for possible on-orbit servicing for satellites makes
the idea of realizing an in-orbit factory promising. In this paper, we present
a novel approach to an in-orbit factory of small satellites covering a digital
process twin, AI-based fault detection, and teleoperated robot-control, which
are being researched as part of the "AI-enabled Cyber-Physical In-Orbit
Factory" project. In addition to the integration of modern automation and
Industry 4.0 production approaches, the question of how artificial intelligence
(AI) and learning approaches can be used to make the production process more
robust, fault-tolerant and autonomous is addressed. This lays the foundation
for a later realisation of satellite production in space in the form of an
in-orbit factory. Central aspect is the development of a robotic AIT (Assembly,
Integration and Testing) system where a small satellite could be assembled by a
manipulator robot from modular subsystems. Approaches developed to improving
this production process with AI include employing neural networks for optical
and electrical fault detection of components. Force sensitive measuring and
motion training helps to deal with uncertainties and tolerances during
assembly. An AI-guided teleoperated control of the robot arm allows for human
intervention while a Digital Process Twin represents process data and provides
supervision during the whole production process. Approaches and results towards
automated satellite production are presented in detail.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17800 title=Abstract>arXiv:2401.17800</a> [<a href=https://arxiv.org/pdf/2401.17800 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17800 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dance-to-Music Generation with Encoder-based Textual Inversion of Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sifei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+W">Weiming Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+F">Fan Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deussen%2C+O">Oliver Deussen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+T">Tong-Yee Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>The harmonious integration of music with dance movements is pivotal in
vividly conveying the artistic essence of dance. This alignment also
significantly elevates the immersive quality of gaming experiences and
animation productions. While there has been remarkable advancement in creating
high-fidelity music from textual descriptions, current methodologies mainly
concentrate on modulating overarching characteristics such as genre and
emotional tone. They often overlook the nuanced management of temporal rhythm,
which is indispensable in crafting music for dance, since it intricately aligns
the musical beats with the dancers' movements. Recognizing this gap, we propose
an encoder-based textual inversion technique for augmenting text-to-music
models with visual control, facilitating personalized music generation.
Specifically, we develop dual-path rhythm-genre inversion to effectively
integrate the rhythm and genre of a dance motion sequence into the textual
space of a text-to-music model. Contrary to the classical textual inversion
method, which directly updates text embeddings to reconstruct a single target
object, our approach utilizes separate rhythm and genre encoders to obtain text
embeddings for two pseudo-words, adapting to the varying rhythms and genres. To
achieve a more accurate evaluation, we propose improved evaluation metrics for
rhythm alignment. We demonstrate that our approach outperforms state-of-the-art
methods across multiple evaluation metrics. Furthermore, our method seamlessly
adapts to in-the-wild data and effectively integrates with the inherent
text-guided generation capability of the pre-trained model. Samples are
available at \url{https://youtu.be/D7XDwtH1YwE}.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17801 title=Abstract>arXiv:2401.17801</a> [<a href=https://arxiv.org/pdf/2401.17801 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17801 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17801 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weighted-Hamming Metric for Parallel Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bitzer%2C+S">Sebastian Bitzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravagnani%2C+A">Alberto Ravagnani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weger%2C+V">Violetta Weger</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Independent parallel q-ary symmetric channels are a suitable transmission
model for several applications. The proposed weighted-Hamming metric is
tailored to this setting and enables optimal decoding performance. We show that
some weighted-Hamming-metric codes exhibit the unusual property that all errors
beyond half the minimum distance can be corrected. Nevertheless, a tight
relation between the error-correction capability of a code and its minimum
distance can be established. Generalizing their Hamming-metric counterparts,
upper and lower bounds on the cardinality of a code with a given
weighted-Hamming distance are obtained. Finally, we propose a simple code
construction with optimal minimum distance for specific parameters.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17802 title=Abstract>arXiv:2401.17802</a> [<a href=https://arxiv.org/pdf/2401.17802 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17802 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distillation Enhanced Time Series Forecasting Network with Momentum Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+H">Haozhi Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Q">Qianqian Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinbao Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Contrastive representation learning is crucial in time series analysis as it
alleviates the issue of data noise and incompleteness as well as sparsity of
supervision signal. However, existing constrastive learning frameworks usually
focus on intral-temporal features, which fails to fully exploit the intricate
nature of time series data. To address this issue, we propose DE-TSMCL, an
innovative distillation enhanced framework for long sequence time series
forecasting. Specifically, we design a learnable data augmentation mechanism
which adaptively learns whether to mask a timestamp to obtain optimized
sub-sequences. Then, we propose a contrastive learning task with momentum
update to explore inter-sample and intra-temporal correlations of time series
to learn the underlying structure feature on the unlabeled time series.
Meanwhile, we design a supervised task to learn more robust representations and
facilitate the contrastive learning process. Finally, we jointly optimize the
above two tasks. By developing model loss from multiple tasks, we can learn
effective representations for downstream forecasting task. Extensive
experiments, in comparison with state-of-the-arts, well demonstrate the
effectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17803 title=Abstract>arXiv:2401.17803</a> [<a href=https://arxiv.org/pdf/2401.17803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yiran Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qianyu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+X">Xuequan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Z">Zhiwen Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lizhuang Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Segment anything model (SAM) has demonstrated excellent generalization
capabilities in common vision scenarios, yet lacking an understanding of
specialized data. Although numerous works have focused on optimizing SAM for
downstream tasks, these task-specific approaches usually limit the
generalizability to other downstream tasks. In this paper, we aim to
investigate the impact of the general vision modules on finetuning SAM and
enable them to generalize across all downstream tasks. We propose a simple
unified framework called SimAda for adapting SAM in underperformed scenes.
Specifically, our framework abstracts the general modules of different methods
into basic design elements, and we design four variants based on a shared
theoretical framework. SimAda is simple yet effective, which removes all
dataset-specific designs and focuses solely on general optimization, ensuring
that SimAda can be applied to all SAM-based and even Transformer-based models.
We conduct extensive experiments on nine datasets of six downstream tasks. The
results demonstrate that SimAda significantly improves the performance of SAM
on multiple downstream tasks and achieves state-of-the-art performance on most
of them, without requiring task-specific designs. Code is available at:
https://github.com/zongzi13545329/SimAda
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17804 title=Abstract>arXiv:2401.17804</a> [<a href=https://arxiv.org/pdf/2401.17804 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17804 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Efficient PGD Solver for Structural Dynamics Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vella%2C+C">Clment Vella</a> (LaMcube), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gosselet%2C+P">Pierre Gosselet</a> (LaMcube), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prudhomme%2C+S">Serge Prudhomme</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>We propose in this paper a Proper Generalized Decomposition (PGD) solver for
reduced-order modeling of linear elastodynamic problems. It primarily focuses
on enhancing the computational efficiency of a previously introduced PGD solver
based on the Hamiltonian formalism. The novelty of this work lies in the
implementation of a solver that is halfway between Modal Decomposition and the
conventional PGD framework, so as to accelerate the fixed-point iteration
algorithm. Additional procedures such that Aitken's delta-squared process and
mode-orthogonalization are incorporated to ensure convergence and stability of
the algorithm. Numerical results regarding the ROM accuracy, time complexity,
and scalability are provided to demonstrate the performance of the new solver
when applied to dynamic simulation of a three-dimensional structure.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17805 title=Abstract>arXiv:2401.17805</a> [<a href=https://arxiv.org/pdf/2401.17805 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17805 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Biospheric AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Korecki%2C+M">Marcin Korecki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The dominant paradigm in AI ethics and value alignment is highly
anthropocentric. The focus of these disciplines is strictly on human values
which limits the depth and breadth of their insights. Recently, attempts to
expand to a sentientist perspective have been initiated. We argue that neither
of these outlooks is sufficient to capture the actual complexity of the
biosphere and ensure that AI does not damage it. Thus, we propose a new
paradigm -- Biospheric AI that assumes an ecocentric perspective. We discuss
hypothetical ways in which such an AI might be designed. Moreover, we give
directions for research and application of the modern AI models that would be
consistent with the biospheric interests. All in all, this work attempts to
take first steps towards a comprehensive program of research that focuses on
the interactions between AI and the biosphere.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17806 title=Abstract>arXiv:2401.17806</a> [<a href=https://arxiv.org/pdf/2401.17806 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17806 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A new class of efficient high order semi-Lagrangian IMEX discontinuous Galerkin methods on staggered unstructured meshes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tavelli%2C+M">M. Tavelli</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Boscheri%2C+W">W. Boscheri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this paper we present a new high order semi-implicit DG scheme on
two-dimensional staggered triangular meshes applied to different nonlinear
systems of hyperbolic conservation laws such as advection-diffusion models,
incompressible Navier-Stokes equations and natural convection problems. While
the temperature and pressure field are defined on a triangular main grid, the
velocity field is defined on a quadrilateral edge-based staggered mesh. A
semi-implicit time discretization is proposed, which separates slow and fast
time scales by treating them explicitly and implicitly, respectively. The
nonlinear convection terms are evolved explicitly using a semi-Lagrangian
approach, whereas we consider an implicit discretization for the diffusion
terms and the pressure contribution. High-order of accuracy in time is achieved
using a new flexible and general framework of IMplicit-EXplicit (IMEX)
Runge-Kutta schemes specifically designed to operate with semi-Lagrangian
methods. To improve the efficiency in the computation of the DG divergence
operator and the mass matrix, we propose to approximate the numerical solution
with a less regular polynomial space on the edge-based mesh, which is defined
on two sub-triangles that split the staggered quadrilateral elements. Due to
the implicit treatment of the fast scale terms, the resulting numerical scheme
is unconditionally stable for the considered governing equations. Contrarily to
a genuinely space-time discontinuous-Galerkin scheme, the IMEX discretization
permits to preserve the symmetry and the positive semi-definiteness of the
arising linear system for the pressure that can be solved at the aid of an
efficient matrix-free implementation of the conjugate gradient method. We
present several convergence results, including nonlinear transport and density
currents, up to third order of accuracy in both space and time.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17807 title=Abstract>arXiv:2401.17807</a> [<a href=https://arxiv.org/pdf/2401.17807 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17807 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advances in 3D Generation: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaoyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+D">Di Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+W">Weihao Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yiming Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Z">Zhihao Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+J">Jing Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>Generating 3D models lies at the core of computer graphics and has been the
focus of decades of research. With the emergence of advanced neural
representations and generative models, the field of 3D content generation is
developing rapidly, enabling the creation of increasingly high-quality and
diverse 3D models. The rapid growth of this field makes it difficult to stay
abreast of all recent developments. In this survey, we aim to introduce the
fundamental methodologies of 3D generation methods and establish a structured
roadmap, encompassing 3D representation, generation methods, datasets, and
corresponding applications. Specifically, we introduce the 3D representations
that serve as the backbone for 3D generation. Furthermore, we provide a
comprehensive overview of the rapidly growing literature on generation methods,
categorized by the type of algorithmic paradigms, including feedforward
generation, optimization-based generation, procedural generation, and
generative novel view synthesis. Lastly, we discuss available datasets,
applications, and open challenges. We hope this survey will help readers
explore this exciting topic and foster further advancements in the field of 3D
content generation.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17809 title=Abstract>arXiv:2401.17809</a> [<a href=https://arxiv.org/pdf/2401.17809 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17809 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaopeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shasha Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+B">Bin Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S">Shezheng Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jie Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaodong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weimin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work in progress; Our code will be released
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Model editing has recently gained widespread attention. Current model editing
methods primarily involve modifying model parameters or adding additional
modules to the existing model. However, the former causes irreversible damage
to LLMs, while the latter incurs additional inference overhead and fuzzy vector
matching is not always reliable. To address these issues, we propose an
expandable Subject Word Embedding Altering (SWEA) framework, which modifies the
representation of subjects and achieve the goal of editing knowledge during the
inference stage. SWEA uses precise key matching outside the model and performs
reliable subject word embedding altering, thus protecting the original weights
of the model without increasing inference overhead. We then propose optimizing
then suppressing fusion method, which first optimizes the embedding vector for
the editing target and then suppresses the Knowledge Embedding Dimension (KED)
to obtain the final fused embedding. We thus propose SWEAOS method for editing
factual knowledge in LLMs. We demonstrate the state-of-the-art performance of
SWEAOS on the COUNTERFACT and zsRE datasets. To further validate the reasoning
ability of SWEAOS in editing knowledge, we evaluate it on the more complex
RIPPLEEDITS benchmark. The results on two subdatasets demonstrate that our
SWEAOS possesses state-of-the-art reasoning ability.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17812 title=Abstract>arXiv:2401.17812</a> [<a href=https://arxiv.org/pdf/2401.17812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deterministic Computing Power Networking: Architecture, Technologies and Prospects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+Q">Qingmin Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yujiao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiaomao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Q">Qianpiao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+K">Kai Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huayu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+R">Renchao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+T">Tao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yunjie Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>With the development of new Internet services such as computation-intensive
and delay-sensitive tasks, the traditional "Best Effort" network transmission
mode has been greatly challenged. The network system is urgently required to
provide end-to-end transmission determinacy and computing determinacy for new
applications to ensure the safe and efficient operation of services. Based on
the research of the convergence of computing and networking, a new network
paradigm named deterministic computing power networking (Det-CPN) is proposed.
In this article, we firstly introduce the research advance of computing power
networking. And then the motivations and scenarios of Det-CPN are analyzed.
Following that, we present the system architecture, technological capabilities,
workflow as well as key technologies for Det-CPN. Finally, the challenges and
future trends of Det-CPN are analyzed and discussed.
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17819 title=Abstract>arXiv:2401.17819</a> [<a href=https://arxiv.org/pdf/2401.17819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17819 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> QTFlow: Quantitative Timing-Sensitive Information Flow for Security-Aware Hardware Design on RTL
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reimann%2C+L+M">Lennart M. Reimann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prashar%2C+A">Anschul Prashar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghinami%2C+C">Chiara Ghinami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelke%2C+R">Rebecca Pelke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sisejkovic%2C+D">Dominik Sisejkovic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merchant%2C+F">Farhad Merchant</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leupers%2C+R">Rainer Leupers</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at IEEE VLSI-DAT 2024, Taiwan; 4 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
</div>
<p class=mathjax>In contemporary Electronic Design Automation (EDA) tools, security often
takes a backseat to the primary goals of power, performance, and area
optimization. Commonly, the security analysis is conducted by hand, leading to
vulnerabilities in the design remaining unnoticed. Security-aware EDA tools
assist the designer in the identification and removal of security threats while
keeping performance and area in mind. Cutting-edge methods employ information
flow analysis to identify inadvertent information leaks in design structures.
Current information leakage detection methods use quantitative information flow
analysis to quantify the leaks. However, handling sequential circuits poses
challenges for state-of-the-art techniques due to their time-agnostic nature,
overlooking timing channels, and introducing false positives. To address this,
we introduce QTFlow, a timing-sensitive framework for quantifying hardware
information leakages during the design phase. Illustrating its effectiveness on
open-source benchmarks, QTFlow autonomously identifies timing channels and
diminishes all false positives arising from time-agnostic analysis when
contrasted with current state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17820 title=Abstract>arXiv:2401.17820</a> [<a href=https://arxiv.org/pdf/2401.17820 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17820 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17820 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The 1/3-conjectures for domination in cubic graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dorbec%2C+P">Paul Dorbec</a> (GREYC), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henning%2C+M+A">Michael Antony Henning</a> (UJ)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>A set S of vertices in a graph G is a dominating set of G if every vertex not
in S is adjacent to a vertex in S . The domination number of G, denoted by
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-221 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-222><span class=mi id=MathJax-Span-223 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>(G), is the minimum cardinality of a dominating set in G. In a
breakthrough paper in 2008, L{\"o}wenstein and Rautenbach proved that if G is a
cubic graph of order n and girth at least 83, then <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-224 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-225><span class=mi id=MathJax-Span-226 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>(G) <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><nobr><span class=math id=MathJax-Span-227 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.7em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-228><span class=mo id=MathJax-Span-229 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> n/3. A
natural question is if this girth condition can be lowered. The question gave
birth to two 1/3-conjectures for domination in cubic graphs. The first
conjecture, posed by Verstraete in 2010, states that if G is a cubic graph on n
vertices with girth at least 6, then <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-230 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-231><span class=mi id=MathJax-Span-232 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>(G) <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-233 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.7em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-234><span class=mo id=MathJax-Span-235 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> n/3. The second
conjecture, first posed as a question by Kostochka in 2009, states that if G is
a cubic, bipartite graph of order n, then <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-236 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-237><span class=mi id=MathJax-Span-238 style=font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>(G) <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-239 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.7em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-240><span class=mo id=MathJax-Span-241 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>n/3. In this paper,
we prove Verstraete's conjecture when there is no 7-cycle and no 8-cycle, and
we prove the Kostochka's related conjecture for bipartite graphs when there is
no 4-cycle and no 8-cycle.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17821 title=Abstract>arXiv:2401.17821</a> [<a href=https://arxiv.org/pdf/2401.17821 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17821 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Do Object Detection Localization Errors Affect Human Performance and Trust?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Witte%2C+S">Sven de Witte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strafforello%2C+O">Ombretta Strafforello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Gemert%2C+J">Jan van Gemert</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Bounding boxes are often used to communicate automatic object detection
results to humans, aiding humans in a multitude of tasks. We investigate the
relationship between bounding box localization errors and human task
performance. We use observer performance studies on a visual multi-object
counting task to measure both human trust and performance with different levels
of bounding box accuracy. The results show that localization errors have no
significant impact on human accuracy or trust in the system. Recall and
precision errors impact both human performance and trust, suggesting that
optimizing algorithms based on the F1 score is more beneficial in
human-computer tasks. Lastly, the paper offers an improvement on bounding boxes
in multi-object counting tasks with center dots, showing improved performance
and better resilience to localization inaccuracy.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17823 title=Abstract>arXiv:2401.17823</a> [<a href=https://arxiv.org/pdf/2401.17823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Privacy-preserving data release leveraging optimal transport and particle gradient descent
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Donhauser%2C+K">Konstantin Donhauser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abad%2C+J">Javier Abad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hulkund%2C+N">Neha Hulkund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+F">Fanny Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>We present a novel approach for differentially private data synthesis of
protected tabular datasets, a relevant task in highly sensitive domains such as
healthcare and government. Current state-of-the-art methods predominantly use
marginal-based approaches, where a dataset is generated from private estimates
of the marginals. In this paper, we introduce PrivPGD, a new generation method
for marginal-based private data synthesis, leveraging tools from optimal
transport and particle gradient descent. Our algorithm outperforms existing
methods on a large range of datasets while being highly scalable and offering
the flexibility to incorporate additional domain-specific constraints.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17824 title=Abstract>arXiv:2401.17824</a> [<a href=https://arxiv.org/pdf/2401.17824 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17824 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey of Pre-trained Language Models for Processing Scientific Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ho%2C+X">Xanh Ho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+A+K+D">Anh Khoa Duong Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dao%2C+A+T">An Tuan Dao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+J">Junfeng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chida%2C+Y">Yuki Chida</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sugimoto%2C+K">Kaito Sugimoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=To%2C+H+Q">Huy Quoc To</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boudin%2C+F">Florian Boudin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aizawa%2C+A">Akiko Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Resources are available at <a href=https://github.com/Alab-NII/Awesome-SciLM>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The number of Language Models (LMs) dedicated to processing scientific text
is on the rise. Keeping pace with the rapid growth of scientific LMs (SciLMs)
has become a daunting task for researchers. To date, no comprehensive surveys
on SciLMs have been undertaken, leaving this issue unaddressed. Given the
constant stream of new SciLMs, appraising the state-of-the-art and how they
compare to each other remain largely unknown. This work fills that gap and
provides a comprehensive review of SciLMs, including an extensive analysis of
their effectiveness across different domains, tasks and datasets, and a
discussion on the challenges that lie ahead.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17826 title=Abstract>arXiv:2401.17826</a> [<a href=https://arxiv.org/pdf/2401.17826 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17826 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PALoc: Advancing SLAM Benchmarking with Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiangcheng Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Linwei Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+R">Ruoyu Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+H">Hexiang Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaoyu Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lujia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jianhao Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 8 figures. Accepted by 2024 IEEE/ASME Transactions on Mechatronics (TMECH)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Accurately generating ground truth (GT) trajectories is essential for
Simultaneous Localization and Mapping (SLAM) evaluation, particularly under
varying environmental conditions. This study introduces a systematic approach
employing a prior map-assisted framework for generating dense
six-degree-of-freedom (6-DoF) GT poses for the first time, enhancing the
fidelity of both indoor and outdoor SLAM datasets. Our method excels in
handling degenerate and stationary conditions frequently encountered in SLAM
datasets, thereby increasing robustness and precision. A significant aspect of
our approach is the detailed derivation of covariances within the factor graph,
enabling an in-depth analysis of pose uncertainty propagation. This analysis
crucially contributes to demonstrating specific pose uncertainties and
enhancing trajectory reliability from both theoretical and empirical
perspectives. Additionally, we provide an open-source toolbox
(https://github.com/JokerJohn/Cloud_Map_Evaluation) for map evaluation
criteria, facilitating the indirect assessment of overall trajectory precision.
Experimental results show at least a 30\% improvement in map accuracy and a
20\% increase in direct trajectory accuracy compared to the Iterative Closest
Point (ICP) \cite{sharp2002icp} algorithm across diverse campus environments,
with substantially enhanced robustness. Our open-source solution
(https://github.com/JokerJohn/PALoc), extensively applied in the
FusionPortable\cite{Jiao2022Mar} dataset, is geared towards SLAM benchmark
dataset augmentation and represents a significant advancement in SLAM
evaluations.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17827 title=Abstract>arXiv:2401.17827</a> [<a href=https://arxiv.org/pdf/2401.17827 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17827 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Machine Translation for Malayalam Paraphrase Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Varghese%2C+C">Christeena Varghese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koshelev%2C+S">Sergey Koshelev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamshchikov%2C+I+P">Ivan P. Yamshchikov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This study explores four methods of generating paraphrases in Malayalam,
utilizing resources available for English paraphrasing and pre-trained Neural
Machine Translation (NMT) models. We evaluate the resulting paraphrases using
both automated metrics, such as BLEU, METEOR, and cosine similarity, as well as
human annotation. Our findings suggest that automated evaluation measures may
not be fully appropriate for Malayalam, as they do not consistently align with
human judgment. This discrepancy underscores the need for more nuanced
paraphrase evaluation approaches especially for highly agglutinative languages.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17828 title=Abstract>arXiv:2401.17828</a> [<a href=https://arxiv.org/pdf/2401.17828 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17828 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmadi%2C+R">Rozhan Ahmadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasaei%2C+S">Shohreh Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 4 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In recent years, weakly supervised semantic segmentation using image-level
labels as supervision has received significant attention in the field of
computer vision. Most existing methods have addressed the challenges arising
from the lack of spatial information in these labels by focusing on
facilitating supervised learning through the generation of pseudo-labels from
class activation maps (CAMs). Due to the localized pattern detection of
Convolutional Neural Networks (CNNs), CAMs often emphasize only the most
discriminative parts of an object, making it challenging to accurately
distinguish foreground objects from each other and the background. Recent
studies have shown that Vision Transformer (ViT) features, due to their global
view, are more effective in capturing the scene layout than CNNs. However, the
use of hierarchical ViTs has not been extensively explored in this field. This
work explores the use of Swin Transformer by proposing "SWTformer" to enhance
the accuracy of the initial seed CAMs by bringing local and global views
together. SWTformer-V1 generates class probabilities and CAMs using only the
patch tokens as features. SWTformer-V2 incorporates a multi-scale feature
fusion mechanism to extract additional information and utilizes a
background-aware mechanism to generate more accurate localization maps with
improved cross-object discrimination. Based on experiments on the PascalVOC
2012 dataset, SWTformer-V1 achieves a 0.98% mAP higher localization accuracy,
outperforming state-of-the-art models. It also yields comparable performance by
0.82% mIoU on average higher than other methods in generating initial
localization maps, depending only on the classification network. SWTformer-V2
further improves the accuracy of the generated seed CAMs by 5.32% mIoU, further
proving the effectiveness of the local-to-global view provided by the Swin
transformer.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17832 title=Abstract>arXiv:2401.17832</a> [<a href=https://arxiv.org/pdf/2401.17832 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17832 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAT-Based Subsumption Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coutelier%2C+R">Robin Coutelier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kov%C3%A1cs%2C+L">Laura Kovcs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rawson%2C+M">Michael Rawson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rath%2C+J">Jakob Rath</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Automated Deduction -- CADE 29 (2023). Lecture Notes in Computer
 Science vol 14132. Springer
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Subsumption resolution is an expensive but highly effective simplifying
inference for first-order saturation theorem provers. We present a new
SAT-based reasoning technique for subsumption resolution, without requiring
radical changes to the underlying saturation algorithm. We implemented our work
in the theorem prover Vampire, and show that it is noticeably faster than the
state of the art.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17835 title=Abstract>arXiv:2401.17835</a> [<a href=https://arxiv.org/pdf/2401.17835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting the Future with Simple World Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saanum%2C+T">Tankred Saanum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dayan%2C+P">Peter Dayan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schulz%2C+E">Eric Schulz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>World models can represent potentially high-dimensional pixel observations in
compact latent spaces, making it tractable to model the dynamics of the
environment. However, the latent dynamics inferred by these models may still be
highly complex. Abstracting the dynamics of the environment with simple models
can have several benefits. If the latent dynamics are simple, the model may
generalize better to novel transitions, and discover useful latent
representations of environment states. We propose a regularization scheme that
simplifies the world model's latent dynamics. Our model, the Parsimonious
Latent Space Model (PLSM), minimizes the mutual information between latent
states and the dynamics that arise between them. This makes the dynamics softly
state-invariant, and the effects of the agent's actions more predictable. We
combine the PLSM with three different model classes used for i) future latent
state prediction, ii) video prediction, and iii) planning. We find that our
regularization improves accuracy, generalization, and performance in downstream
tasks.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17837 title=Abstract>arXiv:2401.17837</a> [<a href=https://arxiv.org/pdf/2401.17837 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17837 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17837 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Safe Reinforcement Learning-Based Eco-Driving Control for Mixed Traffic Flows With Disturbances
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lu%2C+K">Ke Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+D">Dongjun Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Q">Qun Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+K">Kaidi Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+L">Lin Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Song%2C+Z">Ziyou Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper presents a safe learning-based eco-driving framework tailored for
mixed traffic flows, which aims to optimize energy efficiency while
guaranteeing safety during real-system operations. Even though reinforcement
learning (RL) is capable of optimizing energy efficiency in intricate
environments, it is challenged by safety requirements during the training
process. The lack of safety guarantees is the other concern when deploying a
trained policy in real-world application. Compared with RL, model predicted
control (MPC) can handle constrained dynamics systems, ensuring safe driving.
However, the major challenges lie in complicated eco-driving tasks and the
presence of disturbances, which respectively challenge the MPC design and the
satisfaction of constraints. To address these limitations, the proposed
framework incorporates the tube-based enhanced MPC (RMPC) to ensure the safe
execution of the RL policy under disturbances, thereby improving the control
robustness. RL not only optimizes the energy efficiency of the connected and
automated vehicle in mixed traffic but also handles more uncertain scenarios,
in which the energy consumption of the human-driven vehicle and its diverse and
stochastic driving behaviors are considered in the optimization framework.
Simulation results demonstrate that the proposed algorithm, compared with RMPC
technique, shows an average improvement of 10.88% in holistic energy
efficiency, while compared with RL algorithm, it effectively prevents
inter-vehicle collisions.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17838 title=Abstract>arXiv:2401.17838</a> [<a href=https://arxiv.org/pdf/2401.17838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chao%2C+W">Wenshuo Chao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Z">Zhaopeng Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Likang Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zhuoning Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Z">Zhi Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 7 figures, AAAI24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The rapidly changing landscape of technology and industries leads to dynamic
skill requirements, making it crucial for employees and employers to anticipate
such shifts to maintain a competitive edge in the labor market. Existing
efforts in this area either rely on domain-expert knowledge or regarding skill
evolution as a simplified time series forecasting problem. However, both
approaches overlook the sophisticated relationships among different skills and
the inner-connection between skill demand and supply variations. In this paper,
we propose a Cross-view Hierarchical Graph learning Hypernetwork (CHGH)
framework for joint skill demand-supply prediction. Specifically, CHGH is an
encoder-decoder network consisting of i) a cross-view graph encoder to capture
the interconnection between skill demand and supply, ii) a hierarchical graph
encoder to model the co-evolution of skills from a cluster-wise perspective,
and iii) a conditional hyper-decoder to jointly predict demand and supply
variations by incorporating historical demand-supply gaps. Extensive
experiments on three real-world datasets demonstrate the superiority of the
proposed framework compared to seven baselines and the effectiveness of the
three modules.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17839 title=Abstract>arXiv:2401.17839</a> [<a href=https://arxiv.org/pdf/2401.17839 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17839 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Global-Liar: Factuality of LLMs over Time and Geographic Regions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirza%2C+S">Shujaat Mirza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coelho%2C+B">Bruno Coelho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yuyuan Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%B6pper%2C+C">Christina Ppper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McCoy%2C+D">Damon McCoy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 12 figures, 9 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>The increasing reliance on AI-driven solutions, particularly Large Language
Models (LLMs) like the GPT series, for information retrieval highlights the
critical need for their factuality and fairness, especially amidst the rampant
spread of misinformation and disinformation online. Our study evaluates the
factual accuracy, stability, and biases in widely adopted GPT models, including
GPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated
information dissemination.
<br>We introduce 'Global-Liar,' a dataset uniquely balanced in terms of
geographic and temporal representation, facilitating a more nuanced evaluation
of LLM biases. Our analysis reveals that newer iterations of GPT models do not
always equate to improved performance. Notably, the GPT-4 version from March
demonstrates higher factual accuracy than its subsequent June release.
Furthermore, a concerning bias is observed, privileging statements from the
Global North over the Global South, thus potentially exacerbating existing
informational inequities. Regions such as Africa and the Middle East are at a
disadvantage, with much lower factual accuracy. The performance fluctuations
over time suggest that model updates may not consistently benefit all regions
equally.
<br>Our study also offers insights into the impact of various LLM configuration
settings, such as binary decision forcing, model re-runs and temperature, on
model's factuality. Models constrained to binary (true/false) choices exhibit
reduced factuality compared to those allowing an 'unclear' option. Single
inference at a low temperature setting matches the reliability of majority
voting across various configurations. The insights gained highlight the need
for culturally diverse and geographically inclusive model training and
evaluation. This approach is key to achieving global equity in technology,
distributing AI benefits fairly worldwide.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17840 title=Abstract>arXiv:2401.17840</a> [<a href=https://arxiv.org/pdf/2401.17840 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17840 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Propagation Dynamics of Rumor vs. Non-rumor across Multiple Social Media Platforms Driven by User Characteristics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+D">Dongpeng Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+S">Shu Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+C">Chao Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xianghua Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhen Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Studying information propagation dynamics in social media can elucidate user
behaviors and patterns. However, previous research often focuses on single
platforms and fails to differentiate between the nuanced roles of source users
and other participants in cascades. To address these limitations, we analyze
propagation cascades on Twitter and Weibo combined with a crawled dataset of
nearly one million users with authentic attributes. Our preliminary findings
from multiple platforms robustly indicate that rumors tend to spread more
deeply, while non-rumors distribute more broadly. Interestingly, we discover
that the spread of rumors is slower, persists longer, and, in most cases,
involves fewer participants than that of non-rumors. And an undiscovered
highlight is that reputable active users, termed `onlookers', inadvertently or
unwittingly spread rumors due to their extensive online interactions and the
allure of sensational fake news. Conversely, celebrities exhibit caution,
mindful of releasing unverified information. Additionally, we identify cascade
features aligning with exponential patterns, highlight the Credibility Erosion
Effect (CEE) phenomenon in the propagation process, and discover the different
contents and policies between the two platforms. Our findings enhance current
understanding and provide a valuable statistical analysis for future research.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17842 title=Abstract>arXiv:2401.17842</a> [<a href=https://arxiv.org/pdf/2401.17842 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17842 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explainable Benchmarking for Iterative Optimization Heuristics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+Stein%2C+N">Niki van Stein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vermetten%2C+D">Diederick Vermetten</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kononova%2C+A+V">Anna V. Kononova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%A4ck%2C+T">Thomas Bck</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Will be submitted to ACM TELO
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Benchmarking heuristic algorithms is vital to understand under which
conditions and on what kind of problems certain algorithms perform well. In
most current research into heuristic optimization algorithms, only a very
limited number of scenarios, algorithm configurations and hyper-parameter
settings are explored, leading to incomplete and often biased insights and
results. This paper presents a novel approach we call explainable benchmarking.
Introducing the IOH-Xplainer software framework, for analyzing and
understanding the performance of various optimization algorithms and the impact
of their different components and hyper-parameters. We showcase the framework
in the context of two modular optimization frameworks. Through this framework,
we examine the impact of different algorithmic components and configurations,
offering insights into their performance across diverse scenarios. We provide a
systematic method for evaluating and interpreting the behaviour and efficiency
of iterative optimization heuristics in a more transparent and comprehensible
manner, allowing for better benchmarking and algorithm design.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17851 title=Abstract>arXiv:2401.17851</a> [<a href=https://arxiv.org/pdf/2401.17851 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17851 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Instruction-Guided Scene Text Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yongkun Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhineng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Y">Yuchen Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+C">Caiyan Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-modal models have shown appealing performance in visual tasks recently,
as instruction-guided training has evoked the ability to understand
fine-grained visual content. However, current methods cannot be trivially
applied to scene text recognition (STR) due to the gap between natural and text
images. In this paper, we introduce a novel paradigm that formulates STR as an
instruction learning problem, and propose instruction-guided scene text
recognition (IGTR) to achieve effective cross-modal learning. IGTR first
generates rich and diverse instruction triplets of &lt;condition,question,answer&gt;,
serving as guidance for nuanced text image understanding. Then, we devise an
architecture with dedicated cross-modal feature fusion module, and multi-task
answer head to effectively fuse the required instruction and image features for
answering questions. Built upon these designs, IGTR facilitates accurate text
recognition by comprehending character attributes. Experiments on English and
Chinese benchmarks show that IGTR outperforms existing models by significant
margins. Furthermore, by adjusting the instructions, IGTR enables various
recognition schemes. These include zero-shot prediction, where the model is
trained based on instructions not explicitly targeting character recognition,
and the recognition of rarely appearing and morphologically similar characters,
which were previous challenges for existing models.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17856 title=Abstract>arXiv:2401.17856</a> [<a href=https://arxiv.org/pdf/2401.17856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qing Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shuai%2C+W">Wei Shuai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiyao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhida Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+N">Nan Cao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Unfamiliar measurements usually hinder readers from grasping the scale of the
numerical data, understanding the content, and feeling engaged with the
context. To enhance data comprehension and communication, we leverage analogies
to bridge the gap between abstract data and familiar measurements. In this
work, we first conduct semi-structured interviews with design experts to
identify design problems and summarize design considerations. Then, we collect
an analogy dataset of 138 cases from various online sources. Based on the
collected dataset, we characterize a design space for creating data analogies.
Next, we build a prototype system, AnalogyMate, that automatically suggests
data analogies, their corresponding design solutions, and generated visual
representations powered by generative AI. The study results show the usefulness
of AnalogyMate in aiding the creation process of data analogies and the
effectiveness of data analogy in enhancing data comprehension and
communication.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17857 title=Abstract>arXiv:2401.17857</a> [<a href=https://arxiv.org/pdf/2401.17857 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17857 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Anything in 3D Gaussians
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X">Xu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+L">Lue Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+J">Junsong Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+J">Junran Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+Z">Zhen Lei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>3D Gaussian Splatting has emerged as an alternative 3D representation of
Neural Radiance Fields (NeRFs), benefiting from its high-quality rendering
results and real-time rendering speed. Considering the 3D Gaussian
representation remains unparsed, it is necessary first to execute object
segmentation within this domain. Subsequently, scene editing and collision
detection can be performed, proving vital to a multitude of applications, such
as virtual reality (VR), augmented reality (AR), game/movie production, etc. In
this paper, we propose a novel approach to achieve object segmentation in 3D
Gaussian via an interactive procedure without any training process and learned
parameters. We refer to the proposed method as SA-GS, for Segment Anything in
3D Gaussians. Given a set of clicked points in a single input view, SA-GS can
generalize SAM to achieve 3D consistent segmentation via the proposed
multi-view mask generation and view-wise label assignment methods. We also
propose a cross-view label-voting approach to assign labels from different
views. In addition, in order to address the boundary roughness issue of
segmented objects resulting from the non-negligible spatial sizes of 3D
Gaussian located at the boundary, SA-GS incorporates the simple but effective
Gaussian Decomposition scheme. Extensive experiments demonstrate that SA-GS
achieves high-quality 3D segmentation results, which can also be easily applied
for scene editing and collision detection tasks. Codes will be released soon.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17858 title=Abstract>arXiv:2401.17858</a> [<a href=https://arxiv.org/pdf/2401.17858 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17858 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wicke%2C+P">Philipp Wicke</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The rise of Large Language Models (LLMs) has affected various disciplines
that got beyond mere text generation. Going beyond their textual nature, this
project proposal aims to investigate the interaction between LLMs and
non-verbal communication, specifically focusing on gestures. The proposal sets
out a plan to examine the proficiency of LLMs in deciphering both explicit and
implicit non-verbal cues within textual prompts and their ability to associate
these gestures with various contextual factors. The research proposes to test
established psycholinguistic study designs to construct a comprehensive dataset
that pairs textual prompts with detailed gesture descriptions, encompassing
diverse regional variations, and semantic labels. To assess LLMs' comprehension
of gestures, experiments are planned, evaluating their ability to simulate
human behaviour in order to replicate psycholinguistic experiments. These
experiments consider cultural dimensions and measure the agreement between
LLM-identified gestures and the dataset, shedding light on the models'
contextual interpretation of non-verbal cues (e.g. gestures).
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17859 title=Abstract>arXiv:2401.17859</a> [<a href=https://arxiv.org/pdf/2401.17859 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17859 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal Entity Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuanyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+H">Haifeng Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiabo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+W">Wei Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+Q">Qi Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S">Shaoling Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+J">Jianxin Liao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2307.16210>arXiv:2307.16210</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>In Multi-Modal Knowledge Graphs (MMKGs), Multi-Modal Entity Alignment (MMEA)
is crucial for identifying identical entities across diverse modal attributes.
However, semantic inconsistency, mainly due to missing modal attributes, poses
a significant challenge. Traditional approaches rely on attribute
interpolation, but this often introduces modality noise, distorting the
original semantics. Moreover, the lack of a universal theoretical framework
limits advancements in achieving semantic consistency. This study introduces a
novel approach, DESAlign, which addresses these issues by applying a
theoretical framework based on Dirichlet energy to ensure semantic consistency.
We discover that semantic inconsistency leads to model overfitting to modality
noise, causing performance fluctuations, particularly when modalities are
missing. DESAlign innovatively combats over-smoothing and interpolates absent
semantics using existing modalities. Our approach includes a multi-modal
knowledge graph learning strategy and a propagation technique that employs
existing semantic features to compensate for missing ones, providing explicit
Euler solutions. Comprehensive evaluations across 18 benchmarks, including
monolingual and bilingual scenarios, demonstrate that DESAlign surpasses
existing methods, setting a new standard in performance. Further testing on 42
benchmarks with high rates of missing modalities confirms its robustness,
offering an effective solution to semantic inconsistency in real-world MMKGs.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17862 title=Abstract>arXiv:2401.17862</a> [<a href=https://arxiv.org/pdf/2401.17862 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17862 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proximity QA: Unleashing the Power of Multi-Modal Large Language Models for Spatial Proximity Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nan%2C+X">Xi Nan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+M">Ming Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+L">Li Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages,version 1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-modal large language models (MLLMs) have demonstrated remarkable
vision-language capabilities, primarily due to the exceptional in-context
understanding and multi-task learning strengths of large language models
(LLMs). The advent of visual instruction tuning has further enhanced MLLMs'
performance in vision-language understanding. However, while existing MLLMs
adeptly recognize \textit{what} objects are in an image, they still face
challenges in effectively discerning \textit{where} these objects are,
particularly along the distance (scene depth) axis. To overcome this limitation
in MLLMs, we introduce Proximity Question Answering (Proximity QA), a novel
framework designed to enable MLLMs to infer the proximity relationship between
objects in images. The framework operates in two phases: the first phase
focuses on guiding the models to understand the relative depth of objects, and
the second phase further encourages the models to infer the proximity
relationships between objects based on their depth perceptions. We also propose
a VQA dataset called Proximity-110K, containing additional instructions that
incorporate depth information and the proximity relationships of objects. We
have conducted extensive experiments to validate Proximity QA's superior
ability in depth perception and proximity analysis, outperforming other
state-of-the-art MLLMs. Code and dataset will be released at
\textcolor{magenta}{https://github.com/NorthSummer/ProximityQA.git}.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17865 title=Abstract>arXiv:2401.17865</a> [<a href=https://arxiv.org/pdf/2401.17865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Manipulating Predictions over Discrete Inputs in Machine Teaching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaodong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y">Yufei Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dahrouj%2C+H">Hayssam Dahrouj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+J">Jianbing Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+Z">Zhenwen Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiangliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Machine teaching often involves the creation of an optimal (typically
minimal) dataset to help a model (referred to as the `student') achieve
specific goals given by a teacher. While abundant in the continuous domain, the
studies on the effectiveness of machine teaching in the discrete domain are
relatively limited. This paper focuses on machine teaching in the discrete
domain, specifically on manipulating student models' predictions based on the
goals of teachers via changing the training data efficiently. We formulate this
task as a combinatorial optimization problem and solve it by proposing an
iterative searching algorithm. Our algorithm demonstrates significant numerical
merit in the scenarios where a teacher attempts at correcting erroneous
predictions to improve the student's models, or maliciously manipulating the
model to misclassify some specific samples to the target class aligned with his
personal profits. Experimental results show that our proposed algorithm can
have superior performance in effectively and efficiently manipulating the
predictions of the model, surpassing conventional baselines.
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17866 title=Abstract>arXiv:2401.17866</a> [<a href=https://arxiv.org/pdf/2401.17866 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17866 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17866 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Making Sense of Knowledge Intensive Processes: an Oil &amp; Gas Industry Scenario
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferreira%2C+J+J">Juliana Jansen Ferreira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Segura%2C+V">Vincius Segura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fucs%2C+A">Ana Fucs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Paula%2C+R">Rogrio de Paula</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages. This paper was presented at the Sensemaking in a Senseless World workshop during the 2018 ACM CHI Conference on Human Factors in Computing Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Sensemaking is a constant and ongoing process by which people associate
meaning to experiences. It can be an individual process, known as abduction, or
a group process by which people give meaning to collective experiences. The
sensemaking of a group is influenced by the abduction process of each person
about the experience. Every collaborative process needs some level of
sensemaking to show results. For a knowledge intensive process, sensemaking is
central and related to most of its tasks. We present findings from a fieldwork
executed in knowledge intensive process from the Oil and Gas industry. Our
findings indicated that different types of knowledge can be combined to compose
the result of a sensemaking process (e.g. decision, the need for more
discussion, etc.). This paper presents an initial set of knowledge types that
can be combined to compose the result of the sensemaking of a collaborative
decision making process. We also discuss ideas for using systems powered by
Artificial Intelligence to support sensemaking processes.
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17868 title=Abstract>arXiv:2401.17868</a> [<a href=https://arxiv.org/pdf/2401.17868 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17868 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zihan Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zhiqiang Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+T">Tong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+H">Haoyang Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024 Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The Segment Anything Model (SAM) stands as a foundational framework for image
segmentation. While it exhibits remarkable zero-shot generalization in typical
scenarios, its advantage diminishes when applied to specialized domains like
medical imagery and remote sensing. To address this limitation, this paper
introduces Conv-LoRA, a simple yet effective parameter-efficient fine-tuning
approach. By integrating ultra-lightweight convolutional parameters into
Low-Rank Adaptation (LoRA), Conv-LoRA can inject image-related inductive biases
into the plain ViT encoder, further reinforcing SAM's local prior assumption.
Notably, Conv-LoRA not only preserves SAM's extensive segmentation knowledge
but also revives its capacity of learning high-level image semantics, which is
constrained by SAM's foreground-background segmentation pretraining.
Comprehensive experimentation across diverse benchmarks spanning multiple
domains underscores Conv-LoRA's superiority in adapting SAM to real-world
semantic segmentation tasks.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17870 title=Abstract>arXiv:2401.17870</a> [<a href=https://arxiv.org/pdf/2401.17870 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17870 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Subseasonal Weather Forecast using Teleconnection-informed Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Z">Zhitong Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IGARSS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Subseasonal forecasting, which is pivotal for agriculture, water resource
management, and early warning of disasters, faces challenges due to the chaotic
nature of the atmosphere. Recent advances in machine learning (ML) have
revolutionized weather forecasting by achieving competitive predictive skills
to numerical models. However, training such foundation models requires
thousands of GPU days, which causes substantial carbon emissions and limits
their broader applicability. Moreover, ML models tend to fool the pixel-wise
error scores by producing smoothed results which lack physical consistency and
meteorological meaning. To deal with the aforementioned problems, we propose a
teleconnection-informed transformer. Our architecture leverages the pretrained
Pangu model to achieve good initial weights and integrates a
teleconnection-informed temporal module to improve predictability in an
extended temporal range. Remarkably, by adjusting 1.1% of the Pangu model's
parameters, our method enhances predictability on four surface and five
upper-level atmospheric variables at a two-week lead time. Furthermore, the
teleconnection-filtered features improve the spatial granularity of outputs
significantly, indicating their potential physical consistency. Our research
underscores the importance of atmospheric and oceanic teleconnections in
driving future weather conditions. Besides, it presents a resource-efficient
pathway for researchers to leverage existing foundation models on versatile
downstream tasks.
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17874 title=Abstract>arXiv:2401.17874</a> [<a href=https://arxiv.org/pdf/2401.17874 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17874 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VR-based generation of photorealistic synthetic data for training hand-object tracking models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chengyan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhari%2C+R">Rahul Chaudhari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Supervised learning models for precise tracking of hand-object interactions
(HOI) in 3D require large amounts of annotated data for training. Moreover, it
is not intuitive for non-experts to label 3D ground truth (e.g. 6DoF object
pose) on 2D images. To address these issues, we present "blender-hoisynth", an
interactive synthetic data generator based on the Blender software.
Blender-hoisynth can scalably generate and automatically annotate visual HOI
training data. Other competing approaches usually generate synthetic HOI data
compeletely without human input. While this may be beneficial in some
scenarios, HOI applications inherently necessitate direct control over the HOIs
as an expression of human intent. With blender-hoisynth, it is possible for
users to interact with objects via virtual hands using standard Virtual Reality
hardware. The synthetically generated data are characterized by a high degree
of photorealism and contain visually plausible and physically realistic videos
of hands grasping objects and moving them around in 3D. To demonstrate the
efficacy of our data generation, we replace large parts of the training data in
the well-known DexYCB dataset with hoisynth data and train a state-of-the-art
HOI reconstruction model with it. We show that there is no significant
degradation in the model performance despite the data replacement.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17878 title=Abstract>arXiv:2401.17878</a> [<a href=https://arxiv.org/pdf/2401.17878 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17878 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on Data-Centric Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lai%2C+R">Riwei Lai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Li Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Rui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Recommender systems (RS) have become essential tools for mitigating
information overload in a range of real-world scenarios. Recent trends in RS
have seen a paradigm shift, moving the spotlight from model-centric innovations
to the importance of data quality and quantity. This evolution has given rise
to the concept of data-centric recommender systems (Data-Centric RS), marking a
significant development in the field. This survey provides the first systematic
overview of Data-Centric RS, covering 1) the foundational concepts of
recommendation data and Data-Centric RS; 2) three primary issues in
recommendation data; 3) recent research developed to address these issues; and
4) several potential future directions in Data-Centric RS.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17879 title=Abstract>arXiv:2401.17879</a> [<a href=https://arxiv.org/pdf/2401.17879 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17879 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricker%2C+J">Jonas Ricker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lukovnikov%2C+D">Denis Lukovnikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+A">Asja Fischer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>With recent text-to-image models, anyone can generate deceptively realistic
images with arbitrary contents, fueling the growing threat of visual
disinformation. A key enabler for generating high-resolution images with low
computational cost has been the development of latent diffusion models (LDMs).
In contrast to conventional diffusion models, LDMs perform the denoising
process in the low-dimensional latent space of a pre-trained autoencoder (AE)
instead of the high-dimensional image space. Despite their relevance, the
forensic analysis of LDMs is still in its infancy. In this work we propose
AEROBLADE, a novel detection method which exploits an inherent component of
LDMs: the AE used to transform images between image and latent space. We find
that generated images can be more accurately reconstructed by the AE than real
images, allowing for a simple detection approach based on the reconstruction
error. Most importantly, our method is easy to implement and does not require
any training, yet nearly matches the performance of detectors that rely on
extensive training. We empirically demonstrate that AEROBLADE is effective
against state-of-the-art LDMs including Stable Diffusion and Midjourney. Beyond
detection, our approach allows for the qualitative analysis of images, which
can be leveraged for identifying inpainted regions.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17880 title=Abstract>arXiv:2401.17880</a> [<a href=https://arxiv.org/pdf/2401.17880 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17880 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Attention-based Reinforcement Learning for Trajectory Design and Resource Assignment in Multi-UAV Assisted Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zikai Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+D">Di Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+M">Mengxing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)
</div>
<p class=mathjax>In the multiple unmanned aerial vehicle (UAV)- assisted downlink
communication, it is challenging for UAV base stations (UAV BSs) to realize
trajectory design and resource assignment in unknown environments. The
cooperation and competition between UAV BSs in the communication network leads
to a Markov game problem. Multi-agent reinforcement learning is a significant
solution for the above decision-making. However, there are still many common
issues, such as the instability of the system and low utilization of historical
data, that limit its application. In this paper, a novel graph-attention
multi-agent trust region (GA-MATR) reinforcement learning framework is proposed
to solve the multi-UAV assisted communication problem. Graph recurrent network
is introduced to process and analyze complex topology of the communication
network, so as to extract useful information and patterns from observational
information. The attention mechanism provides additional weighting for conveyed
information, so that the critic network can accurately evaluate the value of
behavior for UAV BSs. This provides more reliable feedback signals and helps
the actor network update the strategy more effectively. Ablation simulations
indicate that the proposed approach attains improved convergence over the
baselines. UAV BSs learn the optimal communication strategies to achieve their
maximum cumulative rewards. Additionally, multi-agent trust region method with
monotonic convergence provides an estimated Nash equilibrium for the multi-UAV
assisted communication Markov game.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17881 title=Abstract>arXiv:2401.17881</a> [<a href=https://arxiv.org/pdf/2401.17881 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17881 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PVLR: Prompt-driven Visual-Linguistic Representation Learning for Multi-Label Image Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Hao Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zichang Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+J">Jun Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-label image recognition is a fundamental task in computer vision.
Recently, vision-language models have made notable advancements in this area.
However, previous methods often failed to effectively leverage the rich
knowledge within language models and instead incorporated label semantics into
visual features in a unidirectional manner. In this paper, we propose a
Prompt-driven Visual-Linguistic Representation Learning (PVLR) framework to
better leverage the capabilities of the linguistic modality. In PVLR, we first
introduce a dual-prompting strategy comprising Knowledge-Aware Prompting (KAP)
and Context-Aware Prompting (CAP). KAP utilizes fixed prompts to capture the
intrinsic semantic knowledge and relationships across all labels, while CAP
employs learnable prompts to capture context-aware label semantics and
relationships. Later, we propose an Interaction and Fusion Module (IFM) to
interact and fuse the representations obtained from KAP and CAP. In contrast to
the unidirectional fusion in previous works, we introduce a Dual-Modal
Attention (DMA) that enables bidirectional interaction between textual and
visual features, yielding context-aware label representations and
semantic-related visual representations, which are subsequently used to
calculate similarities and generate final predictions for all labels. Extensive
experiments on three popular datasets including MS-COCO, Pascal VOC 2007, and
NUS-WIDE demonstrate the superiority of PVLR.
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17882 title=Abstract>arXiv:2401.17882</a> [<a href=https://arxiv.org/pdf/2401.17882 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17882 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> I Think, Therefore I am: Awareness in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yue Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yuli Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+S">Siyuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Y">Yao Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Do large language models (LLMs) exhibit any forms of awareness similar to
humans? In this paper, we introduce the concept of awareness to LLMs, arguing
that awareness is an essential aspect of trustworthiness for LLMs to enhance
their interaction with humans while ensuring ethical responses. We define
awareness in LLMs as the ability to perceive and understand themselves as AI
models and to exhibit social intelligence. We identify four key dimensions of
awareness: capability, mission, emotion, and perspective. To assess LLMs on
these dimensions, we introduce a specialized dataset, AwareLLM dataset. Our
findings reveal that LLMs demonstrate a decent degree of awareness, though they
still lack substantial capability awareness.
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17883 title=Abstract>arXiv:2401.17883</a> [<a href=https://arxiv.org/pdf/2401.17883 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17883 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reimagining Reality: A Comprehensive Survey of Video Inpainting Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gowda%2C+S+N">Shreyank N Gowda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thakre%2C+Y">Yash Thakre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gowda%2C+S+N">Shashank Narayana Gowda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+X">Xiaobo Jin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper offers a comprehensive analysis of recent advancements in video
inpainting techniques, a critical subset of computer vision and artificial
intelligence. As a process that restores or fills in missing or corrupted
portions of video sequences with plausible content, video inpainting has
evolved significantly with the advent of deep learning methodologies. Despite
the plethora of existing methods and their swift development, the landscape
remains complex, posing challenges to both novices and established researchers.
Our study deconstructs major techniques, their underpinning theories, and their
effective applications. Moreover, we conduct an exhaustive comparative study,
centering on two often-overlooked dimensions: visual quality and computational
efficiency. We adopt a human-centric approach to assess visual quality,
enlisting a panel of annotators to evaluate the output of different video
inpainting techniques. This provides a nuanced qualitative understanding that
complements traditional quantitative metrics. Concurrently, we delve into the
computational aspects, comparing inference times and memory demands across a
standardized hardware setup. This analysis underscores the balance between
quality and efficiency: a critical consideration for practical applications
where resources may be constrained. By integrating human validation and
computational resource comparison, this survey not only clarifies the present
landscape of video inpainting techniques but also charts a course for future
explorations in this vibrant and evolving field.
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17887 title=Abstract>arXiv:2401.17887</a> [<a href=https://arxiv.org/pdf/2401.17887 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17887 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Groups in Directed and Non-Directed Bipartite Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benatti%2C+A">Alexandre Benatti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=da+F.+Costa%2C+L">Luciano da F. Costa</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>Bipartite networks provide an effective resource for representing,
characterizing, and modeling several abstract and real-world systems and
structures involving binary relations, which include food webs, social
interactions, and customer-product relationships. Of particular interest is the
problem of, given a specific bipartite network, to identify possible respective
groups or clusters characterized by similar interconnecting patterns. The
present work approaches this issue by extending and complementing a previously
described coincidence similarity methodology (Bioarxiv,
doi.org/10.1101/2022.07.16.500294) in several manners, including the
consideration of direct and non-directed bipartite networks, the
characterization of groups in those networks, as well as considering synthetic
bipartite networks presenting groups as a resource for studying the performance
of the described methodology. Several interesting results are described and
discussed, including the corroboration of the potential of the coincidence
similarity methodology for achieving enhanced separation between the groups in
bipartite networks.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17890 title=Abstract>arXiv:2401.17890</a> [<a href=https://arxiv.org/pdf/2401.17890 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17890 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The inherent randomness of news virality on social media
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sangiorgio%2C+E">Emanuele Sangiorgio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cinelli%2C+M">Matteo Cinelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cerqueti%2C+R">Roy Cerqueti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quattrociocchi%2C+W">Walter Quattrociocchi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Applications (stat.AP)
</div>
<p class=mathjax>Initially conceived for entertainment, social media platforms have profoundly
transformed the dissemination of information and consequently reshaped the
dynamics of agenda-setting. In this scenario, understanding the factors that
capture audience attention and drive viral content is crucial. Employing
Gibrat's Law, which posits that an entity's growth rate is unrelated to its
size, we examine the engagement growth dynamics of news outlets on social
media. Our analysis encloses the Facebook historical data of over a thousand
news outlets, encompassing approximately 57 million posts in four European
languages from 2008 to the end of 2022. We discover universal growth dynamics
according to which news virality is independent of the traditional size or
engagement with the outlet. Moreover, our analysis reveals a significant
long-term impact of news source reliability on engagement growth, with
engagement induced by unreliable sources decreasing over time. We conclude the
paper by presenting a statistical model replicating the observed growth
dynamics.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17895 title=Abstract>arXiv:2401.17895</a> [<a href=https://arxiv.org/pdf/2401.17895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bartrum%2C+E">Edward Bartrum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen-Phuoc%2C+T">Thu Nguyen-Phuoc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+C">Chris Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhengqin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+N">Numair Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Avetisyan%2C+A">Armen Avetisyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lanman%2C+D">Douglas Lanman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+L">Lei Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> For our project page, see <a href=https://replaceanything3d.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)
</div>
<p class=mathjax>We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D scene
editing method that enables the replacement of specific objects within a scene.
Given multi-view images of a scene, a text prompt describing the object to
replace, and a text prompt describing the new object, our Erase-and-Replace
approach can effectively swap objects in the scene with newly generated content
while maintaining 3D consistency across multiple viewpoints. We demonstrate the
versatility of ReplaceAnything3D by applying it to various realistic 3D scenes,
showcasing results of modified foreground objects that are well-integrated with
the rest of the scene without affecting its overall integrity.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17897 title=Abstract>arXiv:2401.17897</a> [<a href=https://arxiv.org/pdf/2401.17897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17897 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+C">Chau Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+L">Le-Minh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The objective of legal text entailment is to ascertain whether the assertions
in a legal query logically follow from the information provided in one or
multiple legal articles. ChatGPT, a large language model, is robust in many
natural language processing tasks, including legal text entailment: when we set
the temperature = 0 (the ChatGPT answers are deterministic) and prompt the
model, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperforms
the previous SOTA of 67.89%. On the other hand, if the temperature is larger
than zero, ChatGPT answers are not deterministic, leading to inconsistent
answers and fluctuating results. We propose to leverage label models (a
fundamental component of weak supervision techniques) to integrate the
provisional answers by ChatGPT into consolidated labels. By that way, we treat
ChatGPT provisional answers as noisy predictions which can be consolidated by
label models. The experimental results demonstrate that this approach can
attain an accuracy of 76.15%, marking a significant improvement of 8.26% over
the prior state-of-the-art benchmark. Additionally, we perform an analysis of
the instances where ChatGPT produces incorrect answers, then we classify the
errors, offering insights that could guide potential enhancements for future
research endeavors.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17904 title=Abstract>arXiv:2401.17904</a> [<a href=https://arxiv.org/pdf/2401.17904 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17904 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+M">Maoyuan Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Juhua Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+B">Baocai Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Cong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+B">Bo Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> GitHub repository: <a href=https://github.com/ymy-k/Hi-SAM>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The Segment Anything Model (SAM), a profound vision foundation model
pre-trained on a large-scale dataset, breaks the boundaries of general
segmentation and sparks various downstream applications. This paper introduces
Hi-SAM, a unified model leveraging SAM for hierarchical text segmentation.
Hi-SAM excels in text segmentation across four hierarchies, including stroke,
word, text-line, and paragraph, while realizing layout analysis as well.
Specifically, we first turn SAM into a high-quality text stroke segmentation
(TSS) model through a parameter-efficient fine-tuning approach. We use this TSS
model to iteratively generate the text stroke labels in a semi-automatical
manner, unifying labels across the four text hierarchies in the HierText
dataset. Subsequently, with these complete labels, we launch the end-to-end
trainable Hi-SAM based on the TSS architecture with a customized hierarchical
mask decoder. During inference, Hi-SAM offers both automatic mask generation
(AMG) mode and promptable segmentation mode. In terms of the AMG mode, Hi-SAM
segments text stroke foreground masks initially, then samples foreground points
for hierarchical text mask generation and achieves layout analysis in passing.
As for the promptable mode, Hi-SAM provides word, text-line, and paragraph
masks with a single point click. Experimental results show the state-of-the-art
performance of our TSS model: 84.86% fgIOU on Total-Text and 88.96% fgIOU on
TextSeg for text stroke segmentation. Moreover, compared to the previous
specialist for joint hierarchical detection and layout analysis on HierText,
Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on the
text-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout analysis,
requiring 20x fewer training epochs. The code is available at
https://github.com/ymy-k/Hi-SAM.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17907 title=Abstract>arXiv:2401.17907</a> [<a href=https://arxiv.org/pdf/2401.17907 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17907 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SubPipe: A Submarine Pipeline Inspection Dataset for Segmentation and Visual-inertial Localization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%81lvarez-Tu%C3%B1%C3%B3n%2C+O">Olaya lvarez-Tun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marnet%2C+L+R">Luiza Ribeiro Marnet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antal%2C+L">Lszl Antal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aubard%2C+M">Martin Aubard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+M">Maria Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brodskiy%2C+Y">Yury Brodskiy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper presents SubPipe, an underwater dataset for SLAM, object
detection, and image segmentation. SubPipe has been recorded using a
\gls{LAUV}, operated by OceanScan MST, and carrying a sensor suite including
two cameras, a side-scan sonar, and an inertial navigation system, among other
sensors. The AUV has been deployed in a pipeline inspection environment with a
submarine pipe partially covered by sand. The AUV's pose ground truth is
estimated from the navigation sensors. The side-scan sonar and RGB images
include object detection and segmentation annotations, respectively.
State-of-the-art segmentation, object detection, and SLAM methods are
benchmarked on SubPipe to demonstrate the dataset's challenges and
opportunities for leveraging computer vision algorithms. To the authors'
knowledge, this is the first annotated underwater dataset providing a real
pipeline inspection scenario. The dataset and experiments are publicly
available online at https://github.com/remaro-network/SubPipe-dataset
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17910 title=Abstract>arXiv:2401.17910</a> [<a href=https://arxiv.org/pdf/2401.17910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Controllable Dense Captioner with Multimodal Embedding Bridging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yue Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zonghao Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+W">Weijia Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+C">Chen Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Q">Qixiang Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+F">Fang Wan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> <a href=https://github.com/callsys/ControlCap>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we propose a controllable dense captioner (ControlCap), which
accommodates user's intention to dense captioning by introducing linguistic
guidance. ControlCap is defined as a multimodal embedding bridging
architecture, which comprises multimodal embedding generation (MEG) module and
bi-directional embedding bridging (BEB) module. While MEG module represents
objects/regions by combining embeddings of detailed information with
context-aware ones, it also endows ControlCap the adaptability to specialized
controls by utilizing them as linguistic guidance. BEB module aligns the
linguistic guidance with visual embeddings through borrowing/returning features
from/to the visual domain and gathering such features to predict text
descriptions. Experiments on Visual Genome and VG-COCO datasets show that
ControlCap respectively outperforms the state-of-the-art methods by 1.5% and
3.7% (mAP). Last but not least, with the capability of converting
region-category pairs to region-text pairs, ControlCap is able to act as a
powerful data engine for dense captioning. Code is available at
https://github.com/callsys/ControlCap.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17911 title=Abstract>arXiv:2401.17911</a> [<a href=https://arxiv.org/pdf/2401.17911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knipper%2C+R+A">R. Alexander Knipper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishty%2C+K">Kaniz Mishty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadi%2C+M">Mehdi Sadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>As spiking neural networks receive more attention, we look toward
applications of this computing paradigm in fields other than computer vision
and signal processing. One major field, underexplored in the neuromorphic
setting, is Natural Language Processing (NLP), where most state-of-the-art
solutions still heavily rely on resource-consuming and power-hungry traditional
deep learning architectures. Therefore, it is compelling to design NLP models
for neuromorphic architectures due to their low energy requirements, with the
additional benefit of a more human-brain-like operating model for processing
information. However, one of the biggest issues with bringing NLP to the
neuromorphic setting is in properly encoding text into a spike train so that it
can be seamlessly handled by both current and future SNN architectures. In this
paper, we compare various methods of encoding text as spikes and assess each
method's performance in an associated SNN on a downstream NLP task, namely,
sentiment analysis. Furthermore, we go on to propose a new method of encoding
text as spikes that outperforms a widely-used rate-coding technique, Poisson
rate-coding, by around 13\% on our benchmark NLP tasks. Subsequently, we
demonstrate the energy efficiency of SNNs implemented in hardware for the
sentiment analysis task compared to traditional deep neural networks, observing
an energy efficiency increase of more than 32x during inference and 60x during
training while incurring the expected energy-performance tradeoff.
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17914 title=Abstract>arXiv:2401.17914</a> [<a href=https://arxiv.org/pdf/2401.17914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Escudie%2C+E">Erwan Escudie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matignon%2C+L">Laetitia Matignon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saraydaryan%2C+J">Jacques Saraydaryan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Learning robot navigation strategies among pedestrian is crucial for domain
based applications. Combining perception, planning and prediction allows us to
model the interactions between robots and pedestrians, resulting in impressive
outcomes especially with recent approaches based on deep reinforcement learning
(RL). However, these works do not consider multi-robot scenarios. In this
paper, we present MultiSoc, a new method for learning multi-agent socially
aware navigation strategies using RL. Inspired by recent works on multi-agent
deep RL, our method leverages graph-based representation of agent interactions,
combining the positions and fields of view of entities (pedestrians and
agents). Each agent uses a model based on two Graph Neural Network combined
with attention mechanisms. First an edge-selector produces a sparse graph, then
a crowd coordinator applies node attention to produce a graph representing the
influence of each entity on the others. This is incorporated into a model-free
RL framework to learn multi-agent policies. We evaluate our approach on
simulation and provide a series of experiments in a set of various conditions
(number of agents / pedestrians). Empirical results show that our method learns
faster than social navigation deep RL mono-agent techniques, and enables
efficient multi-agent implicit coordination in challenging crowd navigation
with multiple heterogeneous humans. Furthermore, by incorporating customizable
meta-parameters, we can adjust the neighborhood density to take into account in
our navigation strategy.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17916 title=Abstract>arXiv:2401.17916</a> [<a href=https://arxiv.org/pdf/2401.17916 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17916 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Source-free Domain Adaptive Object Detection in Remote Sensing Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weixing Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+X">Xin Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+H">Han Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recent studies have used unsupervised domain adaptive object detection
(UDAOD) methods to bridge the domain gap in remote sensing (RS) images.
However, UDAOD methods typically assume that the source domain data can be
accessed during the domain adaptation process. This setting is often
impractical in the real world due to RS data privacy and transmission
difficulty. To address this challenge, we propose a practical source-free
object detection (SFOD) setting for RS images, which aims to perform target
domain adaptation using only the source pre-trained model. We propose a new
SFOD method for RS images consisting of two parts: perturbed domain generation
and alignment. The proposed multilevel perturbation constructs the perturbed
domain in a simple yet efficient form by perturbing the domain-variant features
at the image level and feature level according to the color and style bias. The
proposed multilevel alignment calculates feature and label consistency between
the perturbed domain and the target domain across the teacher-student network,
and introduces the distillation of feature prototype to mitigate the noise of
pseudo-labels. By requiring the detector to be consistent in the perturbed
domain and the target domain, the detector is forced to focus on
domaininvariant features. Extensive results of three synthetic-to-real
experiments and three cross-sensor experiments have validated the effectiveness
of our method which does not require access to source domain RS images.
Furthermore, experiments on computer vision datasets show that our method can
be extended to other fields as well. Our code will be available at:
https://weixliu.github.io/ .
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17917 title=Abstract>arXiv:2401.17917</a> [<a href=https://arxiv.org/pdf/2401.17917 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17917 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17917 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GuardFS: a File System for Integrated Detection and Mitigation of Linux-based Ransomware
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+der+Assen%2C+J">Jan von der Assen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdrn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ole%C5%A1%2C+R">Rbert Ole</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bovet%2C+G">Grme Bovet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stiller%2C+B">Burkhard Stiller</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Although ransomware has received broad attention in media and research, this
evolving threat vector still poses a systematic threat. Related literature has
explored their detection using various approaches leveraging Machine and Deep
Learning. While these approaches are effective in detecting malware, they do
not answer how to use this intelligence to protect against threats, raising
concerns about their applicability in a hostile environment. Solutions that
focus on mitigation rarely explore how to prevent and not just alert or halt
its execution, especially when considering Linux-based samples. This paper
presents GuardFS, a file system-based approach to investigate the integration
of detection and mitigation of ransomware. Using a bespoke overlay file system,
data is extracted before files are accessed. Models trained on this data are
used by three novel defense configurations that obfuscate, delay, or track
access to the file system. The experiments on GuardFS test the configurations
in a reactive setting. The results demonstrate that although data loss cannot
be completely prevented, it can be significantly reduced. Usability and
performance analysis demonstrate that the defense effectiveness of the
configurations relates to their impact on resource consumption and usability.
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17919 title=Abstract>arXiv:2401.17919</a> [<a href=https://arxiv.org/pdf/2401.17919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LOCOST: State-Space Models for Long Document Abstractive Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bronnec%2C+F+L">Florian Le Bronnec</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duong%2C+S">Song Duong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allauzen%2C+A">Alexandre Allauzen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+N+F">Nancy F. Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guigue%2C+V">Vincent Guigue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lumbreras%2C+A">Alberto Lumbreras</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soulier%2C+L">Laure Soulier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gallinari%2C+P">Patrick Gallinari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 5 figures, 7 tables, EACL 2024 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>State-space models are a low-complexity alternative to transformers for
encoding long sequences and capturing long-term dependencies. We propose
LOCOST: an encoder-decoder architecture based on state-space models for
conditional text generation with long context inputs. With a computational
complexity of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-242 style=width:5.443em;display:inline-block><span style=display:inline-block;position:relative;width:4.517em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.4em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-243><span class=mi id=MathJax-Span-244 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-245 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-246 style=font-family:MathJax_Math-italic>L</span><span class=mi id=MathJax-Span-247 style=font-family:MathJax_Main;padding-left:0.177em>log</span><span class=mo id=MathJax-Span-248></span><span class=mi id=MathJax-Span-249 style=font-family:MathJax_Math-italic;padding-left:0.177em>L</span><span class=mo id=MathJax-Span-250 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, this architecture can handle significantly longer
sequences than state-of-the-art models that are based on sparse attention
patterns. We evaluate our model on a series of long document abstractive
summarization tasks. The model reaches a performance level that is 93-96%
comparable to the top-performing sparse transformers of the same size while
saving up to 50% memory during training and up to 87% during inference.
Additionally, LOCOST effectively handles input texts exceeding 600K tokens at
inference time, setting new state-of-the-art results on full-book summarization
and opening new perspectives for long input processing.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17922 title=Abstract>arXiv:2401.17922</a> [<a href=https://arxiv.org/pdf/2401.17922 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17922 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> [Lions: 1] and [Tigers: 2] and [Bears: 3], Oh My! Literary Coreference Annotation with LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hicke%2C+R+M+M">Rebecca M. M. Hicke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mimno%2C+D">David Mimno</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to LaTeCH-CLfL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Coreference annotation and resolution is a vital component of computational
literary studies. However, it has previously been difficult to build high
quality systems for fiction. Coreference requires complicated structured
outputs, and literary text involves subtle inferences and highly varied
language. New language-model-based seq2seq systems present the opportunity to
solve both these problems by learning to directly generate a copy of an input
sentence with markdown-like annotations. We create, evaluate, and release
several trained models for coreference, as well as a workflow for training new
models.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17933 title=Abstract>arXiv:2401.17933</a> [<a href=https://arxiv.org/pdf/2401.17933 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17933 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17933 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Moving horizon partition-based state estimation of large-scale systems -- Revised version
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Farina%2C+M">Marcello Farina</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Scattolini%2C+R">Riccardo Scattolini</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This report presents three Moving Horizon Estimation (MHE) methods for
discrete-time partitioned linear systems, i.e. systems decomposed into coupled
subsystems with non-overlapping states. The MHE approach is used due to its
capability of exploiting physical constraints on states in the estimation
process. In the proposed algorithms, each subsystem solves reduced-order MHE
problems to estimate its own state and different estimators have different
computational complexity, accuracy and transmission requirements among
subsystems. In all cases, conditions for the convergence of the estimation
error to zero are analyzed.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17948 title=Abstract>arXiv:2401.17948</a> [<a href=https://arxiv.org/pdf/2401.17948 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17948 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HyperZ<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-251 style=width:0.326em;display:inline-block><span style=display:inline-block;position:relative;width:0.28em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.715em,1000.19em,2.132em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-252><span class=mo id=MathJax-Span-253 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.169em;border-left:0px solid;width:0px;height:0.281em"></span></span></nobr></span>Z<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-254 style=width:0.326em;display:inline-block><span style=display:inline-block;position:relative;width:0.28em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.715em,1000.19em,2.132em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-255><span class=mo id=MathJax-Span-256 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.169em;border-left:0px solid;width:0px;height:0.281em"></span></span></nobr></span>W Operator Connects Slow-Fast Networks for Full Context Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Harvie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 6 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The self-attention mechanism utilizes large implicit weight matrices,
programmed through dot product-based activations with very few trainable
parameters, to enable long sequence modeling. In this paper, we investigate the
possibility of discarding residual learning by employing large implicit kernels
to achieve full context interaction at each layer of the network. To accomplish
it, we introduce coordinate-based implicit MLPs as a slow network to generate
hyper-kernels for another fast convolutional network. To get context-varying
weights for fast dynamic encoding, we propose a
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-257 style=width:7.063em;display:inline-block><span style=display:inline-block;position:relative;width:5.848em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1005.85em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-258><span class=texatom id=MathJax-Span-259><span class=mrow id=MathJax-Span-260><span class=mi id=MathJax-Span-261 style=font-family:MathJax_Main>H</span><span class=mi id=MathJax-Span-262 style=font-family:MathJax_Main>y</span><span class=mi id=MathJax-Span-263 style=font-family:MathJax_Main>p</span><span class=mi id=MathJax-Span-264 style=font-family:MathJax_Main>e</span><span class=mi id=MathJax-Span-265 style=font-family:MathJax_Main>r</span></span></span><span class=texatom id=MathJax-Span-266><span class=mrow id=MathJax-Span-267><span class=mi id=MathJax-Span-268 style=font-family:MathJax_Caligraphic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=texatom id=MathJax-Span-269><span class=mrow id=MathJax-Span-270><span class=mo id=MathJax-Span-271 style=font-family:MathJax_Main></span></span></span><span class=mi id=MathJax-Span-272 style=font-family:MathJax_Caligraphic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=texatom id=MathJax-Span-273><span class=mrow id=MathJax-Span-274><span class=mo id=MathJax-Span-275 style=font-family:MathJax_Main></span></span></span><span class=mi id=MathJax-Span-276 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> operator that connects
hyper-kernels (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-277 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1001.04em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-278><span class=texatom id=MathJax-Span-279><span class=mrow id=MathJax-Span-280><span class=mi id=MathJax-Span-281 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>) and hidden activations (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-282 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.81em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-283><span class=texatom id=MathJax-Span-284><span class=mrow id=MathJax-Span-285><span class=mi id=MathJax-Span-286 style=font-family:MathJax_Caligraphic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>) through
simple elementwise multiplication, followed by convolution of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-287 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.81em,2.202em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-288><span class=texatom id=MathJax-Span-289><span class=mrow id=MathJax-Span-290><span class=mi id=MathJax-Span-291 style=font-family:MathJax_Caligraphic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
using the context-dependent <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-292 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1001.04em,2.26em,-999.997em);top:-2.023em;left:0em><span class=mrow id=MathJax-Span-293><span class=texatom id=MathJax-Span-294><span class=mrow id=MathJax-Span-295><span class=mi id=MathJax-Span-296 style=font-family:MathJax_Caligraphic>W<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.028em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. Based on this design, we present a
novel Terminator architecture that integrates hyper-kernels of different sizes
to produce multi-branch hidden representations for enhancing the feature
extraction capability of each layer. Additionally, a bottleneck layer is
employed to compress the concatenated channels, allowing only valuable
information to propagate to the subsequent layers. Notably, our model
incorporates several innovative components and exhibits excellent properties,
such as introducing local feedback error for updating the slow network, stable
zero-mean features, faster training convergence, and fewer model parameters.
Extensive experimental results on pixel-level 1D and 2D image classification
benchmarks demonstrate the superior performance of our architecture.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17952 title=Abstract>arXiv:2401.17952</a> [<a href=https://arxiv.org/pdf/2401.17952 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17952 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17952 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error-Tolerant E-Discovery Protocols
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jinshuo Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartline%2C+J+D">Jason D. Hartline</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+L">Liren Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vijayaraghavan%2C+A">Aravindan Vijayaraghavan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 6 figures, CSLAW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Data Structures and Algorithms (cs.DS); Information Retrieval (cs.IR)
</div>
<p class=mathjax>We consider the multi-party classification problem introduced by Dong,
Hartline, and Vijayaraghavan (2022) in the context of electronic discovery
(e-discovery). Based on a request for production from the requesting party, the
responding party is required to provide documents that are responsive to the
request except for those that are legally privileged. Our goal is to find a
protocol that verifies that the responding party sends almost all responsive
documents while minimizing the disclosure of non-responsive documents. We
provide protocols in the challenging non-realizable setting, where the instance
may not be perfectly separated by a linear classifier. We demonstrate
empirically that our protocol successfully manages to find almost all relevant
documents, while incurring only a small disclosure of non-responsive documents.
We complement this with a theoretical analysis of our protocol in the
single-dimensional setting, and other experiments on simulated data which
suggest that the non-responsive disclosure incurred by our protocol may be
unavoidable.
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17957 title=Abstract>arXiv:2401.17957</a> [<a href=https://arxiv.org/pdf/2401.17957 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17957 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17957 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Avoiding breakdown in incomplete factorizations in low precision arithmetic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Scott%2C+J">Jennifer Scott</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=T%C5%AFma%2C+M">Miroslav Tma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>The emergence of low precision floating-point arithmetic in computer hardware
has led to a resurgence of interest in the use of mixed precision numerical
linear algebra. For linear systems of equations, there has been renewed
enthusiasm for mixed precision variants of iterative refinement. We consider
the iterative solution of large sparse systems using incomplete factorization
preconditioners. The focus is on the robust computation of such preconditioners
in half precision arithmetic and employing them to solve symmetric positive
definite systems to higher precision accuracy; however, the proposed ideas can
be applied more generally. Even for well-conditioned problems, incomplete
factorizations can break down when small entries occur on the diagonal during
the factorization. When using half precision arithmetic, overflows are an
additional possible source of breakdown. We examine how breakdowns can be
avoided and we implement our strategies within new half precision Fortran
sparse incomplete Cholesky factorization software. Results are reported for a
range of problems from practical applications. These demonstrate that, even for
highly ill-conditioned problems, half precision preconditioners can potentially
replace double precision preconditioners, although unsurprisingly this may be
at the cost of additional iterations of a Krylov solver.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17959 title=Abstract>arXiv:2401.17959</a> [<a href=https://arxiv.org/pdf/2401.17959 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17959 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17959 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> University Students Motives and Challenges in Utilising Institutional Repository Resources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masawe%2C+S">Suzan Masawe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muneja%2C+P">Paul Muneja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Msonge%2C+V">Vincent Msonge</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
<p class=mathjax>One of the core functions of an academic institution is to generate
knowledge, disseminate it to the intended audiences, and preserve it for future
use. Academic institutions are now establishing Institutional Repositories
(IRs) to collect produced resources to facilitate accessibility, dissemination,
utilization, and management of intellectual materials produced within an
institution. This study aimed to assess postgraduate students motives for
utilizing IR resources and the challenges they encounter when utilizing IR
resources at the University of Dar es Salaam. This study was conducted using a
descriptive study design whereby it used both qualitative and quantitative
research approaches. The population of this study comprised postgraduate
students, librarians, and ICT personnel from the University of Dar es Salaam. A
sample of 102 respondents was drawn conveniently and purposively for this
study. Data were collected through questionnaires, interviews, as well as a
review of documentary sources. Quantitative data were analyzed through a
Version 16 Statistics Package for Social Science and qualitative data were
analyzed using content analysis. The findings indicate that access to fulltext
documents, the relevance of IR resources, and easy searching of the materials
in the repository system motivate the utilization of IR resources. However,
several challenges impede the utilization of these resources including
unreliable internet access, inaccessibility of full-text and lack of guiding
policy have been revealed as the major challenges toward utilization of IR
resources. The study recommends training postgraduate students on the general
use of IRs. Also, the University management should develop an IR policy that
will guide the utilization of IR resources
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17967 title=Abstract>arXiv:2401.17967</a> [<a href=https://arxiv.org/pdf/2401.17967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CONCORD: Towards a DSL for Configurable Graph Code Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saad%2C+M">Mootez Saad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+T">Tushar Sharma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Deep learning is widely used to uncover hidden patterns in large code
corpora. To achieve this, constructing a format that captures the relevant
characteristics and features of source code is essential. Graph-based
representations have gained attention for their ability to model structural and
semantic information. However, existing tools lack flexibility in constructing
graphs across different programming languages, limiting their use.
Additionally, the output of these tools often lacks interoperability and
results in excessively large graphs, making graph-based neural networks
training slower and less scalable.
<br>We introduce CONCORD, a domain-specific language to build customizable graph
representations. It implements reduction heuristics to reduce graphs' size
complexity. We demonstrate its effectiveness in code smell detection as an
illustrative use case and show that: first, CONCORD can produce code
representations automatically per the specified configuration, and second, our
heuristics can achieve comparable performance with significantly reduced size.
CONCORD will help researchers a) create and experiment with customizable
graph-based code representations for different software engineering tasks
involving DL, b) reduce the engineering work to generate graph representations,
c) address the issue of scalability in GNN models, and d) enhance the
reproducibility of experiments in research through a standardized approach to
code representation and analysis.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17972 title=Abstract>arXiv:2401.17972</a> [<a href=https://arxiv.org/pdf/2401.17972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MelNet: A Real-Time Deep Learning Algorithm for Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azadvatan%2C+Y">Yashar Azadvatan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kurt%2C+M">Murat Kurt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 9 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>In this study, a novel deep learning algorithm for object detection, named
MelNet, was introduced. MelNet underwent training utilizing the KITTI dataset
for object detection. Following 300 training epochs, MelNet attained an mAP
(mean average precision) score of 0.732. Additionally, three alternative models
-YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTI
dataset and juxtaposed with MelNet for object detection.
<br>The outcomes underscore the efficacy of employing transfer learning in
certain instances. Notably, preexisting models trained on prominent datasets
(e.g., ImageNet, COCO, and Pascal VOC) yield superior results. Another finding
underscores the viability of creating a new model tailored to a specific
scenario and training it on a specific dataset. This investigation demonstrates
that training MelNet exclusively on the KITTI dataset also surpasses
EfficientDet after 150 epochs. Consequently, post-training, MelNet's
performance closely aligns with that of other pre-trained models.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17973 title=Abstract>arXiv:2401.17973</a> [<a href=https://arxiv.org/pdf/2401.17973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Validated numerics for algebraic path tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Guillemot%2C+A">Alexandre Guillemot</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lairez%2C+P">Pierre Lairez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Symbolic Computation (cs.SC)
</div>
<p class=mathjax>Using validated numerical methods, interval arithmetic and Taylor models, we
propose a certified predictor-corrector loop for tracking zeros of polynomial
systems with a parameter. We provide a Rust implementation which shows
tremendous improvement over existing software for certified path tracking.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17974 title=Abstract>arXiv:2401.17974</a> [<a href=https://arxiv.org/pdf/2401.17974 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17974 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GUMsley: Evaluating Entity Salience in Summarization for 12 English Genres
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jessica Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeldes%2C+A">Amir Zeldes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Camera-ready for EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>As NLP models become increasingly capable of understanding documents in terms
of coherent entities rather than strings, obtaining the most salient entities
for each document is not only an important end task in itself but also vital
for Information Retrieval (IR) and other downstream applications such as
controllable summarization. In this paper, we present and evaluate GUMsley, the
first entity salience dataset covering all named and non-named salient entities
for 12 genres of English text, aligned with entity types, Wikification links
and full coreference resolution annotations. We promote a strict definition of
salience using human summaries and demonstrate high inter-annotator agreement
for salience based on whether a source entity is mentioned in the summary. Our
evaluation shows poor performance by pre-trained SOTA summarization models and
zero-shot LLM prompting in capturing salient entities in generated summaries.
We also show that predicting or providing salient entities to several model
architectures enhances performance and helps derive higher-quality summaries by
alleviating the entity hallucination problem in existing abstractive
summarization.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17975 title=Abstract>arXiv:2401.17975</a> [<a href=https://arxiv.org/pdf/2401.17975 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17975 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Understanding polysemanticity in neural networks through coding theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marshall%2C+S+C">Simon C. Marshall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kirchner%2C+J+H">Jan H. Kirchner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Despite substantial efforts, neural network interpretability remains an
elusive goal, with previous research failing to provide succinct explanations
of most single neurons' impact on the network output. This limitation is due to
the polysemantic nature of most neurons, whereby a given neuron is involved in
multiple unrelated network states, complicating the interpretation of that
neuron. In this paper, we apply tools developed in neuroscience and information
theory to propose both a novel practical approach to network interpretability
and theoretical insights into polysemanticity and the density of codes. We
infer levels of redundancy in the network's code by inspecting the
eigenspectrum of the activation's covariance matrix. Furthermore, we show how
random projections can reveal whether a network exhibits a smooth or
non-differentiable code and hence how interpretable the code is. This same
framework explains the advantages of polysemantic neurons to learning
performance and explains trends found in recent results by Elhage et
al.~(2022). Our approach advances the pursuit of interpretability in neural
networks, providing insights into their underlying structure and suggesting new
avenues for circuit-level interpretability.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17979 title=Abstract>arXiv:2401.17979</a> [<a href=https://arxiv.org/pdf/2401.17979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Entity Linking in the Job Market Domain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mike Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+der+Goot%2C+R">Rob van der Goot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plank%2C+B">Barbara Plank</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at EACL 2024 Findings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In Natural Language Processing, entity linking (EL) has centered around
Wikipedia, but yet remains underexplored for the job market domain.
Disambiguating skill mentions can help us get insight into the current labor
market demands. In this work, we are the first to explore EL in this domain,
specifically targeting the linkage of occupational skills to the ESCO taxonomy
(le Vrang et al., 2014). Previous efforts linked coarse-grained (full)
sentences to a corresponding ESCO skill. In this work, we link more
fine-grained span-level mentions of skills. We tune two high-performing neural
EL models, a bi-encoder (Wu et al., 2020) and an autoregressive model (Cao et
al., 2021), on a synthetically generated mention--skill pair dataset and
evaluate them on a human-annotated skill-linking benchmark. Our findings reveal
that both models are capable of linking implicit mentions of skills to their
correct taxonomy counterparts. Empirically, BLINK outperforms GENRE in strict
evaluation, but GENRE performs better in loose evaluation (accuracy@<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-297 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-298><span class=mi id=MathJax-Span-299 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>).
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17981 title=Abstract>arXiv:2401.17981</a> [<a href=https://arxiv.org/pdf/2401.17981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+Q">Qirui Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yilun Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Ying Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Despite the impressive capabilities of Multimodal Large Language Models
(MLLMs) in integrating text and image modalities, challenges remain in
accurately interpreting detailed visual elements. This paper presents an
empirical study on enhancing MLLMs with state-of-the-art (SOTA) object
detection and Optical Character Recognition models to improve fine-grained
image understanding and reduce hallucination in responses. Our research
investigates the embedding-based infusion of detection information, the impact
of such infusion on the MLLMs' original abilities, and the interchangeability
of detection models. We conduct systematic experiments with models such as
LLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refines
MLLMs' performance in specific visual tasks but also maintains their original
strengths. The resulting enhanced MLLMs outperform SOTA models on 9 out of 10
benchmarks, achieving an improvement of up to 12.99% on the normalized average
score, marking a notable advancement in multimodal understanding. We release
our codes to facilitate further exploration into the fine-grained multimodal
dialogue capabilities of MLLMs.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17984 title=Abstract>arXiv:2401.17984</a> [<a href=https://arxiv.org/pdf/2401.17984 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17984 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Makinote: An FPGA-Based HW/SW Platform for Pre-Silicon Emulation of RISC-V Designs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perdomo%2C+E">Elias Perdomo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kropotov%2C+A">Alexander Kropotov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cano%2C+F">Francelly Cano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zafar%2C+S">Syed Zafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cervero%2C+T">Teresa Cervero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martorell%2C+X">Xavier Martorell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salami%2C+B">Behzad Salami</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 5 figures, presented in Rapid Simulation and Performance Evaluation for Design 2024 (RAPIDO24) and published in ACM Proceedings of Rapid Simulation and Performance Evaluation for Design
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Emulating chip functionality before silicon production is crucial, especially
with the increasing prevalence of RISC-V-based designs. FPGAs are promising
candidates for such purposes due to their high-speed and reconfigurable
architecture. In this paper, we introduce our Makinote, an FPGA-based Cluster
platform, hosted at Barcelona Supercomputing Center (BSC-CNS), which is
composed of a large number of FPGAs (in total 96 AMD/Xilinx Alveo U55c) to
emulate massive size RTL designs (up to 750M ASIC cells). In addition, we
introduce our FPGA shell as a powerful tool to facilitate the utilization of
such a large FPGA cluster with minimal effort needed by the designers. The
proposed FPGA shell provides an easy-to-use interface for the RTL developers to
rapidly port such design into several FPGAs by automatically connecting to the
necessary ports, e.g., PCIe Gen4, DRAM (DDR4 and HBM), ETH10g/100g. Moreover,
specific drivers for exploiting RISC-V based architectures are provided within
the set of tools associated with the FPGA shell. We release the tool online for
further extensions.
<br>We validate the efficiency of our hardware platform (i.e., FPGA cluster) and
the software tool (i.e., FPGA Shell) by emulating a RISC-V processor and
experimenting HPC Challenge application running on 32 FPGAs. Our results
demonstrate that the performance improves by 8 times over the single-FPGA case.
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17985 title=Abstract>arXiv:2401.17985</a> [<a href=https://arxiv.org/pdf/2401.17985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shrub of a thousand faces: an individual segmentation from satellite images using deep learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaldi%2C+R">Rohaifa Khaldi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabik%2C+S">Siham Tabik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puertas-Ruiz%2C+S">Sergio Puertas-Ruiz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Giles%2C+J+P">Julio Peas de Giles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Correa%2C+J+A+H">Jos Antonio Hdar Correa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zamora%2C+R">Regino Zamora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Segura%2C+D+A">Domingo Alcaraz Segura</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 39 pages, 20 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Monitoring the distribution and size structure of long-living shrubs, such as
Juniperus communis, can be used to estimate the long-term effects of climate
change on high-mountain and high latitude ecosystems. Historical aerial
very-high resolution imagery offers a retrospective tool to monitor shrub
growth and distribution at high precision. Currently, deep learning models
provide impressive results for detecting and delineating the contour of objects
with defined shapes. However, adapting these models to detect natural objects
that express complex growth patterns, such as junipers, is still a challenging
task.
<br>This research presents a novel approach that leverages remotely sensed RGB
imagery in conjunction with Mask R-CNN-based instance segmentation models to
individually delineate Juniperus shrubs above the treeline in Sierra Nevada
(Spain). In this study, we propose a new data construction design that consists
in using photo interpreted (PI) and field work (FW) data to respectively
develop and externally validate the model. We also propose a new shrub-tailored
evaluation algorithm based on a new metric called Multiple Intersections over
Ground Truth Area (MIoGTA) to assess and optimize the model shrub delineation
performance. Finally, we deploy the developed model for the first time to
generate a wall-to-wall map of Juniperus individuals.
<br>The experimental results demonstrate the efficiency of our dual data
construction approach in overcoming the limitations associated with traditional
field survey methods. They also highlight the robustness of MIoGTA metric in
evaluating instance segmentation models on species with complex growth patterns
showing more resilience against data annotation uncertainty. Furthermore, they
show the effectiveness of employing Mask R-CNN with ResNet101-C4 backbone in
delineating PI and FW shrubs, achieving an F1-score of 87,87% and 76.86%,
respectively.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17991 title=Abstract>arXiv:2401.17991</a> [<a href=https://arxiv.org/pdf/2401.17991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating the Effectiveness of GPT-4 Turbo in Creating Defeaters for Assurance Cases
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahandashti%2C+K+K">Kimya Khakzad Shahandashti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sivakumar%2C+M">Mithila Sivakumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohajer%2C+M+M">Mohammad Mahdi Mohajer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belle%2C+A+B">Alvine B. Belle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lethbridge%2C+T+C">Timothy C. Lethbridge</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Assurance cases (ACs) are structured arguments that support the verification
of the correct implementation of systems' non-functional requirements, such as
safety and security, thereby preventing system failures which could lead to
catastrophic outcomes, including loss of lives. ACs facilitate the
certification of systems in accordance with industrial standards, for example,
DO-178C and ISO 26262. Identifying defeaters arguments that refute these ACs is
essential for improving the robustness and confidence in ACs. To automate this
task, we introduce a novel method that leverages the capabilities of GPT-4
Turbo, an advanced Large Language Model (LLM) developed by OpenAI, to identify
defeaters within ACs formalized using the Eliminative Argumentation (EA)
notation. Our initial evaluation gauges the model's proficiency in
understanding and generating arguments within this framework. The findings
indicate that GPT-4 Turbo excels in EA notation and is capable of generating
various types of defeaters.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17992 title=Abstract>arXiv:2401.17992</a> [<a href=https://arxiv.org/pdf/2401.17992 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17992 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multilinear Operator Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yixin Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chrysos%2C+G+G">Grigorios G. Chrysos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Georgopoulos%2C+M">Markos Georgopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cevher%2C+V">Volkan Cevher</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Conference on Learning Representations Poster(2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Despite the remarkable capabilities of deep neural networks in image
recognition, the dependence on activation functions remains a largely
unexplored area and has yet to be eliminated. On the other hand, Polynomial
Networks is a class of models that does not require activation functions, but
have yet to perform on par with modern architectures. In this work, we aim
close this gap and propose MONet, which relies solely on multilinear operators.
The core layer of MONet, called Mu-Layer, captures multiplicative interactions
of the elements of the input token. MONet captures high-degree interactions of
the input elements and we demonstrate the efficacy of our approach on a series
of image recognition and scientific computing benchmarks. The proposed model
outperforms prior polynomial networks and performs on par with modern
architectures. We believe that MONet can inspire further research on models
that use entirely multilinear operations.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17994 title=Abstract>arXiv:2401.17994</a> [<a href=https://arxiv.org/pdf/2401.17994 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17994 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimizing Grid Resilience: A Capacity Reserve Market for High Impact Low Probability Events
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Salman%2C+U+T">Umar T. Salman</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Z">Zongjie Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hansen%2C+T+M">Timothy M. Hansen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper addresses the challenges of high-impact low-probability (HILP)
events by proposing a novel capacity reserve event market for mobile generation
assets, aimed at supporting the transmission network during such incidents.
Despite the usefulness of portable generators and mobile energy units in
restoring power, there are drawbacks such as environmental impact, finite
operation, and complex cost recovery. The proposed market integrates these
resources into a dispatch framework based on pre-established contracts,
ensuring fair compensation and considering factors like capacity, pricing, and
travel distance. Resource owners receive advanced notifications for potential
events, allowing them to adjust their bids for cost recovery. Simulations on an
IEEE 30-bus case have been conducted to demonstrate the model effectiveness in
increasing grid resiliency.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17996 title=Abstract>arXiv:2401.17996</a> [<a href=https://arxiv.org/pdf/2401.17996 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17996 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Development and Adaptation of Robotic Vision in the Real-World: the Challenge of Door Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antonazzi%2C+M">Michele Antonazzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luperto%2C+M">Matteo Luperto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borghese%2C+N+A">N. Alberto Borghese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Basilico%2C+N">Nicola Basilico</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Mobile service robots are increasingly prevalent in human-centric, real-world
domains, operating autonomously in unconstrained indoor environments. In such a
context, robotic vision plays a central role in enabling service robots to
perceive high-level environmental features from visual observations. Despite
the data-driven approaches based on deep learning push the boundaries of vision
systems, applying these techniques to real-world robotic scenarios presents
unique methodological challenges. Traditional models fail to represent the
challenging perception constraints typical of service robots and must be
adapted for the specific environment where robots finally operate. We propose a
method leveraging photorealistic simulations that balances data quality and
acquisition costs for synthesizing visual datasets from the robot perspective
used to train deep architectures. Then, we show the benefits in qualifying a
general detector for the target domain in which the robot is deployed, showing
also the trade-off between the effort for obtaining new examples from such a
setting and the performance gain. In our extensive experimental campaign, we
focus on the door detection task (namely recognizing the presence and the
traversability of doorways) that, in dynamic settings, is useful to infer the
topology of the map. Our findings are validated in a real-world robot
deployment, comparing prominent deep-learning models and demonstrating the
effectiveness of our approach in practical settings.
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17999 title=Abstract>arXiv:2401.17999</a> [<a href=https://arxiv.org/pdf/2401.17999 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17999 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17999 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Remote Estimation of Markov Processes over Costly Channels: On the Benefits of Implicit Information
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Santi%2C+E+D">Edoardo David Santi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Soleymani%2C+T">Touraj Soleymani</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In this paper, we study the remote estimation problem of a Markov process
over a channel with a cost. We formulate this problem as an infinite horizon
optimization problem with two players, i.e., a sensor and a monitor, that have
distinct information, and with a reward function that takes into account both
the communication cost and the estimation quality. We show that the main
challenge in solving this problem is associated with the consideration of
implicit information, i.e., information that the monitor can obtain about the
source when the sensor is silent. Our main objective is to develop a framework
for finding solutions to this problem without neglecting implicit information a
priori. To that end, we propose three different algorithms. The first one is an
alternating policy algorithm that converges to a Nash equilibrium. The second
one is an occupancy-state algorithm that is guaranteed to find a globally
optimal solution. The last one is a heuristic algorithm that is able to find a
near-optimal solution.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18001 title=Abstract>arXiv:2401.18001</a> [<a href=https://arxiv.org/pdf/2401.18001 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18001 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Desiderata for the Context Use of Question Answering Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaier%2C+S">Sagi Shaier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hunter%2C+L+E">Lawrence E Hunter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+der+Wense%2C+K">Katharina von der Wense</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Prior work has uncovered a set of common problems in state-of-the-art
context-based question answering (QA) systems: a lack of attention to the
context when the latter conflicts with a model's parametric knowledge, little
robustness to noise, and a lack of consistency with their answers. However,
most prior work focus on one or two of those problems in isolation, which makes
it difficult to see trends across them. We aim to close this gap, by first
outlining a set of -- previously discussed as well as novel -- desiderata for
QA models. We then survey relevant analysis and methods papers to provide an
overview of the state of the field. The second part of our work presents
experiments where we evaluate 15 QA systems on 5 datasets according to all
desiderata at once. We find many novel trends, including (1) systems that are
less susceptible to noise are not necessarily more consistent with their
answers when given irrelevant context; (2) most systems that are more
susceptible to noise are more likely to correctly answer according to a context
that conflicts with their parametric knowledge; and (3) the combination of
conflicting knowledge and noise can reduce system performance by up to 96%. As
such, our desiderata help increase our understanding of how these models work
and reveal potential avenues for improvements.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18013 title=Abstract>arXiv:2401.18013</a> [<a href=https://arxiv.org/pdf/2401.18013 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18013 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On The Power of Subtle Expressive Cues in the Perception of Human Affects
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dede%2C+E">Ezgi Dede</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agilonu%2C+K+A">Kamile Asli Agilonu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sezgin%2C+M">Metin Sezgin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>In this study, we introduce a sketch-based method for testing how subtle
expressive cues influence the perception of affect in illustrations of human
figures. We specifically study the impact of human posture and gaze direction,
implicitly specified through nose orientation, on perceived emotions and mood.
Through a series of user studies using sketchy illustrations of a running
figure, where a professional illustrator manipulated gaze direction through
adjustments on the nose orientation, we found that this simple change resulted
in a diverse range of perceived affects, spanning from fear to concern and
wonder. These findings shed light on the importance of fine details in defining
context for context-aware system designs and underscore the importance of
recognizing and expressing affect. Understanding minor expressive cues is
crucial to developing emotionally intelligent systems capable of expressing
affect.
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18018 title=Abstract>arXiv:2401.18018</a> [<a href=https://arxiv.org/pdf/2401.18018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt-Driven LLM Safeguarding via Directed Representation Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+C">Chujie Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+F">Fan Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+F">Fandong Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jie Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+M">Minlie Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Prepending model inputs with safety prompts is a common practice of
safeguarding large language models (LLMs) from complying with queries that
contain harmful intents. However, the working mechanisms of safety prompts have
not yet been fully understood, which hinders the potential for automatically
optimizing them for improved LLM safety. Motivated by this problem, we
investigate the impact of safety prompts from the perspective of model
representations. We find that in models' representation space, harmful and
harmless queries can be largely distinguished, but this is not noticeably
enhanced by safety prompts. Instead, the queries' representations are moved by
different safety prompts in similar directions, where models become more prone
to refusal (i.e., refusing to provide assistance) even when the queries are
harmless. Inspired by these findings, we propose a method called DRO (Directed
Representation Optimization) for automatic safety prompt optimization. DRO
treats safety prompts as continuous, trainable embeddings and learns to move
the representations of harmful/harmless queries along/opposite the direction in
which the model's refusal probability increases. We demonstrate that DRO
remarkably improves the safeguarding performance of human-crafted safety
prompts and outperforms strong baselines, as evaluated on out-of-domain
benchmarks, without compromising the general model capability.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18019 title=Abstract>arXiv:2401.18019</a> [<a href=https://arxiv.org/pdf/2401.18019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joining Entities Across Relation and Graph with a Unified Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+W">Wenzhi Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 16 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>This paper introduces RG (Relational Genetic) model, a revised relational
model to represent graph-structured data in RDBMS while preserving its
topology, for efficiently and effectively extracting data in different formats
from disparate sources. Along with: (a) SQL<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-300 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.466em,1000.41em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-301><span class=msubsup id=MathJax-Span-302><span style=display:inline-block;position:relative;width:0.408em;height:0px><span style=position:absolute;clip:rect(3.822em,1000em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-303></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0em><span class=mi id=MathJax-Span-304 style=font-size:70.7%;font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.767em"></span></span></nobr></span>, an SQL dialect augmented
with graph pattern queries and tuple-vertex joins, such that one can extract
graph properties via graph pattern matching, and "semantically" match entities
across relations and graphs; (b) a logical representation of graphs in RDBMS,
which introduces an exploration operator for efficient pattern querying,
supports also browsing and updating graph-structured data; and (c) a strategy
to uniformly evaluate SQL, pattern and hybrid queries that join tuples and
vertices, all inside an RDBMS by leveraging its optimizer without performance
degradation on switching different execution engines. A lightweight system,
WhiteDB, is developed as an implementation to evaluate the benefits it can
actually bring on real-life data. We empirically verified that the RG model
enables the graph pattern queries to be answered as efficiently as in native
graph engines; can consider the access on graph and relation in any order for
optimal plan; and supports effective data enrichment.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18024 title=Abstract>arXiv:2401.18024</a> [<a href=https://arxiv.org/pdf/2401.18024 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18024 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking Private Population Data Release Mechanisms: Synthetic Data vs. TopDown
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maddi%2C+A">Aadyaa Maddi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Routray%2C+S">Swadhin Routray</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldberg%2C+A">Alexander Goldberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fanti%2C+G">Giulia Fanti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The 5th AAAI Workshop on Privacy-Preserving Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Differential privacy (DP) is increasingly used to protect the release of
hierarchical, tabular population data, such as census data. A common approach
for implementing DP in this setting is to release noisy responses to a
predefined set of queries. For example, this is the approach of the TopDown
algorithm used by the US Census Bureau. Such methods have an important
shortcoming: they cannot answer queries for which they were not optimized. An
appealing alternative is to generate DP synthetic data, which is drawn from
some generating distribution. Like the TopDown method, synthetic data can also
be optimized to answer specific queries, while also allowing the data user to
later submit arbitrary queries over the synthetic population data. To our
knowledge, there has not been a head-to-head empirical comparison of these
approaches. This study conducts such a comparison between the TopDown algorithm
and private synthetic data generation to determine how accuracy is affected by
query complexity, in-distribution vs. out-of-distribution queries, and privacy
guarantees. Our results show that for in-distribution queries, the TopDown
algorithm achieves significantly better privacy-fidelity tradeoffs than any of
the synthetic data methods we evaluated; for instance, in our experiments,
TopDown achieved at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-305 style=width:2.202em;display:inline-block><span style=display:inline-block;position:relative;width:1.797em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.62em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-306><span class=mn id=MathJax-Span-307 style=font-family:MathJax_Main>20</span><span class=mo id=MathJax-Span-308 style=font-family:MathJax_Main></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> lower error on counting queries than the
leading synthetic data method at the same privacy budget. Our findings suggest
guidelines for practitioners and the synthetic data research community.
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18028 title=Abstract>arXiv:2401.18028</a> [<a href=https://arxiv.org/pdf/2401.18028 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18028 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18028 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supporting Anticipatory Governance using LLMs: Evaluating and Aligning Large Language Models with the News Media to Anticipate the Negative Impacts of AI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Allaham%2C+M">Mowafak Allaham</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diakopoulos%2C+N">Nicholas Diakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages + research ethics and social impact statement, references, and appendix. Under conference review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
<p class=mathjax>Anticipating the negative impacts of emerging AI technologies is a challenge,
especially in the early stages of development. An understudied approach to such
anticipation is the use of LLMs to enhance and guide this process. Despite
advancements in LLMs and evaluation metrics to account for biases in generated
text, it is unclear how well these models perform in anticipatory tasks.
Specifically, the use of LLMs to anticipate AI impacts raises questions about
the quality and range of categories of negative impacts these models are
capable of generating. In this paper we leverage news media, a diverse data
source that is rich with normative assessments of emerging technologies, to
formulate a taxonomy of impacts to act as a baseline for comparing against. By
computationally analyzing thousands of news articles published by hundreds of
online news domains around the world, we develop a taxonomy consisting of ten
categories of AI impacts. We then evaluate both instruction-based (GPT-4 and
Mistral-7B-Instruct) and fine-tuned completion models (Mistral-7B and GPT-3)
using a sample from this baseline. We find that the generated impacts using
Mistral-7B, fine-tuned on impacts from the news media, tend to be qualitatively
on par with impacts generated using a larger scale model such as GPT-4.
Moreover, we find that these LLMs generate impacts that largely reflect the
taxonomy of negative impacts identified in the news media, however the impacts
produced by instruction-based models had gaps in the production of certain
categories of impacts in comparison to fine-tuned models. This research
highlights a potential bias in state-of-the-art LLMs when used for anticipating
impacts and demonstrates the advantages of aligning smaller LLMs with a diverse
range of impacts, such as those reflected in the news media, to better reflect
such impacts during anticipatory exercises.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18029 title=Abstract>arXiv:2401.18029</a> [<a href=https://arxiv.org/pdf/2401.18029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Context-Sensitive Abstract Interpretation of Dynamic Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piszcz%2C+F">Franciszek Piszcz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)
</div>
<p class=mathjax>There is a vast gap in the quality of IDE tooling between static languages
like Java and dynamic languages like Python or JavaScript. Modern frameworks
and libraries in these languages heavily use their dynamic capabilities to
achieve the best ergonomics and readability. This has a side effect of making
the current generation of IDEs blind to control flow and data flow, which often
breaks navigation, autocompletion and refactoring. In this thesis we propose an
algorithm that can bridge this gap between tooling for dynamic and static
languages by statically analyzing dynamic metaprogramming and runtime
reflection in programs. We use a technique called abstract interpretation to
partially execute programs and extract information that is usually only
available at runtime. Our algorithm has been implemented in a prototype
analyzer that can analyze programs written in a subset of JavaScript.
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18032 title=Abstract>arXiv:2401.18032</a> [<a href=https://arxiv.org/pdf/2401.18032 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18032 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DROP: Decouple Re-Identification and Human Parsing with Task-specific Features for Occluded Person Re-identification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+S">Shuguang Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xiangyang Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Y">Yuanpeng Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Junyao Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+Z">Zefan Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qingsong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+C">Cairong Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The paper introduces the Decouple Re-identificatiOn and human Parsing (DROP)
method for occluded person re-identification (ReID). Unlike mainstream
approaches using global features for simultaneous multi-task learning of ReID
and human parsing, or relying on semantic information for attention guidance,
DROP argues that the inferior performance of the former is due to distinct
granularity requirements for ReID and human parsing features. ReID focuses on
instance part-level differences between pedestrian parts, while human parsing
centers on semantic spatial context, reflecting the internal structure of the
human body. To address this, DROP decouples features for ReID and human
parsing, proposing detail-preserving upsampling to combine varying resolution
feature maps. Parsing-specific features for human parsing are decoupled, and
human position information is exclusively added to the human parsing branch. In
the ReID branch, a part-aware compactness loss is introduced to enhance
instance-level part differences. Experimental results highlight the efficacy of
DROP, especially achieving a Rank-1 accuracy of 76.8% on Occluded-Duke,
surpassing two mainstream methods. The codebase is accessible at
https://github.com/shuguang-52/DROP.
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18034 title=Abstract>arXiv:2401.18034</a> [<a href=https://arxiv.org/pdf/2401.18034 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18034 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18034 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Paramanu: A Family of Novel Efficient Indic Generative Foundation Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyogi%2C+M">Mitodru Niyogi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+A">Arnab Bhattacharya</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We present Gyan AI Paramanu ("atom"), a family of novel language models for
Indian languages. It is a collection of auto-regressive monolingual, bilingual,
and multilingual Indic language models pretrained from scratch on a single GPU
for 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi,
Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia,
Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models are
pretrained with a context size of 1024 on a single GPU. The models are very
efficient, small, fast, and powerful. We have also developed an efficient most
advanced Indic tokenizer that can even tokenize unseen languages. In order to
avoid the "curse of multi-linguality" in our multilingual mParamanu model, we
pretrained on comparable corpora by typological grouping using the same script.
We performed human evaluation of our pretrained models for open end text
generation on grammar, coherence, creativity, and factuality metrics for
Bangla, Hindi, and Sanskrit. Our Bangla, Hindi, and Sanskrit models
outperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B,
GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despite
being smaller in size by 66 to 20 times compared to standard 7B LLMs. To run
inference on our pretrained models, CPU is enough, and GPU is not needed. We
also instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugu
models on 23k instructions in respective languages. Our pretrained and
instruction-tuned models which are first of its kind, most powerful efficient
small generative language models ever developed for Indic languages, and the
various results lead to the conclusion that high quality generative language
models are possible without high amount of compute power and humongous number
of parameters. We plan to release our models at https://www.bharatgpts.com.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18035 title=Abstract>arXiv:2401.18035</a> [<a href=https://arxiv.org/pdf/2401.18035 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18035 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimizing contrastive learning for cortical folding pattern detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaudin%2C+A">Aymeric Gaudin</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guillon%2C+L">Louise Guillon</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer%2C+C">Clara Fischer</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cachia%2C+A">Arnaud Cachia</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivi%C3%A8re%2C+D">Denis Rivire</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mangin%2C+J">Jean-Franois Mangin</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chavas%2C+J">Jol Chavas</a> (1) ((1) Neurospin, Gif-sur-Yvette, France, (2) LaPsyD, Laboratoire A.Binet-Sorbonne, Paris, France)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 6 figures, 1 table, SPIE Imaging 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>The human cerebral cortex has many bumps and grooves called gyri and sulci.
Even though there is a high inter-individual consistency for the main cortical
folds, this is not the case when we examine the exact shapes and details of the
folding patterns. Because of this complexity, characterizing the cortical
folding variability and relating them to subjects' behavioral characteristics
or pathologies is still an open scientific problem. Classical approaches
include labeling a few specific patterns, either manually or
semi-automatically, based on geometric distances, but the recent availability
of MRI image datasets of tens of thousands of subjects makes modern
deep-learning techniques particularly attractive. Here, we build a
self-supervised deep-learning model to detect folding patterns in the cingulate
region. We train a contrastive self-supervised model (SimCLR) on both Human
Connectome Project (1101 subjects) and UKBioBank (21070 subjects) datasets with
topological-based augmentations on the cortical skeletons, which are
topological objects that capture the shape of the folds. We explore several
backbone architectures (convolutional network, DenseNet, and PointNet) for the
SimCLR. For evaluation and testing, we perform a linear classification task on
a database manually labeled for the presence of the "double-parallel" folding
pattern in the cingulate region, which is related to schizophrenia
characteristics. The best model, giving a test AUC of 0.76, is a convolutional
network with 6 layers, a 10-dimensional latent space, a linear projection head,
and using the branch-clipping augmentation. This is the first time that a
self-supervised deep learning model has been applied to cortical skeletons on
such a large dataset and quantitatively evaluated. We can now envisage the next
step: applying it to other brain regions to detect other biomarkers.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18040 title=Abstract>arXiv:2401.18040</a> [<a href=https://arxiv.org/pdf/2401.18040 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18040 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18040 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamuni%2C+N">Navin Kamuni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+H">Hardik Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chintala%2C+S">Sathishkumar Chintala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kunchakuri%2C+N">Naveen Kunchakuri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dominion%2C+S+A+O">Sujatha Alla Old Dominion</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 1 figure, 18th IEEE International Conference on Semantic Computing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>End-to-end multi-task dialogue systems are usually designed with separate
modules for the dialogue pipeline. Among these, the policy module is essential
for deciding what to do in response to user input. This policy is trained by
reinforcement learning algorithms by taking advantage of an environment in
which an agent receives feedback in the form of a reward signal. The current
dialogue systems, however, only provide meagre and simplistic rewards.
Investigating intrinsic motivation reinforcement learning algorithms is the
goal of this study. Through this, the agent can quickly accelerate training and
improve its capacity to judge the quality of its actions by teaching it an
internal incentive system. In particular, we adapt techniques for random
network distillation and curiosity-driven reinforcement learning to measure the
frequency of state visits and encourage exploration by using semantic
similarity between utterances. Experimental results on MultiWOZ, a
heterogeneous dataset, show that intrinsic motivation-based debate systems
outperform policies that depend on extrinsic incentives. By adopting random
network distillation, for example, which is trained using semantic similarity
between user-system dialogues, an astounding average success rate of 73% is
achieved. This is a significant improvement over the baseline Proximal Policy
Optimization (PPO), which has an average success rate of 60%. In addition,
performance indicators such as booking rates and completion rates show a 10%
rise over the baseline. Furthermore, these intrinsic incentive models help
improve the system's policy's resilience in an increasing amount of domains.
This implies that they could be useful in scaling up to settings that cover a
wider range of domains.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18045 title=Abstract>arXiv:2401.18045</a> [<a href=https://arxiv.org/pdf/2401.18045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yihan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenda Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xihua Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+R">Ruihua Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Recent advancements in language models have significantly enhanced
performance in multiple speech-related tasks. Existing speech language models
typically utilize task-dependent prompt tokens to unify various speech tasks in
a single model. However, this design omits the intrinsic connections between
different speech tasks, which can potentially boost the performance of each
task. In this work, we propose a novel decoder-only speech language model,
SpeechComposer, that can unify common speech tasks by composing a fixed set of
prompt tokens. Built upon four primary tasks -- speech synthesis, speech
recognition, speech language modeling, and text language modeling --
SpeechComposer can easily extend to more speech tasks via compositions of
well-designed prompt tokens, like voice conversion and speech enhancement. The
unification of prompt tokens also makes it possible for knowledge sharing among
different speech tasks in a more structured manner. Experimental results
demonstrate that our proposed SpeechComposer can improve the performance of
both primary tasks and composite tasks, showing the effectiveness of the shared
prompt tokens. Remarkably, the unified decoder-only model achieves a comparable
and even better performance than the baselines which are expert models designed
for single tasks.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18046 title=Abstract>arXiv:2401.18046</a> [<a href=https://arxiv.org/pdf/2401.18046 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18046 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multipath parsing in the brain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franzluebbers%2C+B">Berta Franzluebbers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dunagan%2C+D">Donald Dunagan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stanojevi%C4%87%2C+M">Milo Stanojevi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buys%2C+J">Jan Buys</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hale%2C+J+T">John T. Hale</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Humans understand sentences word-by-word, in the order that they hear them.
This incrementality entails resolving temporary ambiguities about syntactic
relationships. We investigate how humans process these syntactic ambiguities by
correlating predictions from incremental generative dependency parsers with
timecourse data from people undergoing functional neuroimaging while listening
to an audiobook. In particular, we compare competing hypotheses regarding the
number of developing syntactic analyses in play during word-by-word
comprehension: one vs more than one. This comparison involves evaluating
syntactic surprisal from a state-of-the-art dependency parser with LLM-adapted
encodings against an existing fMRI dataset. In both English and Chinese data,
we find evidence for multipath parsing. Brain regions associated with this
multipath effect include bilateral superior temporal gyrus.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18047 title=Abstract>arXiv:2401.18047</a> [<a href=https://arxiv.org/pdf/2401.18047 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18047 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Epidemic Modeling using Hybrid of Time-varying SIRD, Particle Swarm Optimization, and Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+N">Naresh Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Susan%2C+S">Seba Susan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICCCNT 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Physics and Society (physics.soc-ph)
</div>
<p class=mathjax>Epidemiological models are best suitable to model an epidemic if the spread
pattern is stationary. To deal with non-stationary patterns and multiple waves
of an epidemic, we develop a hybrid model encompassing epidemic modeling,
particle swarm optimization, and deep learning. The model mainly caters to
three objectives for better prediction: 1. Periodic estimation of the model
parameters. 2. Incorporating impact of all the aspects using data fitting and
parameter optimization 3. Deep learning based prediction of the model
parameters. In our model, we use a system of ordinary differential equations
(ODEs) for Susceptible-Infected-Recovered-Dead (SIRD) epidemic modeling,
Particle Swarm Optimization (PSO) for model parameter optimization, and
stacked-LSTM for forecasting the model parameters. Initial or one time
estimation of model parameters is not able to model multiple waves of an
epidemic. So, we estimate the model parameters periodically (weekly). We use
PSO to identify the optimum values of the model parameters. We next train the
stacked-LSTM on the optimized parameters, and perform forecasting of the model
parameters for upcoming four weeks. Further, we fed the LSTM forecasted
parameters into the SIRD model to forecast the number of COVID-19 cases. We
evaluate the model for highly affected three countries namely; the USA, India,
and the UK. The proposed hybrid model is able to deal with multiple waves, and
has outperformed existing methods on all the three datasets.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18050 title=Abstract>arXiv:2401.18050</a> [<a href=https://arxiv.org/pdf/2401.18050 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18050 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18050 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hypermultiplexed Integrated Tensor Optical Processor
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+S">Shaoyuan Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sludds%2C+A">Alexander Sludds</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hamerly%2C+R">Ryan Hamerly</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Ke Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+H">Hanke Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+E">Eric Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Cheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Englund%2C+D">Dirk Englund</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+M">Mengjie Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zaijun Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Optics (physics.optics)
</div>
<p class=mathjax>Optical processors hold great potential to accelerate deep learning tasks
with their high clock-rates and low-loss data transmission. However, existing
integrated systems are hindered by low scalability due to the quadratic scaling
of device counts, energy costs with high-speed analog-to-digital converters,
and lack of inline nonlinearity. Here, we overcome these challenges with a
wavelength-space-time multiplexed optical tensor processor. Hyperdimensional
parallelism allows matrix-matrix multiplications (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-309 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.003em,1001.39em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-310><span class=msubsup id=MathJax-Span-311><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-312 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=texatom id=MathJax-Span-313><span class=mrow id=MathJax-Span-314><span class=mn id=MathJax-Span-315 style=font-size:70.7%;font-family:MathJax_Main>3</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> operations) using
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-316 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-317><span class=mi id=MathJax-Span-318 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-319 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-320 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-321 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> devices. We incorporated wavelength-multiplexed III/V-based micron-scale
lasers (spanning ~1 THz) for input activation with inline rectifier (ReLU)
nonlinearities and thin-film Lithium-Niobate electro-optic modulators
(<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-322 style=width:5.385em;display:inline-block><span style=display:inline-block;position:relative;width:4.459em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.46em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-323><span class=msubsup id=MathJax-Span-324><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-325 style=font-family:MathJax_Math-italic>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=texatom id=MathJax-Span-326><span class=mrow id=MathJax-Span-327><span class=mi id=MathJax-Span-328 style=font-size:70.7%;font-family:MathJax_Math-italic><span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-329 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-330 style=font-family:MathJax_Main;padding-left:0.292em>1.3</span><span class=mi id=MathJax-Span-331 style=font-family:MathJax_Math-italic>V<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>) for dynamic weighting. With each device encoding
10-billion activations per second, we demonstrated a machine-learning model
with 405,000 parameters. High-clock-rate (10 GS/s), low-energy (500 fJ/OP)
parallel computing with real-time programmability unlocks the full potential of
light for next-generation scalable AI accelerators.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18053 title=Abstract>arXiv:2401.18053</a> [<a href=https://arxiv.org/pdf/2401.18053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How to Measure TLS, X.509 Certificates, and Web PKI: A Tutorial and Brief Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tehrani%2C+P+F">Pouyan Fotouhi Tehrani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Osterweil%2C+E">Eric Osterweil</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidt%2C+T+C">Thomas C. Schmidt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=W%C3%A4hlisch%2C+M">Matthias Whlisch</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Transport Layer Security (TLS) is the base for many Internet applications and
services to achieve end-to-end security. In this paper, we provide guidance on
how to measure TLS deployments, including X.509 certificates and Web PKI. We
introduce common data sources and tools, and systematically describe necessary
steps to conduct sound measurements and data analysis. By surveying prior TLS
measurement studies we find that diverging results are rather rooted in
different setups instead of different deployments. To improve the situation, we
identify common pitfalls and introduce a framework to describe TLS and Web PKI
measurements. Where necessary, our insights are bolstered by a data-driven
approach, in which we complement arguments by additional measurements.
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18054 title=Abstract>arXiv:2401.18054</a> [<a href=https://arxiv.org/pdf/2401.18054 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18054 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+W">Wei Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Schepper%2C+T">Tom De Schepper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mets%2C+K">Kevin Mets</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work is accepted at VISAPP 2024 as a short paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Continual learning (CL) is the research field that aims to build machine
learning models that can accumulate knowledge continuously over different tasks
without retraining from scratch. Previous studies have shown that pre-training
graph neural networks (GNN) may lead to negative transfer (Hu et al., 2020)
after fine-tuning, a setting which is closely related to CL. Thus, we focus on
studying GNN in the continual graph learning (CGL) setting. We propose the
first continual graph learning benchmark for spatio-temporal graphs and use it
to benchmark well-known CGL methods in this novel setting. The benchmark is
based on the N-UCLA and NTU-RGB+D datasets for skeleton-based action
recognition. Beyond benchmarking for standard performance metrics, we study the
class and task-order sensitivity of CGL methods, i.e., the impact of learning
order on each class/task's performance, and the architectural sensitivity of
CGL methods with backbone GNN at various widths and depths. We reveal that
task-order robust methods can still be class-order sensitive and observe
results that contradict previous empirical observations on architectural
sensitivity in CL.
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18057 title=Abstract>arXiv:2401.18057</a> [<a href=https://arxiv.org/pdf/2401.18057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rank Supervised Contrastive Learning for Time Series Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+Q">Qianying Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+D">Dongsheng Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+D">Dongjin Song</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recently, various contrastive learning techniques have been developed to
categorize time series data and exhibit promising performance. A general
paradigm is to utilize appropriate augmentations and construct feasible
positive samples such that the encoder can yield robust and discriminative
representations by mapping similar data points closer together in the feature
space while pushing dissimilar data points farther apart. Despite its efficacy,
the fine-grained relative similarity (e.g., rank) information of positive
samples is largely ignored, especially when labeled samples are limited. To
this end, we present Rank Supervised Contrastive Learning (RankSCL) to perform
time series classification. Different from conventional contrastive learning
frameworks, RankSCL augments raw data in a targeted way in the embedding space
and adopts certain filtering rules to select more informative positive and
negative pairs of samples. Moreover, a novel rank loss is developed to assign
different weights for different levels of positive samples, enable the encoder
to extract the fine-grained information of the same class, and produce a clear
boundary among different classes. Thoroughly empirical studies on 128 UCR
datasets and 30 UEA datasets demonstrate that the proposed RankSCL can achieve
state-of-the-art performance compared to existing baseline methods.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18058 title=Abstract>arXiv:2401.18058</a> [<a href=https://arxiv.org/pdf/2401.18058 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18058 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LongAlign: A Recipe for Long Context Alignment of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yushi Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+X">Xin Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiajie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yuze He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+J">Ji Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+L">Lei Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jie Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Juanzi Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Extending large language models to effectively handle long contexts requires
instruction fine-tuning on input sequences of similar length. To address this,
we present LongAlign -- a recipe of the instruction data, training, and
evaluation for long context alignment. First, we construct a long
instruction-following dataset using Self-Instruct. To ensure the data
diversity, it covers a broad range of tasks from various long context sources.
Second, we adopt the packing and sorted batching strategies to speed up
supervised fine-tuning on data with varied length distributions. Additionally,
we develop a loss weighting method to balance the contribution to the loss
across different sequences during packing training. Third, we introduce the
LongBench-Chat benchmark for evaluating instruction-following capabilities on
queries of 10k-100k in length. Experiments show that LongAlign outperforms
existing recipes for LLMs in long context tasks by up to 30\%, while also
maintaining their proficiency in handling short, generic tasks. The code, data,
and long-aligned models are open-sourced at https://github.com/THUDM/LongAlign.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18059 title=Abstract>arXiv:2401.18059</a> [<a href=https://arxiv.org/pdf/2401.18059 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18059 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarthi%2C+P">Parth Sarthi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdullah%2C+S">Salman Abdullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tuli%2C+A">Aditi Tuli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khanna%2C+S">Shubh Khanna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldie%2C+A">Anna Goldie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manning%2C+C+D">Christopher D. Manning</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Retrieval-augmented language models can better adapt to changes in world
state and incorporate long-tail knowledge. However, most existing methods
retrieve only short contiguous chunks from a retrieval corpus, limiting
holistic understanding of the overall document context. We introduce the novel
approach of recursively embedding, clustering, and summarizing chunks of text,
constructing a tree with differing levels of summarization from the bottom up.
At inference time, our RAPTOR model retrieves from this tree, integrating
information across lengthy documents at different levels of abstraction.
Controlled experiments show that retrieval with recursive summaries offers
significant improvements over traditional retrieval-augmented LMs on several
tasks. On question-answering tasks that involve complex, multi-step reasoning,
we show state-of-the-art results; for example, by coupling RAPTOR retrieval
with the use of GPT-4, we can improve the best performance on the QuALITY
benchmark by 20% in absolute accuracy.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18063 title=Abstract>arXiv:2401.18063</a> [<a href=https://arxiv.org/pdf/2401.18063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AoII-Optimum Sampling of CTMC Information Sources Under Sampling Rate Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cosandal%2C+I">Ismail Cosandal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akar%2C+N">Nail Akar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulukus%2C+S">Seennur Ulukus</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)
</div>
<p class=mathjax>We consider a sensor that samples an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-332 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-333><span class=mi id=MathJax-Span-334 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-state continuous-time Markov chain
(CTMC)-based information source process, and transmits the observed state of
the source, to a remote monitor tasked with timely tracking of the source
process. The mismatch between the source and monitor processes is quantified by
age of incorrect information (AoII), which penalizes the mismatch as it stays
longer, and our objective is to minimize the average AoII under an average
sampling rate constraint. We assume a perfect reverse channel and hence the
sensor has information of the estimate while initiating a transmission or
preempting an ongoing transmission. First, by modeling the problem as an
average cost constrained semi-Markov decision process (CSMDP), we show that the
structure of the problem gives rise to an optimum threshold policy for which
the sensor initiates a transmission once the AoII exceeds a threshold depending
on the instantaneous values of both the source and monitor processes. However,
due to the high complexity of obtaining the optimum policy in this general
setting, we consider a relaxed problem where the thresholds are allowed to be
dependent only on the estimate. We show that this relaxed problem can be solved
with a novel CSMDP formulation based on the theory of absorbing MCs, with a
computational complexity of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-335 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.84em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-336><span class=texatom id=MathJax-Span-337><span class=mrow id=MathJax-Span-338><span class=mi id=MathJax-Span-339 style=font-family:MathJax_Caligraphic>O</span></span></span><span class=mo id=MathJax-Span-340 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-341><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-342 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mn id=MathJax-Span-343 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-344 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, allowing one to obtain optimum
policies for general CTMCs with over a hundred states.
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18064 title=Abstract>arXiv:2401.18064</a> [<a href=https://arxiv.org/pdf/2401.18064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Locality Sensitive Hashing for Entity Blocking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Runhui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+L">Luyang Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+Y">Yefan Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borthwick%2C+A">Andrew Borthwick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golac%2C+D">Davor Golac</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Johnson%2C+H">Henrik Johnson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hijazi%2C+S">Shadie Hijazi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+D">Dong Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Databases (cs.DB)
</div>
<p class=mathjax>Locality-sensitive hashing (LSH) is a fundamental algorithmic technique
widely employed in large-scale data processing applications, such as
nearest-neighbor search, entity resolution, and clustering. However, its
applicability in some real-world scenarios is limited due to the need for
careful design of hashing functions that align with specific metrics. Existing
LSH-based Entity Blocking solutions primarily rely on generic similarity
metrics such as Jaccard similarity, whereas practical use cases often demand
complex and customized similarity rules surpassing the capabilities of generic
similarity metrics. Consequently, designing LSH functions for these customized
similarity rules presents considerable challenges. In this research, we propose
a neuralization approach to enhance locality-sensitive hashing by training deep
neural networks to serve as hashing functions for complex metrics. We assess
the effectiveness of this approach within the context of the entity resolution
problem, which frequently involves the use of task-specific metrics in
real-world applications. Specifically, we introduce NLSHBlock (Neural-LSH
Block), a novel blocking methodology that leverages pre-trained language
models, fine-tuned with a novel LSH-based loss function. Through extensive
evaluations conducted on a diverse range of real-world datasets, we demonstrate
the superiority of NLSHBlock over existing methods, exhibiting significant
performance improvements. Furthermore, we showcase the efficacy of NLSHBlock in
enhancing the performance of the entity matching phase, particularly within the
semi-supervised setting.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18067 title=Abstract>arXiv:2401.18067</a> [<a href=https://arxiv.org/pdf/2401.18067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18067 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reduced-Order Model of Power Converters to Optimize Power Hardware-In-the-Loop Technology in Dc-Distributed Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanz%2C+M">Marina Sanz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Santamargarita%2C+D">Daniel Santamargarita</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huerta%2C+F">Francisco Huerta</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ochoa%2C+D">Diego Ochoa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lazaro%2C+A">Antonio Lazaro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Barrado%2C+A">Andres Barrado</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Applied Power Electronics Conference and Exposition (APEC)
 2020
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The Power Hardware-In-the-Loop (PHIL) technology provides a powerful tool for
testing scenarios where there is a high-power interchange, in which the
performance of field tests can be very complex or expensive. When performing
PHIL simulations of systems with a high number of components, such as
DC-distributed systems on a ship or aircraft, the use of switched or average
models of the converters can require the use of expensive commercial real-time
digital simulators (RTDS) reducing the advantages of these technology. This
paper is focused on the proposal of a reduced order model of converters to be
able to perform PHIL analysis of Dc-distributed systems using low resources of
the required real-time digital simulator. The paper validates that the proposed
reduced-order model is able to determine the stability on the Dc-distributed
system in comparison with more complex converter models. Moreover, a comparison
between both models regarding the required resources in the implementation in a
commercial RTDS platform is performed to validate the benefits of the proposed
model in performing PHIL analysis of large power distribution systems.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18069 title=Abstract>arXiv:2401.18069</a> [<a href=https://arxiv.org/pdf/2401.18069 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18069 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Classification-Oriented Semantic Wireless Communications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutay%2C+E">Emrecan Kutay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yener%2C+A">Aylin Yener</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in ICASSP24. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We propose semantic communication over wireless channels for various
modalities, e.g., text and images, in a task-oriented communications setup
where the task is classification. We present two approaches based on memory and
learning. Both approaches rely on a pre-trained neural network to extract
semantic information but differ in codebook construction. In the memory-based
approach, we use semantic quantization and compression models, leveraging past
source realizations as a codebook to eliminate the need for further training.
In the learning-based approach, we use a semantic vector quantized autoencoder
model that learns a codebook from scratch. Both are followed by a channel coder
in order to reliably convey semantic information to the receiver (classifier)
through the wireless medium. In addition to classification accuracy, we define
system time efficiency as a new performance metric. Our results demonstrate
that the proposed memory-based approach outperforms its learning-based
counterpart with respect to system time efficiency while offering comparable
accuracy to semantic agnostic conventional baselines.
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18070 title=Abstract>arXiv:2401.18070</a> [<a href=https://arxiv.org/pdf/2401.18070 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18070 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Opedal%2C+A">Andreas Opedal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stolfo%2C+A">Alessandro Stolfo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shirakami%2C+H">Haruki Shirakami</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+Y">Ying Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6lkopf%2C+B">Bernhard Schlkopf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saparov%2C+A">Abulhair Saparov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sachan%2C+M">Mrinmaya Sachan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>There is increasing interest in employing large language models (LLMs) as
cognitive models. For such purposes, it is central to understand which
cognitive properties are well-modeled by LLMs, and which are not. In this work,
we study the biases of LLMs in relation to those known in children when solving
arithmetic word problems. Surveying the learning science literature, we posit
that the problem-solving process can be split into three distinct steps: text
comprehension, solution planning and solution execution. We construct tests for
each one in order to understand which parts of this process can be faithfully
modeled by current state-of-the-art LLMs. We generate a novel set of word
problems for each of these tests, using a neuro-symbolic method that enables
fine-grained control over the problem features. We find evidence that LLMs,
with and without instruction-tuning, exhibit human-like biases in both the
text-comprehension and the solution-planning steps of the solving process, but
not during the final step which relies on the problem's arithmetic expressions
(solution execution).
</p>
</div>
</dd>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18075 title=Abstract>arXiv:2401.18075</a> [<a href=https://arxiv.org/pdf/2401.18075 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18075 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiezhi Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Desai%2C+K">Khushi Desai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Packer%2C+C">Charles Packer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatia%2C+H">Harshil Bhatia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rhinehart%2C+N">Nicholas Rhinehart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McAllister%2C+R">Rowan McAllister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+J">Joseph Gonzalez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We propose CARFF: Conditional Auto-encoded Radiance Field for 3D Scene
Forecasting, a method for predicting future 3D scenes given past observations,
such as 2D ego-centric images. Our method maps an image to a distribution over
plausible 3D latent scene configurations using a probabilistic encoder, and
predicts the evolution of the hypothesized scenes through time. Our latent
scene representation conditions a global Neural Radiance Field (NeRF) to
represent a 3D scene model, which enables explainable predictions and
straightforward downstream applications. This approach extends beyond previous
neural rendering work by considering complex scenarios of uncertainty in
environmental states and dynamics. We employ a two-stage training of
Pose-Conditional-VAE and NeRF to learn 3D representations. Additionally, we
auto-regressively predict latent scene representations as a partially
observable Markov decision process, utilizing a mixture density network. We
demonstrate the utility of our method in realistic scenarios using the CARLA
driving simulator, where CARFF can be used to enable efficient trajectory and
contingency planning in complex multi-agent autonomous driving scenarios
involving visual occlusions.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18079 title=Abstract>arXiv:2401.18079</a> [<a href=https://arxiv.org/pdf/2401.18079 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18079 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hooper%2C+C">Coleman Hooper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sehoon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadzadeh%2C+H">Hiva Mohammadzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahoney%2C+M+W">Michael W. Mahoney</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+Y+S">Yakun Sophia Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gholami%2C+A">Amir Gholami</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>LLMs are seeing growing use for applications such as document analysis and
summarization which require large context windows, and with these large context
windows KV cache activations surface as the dominant contributor to memory
consumption during inference. Quantization is a promising approach for
compressing KV cache activations; however, existing solutions fail to represent
activations accurately in ultra-low precisions, such as sub-4-bit. In this
work, we present KVQuant, which addresses this problem by incorporating novel
methods for quantizing cached KV activations, including: (i) Per-Channel Key
Quantization, where we adjust the dimension along which we quantize the Key
activations to better match the distribution; (ii) Pre-RoPE Key Quantization,
where we quantize Key activations before the rotary positional embedding to
mitigate its impact on quantization; (iii) Non-Uniform KV Cache Quantization,
where we derive per-layer sensitivity-weighted non-uniform datatypes that
better represent the distributions; (iv) Per-Vector Dense-and-Sparse
Quantization, where we isolate outliers separately for each vector to minimize
skews in quantization ranges; and (v) Q-Norm, where we normalize quantization
centroids in order to mitigate distribution shift, providing additional
benefits for 2-bit quantization. By applying our method to the LLaMA, LLaMA-2,
and Mistral models, we achieve <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-345 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-346><span class=mo id=MathJax-Span-347 style=font-family:MathJax_Main>&lt;</span><span class=mn id=MathJax-Span-348 style=font-family:MathJax_Main;padding-left:0.292em>0.1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> perplexity degradation with 3-bit
quantization on both Wikitext-2 and C4, outperforming existing approaches. Our
method enables serving the LLaMA-7B model with a context length of up to 1
million on a single A100-80GB GPU and up to 10 million on an 8-GPU system.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18083 title=Abstract>arXiv:2401.18083</a> [<a href=https://arxiv.org/pdf/2401.18083 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18083 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved Scene Landmark Detection for Camera Localization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+T">Tien Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+S+N">Sudipta N. Sinha</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be presented at 3DV 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>Camera localization methods based on retrieval, local feature matching, and
3D structure-based pose estimation are accurate but require high storage, are
slow, and are not privacy-preserving. A method based on scene landmark
detection (SLD) was recently proposed to address these limitations. It involves
training a convolutional neural network (CNN) to detect a few predetermined,
salient, scene-specific 3D points or landmarks and computing camera pose from
the associated 2D-3D correspondences. Although SLD outperformed existing
learning-based approaches, it was notably less accurate than 3D structure-based
methods. In this paper, we show that the accuracy gap was due to insufficient
model capacity and noisy labels during training. To mitigate the capacity
issue, we propose to split the landmarks into subgroups and train a separate
network for each subgroup. To generate better training labels, we propose using
dense reconstructions to estimate visibility of scene landmarks. Finally, we
present a compact architecture to improve memory efficiency. Accuracy wise, our
approach is on par with state of the art structure based methods on the
INDOOR-6 dataset but runs significantly faster and uses less storage. Code and
models can be found at https://github.com/microsoft/SceneLandmarkLocalization.
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18084 title=Abstract>arXiv:2401.18084</a> [<a href=https://arxiv.org/pdf/2401.18084 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18084 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Binding Touch to Everything: Learning Unified Multimodal Tactile Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+F">Fengyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+H">Hyoungseob Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Daniel Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+Y">Yiming Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Ziyao Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xien Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gangopadhyay%2C+R">Rit Gangopadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Owens%2C+A">Andrew Owens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+A">Alex Wong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>The ability to associate touch with other modalities has huge implications
for humans and computational systems. However, multimodal learning with touch
remains challenging due to the expensive data collection process and
non-standardized sensor outputs. We introduce UniTouch, a unified tactile model
for vision-based touch sensors connected to multiple modalities, including
vision, language, and sound. We achieve this by aligning our UniTouch
embeddings to pretrained image embeddings already associated with a variety of
other modalities. We further propose learnable sensor-specific tokens, allowing
the model to learn from a set of heterogeneous tactile sensors, all at the same
time. UniTouch is capable of conducting various touch sensing tasks in the
zero-shot setting, from robot grasping prediction to touch image question
answering. To the best of our knowledge, UniTouch is the first to demonstrate
such capabilities. Project page: https://cfeng16.github.io/UniTouch/
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18085 title=Abstract>arXiv:2401.18085</a> [<a href=https://arxiv.org/pdf/2401.18085 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18085 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geng%2C+D">Daniel Geng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Owens%2C+A">Andrew Owens</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Diffusion models are capable of generating impressive images conditioned on
text descriptions, and extensions of these models allow users to edit images at
a relatively coarse scale. However, the ability to precisely edit the layout,
position, pose, and shape of objects in images with diffusion models is still
difficult. To this end, we propose motion guidance, a zero-shot technique that
allows a user to specify dense, complex motion fields that indicate where each
pixel in an image should move. Motion guidance works by steering the diffusion
sampling process with the gradients through an off-the-shelf optical flow
network. Specifically, we design a guidance loss that encourages the sample to
have the desired motion, as estimated by a flow network, while also being
visually similar to the source image. By simultaneously sampling from a
diffusion model and guiding the sample to have low guidance loss, we can obtain
a motion-edited image. We demonstrate that our technique works on complex
motions and produces high quality edits of real and generated images.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 1 Feb 24</h3>
<dl>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17317 title=Abstract>arXiv:2401.17317</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2401.17317 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17317 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17317 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection of Auditory Brainstem Response Peaks Using Image Processing Techniques in Infants with Normal Hearing Sensitivity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Majidpour%2C+A">Amir Majidpour</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Jameel%2C+S+K">Samer Kais Jameel</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Majidpour%2C+J">Jafar Majidpour</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Bagheri%2C+H">Houra Bagheri</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Rashid%2C+T+A">Tarik A.Rashid</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Nazeri%2C+A">Ahmadreza Nazeri</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Aleaba%2C+M+M">Mahshid Moheb Aleaba</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Introduction: The auditory brainstem response (ABR) is measured to find the
brainstem-level peripheral auditory nerve system integrity in children having
normal hearing. The Auditory Evoked Potential (AEP) is generated using acoustic
stimuli. Interpreting these waves requires competence to avoid misdiagnosing
hearing problems. Automating ABR test labeling with computer vision may reduce
human error. Method: The ABR test results of 26 children aged 1 to 20 months
with normal hearing in both ears were used. A new approach is suggested for
automatically calculating the peaks of waves of different intensities (in
decibels). The procedure entails acquiring wave images from an Audera device
using the Color Thresholder method, segmenting each wave as a single wave image
using the Image Region Analyzer application, converting all wave images into
waves using Image Processing (IP) techniques, and finally calculating the
latency of the peaks for each wave to be used by an audiologist for diagnosing
the disease. Findings: Image processing techniques were able to detect 1, 3,
and 5 waves in the diagnosis field with accuracy (0.82), (0.98), and (0.98),
respectively, and its precision for waves 1, 3, and 5, were respectively
(0.32), (0.97) and (0.87). This evaluation also worked well in the thresholding
part and 82.7 % correctly detected the ABR waves. Conclusion: Our findings
indicate that the audiology test battery suite can be made more accurate,
quick, and error-free by using technology to automatically detect and label ABR
waves.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17320 title=Abstract>arXiv:2401.17320</a> (cross-list from q-bio.NC) [<a href=https://arxiv.org/pdf/2401.17320 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17320 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17320 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sigma-lognormal modeling of speech
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Carmona-Duarte%2C+C">C. Carmona-Duarte</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ferrer%2C+M+A">M.A.Ferrer</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Plamondon%2C+R">R. Plamondon</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Gomez-Rodellar%2C+A">A. Gomez-Rodellar</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Gomez-Vilda%2C+P">P. Gomez-Vilda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in Open Acces
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Cognitive Computation, 13(2). pp. 488-503, 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Human movement studies and analyses have been fundamental in many scientific
domains, ranging from neuroscience to education, pattern recognition to
robotics, health care to sports, and beyond. Previous speech motor models were
proposed to understand how speech movement is produced and how the resulting
speech varies when some parameters are changed. However, the inverse approach,
in which the muscular response parameters and the subject's age are derived
from real continuous speech, is not possible with such models. Instead, in the
handwriting field, the kinematic theory of rapid human movements and its
associated Sigma-lognormal model have been applied successfully to obtain the
muscular response parameters. This work presents a speech kinematics based
model that can be used to study, analyze, and reconstruct complex speech
kinematics in a simplified manner. A method based on the kinematic theory of
rapid human movements and its associated Sigma lognormal model are applied to
describe and to parameterize the asymptotic impulse response of the
neuromuscular networks involved in speech as a response to a neuromotor
command. The method used to carry out transformations from formants to a
movement observation is also presented. Experiments carried out with the
(English) VTR TIMIT database and the (German) Saarbrucken Voice Database,
including people of different ages, with and without laryngeal pathologies,
corroborate the link between the extracted parameters and aging, on the one
hand, and the proportion between the first and second formants required in
applying the kinematic theory of rapid human movements, on the other. The
results should drive innovative developments in the modeling and understanding
of speech kinematics.
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17380 title=Abstract>arXiv:2401.17380</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.17380 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17380 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting gamma-band responses to the speech envelope for the ICASSP 2024 Auditory EEG Decoding Signal Processing Grand Challenge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Thornton%2C+M">Mike Thornton</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Auernheimer%2C+J">Jonas Auernheimer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jehn%2C+C">Constantin Jehn</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mandic%2C+D">Danilo Mandic</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Reichenbach%2C+T">Tobias Reichenbach</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for ICASSP 2024 (challenge track)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>The 2024 ICASSP Auditory EEG Signal Processing Grand Challenge concerns the
decoding of electroencephalography (EEG) measurements taken from participants
who listened to speech material. This work details our solution to the
match-mismatch sub-task: given a short temporal segment of EEG recordings and
several candidate speech segments, the task is to classify which of the speech
segments was time-aligned with the EEG signals. We show that high-frequency
gamma-band responses to the speech envelope can be detected with a high
accuracy. By jointly assessing gamma-band responses and low-frequency envelope
tracking, we develop a match-mismatch decoder which placed first in this task.
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17424 title=Abstract>arXiv:2401.17424</a> (cross-list from astro-ph.HE) [<a href=https://arxiv.org/pdf/2401.17424 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17424 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Application of Neural Networks for the Reconstruction of Supernova Neutrino Energy Spectra Following Fast Neutrino Flavor Conversions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Abbar%2C+S">Sajad Abbar</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Wu%2C+M">Meng-Ru Wu</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Xiong%2C+Z">Zewei Xiong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures, submitted to PRD. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.15656>arXiv:2311.15656</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>Neutrinos can undergo fast flavor conversions (FFCs) within extremely dense
astrophysical environments such as core-collapse supernovae (CCSNe) and neutron
star mergers (NSMs). In this study, we explore FFCs in a \emph{multi-energy}
neutrino gas, revealing that when the FFC growth rate significantly exceeds
that of the vacuum Hamiltonian, all neutrinos (regardless of energy) share a
common survival probability dictated by the energy-integrated neutrino
spectrum. We then employ physics-informed neural networks (PINNs) to predict
the asymptotic outcomes of FFCs within such a multi-energy neutrino gas. These
predictions are based on the first two moments of neutrino angular
distributions for each energy bin, typically available in state-of-the-art CCSN
and NSM simulations. Our PINNs achieve errors as low as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-349 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1002.38em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-350><span class=mo id=MathJax-Span-351 style=font-family:MathJax_AMS></span><span class=mn id=MathJax-Span-352 style=font-family:MathJax_Main;padding-left:0.292em>6</span><span class=mi id=MathJax-Span-353 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-354 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1002.84em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-355><span class=mo id=MathJax-Span-356 style=font-family:MathJax_AMS></span><span class=mn id=MathJax-Span-357 style=font-family:MathJax_Main;padding-left:0.292em>18</span><span class=mi id=MathJax-Span-358 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> for predicting the number of neutrinos in the electron channel
and the relative absolute error in the neutrino moments, respectively.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17442 title=Abstract>arXiv:2401.17442</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.17442 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17442 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17442 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection of Signals in Colored Noise: Leading Eigenvalue Test for Non-central <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-359 style=width:0.928em;display:inline-block><span style=display:inline-block;position:relative;width:0.743em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.74em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-360><span class=mi id=MathJax-Span-361 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.095em></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-matrices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dharmawansa%2C+P">Prathapasinghe Dharmawansa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Atapattu%2C+S">Saman Atapattu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Evans%2C+J">Jamie Evans</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sithamparanathan%2C+K">Kandeepan Sithamparanathan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 2 figures, conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>This paper investigates the signal detection problem in colored noise with an
unknown covariance matrix. In particular, we focus on detecting an unknown
non-random signal by capitalizing on the leading eigenvalue of the whitened
sample covariance matrix as the test statistic (a.k.a. Roy's largest root
test). Since the unknown signal is non-random, the whitened sample covariance
matrix turns out to have a non-central <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-362 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-363><span class=mi id=MathJax-Span-364 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-distribution. This distribution
assumes a singular or non-singular form depending on whether the number of
observations <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-365 style=width:1.913em;display:inline-block><span style=display:inline-block;position:relative;width:1.565em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1001.51em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-366><span class=mi id=MathJax-Span-367 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-368 style=font-family:MathJax_AMS;padding-left:0.292em></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> the system dimensionality <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-369 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-370><span class=mi id=MathJax-Span-371 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>. Therefore, we
statistically characterize the leading eigenvalue of the singular and
non-singular <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-372 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-373><span class=mi id=MathJax-Span-374 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-matrices by deriving their cumulative distribution functions
(c.d.f.). Subsequently, they have been utilized in deriving the corresponding
receiver operating characteristic (ROC) profiles. We also extend our analysis
into the high dimensional domain. It turns out that, when the signal is
sufficiently strong, the maximum eigenvalue can reliably detect it in this
regime. Nevertheless, weak signals cannot be detected in the high dimensional
regime with the leading eigenvalue.
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17447 title=Abstract>arXiv:2401.17447</a> (cross-list from math.CT) [<a href=https://arxiv.org/pdf/2401.17447 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17447 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17447 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reversing information flow: retrodiction in semicartesian categories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Parzygnat%2C+A+J">Arthur J. Parzygnat</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20.5 pages + references, some diagrams
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Category Theory (math.CT)</span>; Information Theory (cs.IT); Probability (math.PR); Quantum Physics (quant-ph)
</div>
<p class=mathjax>In statistical inference, retrodiction is the act of inferring potential
causes in the past based on knowledge of the effects in the present and the
dynamics leading to the present. Retrodiction is applicable even when the
dynamics is not reversible, and it agrees with the reverse dynamics when it
exists, so that retrodiction may be viewed as an extension of inversion, i.e.,
time-reversal. Recently, an axiomatic definition of retrodiction has been made
in a way that is applicable to both classical and quantum probability using
ideas from category theory. Almost simultaneously, a framework for information
flow in in terms of semicartesian categories has been proposed in the setting
of categorical probability theory. Here, we formulate a general definition of
retrodiction to add to the information flow axioms in semicartesian categories,
thus providing an abstract framework for retrodiction beyond classical and
quantum probability theory. More precisely, we extend Bayesian inference, and
more generally Jeffrey's probability kinematics, to arbitrary semicartesian
categories.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17450 title=Abstract>arXiv:2401.17450</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17450 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17450 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Qplacer: Frequency-Aware Component Placement for Superconducting Quantum Computers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zhang%2C+J">Junyao Zhang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wang%2C+H">Hanrui Wang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ding%2C+Q">Qi Ding</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Assouly%2C+R">Reouven Assouly</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Oliver%2C+W+D">William D. Oliver</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Han%2C+S">Song Han</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Brown%2C+K+R">Kenneth R. Brown</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Li%2C+H+%22">Hai "Helen" Li</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Systems and Control (eess.SY)
</div>
<p class=mathjax>Noisy Intermediate-Scale Quantum (NISQ) computers face a critical limitation
in qubit numbers, hindering their progression towards large-scale and
fault-tolerant quantum computing. A significant challenge impeding scaling is
crosstalk, characterized by unwanted interactions among neighboring components
on quantum chips, including qubits, resonators, and substrate. We motivate a
general approach to systematically resolving multifaceted crosstalks in a
limited substrate area. We propose Qplacer, a frequency-aware
electrostatic-based placement framework tailored for superconducting quantum
computers, to alleviate crosstalk by isolating these components in spatial and
frequency domains alongside compact substrate design. Qplacer commences with a
frequency assigner that ensures frequency domain isolation for qubits and
resonators. It then incorporates a padding strategy and resonator partitioning
for layout flexibility. Central to our approach is the conceptualization of
quantum components as charged particles, enabling strategic spatial isolation
through a 'frequency repulsive force' concept. Our results demonstrate that
Qplacer carefully crafts the physical component layout in mitigating various
crosstalk impacts while maintaining a compact substrate size. On device
topology benchmarks, Qplacer can reduce the required area for theoretical
crosstalk-free layout by 2.61x and 2.25x on average, compared to the results of
manual design and classical placement engines, respectively.
</p>
</div>
</dd>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17455 title=Abstract>arXiv:2401.17455</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.17455 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17455 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiscale Parallel Tempering for Fast Sampling on Redistricting Plans
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Chuang%2C+G">Gabriel Chuang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Herschlag%2C+G">Gregory Herschlag</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Mattingly%2C+J+C">Jonathan C. Mattingly</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages with appendix; 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Probability (math.PR)
</div>
<p class=mathjax>When auditing a redistricting plan, a persuasive method is to compare the
plan with an ensemble of neutrally drawn redistricting plans. Ensembles are
generated via algorithms that sample distributions on balanced graph
partitions. To audit the partisan difference between the ensemble and a given
plan, one must ensure that the non-partisan criteria are matched so that we may
conclude that partisan differences come from bias rather than, for example,
levels of compactness or differences in community preservation. Certain
sampling algorithms allow one to explicitly state the policy-based probability
distribution on plans, however, these algorithms have shown poor mixing times
for large graphs (i.e. redistricting spaces) for all but a few specialized
measures. In this work, we generate a multiscale parallel tempering approach
that makes local moves at each scale. The local moves allow us to adopt a wide
variety of policy-based measures. We examine our method in the state of
Connecticut and succeed at achieving fast mixing on a policy-based distribution
that has never before been sampled at this scale. Our algorithm shows promise
to expand to a significantly wider class of measures that will (i) allow for
more principled and situation-based comparisons and (ii) probe for the typical
partisan impact that policy can have on redistricting.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17467 title=Abstract>arXiv:2401.17467</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.17467 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17467 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17467 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An entropy-based measurement for understanding origin-destination trip distributions: a case study of New York City taxis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Jiang%2C+Y">Yuqin Jiang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Yuan%2C+Y">Yihong Yuan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Han%2C+S+Y">Su Yeon Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>A comprehensive understanding of human mobility patterns in urban areas is
essential for urban development and transportation planning. In this study, we
create entropy-based measurements to capture the geographical distribution
diversity of trip origins and destinations. Specifically, we develop
origin-entropy and destination-entropy based on taxi and ride-sharing trip
records. The origin-entropy for a given zone accounts for all the trips that
originate from this zone and calculates the level of geographical distribution
diversity of these trips destinations. Likewise, the destination-entropy for a
given zone considers all the trips that end in this zone and calculates the
level of geographical distribution diversity of these trips origins.
Furthermore, we created a CyberGIS application to visualize the measurements of
origin- and destination-entropy, which allow researchers to examine and compare
travel patterns to identify their spatial and temporal changes. Results show
that the entropy-based measurements can capture the shifts in the geographical
distribution diversity of trips origins and destinations, reflecting changes in
people travel decision corresponding to major events, such as the COVID-19
pandemic. The entropy-based measurements, complementing the number of trips,
provide a more comprehensive understanding of human flows in the city.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17472 title=Abstract>arXiv:2401.17472</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17472 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17472 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence of the deep BSDE method for stochastic control problems formulated through the stochastic maximum principle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Huang%2C+Z">Zhipeng Huang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Negyesi%2C+B">Balint Negyesi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Oosterlee%2C+C+W">Cornelis W. Oosterlee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Computational Finance (q-fin.CP)
</div>
<p class=mathjax>It is well-known that decision-making problems from stochastic control can be
formulated by means of forward-backward stochastic differential equation
(FBSDE). Recently, the authors of Ji et al. 2022 proposed an efficient deep
learning-based algorithm which was based on the stochastic maximum principle
(SMP). In this paper, we provide a convergence result for this deep SMP-BSDE
algorithm and compare its performance with other existing methods. In
particular, by adopting a similar strategy as in Han and Long 2020, we derive a
posteriori error estimate, and show that the total approximation error can be
bounded by the value of the loss functional and the discretization error. We
present numerical examples for high-dimensional stochastic control problems,
both in case of drift- and diffusion control, which showcase superior
performance compared to existing algorithms.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17493 title=Abstract>arXiv:2401.17493</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17493 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17493 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CLAIRE: Scalable GPU-Accelerated Algorithms for Diffeomorphic Image Registration in 3D
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mang%2C+A">Andreas Mang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>We present our work on scalable, GPU-accelerated algorithms for diffeomorphic
image registration. The associated software package is termed CLAIRE. Image
registration is a non-linear inverse problem. It is about computing a spatial
mapping from one image of the same object or scene to another. In diffeomorphic
image registration, the set of admissible spatial transformations is restricted
to maps that are smooth, one-to-one, and have a smooth inverse. We formulate
diffeomorphic image registration as a variational problem governed by transport
equations. We use an inexact, globalized (Gauss--)Newton--Krylov method for
numerical optimization. We consider semi-Lagrangian methods for numerical time
integration. Our solver features mixed-precision, hardware-accelerated
computational kernels for optimal computational throughput. We use the
message-passing interface for distributed-memory parallelism and deploy our
code on modern high-performance computing architectures. Our solver allows us
to solve clinically relevant problems in under four seconds on a single GPU. It
can also be applied to large-scale 3D imaging applications with data that is
discretized on meshes with billions of voxels. We demonstrate that our
numerical framework yields high-fidelity results in only a few seconds, even if
we search for an optimal regularization parameter.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17503 title=Abstract>arXiv:2401.17503</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17503 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17503 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Differentiated Service Entanglement Routing for Quantum Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Han%2C+H">Hui Han</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Liu%2C+B">Bo Liu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Tang%2C+B">Bangying Tang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Xiong%2C+S">Siyu Xiong</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Huang%2C+J">Jinquan Huang</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Yu%2C+W">Wanrong Yu</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Chen%2C+S">Shuhui Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>The entanglement distribution networks with various topologies are mainly
implemented by active wavelength multiplexing routing strategies. However,
designing an entanglement routing scheme, which achieves the maximized network
connections and the optimal overall network efficiency simultaneously, remains
a huge challenge for quantum networks. In this article, we propose a
differentiated service entanglement routing (DSER) scheme, which firstly finds
out the lowest loss paths and supported wavelength channels with the
tensor-based path searching algorithm, and then allocates the paired channels
with the differentiated routing strategies. The evaluation results show that
the proposed DSER scheme can be performed for constructing various large scale
quantum networks.
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17513 title=Abstract>arXiv:2401.17513</a> (cross-list from physics.bio-ph) [<a href=https://arxiv.org/pdf/2401.17513 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17513 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A PNP ion channel deep learning solver with local neural network and finite element input data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lee%2C+H">Hwi Lee</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Chao%2C+Z">Zhen Chao</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Cobb%2C+H">Harris Cobb</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Liu%2C+Y">Yingjie Liu</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Xie%2C+D">Dexuan Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 4 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biological Physics (physics.bio-ph)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>In this paper, a deep learning method for solving an improved one-dimensional
Poisson-Nernst-Planck ion channel (PNPic) model, called the PNPic deep learning
solver, is presented. In particular, it combines a novel local neural network
scheme with an effective PNPic finite element solver. Since the input data of
the neural network scheme only involves a small local patch of coarse grid
solutions, which the finite element solver can quickly produce, the PNPic deep
learning solver can be trained much faster than any corresponding conventional
global neural network solvers. After properly trained, it can output a
predicted PNPic solution in a much higher degree of accuracy than the low cost
coarse grid solutions and can reflect different perturbation cases on the
parameters, ion channel subregions, and interface and boundary values, etc.
Consequently, the PNPic deep learning solver can generate a numerical solution
with high accuracy for a family of PNPic models. As an initial study, two types
of numerical tests were done by perturbing one and two parameters of the PNPic
model, respectively, as well as the tests done by using a few perturbed
interface positions of the model as training samples. These tests demonstrate
that the PNPic deep learning solver can generate highly accurate PNPic
numerical solutions.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17569 title=Abstract>arXiv:2401.17569</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17569 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17569 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17569 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A high contrast and resolution reconstruction algorithm in quantitative photoacoustic tomography
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dey%2C+A">Anwesa Dey</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Borzi%2C+A">Alfio Borzi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Roy%2C+S">Souvik Roy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>A framework for reconstruction of optical diffusion and absorption
coefficients in quantitative photoacoustic tomography is presented. This
framework is based on a Tikhonov-type functional with a regularization term
promoting sparsity of the absorption coefficient and a prior involving a
Kubelka-Munk absorption-diffusion relation that allows to obtain superior
reconstructions. The reconstruction problem is formulated as the minimization
of this functional subject to the differential constraint given by a
photon-propagation model. The solution of this problem is obtained by a fast
and robust sequential quadratic hamiltonian algorithm based on the Pontryagin
maximum principle. Results of several numerical experiments demonstrate that
the proposed computational strategy is able to obtain reconstructions of the
optical coefficients with high contrast and resolution for a wide variety of
objects.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17571 title=Abstract>arXiv:2401.17571</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.17571 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17571 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is Registering Raw Tagged-MR Enough for Strain Estimation in the Era of Deep Learning?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bian%2C+Z">Zhangxing Bian</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alshareef%2C+A">Ahmed Alshareef</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wei%2C+S">Shuwen Wei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+J">Junyu Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yuli Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Woo%2C+J">Jonghye Woo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pham%2C+D+L">Dzung L. Pham</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhuo%2C+J">Jiachen Zhuo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Carass%2C+A">Aaron Carass</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Prince%2C+J+L">Jerry L. Prince</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to SPIE Medical Imaging 2024 (oral)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Magnetic Resonance Imaging with tagging (tMRI) has long been utilized for
quantifying tissue motion and strain during deformation. However, a phenomenon
known as tag fading, a gradual decrease in tag visibility over time, often
complicates post-processing. The first contribution of this study is to model
tag fading by considering the interplay between <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-375 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-376><span class=msubsup id=MathJax-Span-377><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-378 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mn id=MathJax-Span-379 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> relaxation and the
repeated application of radio frequency (RF) pulses during serial imaging
sequences. This is a factor that has been overlooked in prior research on tMRI
post-processing. Further, we have observed an emerging trend of utilizing raw
tagged MRI within a deep learning-based (DL) registration framework for motion
estimation. In this work, we evaluate and analyze the impact of commonly used
image similarity objectives in training DL registrations on raw tMRI. This is
then compared with the Harmonic Phase-based approach, a traditional approach
which is claimed to be robust to tag fading. Our findings, derived from both
simulated images and an actual phantom scan, reveal the limitations of various
similarity losses in raw tMRI and emphasize caution in registration tasks where
image intensity changes over time.
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17573 title=Abstract>arXiv:2401.17573</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17573 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17573 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17573 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Li%2C+Y">Yanrong Li</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Du%2C+J">Juan Du</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tsung%2C+F">Fugee Tsung</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jiang%2C+W">Wei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Systems and Control (eess.SY)
</div>
<p class=mathjax>With the development and popularity of sensors installed in manufacturing
systems, complex data are collected during manufacturing processes, which
brings challenges for traditional process control methods. This paper proposes
a novel process control and monitoring method for the complex structure of
high-dimensional image-based overlay errors (modeled in tensor form), which are
collected in semiconductor manufacturing processes. The proposed method aims to
reduce overlay errors using limited control recipes. We first build a
high-dimensional process model and propose different tensor-on-vector
regression algorithms to estimate parameters in the model to alleviate the
curse of dimensionality. Then, based on the estimate of tensor parameters, the
exponentially weighted moving average (EWMA) controller for tensor data is
designed whose stability is theoretically guaranteed. Considering the fact that
low-dimensional control recipes cannot compensate for all high-dimensional
disturbances on the image, control residuals are monitored to prevent
significant drifts of uncontrollable high-dimensional disturbances. Through
extensive simulations and real case studies, the performances of parameter
estimation algorithms and the EWMA controller in tensor space are evaluated.
Compared with existing image-based feedback controllers, the superiority of our
method is verified especially when disturbances are not stable.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17593 title=Abstract>arXiv:2401.17593</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.17593 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17593 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Head and Neck Tumor Segmentation from [18F]F-FDG PET/CT Images Based on 3D Diffusion Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dong%2C+Y">Yafei Dong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gong%2C+K">Kuang Gong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)
</div>
<p class=mathjax>Head and neck (H&amp;N) cancers are among the most prevalent types of cancer
worldwide, and [18F]F-FDG PET/CT is widely used for H&amp;N cancer management.
Recently, the diffusion model has demonstrated remarkable performance in
various image-generation tasks. In this work, we proposed a 3D diffusion model
to accurately perform H&amp;N tumor segmentation from 3D PET and CT volumes. The 3D
diffusion model was developed considering the 3D nature of PET and CT images
acquired. During the reverse process, the model utilized a 3D UNet structure
and took the concatenation of PET, CT, and Gaussian noise volumes as the
network input to generate the tumor mask. Experiments based on the HECKTOR
challenge dataset were conducted to evaluate the effectiveness of the proposed
diffusion model. Several state-of-the-art techniques based on U-Net and
Transformer structures were adopted as the reference methods. Benefits of
employing both PET and CT as the network input as well as further extending the
diffusion model from 2D to 3D were investigated based on various quantitative
metrics and the uncertainty maps generated. Results showed that the proposed 3D
diffusion model could generate more accurate segmentation results compared with
other methods. Compared to the diffusion model in 2D format, the proposed 3D
model yielded superior results. Our experiments also highlighted the advantage
of utilizing dual-modality PET and CT data over only single-modality data for
H&amp;N tumor segmentation.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17639 title=Abstract>arXiv:2401.17639</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.17639 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17639 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17639 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Assessment of Diagnostic Capabilities of Methods of Recreation of Voltage Fluctuations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kuwa%C5%82ek%2C+P">Piotr Kuwaek</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 5 figures, submitted to proceedings from international conferences
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>Voltage fluctuations are one of the most common low-frequency disturbances of
power quality. Diagnostics of these disturbances are a complex process because
voltage fluctuations affect different loads in different ways. Therefore, there
is no measure of power quality that allows for the complementary assessment of
severity of this disturbance, allow for the identification of sources of
voltage fluctuations, and post-factum investigation of their effects. Among the
currently used measures of voltage fluctuations, voltage fluctuation indices
have the greatest diagnostic capabilities. Many preliminary studies also show
the potential possibility of recreation of voltage fluctuations, including:
based on voltage fluctuation indices. This paper presents the results of
research on methods of recreation of voltage fluctuations from voltage
fluctuation indices. The research carried out included a set of data obtained
in a real power grid. Moreover, the impact of the discrimination period on the
accuracy of recreation of voltage fluctuations has been assessed. The presented
research results show, on the one hand, the usefulness of voltage fluctuation
indices in the process of recreation of voltage fluctuations and, on the other
hand, further challenges in the recreation of voltage fluctuations.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17643 title=Abstract>arXiv:2401.17643</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.17643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17643 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Laboratory Setup for Testing Low-Frequency Disturbances of Power Quality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kuwa%C5%82ek%2C+P">Piotr Kuwaek</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wiczy%C5%84ski%2C+G">Grzegorz Wiczyski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 10 figures, submitted to proceedings from international conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Low-frequency disturbances of power quality are one of the most common
disturbances in the power grid. These disturbances are most often the result of
the impact of power electronic and energy-saving devices, the number of which
is increasing significantly in the power grid. Due to the simultaneous
operation of various types of loads in the power grid, various types of
simultaneous disturbances of power quality occur, such as voltage fluctuations
and distortions. Therefore, there is a need to analyze this type of
simultaneous interaction. For this purpose, a special and complementary
laboratory setup has been prepared, which allows for the examination of actual
states occurring in modern power networks. Selected research results are
presented for this laboratory setup, which determine its basic properties.
Possible applications and possibilities of the laboratory setup are presented
from the point of view of current challenges.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17675 title=Abstract>arXiv:2401.17675</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17675 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17675 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17675 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence analysis of t-SNE as a gradient flow for point cloud on a manifold
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jeong%2C+S">Seonghyeon Jeong</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Wu%2C+H">Hau-Tieng Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)
</div>
<p class=mathjax>We present a theoretical foundation regarding the boundedness of the t-SNE
algorithm. t-SNE employs gradient descent iteration with Kullback-Leibler (KL)
divergence as the objective function, aiming to identify a set of points that
closely resemble the original data points in a high-dimensional space,
minimizing KL divergence. Investigating t-SNE properties such as perplexity and
affinity under a weak convergence assumption on the sampled dataset, we examine
the behavior of points generated by t-SNE under continuous gradient flow.
Demonstrating that points generated by t-SNE remain bounded, we leverage this
insight to establish the existence of a minimizer for KL divergence.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17690 title=Abstract>arXiv:2401.17690</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.17690 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17690 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+J">Jaeyeon Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jung%2C+J">Jaeyoon Jung</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lee%2C+J">Jinjoo Lee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Woo%2C+S+H">Sang Hoon Woo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)
</div>
<p class=mathjax>We propose EnCLAP, a novel framework for automated audio captioning. EnCLAP
employs two acoustic representation models, EnCodec and CLAP, along with a
pretrained language model, BART. We also introduce a new training objective
called masked codec modeling that improves acoustic awareness of the pretrained
language model. Experimental results on AudioCaps and Clotho demonstrate that
our model surpasses the performance of baseline models. Source code will be
available at https://github.com/jaeyeonkim99/EnCLAP . An online demo is
available at https://huggingface.co/spaces/enclap-team/enclap .
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17737 title=Abstract>arXiv:2401.17737</a> (cross-list from stat.ME) [<a href=https://arxiv.org/pdf/2401.17737 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17737 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ter-Minassian%2C+L">Lucile Ter-Minassian</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Szlak%2C+L">Liran Szlak</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Karavani%2C+E">Ehud Karavani</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Holmes%2C+C">Chris Holmes</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shimoni%2C+Y">Yishai Shimoni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Interpretability and transparency are essential for incorporating causal
effect models from observational data into policy decision-making. They can
provide trust for the model in the absence of ground truth labels to evaluate
the accuracy of such models. To date, attempts at transparent causal effect
estimation consist of applying post hoc explanation methods to black-box
models, which are not interpretable. Here, we present BICauseTree: an
interpretable balancing method that identifies clusters where natural
experiments occur locally. Our approach builds on decision trees with a
customized objective function to improve balancing and reduce treatment
allocation bias. Consequently, it can additionally detect subgroups presenting
positivity violations, exclude them, and provide a covariate-based definition
of the target population we can infer from and generalize to. We evaluate the
method's performance using synthetic and realistic datasets, explore its
bias-interpretability tradeoff, and show that it is comparable with existing
approaches.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17760 title=Abstract>arXiv:2401.17760</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17760 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Mahadi%2C+M">Maaz Mahadi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ballal%2C+T">Tarig Ballal</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Moinuddin%2C+M">Muhammad Moinuddin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Al-Saggaf%2C+U+M">Ubaid M. Al-Saggaf</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>Linear discriminant analysis (LDA) is a widely used technique for data
classification. The method offers adequate performance in many classification
problems, but it becomes inefficient when the data covariance matrix is
ill-conditioned. This often occurs when the feature space's dimensionality is
higher than or comparable to the training data size. Regularized LDA (RLDA)
methods based on regularized linear estimators of the data covariance matrix
have been proposed to cope with such a situation. The performance of RLDA
methods is well studied, with optimal regularization schemes already proposed.
In this paper, we investigate the capability of a positive semidefinite
ridge-type estimator of the inverse covariance matrix that coincides with a
nonlinear (NL) covariance matrix estimator. The estimator is derived by
reformulating the score function of the optimal classifier utilizing linear
estimation methods, which eventually results in the proposed NL-RLDA
classifier. We derive asymptotic and consistent estimators of the proposed
technique's misclassification rate under the assumptions of a double-asymptotic
regime and multivariate Gaussian model for the classes. The consistent
estimator, coupled with a one-dimensional grid search, is used to set the value
of the regularization parameter required for the proposed NL-RLDA classifier.
Performance evaluations based on both synthetic and real data demonstrate the
effectiveness of the proposed classifier. The proposed technique outperforms
state-of-art methods over multiple datasets. When compared to state-of-the-art
methods across various datasets, the proposed technique exhibits superior
performance.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17781 title=Abstract>arXiv:2401.17781</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.17781 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17781 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vision-Assisted Digital Twin Creation for mmWave Beam Management
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Arnold%2C+M">Maximilian Arnold</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Major%2C+B">Bence Major</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Massoli%2C+F+V">Fabio Valerio Massoli</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Soriaga%2C+J+B">Joseph B. Soriaga</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Behboodi%2C+A">Arash Behboodi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICC2024 accepted paper. Copyright IEEE
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In the context of communication networks, digital twin technology provides a
means to replicate the radio frequency (RF) propagation environment as well as
the system behaviour, allowing for a way to optimize the performance of a
deployed system based on simulations. One of the key challenges in the
application of Digital Twin technology to mmWave systems is the prevalent
channel simulators' stringent requirements on the accuracy of the 3D Digital
Twin, reducing the feasibility of the technology in real applications. We
propose a practical Digital Twin creation pipeline and a channel simulator,
that relies only on a single mounted camera and position information. We
demonstrate the performance benefits compared to methods that do not explicitly
model the 3D environment, on downstream sub-tasks in beam acquisition, using
the real-world dataset of the DeepSense6G challenge
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17814 title=Abstract>arXiv:2401.17814</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.17814 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17814 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection of Critical Events in Renewable Energy Production Time Series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Stoop%2C+L+P">Laurens P. Stoop</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Duijm%2C+E">Erik Duijm</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Feelders%2C+A+J">Ad J. Feelders</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=van+den+Broek%2C+M">Machteld van den Broek</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> In: AALTD 2021. Lecture Notes in Computer Science(), vol 13114
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The introduction of more renewable energy sources into the energy system
increases the variability and weather dependence of electricity generation.
Power system simulations are used to assess the adequacy and reliability of the
electricity grid over decades, but often become computational intractable for
such long simulation periods with high technical detail. To alleviate this
computational burden, we investigate the use of outlier detection algorithms to
find periods of extreme renewable energy generation which enables detailed
modelling of the performance of power systems under these circumstances.
Specifically, we apply the Maximum Divergent Intervals (MDI) algorithm to power
generation time series that have been derived from ERA5 historical climate
reanalysis covering the period from 1950 through 2019. By applying the MDI
algorithm on these time series, we identified intervals of extreme low and high
energy production. To determine the outlierness of an interval different
divergence measures can be used. Where the cross-entropy measure results in
shorter and strongly peaking outliers, the unbiased Kullback-Leibler divergence
tends to detect longer and more persistent intervals. These intervals are
regarded as potential risks for the electricity grid by domain experts,
showcasing the capability of the MDI algorithm to detect critical events in
these time series. For the historical period analysed, we found no trend in
outlier intensity, or shift and lengthening of the outliers that could be
attributed to climate change. By applying MDI on climate model output, power
system modellers can investigate the adequacy and possible changes of risk for
the current and future electricity grid under a wider range of scenarios.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17829 title=Abstract>arXiv:2401.17829</a> (cross-list from math.ST) [<a href=https://arxiv.org/pdf/2401.17829 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17829 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17829 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolving privacy: drift parameter estimation for discretely observed i.i.d. diffusion processes under LDP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Amorino%2C+C">Chiara Amorino</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gloter%2C+A">Arnaud Gloter</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Halconruy%2C+H">Hlne Halconruy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 45 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>The problem of estimating a parameter in the drift coefficient is addressed
for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-380 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-381><span class=mi id=MathJax-Span-382 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> discretely observed independent and identically distributed stochastic
differential equations (SDEs). This is done considering additional constraints,
wherein only public data can be published and used for inference. The concept
of local differential privacy (LDP) is formally introduced for a system of
stochastic differential equations. The objective is to estimate the drift
parameter by proposing a contrast function based on a pseudo-likelihood
approach. A suitably scaled Laplace noise is incorporated to meet the privacy
requirements. Our key findings encompass the derivation of explicit conditions
tied to the privacy level. Under these conditions, we establish the consistency
and asymptotic normality of the associated estimator. Notably, the convergence
rate is intricately linked to the privacy level, and is some situations may be
completely different from the case where privacy constraints are ignored. Our
results hold true as the discretization step approaches zero and the number of
processes <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-383 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-384><span class=mi id=MathJax-Span-385 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> tends to infinity.
</p>
</div>
</dd>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17846 title=Abstract>arXiv:2401.17846</a> (cross-list from physics.soc-ph) [<a href=https://arxiv.org/pdf/2401.17846 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17846 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Drift Diffusion Model to understand (mis)information sharing dynamic in complex networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Alvarez-Zuzek%2C+L+G">Lucila G. Alvarez-Zuzek</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Grujic%2C+J">Jelena Grujic</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Gallotti%2C+R">Riccardo Gallotti</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 46 pages and 22 figures (taking into account the Supplementary Information)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Sharing misinformation threatens societies as misleading news shapes the risk
perception of individuals. We witnessed this during the COVID-19 pandemic,
where misinformation undermined the effectiveness of stay-at-home orders,
posing an additional obstacle in the fight against the virus. In this research,
we study misinformation spreading, reanalyzing behavioral data on online
sharing, and analyzing decision-making mechanisms using the Drift Diffusion
Model (DDM). We find that subjects display an increased instinctive inclination
towards sharing misleading news, but rational thinking significantly curbs this
reaction, especially for more cautious and older individuals. Using an
agent-based model, we expand this individual knowledge to a social network
where individuals are exposed to misinformation through friends and share (or
not) content with probabilities driven by DDM. The natural shape of the Twitter
network provides a fertile ground for any news to rapidly become viral, yet we
found that limiting users' followers proves to be an appropriate and feasible
containment strategy.
</p>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17855 title=Abstract>arXiv:2401.17855</a> (cross-list from stat.AP) [<a href=https://arxiv.org/pdf/2401.17855 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17855 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Network-based Topic Structure Visualization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jeon%2C+Y">Yeseul Jeon</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Park%2C+J">Jina Park</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Jin%2C+I+H">Ick Hoon Jin</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chungc%2C+D">Dongjun Chungc</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Applications (stat.AP)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)
</div>
<p class=mathjax>In the real world, many topics are inter-correlated, making it challenging to
investigate their structure and relationships. Understanding the interplay
between topics and their relevance can provide valuable insights for
researchers, guiding their studies and informing the direction of research. In
this paper, we utilize the topic-words distribution, obtained from topic
models, as item-response data to model the structure of topics using a latent
space item response model. By estimating the latent positions of topics based
on their distances toward words, we can capture the underlying topic structure
and reveal their relationships. Visualizing the latent positions of topics in
Euclidean space allows for an intuitive understanding of their proximity and
associations. We interpret relationships among topics by characterizing each
topic based on representative words selected using a newly proposed scoring
scheme. Additionally, we assess the maturity of topics by tracking their latent
positions using different word sets, providing insights into the robustness of
topics. To demonstrate the effectiveness of our approach, we analyze the topic
composition of COVID-19 studies during the early stage of its emergence using
biomedical literature in the PubMed database. The software and data used in
this paper are publicly available at https://github.com/jeon9677/gViz .
</p>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17860 title=Abstract>arXiv:2401.17860</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.17860 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17860 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17860 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automorphism groups of Cayley graphs generated by general transposition sets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gijswijt%2C+D">Dion Gijswijt</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=de+Meijer%2C+F">Frank de Meijer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>In this paper we study the Cayley graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-386 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.69em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-387><span class=texatom id=MathJax-Span-388><span class=mrow id=MathJax-Span-389><span class=mi id=MathJax-Span-390 style=font-family:MathJax_Main>C</span><span class=mi id=MathJax-Span-391 style=font-family:MathJax_Main>a</span><span class=mi id=MathJax-Span-392 style=font-family:MathJax_Main>y</span></span></span><span class=mo id=MathJax-Span-393 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-394><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-395 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-396 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-397 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-398 style=font-family:MathJax_Math-italic;padding-left:0.177em>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-399 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> of the
symmetric group <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-400 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-401><span class=msubsup id=MathJax-Span-402><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-403 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-404 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> generated by a set of transpositions <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-405 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-406><span class=mi id=MathJax-Span-407 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We show that
for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-408 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.43em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-409><span class=mi id=MathJax-Span-410 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-411 style=font-family:MathJax_Main;padding-left:0.292em></span><span class=mn id=MathJax-Span-412 style=font-family:MathJax_Main;padding-left:0.292em>5</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> the Cayley graph is normal. As a corollary, we show that its
automorphism group is a direct product of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-413 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-414><span class=msubsup id=MathJax-Span-415><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-416 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-417 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and the automorphism group of
the transposition graph associated to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-418 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-419><span class=mi id=MathJax-Span-420 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. This provides an affirmative answer
to a conjecture raised by Ganesan in <a href=https://arxiv.org/abs/1703.08109>arXiv:1703.08109</a>, showing that
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><nobr><span class=math id=MathJax-Span-421 style=width:5.79em;display:inline-block><span style=display:inline-block;position:relative;width:4.806em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.69em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-422><span class=texatom id=MathJax-Span-423><span class=mrow id=MathJax-Span-424><span class=mi id=MathJax-Span-425 style=font-family:MathJax_Main>C</span><span class=mi id=MathJax-Span-426 style=font-family:MathJax_Main>a</span><span class=mi id=MathJax-Span-427 style=font-family:MathJax_Main>y</span></span></span><span class=mo id=MathJax-Span-428 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-429><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-430 style=font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-431 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-432 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-433 style=font-family:MathJax_Math-italic;padding-left:0.177em>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-434 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is normal if and only if the transposition graph is not
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-435 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-436><span class=msubsup id=MathJax-Span-437><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-438 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mn id=MathJax-Span-439 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> or <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-440 style=width:1.623em;display:inline-block><span style=display:inline-block;position:relative;width:1.334em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.33em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-441><span class=msubsup id=MathJax-Span-442><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-443 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=mi id=MathJax-Span-444 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17902 title=Abstract>arXiv:2401.17902</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.17902 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17902 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting speech segmentation and lexicon learning with better features
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kamper%2C+H">Herman Kamper</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=van+Niekerk%2C+B">Benjamin van Niekerk</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)
</div>
<p class=mathjax>We revisit a self-supervised method that segments unlabelled speech into
word-like segments. We start from the two-stage duration-penalised dynamic
programming method that performs zero-resource segmentation without learning an
explicit lexicon. In the first acoustic unit discovery stage, we replace
contrastive predictive coding features with HuBERT. After word segmentation in
the second stage, we get an acoustic word embedding for each segment by
averaging HuBERT features. These embeddings are clustered using K-means to get
a lexicon. The result is good full-coverage segmentation with a lexicon that
achieves state-of-the-art performance on the ZeroSpeech benchmarks.
</p>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17921 title=Abstract>arXiv:2401.17921</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17921 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17921 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17921 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Ripple-Carry Adders and Comparator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Remaud%2C+M">Maxime Remaud</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>Addition is the most elementary arithmetic operation, and the basic building
block of many algorithms. Having an efficient adder in terms of both physical
resources and time is naturally essential. In this paper, we propose new
quantum adders using the ripple-carry strategy as well as a new comparator. In
particular, we show that a delay of 8n+O(1) is enough for adding or comparing
two n-bit numbers and that there exists a circuit with a quantum cost of
12n+O(1) and a delay of 10n+O(1) for the addition. Even when focusing on the
Clifford+T gate set, we obtain circuits using less gates than what was
previously known. All our circuits use at most a single ancillary qubit and do
not produce any garbage output.
</p>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17929 title=Abstract>arXiv:2401.17929</a> (cross-list from econ.GN) [<a href=https://arxiv.org/pdf/2401.17929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Technological Shocks and Algorithmic Decision Aids in Credence Goods Markets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Erlei%2C+A">Alexander Erlei</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Meub%2C+L">Lukas Meub</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>General Economics (econ.GN)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>In credence goods markets such as health care or repair services, consumers
rely on experts with superior information to adequately diagnose and treat
them. Experts, however, are constrained in their diagnostic abilities, which
hurts market efficiency and consumer welfare. Technological breakthroughs that
substitute or complement expert judgments have the potential to alleviate
consumer mistreatment. This article studies how competitive experts adopt novel
diagnostic technologies when skills are heterogeneously distributed and
obfuscated to consumers. We differentiate between novel technologies that
increase expert abilities, and algorithmic decision aids that complement expert
judgments, but do not affect an expert's personal diagnostic precision. We show
that high-ability experts may be incentivized to forego the decision aid in
order to escape a pooling equilibrium by differentiating themselves from
low-ability experts. Results from an online experiment support our hypothesis,
showing that high-ability experts are significantly less likely than
low-ability experts to invest into an algorithmic decision aid. Furthermore, we
document pervasive under-investments, and no effect on expert honesty.
</p>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17937 title=Abstract>arXiv:2401.17937</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Branch-and-Price for the Length-Constrained Cycle Partition Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ghannam%2C+M">Mohammed Ghannam</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mexi%2C+G">Gioni Mexi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lam%2C+E">Edward Lam</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gleixner%2C+A">Ambros Gleixner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>The length-constrained cycle partition problem (LCCP) is a graph optimization
problem in which a set of nodes must be partitioned into a minimum number of
cycles. Every node is associated with a critical time and the length of every
cycle must not exceed the critical time of any node in the cycle. We formulate
LCCP as a set partitioning model and solve it using an exact branch-and-price
approach. We use a dynamic programming-based pricing algorithm to generate
improving cycles, exploiting the particular structure of the pricing problem
for efficient bidirectional search and symmetry breaking. Computational results
show that the LP relaxation of the set partitioning model produces strong dual
bounds and our branch-and-price method improves significantly over the state of
the art. It is able to solve closed instances in a fraction of the previously
needed time and closes 13 previously unsolved instances, one of which has 76
nodes, a notable improvement over the previous limit of 52 nodes.
</p>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17958 title=Abstract>arXiv:2401.17958</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17958 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17958 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17958 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence Analysis for General Probability Flow ODEs of Diffusion Models in Wasserstein Distances
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gao%2C+X">Xuefeng Gao</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhu%2C+L">Lingjiong Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, 3 tables. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.11003>arXiv:2311.11003</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR)
</div>
<p class=mathjax>Score-based generative modeling with probability flow ordinary differential
equations (ODEs) has achieved remarkable success in a variety of applications.
While various fast ODE-based samplers have been proposed in the literature and
employed in practice, the theoretical understandings about convergence
properties of the probability flow ODE are still quite limited. In this paper,
we provide the first non-asymptotic convergence analysis for a general class of
probability flow ODE samplers in 2-Wasserstein distance, assuming accurate
score estimates. We then consider various examples and establish results on the
iteration complexity of the corresponding ODE-based samplers.
</p>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17976 title=Abstract>arXiv:2401.17976</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17976 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17976 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Circuit Partitioning for Multi-Core Quantum Architectures with Deep Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Pastor%2C+A">Arnau Pastor</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Escofet%2C+P">Pau Escofet</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Rached%2C+S+B">Sahar Ben Rached</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Alarc%C3%B3n%2C+E">Eduard Alarcn</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Barlet-Ros%2C+P">Pere Barlet-Ros</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Abadal%2C+S">Sergi Abadal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Quantum computing holds immense potential for solving classically intractable
problems by leveraging the unique properties of quantum mechanics. The
scalability of quantum architectures remains a significant challenge.
Multi-core quantum architectures are proposed to solve the scalability problem,
arising a new set of challenges in hardware, communications and compilation,
among others. One of these challenges is to adapt a quantum algorithm to fit
within the different cores of the quantum computer. This paper presents a novel
approach for circuit partitioning using Deep Reinforcement Learning,
contributing to the advancement of both quantum computing and graph
partitioning. This work is the first step in integrating Deep Reinforcement
Learning techniques into Quantum Circuit Mapping, opening the door to a new
paradigm of solutions to such problems.
</p>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18006 title=Abstract>arXiv:2401.18006</a> (cross-list from eess.SP) [<a href=https://arxiv.org/pdf/2401.18006 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18006 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EEG-GPT: Exploring Capabilities of Large Language Models for EEG Classification and Interpretation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kim%2C+J+W">Jonathan W. Kim</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alaa%2C+A">Ahmed Alaa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bernardo%2C+D">Danilo Bernardo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>In conventional machine learning (ML) approaches applied to
electroencephalography (EEG), this is often a limited focus, isolating specific
brain activities occurring across disparate temporal scales (from transient
spikes in milliseconds to seizures lasting minutes) and spatial scales (from
localized high-frequency oscillations to global sleep activity). This siloed
approach limits the development EEG ML models that exhibit multi-scale
electrophysiological understanding and classification capabilities. Moreover,
typical ML EEG approaches utilize black-box approaches, limiting their
interpretability and trustworthiness in clinical contexts. Thus, we propose
EEG-GPT, a unifying approach to EEG classification that leverages advances in
large language models (LLM). EEG-GPT achieves excellent performance comparable
to current state-of-the-art deep learning methods in classifying normal from
abnormal EEG in a few-shot learning paradigm utilizing only 2% of training
data. Furthermore, it offers the distinct advantages of providing intermediate
reasoning steps and coordinating specialist EEG tools across multiple scales in
its operation, offering transparent and interpretable step-by-step
verification, thereby promoting trustworthiness in clinical contexts.
</p>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18012 title=Abstract>arXiv:2401.18012</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.18012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Coordinated Concurrent Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tse%2C+T">Tim Tse</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chan%2C+I">Isaac Chan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chen%2C+Z">Zhitang Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this work, we propose a novel algorithmic framework for data sharing and
coordinated exploration for the purpose of learning more data-efficient and
better performing policies under a concurrent reinforcement learning (CRL)
setting. In contrast to other work which make the assumption that all agents
act under identical environments, we relax this restriction and instead
consider the formulation where each agent acts within an environment which
shares a global structure but also exhibits individual variations. Our
algorithm leverages a causal inference algorithm in the form of Additive Noise
Model - Mixture Model (ANM-MM) in extracting model parameters governing
individual differentials via independence enforcement. We propose a new data
sharing scheme based on a similarity measure of the extracted model parameters
and demonstrate superior learning speeds on a set of autoregressive, pendulum
and cart-pole swing-up tasks and finally, we show the effectiveness of diverse
action selection between common agents under a sparse reward setting. To the
best of our knowledge, this is the first work in considering non-identical
environments in CRL and one of the few works which seek to integrate causal
inference with reinforcement learning (RL).
</p>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18017 title=Abstract>arXiv:2401.18017</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.18017 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18017 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18017 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Discovery by Kernel Deviance Measures with Heterogeneous Transforms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tse%2C+T">Tim Tse</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chen%2C+Z">Zhitang Chen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhu%2C+S">Shengyu Zhu</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Liu%2C+Y">Yue Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The discovery of causal relationships in a set of random variables is a
fundamental objective of science and has also recently been argued as being an
essential component towards real machine intelligence. One class of causal
discovery techniques are founded based on the argument that there are inherent
structural asymmetries between the causal and anti-causal direction which could
be leveraged in determining the direction of causation. To go about capturing
these discrepancies between cause and effect remains to be a challenge and many
current state-of-the-art algorithms propose to compare the norms of the kernel
mean embeddings of the conditional distributions. In this work, we argue that
such approaches based on RKHS embeddings are insufficient in capturing
principal markers of cause-effect asymmetry involving higher-order structural
variabilities of the conditional distributions. We propose Kernel Intrinsic
Invariance Measure with Heterogeneous Transform (KIIM-HT) which introduces a
novel score measure based on heterogeneous transformation of RKHS embeddings to
extract relevant higher-order moments of the conditional densities for causal
discovery. Inference is made via comparing the score of each hypothetical
cause-effect direction. Tests and comparisons on a synthetic dataset, a
two-dimensional synthetic dataset and the real-world benchmark dataset
T\"ubingen Cause-Effect Pairs verify our approach. In addition, we conduct a
sensitivity analysis to the regularization parameter to faithfully compare
previous work to our method and an experiment with trials on varied
hyperparameter values to showcase the robustness of our algorithm.
</p>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18030 title=Abstract>arXiv:2401.18030</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.18030 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18030 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18030 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distributed fixed-point algorithms for dynamic convex optimization over decentralized and unbalanced wireless networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Agrawal%2C+N">Navneet Agrawal</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Cavalcante%2C+R+L+G">Renato L.G. Cavalcante</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Stanczak%2C+S">Slawomir Stanczak</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as 27th International Workshop on Smart Antennas (WSA 2024), and will be presented during the conference on March 17 to 19, 2024, Dresden, Germany
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)
</div>
<p class=mathjax>We consider problems where agents in a network seek a common quantity,
measured independently and periodically by each agent through a local
time-varying process. Numerous solvers addressing such problems have been
developed in the past, featuring various adaptations of the local processing
and the consensus step. However, existing solvers still lack support for
advanced techniques, such as superiorization and over-the-air function
computation (OTA-C). To address this limitation, we introduce a comprehensive
framework for the analysis of distributed algorithms by characterizing them
using the quasi-Fej\'er type algorithms and an extensive communication model.
Under weak assumptions, we prove almost sure convergence of the algorithm to a
common estimate for all agents. Moreover, we develop a specific class of
algorithms within this framework to tackle distributed optimization problems
with time-varying objectives, and, assuming that a time-invariant solution
exists, prove its convergence to a solution. We also present a novel OTA-C
protocol for consensus step in large decentralized networks, reducing
communication overhead and enhancing network autonomy as compared to the
existing protocols. The effectiveness of the algorithm, featuring
superiorization and OTA-C, is demonstrated in a real-world application of
distributed supervised learning over time-varying wireless networks,
highlighting its low-latency and energy-efficiency compared to standard
approaches.
</p>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18039 title=Abstract>arXiv:2401.18039</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.18039 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18039 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18039 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variable selection for Nave Bayes classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Blanquero%2C+R">Rafael Blanquero</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Carrizosa%2C+E">Emilio Carrizosa</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ram%C3%ADrez-Cobo%2C+P">Pepa Ramrez-Cobo</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sillero-Denamiel%2C+M+R">M. Remedios Sillero-Denamiel</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Computers &amp; Operations Research, Volume 135, 2021, 105456,
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The Na\"ive Bayes has proven to be a tractable and efficient method for
classification in multivariate analysis. However, features are usually
correlated, a fact that violates the Na\"ive Bayes' assumption of conditional
independence, and may deteriorate the method's performance. Moreover, datasets
are often characterized by a large number of features, which may complicate the
interpretation of the results as well as slow down the method's execution.
<br>In this paper we propose a sparse version of the Na\"ive Bayes classifier
that is characterized by three properties. First, the sparsity is achieved
taking into account the correlation structure of the covariates. Second,
different performance measures can be used to guide the selection of features.
Third, performance constraints on groups of higher interest can be included.
Our proposal leads to a smart search, which yields competitive running times,
whereas the flexibility in terms of performance measure for classification is
integrated. Our findings show that, when compared against well-referenced
feature selection approaches, the proposed sparse Na\"ive Bayes obtains
competitive results regarding accuracy, sparsity and running times for balanced
datasets. In the case of datasets with unbalanced (or with different
importance) classes, a better compromise between classification rates for the
different classes is achieved.
</p>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18060 title=Abstract>arXiv:2401.18060</a> (cross-list from math.NT) [<a href=https://arxiv.org/pdf/2401.18060 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.18060 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.18060 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rarity of the infinite chains in the tree of numerical semigroups
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bras-Amor%C3%B3s%2C+M">Maria Bras-Amors</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ribeiro%2C+M+R">Mariana Rosas Ribeiro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)
</div>
<p class=mathjax>We prove that, for each fixed genus g, the portion of semigroups belonging to
infinite chains in the semigroup tree approaches 0 as the genus grows to
infinite. This problem has been open since 2009.
</p>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.18065 title=Abstract>arXiv:2401.18065</a> (cross-list from cond-mat.stat-mech) [<a href=https://arxiv.org/pdf/2401.18065 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.18065 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Game susceptibility, Correlation and Payoff capacity as a measure of Cooperative behavior in the thermodynamic limit of some Social dilemmas
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Tah%2C+R">Rajdeep Tah</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Benjamin%2C+C">Colin Benjamin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 16 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistical Mechanics (cond-mat.stat-mech)</span>; Multiagent Systems (cs.MA); Populations and Evolution (q-bio.PE)
</div>
<p class=mathjax>Analytically, finding the origins of cooperative behavior in infinite-player
games is an exciting topic of current interest. Previously, cooperative
behavior has been studied by considering game magnetization and individual
player's average payoff as indicators. This paper shows that game
susceptibility, correlation, and payoff capacity can aid in understanding
cooperative behavior in social dilemmas in the thermodynamic limit. In this
paper, we compare three analytical methods, i.e., Nash equilibrium mapping
(NEM), Darwinian selection (DS), and Aggregate selection (AS), with a
numerical-based method (ABM) via the game susceptibility, correlation, and
payoff capacity as indicators of cooperative behavior. AS and DS fail compared
to NEM and ABM by giving incorrect results for the indicators in question. The
results obtained via NEM and ABM are in good agreement for all three indicators
in question, for both Hawk-Dove and the Public goods games. After comparing the
results obtained for all five indicators, we see that individual players'
average payoff and payoff capacity are the best indicators to study cooperative
behavior among players in the thermodynamic limit. This paper finds that NEM
and ABM, along with the selected indicators, offer valuable insights into
cooperative behavior in infinite-player games, contributing to understanding
social dilemmas in the thermodynamic limit.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 1 Feb 24</h3>
<dl>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1807.05443 title=Abstract>arXiv:1807.05443</a> (replaced) [<a href=https://arxiv.org/pdf/1807.05443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/1807.05443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exact Algorithms and Lower Bounds for Stable Instances of Euclidean k-Means
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friggstad%2C+Z">Zachary Friggstad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khodamoradi%2C+K">Kamyar Khodamoradi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salavatipour%2C+M+R">Mohammad R. Salavatipour</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2006.02570 title=Abstract>arXiv:2006.02570</a> (replaced) [<a href=https://arxiv.org/pdf/2006.02570 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2006.02570 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploration of Interpretability Techniques for Deep COVID-19 Classification using Chest X-ray Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chatterjee%2C+S">Soumick Chatterjee</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Saad%2C+F">Fatima Saad</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sarasaen%2C+C">Chompunuch Sarasaen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ghosh%2C+S">Suhita Ghosh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Krug%2C+V">Valerie Krug</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khatun%2C+R">Rupali Khatun</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mishra%2C+R">Rahul Mishra</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Desai%2C+N">Nirja Desai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Radeva%2C+P">Petia Radeva</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rose%2C+G">Georg Rose</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Stober%2C+S">Sebastian Stober</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Speck%2C+O">Oliver Speck</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=N%C3%BCrnberger%2C+A">Andreas Nrnberger</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2009.03218 title=Abstract>arXiv:2009.03218</a> (replaced) [<a href=https://arxiv.org/pdf/2009.03218 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2009.03218 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast simulation of planar Clifford circuits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gosset%2C+D">David Gosset</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Grier%2C+D">Daniel Grier</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kerzner%2C+A">Alex Kerzner</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Schaeffer%2C+L">Luke Schaeffer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)
</div>
</div>
</dd>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2104.13130 title=Abstract>arXiv:2104.13130</a> (replaced) [<a href=https://arxiv.org/pdf/2104.13130 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2104.13130 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2104.13130 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Secure and Efficient Federated Learning Through Layering and Sharding Blockchain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuo Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+B">Bin Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z">Zhiguo Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+M">Mugen Peng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Network Science and Engineering
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2105.11309 title=Abstract>arXiv:2105.11309</a> (replaced) [<a href=https://arxiv.org/pdf/2105.11309 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2105.11309 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2105.11309 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficiently Solving High-Order and Nonlinear ODEs with Rational Fraction Polynomial: the Ratio Net
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+C">Chenxin Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruhao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Maocai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shengyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chichun Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2110.15345 title=Abstract>arXiv:2110.15345</a> (replaced) [<a href=https://arxiv.org/pdf/2110.15345 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2110.15345 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Measuring the Consolidation of DNS and Web Hosting Providers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Synthia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=MacMillan%2C+K">Kyle MacMillan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaffner%2C+B">Brennan Schaffner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feamster%2C+N">Nick Feamster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chetty%2C+M">Marshini Chetty</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2112.10953 title=Abstract>arXiv:2112.10953</a> (replaced) [<a href=https://arxiv.org/pdf/2112.10953 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2112.10953 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An adaptation of InfoMap to absorbing random walks using absorption-scaled graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernal%2C+E+V">Esteban Vargas Bernal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porter%2C+M+A">Mason A. Porter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tien%2C+J+H">Joseph H. Tien</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Probability (math.PR); Adaptation and Self-Organizing Systems (nlin.AO); Physics and Society (physics.soc-ph)
</div>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2201.09196 title=Abstract>arXiv:2201.09196</a> (replaced) [<a href=https://arxiv.org/pdf/2201.09196 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2201.09196 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning to Predict Gradients for Semi-Supervised Continual Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+Y">Yongkang Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kankanhalli%2C+M">Mohan Kankanhalli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qi Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Neural Networks and Learning Systems, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2201.09646 title=Abstract>arXiv:2201.09646</a> (replaced) [<a href=https://arxiv.org/pdf/2201.09646 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2201.09646 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Numerical analysis of a mixed-dimensional poromechanical model with frictionless contact at matrix-fracture interfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bonaldi%2C+F">Francesco Bonaldi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Droniou%2C+J">Jrme Droniou</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Masson%2C+R">Roland Masson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2201.13391 title=Abstract>arXiv:2201.13391</a> (replaced) [<a href=https://arxiv.org/pdf/2201.13391 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2201.13391 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-driven structure-preserving model reduction for stochastic Hamiltonian systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tyranowski%2C+T+M">Tomasz M. Tyranowski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 43 pages, 16 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG); Dynamical Systems (math.DS); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.13833 title=Abstract>arXiv:2202.13833</a> (replaced) [<a href=https://arxiv.org/pdf/2202.13833 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.13833 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Formally verified asymptotic consensus in robust networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tekriwal%2C+M">Mohit Tekriwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tachna-Fram%2C+A">Avi Tachna-Fram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeannin%2C+J">Jean-Baptiste Jeannin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kapritsos%2C+M">Manos Kapritsos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted for publication at the TACAS,2024 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2203.01327 title=Abstract>arXiv:2203.01327</a> (replaced) [<a href=https://arxiv.org/pdf/2203.01327 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2203.01327 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hyperspectral Pixel Unmixing with Latent Dirichlet Variational Autoencoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mantripragada%2C+K">Kiran Mantripragada</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Qureshi%2C+F+Z">Faisal Z. Qureshi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.07680 title=Abstract>arXiv:2204.07680</a> (replaced) [<a href=https://arxiv.org/pdf/2204.07680 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2204.07680 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2204.07680 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sequential discretisation schemes for a class of stochastic differential equations and their application to Bayesian filtering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Akyildiz%2C+D">Deniz Akyildiz</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Crisan%2C+D">Dan Crisan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Miguez%2C+J">Joaquin Miguez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation (stat.CO)</span>; Numerical Analysis (math.NA); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.03256 title=Abstract>arXiv:2205.03256</a> (replaced) [<a href=https://arxiv.org/pdf/2205.03256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.03256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OROS: Online Operation and Orchestration of Collaborative Robots using 5G
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zanzi%2C+L">Lanfranco Zanzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa-P%C3%A9rez%2C+X">Xavier Costa-Prez</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.09622 title=Abstract>arXiv:2205.09622</a> (replaced) [<a href=https://arxiv.org/pdf/2205.09622 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.09622 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Is Fairness? On the Role of Protected Attributes and Fictitious Worlds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bothmann%2C+L">Ludwig Bothmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peters%2C+K">Kristina Peters</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bischl%2C+B">Bernd Bischl</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.15523 title=Abstract>arXiv:2205.15523</a> (replaced) [<a href=https://arxiv.org/pdf/2205.15523 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2205.15523 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variational Transfer Learning using Cross-Domain Latent Modulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+J">Jinyong Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+J+D">Jeremiah D. Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cranefield%2C+S">Stephen Cranefield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Din%2C+X">Xuejie Din</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review. Extended version of a previous WACV paper (<a href=https://arxiv.org/abs/2012.11727>arXiv:2012.11727</a>). 13 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.05239 title=Abstract>arXiv:2206.05239</a> (replaced) [<a href=https://arxiv.org/pdf/2206.05239 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.05239 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StructCoder: Structure-Aware Transformer for Code Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tipirneni%2C+S">Sindhu Tipirneni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+M">Ming Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reddy%2C+C+K">Chandan K. Reddy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2207.09524 title=Abstract>arXiv:2207.09524</a> (replaced) [<a href=https://arxiv.org/pdf/2207.09524 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2207.09524 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identifying and characterizing superspreaders of low-credibility content on Twitter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeVerna%2C+M+R">Matthew R. DeVerna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aiyappa%2C+R">Rachith Aiyappa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pacheco%2C+D">Diogo Pacheco</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bryden%2C+J">John Bryden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.08316 title=Abstract>arXiv:2209.08316</a> (replaced) [<a href=https://arxiv.org/pdf/2209.08316 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.08316 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Empathetic AI Coach for Self-Attachment Therapy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alazraki%2C+L">Lisa Alazraki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghachem%2C+A">Ali Ghachem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polydorou%2C+N">Neophytos Polydorou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khosmood%2C+F">Foaad Khosmood</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edalat%2C+A">Abbas Edalat</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2021 IEEE Third International Conference on Cognitive Machine
 Intelligence (CogMI), 2021, pp. 78-87
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.09641 title=Abstract>arXiv:2209.09641</a> (replaced) [<a href=https://arxiv.org/pdf/2209.09641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.09641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Calibrating Segmentation Networks with Margin-based Label Smoothing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murugesan%2C+B">Balamurali Murugesan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bingyuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Galdran%2C+A">Adrian Galdran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dolz%2C+J">Jose Dolz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> MedIA 2023. The code is available at <a href=https://github.com/Bala93/MarginLoss.>this https URL</a> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2111.15430>arXiv:2111.15430</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.02638 title=Abstract>arXiv:2210.02638</a> (replaced) [<a href=https://arxiv.org/pdf/2210.02638 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2210.02638 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2210.02638 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Can We Compute in a Single Round of the Congested Clique?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+P">Peter Robinson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Appeared at PODC 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.06225 title=Abstract>arXiv:2210.06225</a> (replaced) [<a href=https://arxiv.org/pdf/2210.06225 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.06225 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Generalizability of ECG-based Stress Detection Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prajod%2C+P">Pooja Prajod</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andr%C3%A9%2C+E">Elisabeth Andr</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in Proceedings of 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.07172 title=Abstract>arXiv:2211.07172</a> (replaced) [<a href=https://arxiv.org/pdf/2211.07172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.07172 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.07172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pilot-Aided Distributed Multi-Group Multicast Precoding Design for Cell-Free Massive MIMO
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gouda%2C+B">Bikshapathi Gouda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Atzeni%2C+I">Italo Atzeni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C3%B6lli%2C+A">Antti Tlli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to TWC
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.01713 title=Abstract>arXiv:2212.01713</a> (replaced) [<a href=https://arxiv.org/pdf/2212.01713 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.01713 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SoK: Fully Homomorphic Encryption Accelerators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junxue Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xiaodian Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Liu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinbin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Ximeng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
</div>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.10558 title=Abstract>arXiv:2212.10558</a> (replaced) [<a href=https://arxiv.org/pdf/2212.10558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.10558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On-the-fly Denoising for Data Augmentation in Natural Language Understanding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+T">Tianqing Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wenxuan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fangyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yangqiu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Findings of EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.10767 title=Abstract>arXiv:2212.10767</a> (replaced) [<a href=https://arxiv.org/pdf/2212.10767 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.10767 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Does Beam Search improve Span-Level Confidence Estimation in Generative Sequence Labeling?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hashimoto%2C+K">Kazuma Hashimoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naim%2C+I">Iftekhar Naim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raman%2C+K">Karthik Raman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> UncertaiNLP 2024 (an EACL 2024 workshop: <a href=https://uncertainlp.github.io/>this https URL</a>)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.11673 title=Abstract>arXiv:2301.11673</a> (replaced) [<a href=https://arxiv.org/pdf/2301.11673 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.11673 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Self-Supervised Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.13530 title=Abstract>arXiv:2301.13530</a> (replaced) [<a href=https://arxiv.org/pdf/2301.13530 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.13530 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain-Generalizable Multiple-Domain Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rozner%2C+A">Amit Rozner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Battash%2C+B">Barak Battash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+L">Lior Wolf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lindenbaum%2C+O">Ofir Lindenbaum</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06124 title=Abstract>arXiv:2302.06124</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06124 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06124 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revet: A Language and Compiler for Dataflow Threads
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rucker%2C+A">Alexander Rucker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sundram%2C+S">Shiv Sundram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+C">Coleman Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vilim%2C+M">Matthew Vilim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prabhakar%2C+R">Raghu Prabhakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kjolstad%2C+F">Fredrik Kjolstad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olukotun%2C+K">Kunle Olukotun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in HPCA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.06432 title=Abstract>arXiv:2302.06432</a> (replaced) [<a href=https://arxiv.org/pdf/2302.06432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.06432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Deep Learning-based Global and Segmentation-based Semantic Feature Fusion Approach for Indoor Scene Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pereira%2C+R">Ricardo Pereira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barros%2C+T">Tiago Barros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garrote%2C+L">Luis Garrote</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lopes%2C+A">Ana Lopes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nunes%2C+U+J">Urbano J. Nunes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at Pattern Recognition Letters 2024 (DOI: 10.1016/j.patrec.2024.01.022)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Pattern Recognition Letters, vol 179, pp. 24-30, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.13081 title=Abstract>arXiv:2302.13081</a> (replaced) [<a href=https://arxiv.org/pdf/2302.13081 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.13081 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Isolated Suborders and their Application to Counting Closure Operators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gl%C3%BCck%2C+R">Roland Glck</a> (1) ((1) German Aerospace Center)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>
</div>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.09171 title=Abstract>arXiv:2303.09171</a> (replaced) [<a href=https://arxiv.org/pdf/2303.09171 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.09171 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Empowering CAM-Based Methods with Capability to Generate Fine-Grained and High-Faithfulness Explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+C">Changqing Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+F">Fusheng Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yining Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.14346 title=Abstract>arXiv:2303.14346</a> (replaced) [<a href=https://arxiv.org/pdf/2303.14346 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.14346 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative Multi-Object Tracking with Conformal Uncertainty Propagation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+S">Sanbao Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+S">Songyang Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yiming Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhili Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+C">Chen Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+C">Caiwen Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+F">Fei Miao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by IEEE Robotics and Automation Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.17615 title=Abstract>arXiv:2303.17615</a> (replaced) [<a href=https://arxiv.org/pdf/2303.17615 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.17615 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Utilizing Reinforcement Learning for de novo Drug Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Svensson%2C+H+G">Hampus Gummesson Svensson</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Tyrchan%2C+C">Christian Tyrchan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Engkvist%2C+O">Ola Engkvist</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.07363 title=Abstract>arXiv:2304.07363</a> (replaced) [<a href=https://arxiv.org/pdf/2304.07363 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.07363 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Integrated Cyber-Physical Risk Assessment Framework for Worst-Case Attacks in Industrial Control Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Aftabi%2C+N">Navid Aftabi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+D">Dan Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=D.%2C+P">Ph.D.</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sharkey%2C+T">Thomas Sharkey</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=D%2C+P">Ph.D</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.00066 title=Abstract>arXiv:2305.00066</a> (replaced) [<a href=https://arxiv.org/pdf/2305.00066 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.00066 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Kolmogorov N-width for linear transport: Exact representation and the influence of the data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Arbes%2C+F">Florian Arbes</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Greif%2C+C">Constantin Greif</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Urban%2C+K">Karsten Urban</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06614 title=Abstract>arXiv:2305.06614</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.06614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust stability of moving horizon estimation for continuous-time systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schiller%2C+J+D">Julian D. Schiller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=M%C3%BCller%2C+M+A">Matthias A. Mller</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Replaced by accepted version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> at-Automatisierungstechnik 2024; 72(2): 120-133
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06715 title=Abstract>arXiv:2305.06715</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06715 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.06715 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Backpropagation-Free 4D Continuous Ant-Based Neural Topology Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=ElSaid%2C+A">AbdElRahman ElSaid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ricanek%2C+K">Karl Ricanek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+Z">Zeming Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ororbia%2C+A">Alexander Ororbia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Desell%2C+T">Travis Desell</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2011.10831>arXiv:2011.10831</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> j.asoc.2023.110737
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.11588 title=Abstract>arXiv:2305.11588</a> (replaced) [<a href=https://arxiv.org/pdf/2305.11588 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.11588 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaoyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z">Ziyu Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Can Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by TVCG; Homepage: <a href=https://eckertzhang.github.io/Text2NeRF.github.io/>this https URL</a> Code:<a href=https://github.com/eckertzhang/Text2NeRF>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.12095 title=Abstract>arXiv:2305.12095</a> (replaced) [<a href=https://arxiv.org/pdf/2305.12095 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.12095 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+W">Wang Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+T">Tian Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jinyang Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+B">Bolin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14205 title=Abstract>arXiv:2305.14205</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-445 style=width:0.743em;display:inline-block><span style=display:inline-block;position:relative;width:0.604em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.6em,2.317em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-446><span class=texatom id=MathJax-Span-447><span class=mrow id=MathJax-Span-448><span class=mo id=MathJax-Span-449 style=font-family:MathJax_Math-italic></span></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.331em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span>PLAN: Summarizing using a Content Plan as Cross-Lingual Bridge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huot%2C+F">Fantine Huot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maynez%2C+J">Joshua Maynez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alberti%2C+C">Chris Alberti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amplayo%2C+R+K">Reinald Kim Amplayo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agrawal%2C+P">Priyanka Agrawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fierro%2C+C">Constanza Fierro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayan%2C+S">Shashi Narayan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14297 title=Abstract>arXiv:2305.14297</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14297 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14297 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Order conditions for Runge--Kutta-like methods with solution-dependent coefficients
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Izgin%2C+T">Thomas Izgin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ketcheson%2C+D+I">David I. Ketcheson</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meister%2C+A">Andreas Meister</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.14341 title=Abstract>arXiv:2305.14341</a> (replaced) [<a href=https://arxiv.org/pdf/2305.14341 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.14341 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> APPLS: Evaluating Evaluation Metrics for Plain Language Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yue Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=August%2C+T">Tal August</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leroy%2C+G">Gondy Leroy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+T">Trevor Cohen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L+L">Lucy Lu Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15002 title=Abstract>arXiv:2305.15002</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15002 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15002 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A RelEntLess Benchmark for Modelling Graded Relations between Named Entities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ushio%2C+A">Asahi Ushio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Collados%2C+J+C">Jose Camacho Collados</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 main conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.17323 title=Abstract>arXiv:2305.17323</a> (replaced) [<a href=https://arxiv.org/pdf/2305.17323 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.17323 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Some Primal-Dual Theory for Subgradient Methods for Strongly Convex Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Grimmer%2C+B">Benjamin Grimmer</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+D">Danlin Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, major revision shortened the write-up and unified the analysis to be done just once in a single "super" setting
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.04910 title=Abstract>arXiv:2306.04910</a> (replaced) [<a href=https://arxiv.org/pdf/2306.04910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.04910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Transferability Metric Using Scene Similarity and Local Map Observation for DRL Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+S">Shiwei Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+F">Feitian Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.05658 title=Abstract>arXiv:2306.05658</a> (replaced) [<a href=https://arxiv.org/pdf/2306.05658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.05658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GMS-3DQA: Projection-based Grid Mini-patch Sampling for 3D Model Quality Assessment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Wei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Houning Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yingjie Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Min%2C+X">Xiongkuo Min</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+W">Weisi Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.08915 title=Abstract>arXiv:2306.08915</a> (replaced) [<a href=https://arxiv.org/pdf/2306.08915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.08915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt Performance Prediction for Image Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bizzozzero%2C+N">Nicolas Bizzozzero</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bendidi%2C+I">Ihab Bendidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Risser-Maroix%2C+O">Olivier Risser-Maroix</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09882 title=Abstract>arXiv:2306.09882</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09882 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09882 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xinke Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xianghui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jiayuan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiaowei Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In proceeding of CIKM 2023. Doi: <a href=https://dl.acm.org/doi/10.1145/3583780.3615215>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML); Other Statistics (stat.OT)
</div>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.11643 title=Abstract>arXiv:2306.11643</a> (replaced) [<a href=https://arxiv.org/pdf/2306.11643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.11643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Cross-Layer Interactions of QUIC, Encrypted DNS and HTTP/3: Design, Evaluation and Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sengupta%2C+J">Jayasree Sengupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kosek%2C+M">Mike Kosek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fries%2C+J">Justus Fries</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferlin%2C+S">Simone Ferlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dikshit%2C+P">Pratyush Dikshit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bajpai%2C+V">Vaibhav Bajpai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 12 figures and 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00162 title=Abstract>arXiv:2307.00162</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00162 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.00162 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What Do Self-Supervised Speech Models Know About Words?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pasad%2C+A">Ankita Pasad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chien%2C+C">Chung-Ming Chien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Settle%2C+S">Shane Settle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Livescu%2C+K">Karen Livescu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Pre-MIT Press publication version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.01406 title=Abstract>arXiv:2307.01406</a> (replaced) [<a href=https://arxiv.org/pdf/2307.01406 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.01406 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance metrics for the continuous distribution of entanglement in multi-user quantum networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=I%C3%B1esta%2C+%C3%81+G">lvaro G. Iesta</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wehner%2C+S">Stephanie Wehner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages with 7 figures (main text); 13 pages appendix with 7 figures. v2: minor improvements to readability, corrected typos
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Physical Review A 108.5 (2023): 052615
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.02096 title=Abstract>arXiv:2307.02096</a> (replaced) [<a href=https://arxiv.org/pdf/2307.02096 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.02096 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive multi-stage integration schemes for Hamiltonian Monte Carlo
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nagar%2C+L">Lorenzo Nagar</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Fern%C3%A1ndez-Pend%C3%A1s%2C+M">Mario Fernndez-Pends</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sanz-Serna%2C+J+M">Jess Mara Sanz-Serna</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Akhmatskaya%2C+E">Elena Akhmatskaya</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of Computational Physics, Volume 502, 1 April 2024, 112800
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation (stat.CO)</span>; Numerical Analysis (math.NA); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.05318 title=Abstract>arXiv:2307.05318</a> (replaced) [<a href=https://arxiv.org/pdf/2307.05318 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.05318 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Predicting small molecules solubilities on endpoint devices using deep ensemble neural networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ramos%2C+M+C">Mayk Caldas Ramos</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=White%2C+A+D">Andrew D. White</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.06555 title=Abstract>arXiv:2307.06555</a> (replaced) [<a href=https://arxiv.org/pdf/2307.06555 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.06555 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Network Approximation: Beyond ReLU to Diverse Activation Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shijun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hongkai Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.08202 title=Abstract>arXiv:2307.08202</a> (replaced) [<a href=https://arxiv.org/pdf/2307.08202 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.08202 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Next-Generation Urban Connectivity: Is the Integrated HAPS-Terrestrial Network a Solution?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shamsabadi%2C+A+A">Afsoon Alidadi Shamsabadi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yadav%2C+A">Animesh Yadav</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages singlecolumn, 4 figures, under review in IEEE Communications Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.08775 title=Abstract>arXiv:2307.08775</a> (replaced) [<a href=https://arxiv.org/pdf/2307.08775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.08775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yining Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Haoping Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khashabi%2C+D">Daniel Khashabi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.10895 title=Abstract>arXiv:2307.10895</a> (replaced) [<a href=https://arxiv.org/pdf/2307.10895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.10895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variational Autoencoding of Dental Point Clouds
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J+Z">Johan Ziruo Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%98rkild%2C+T">Thomas rkild</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=S%C3%B8ndergaard%2C+P+L">Peter Lempel Sndergaard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hauberg%2C+S">Sren Hauberg</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.12445 title=Abstract>arXiv:2307.12445</a> (replaced) [<a href=https://arxiv.org/pdf/2307.12445 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.12445 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SCRAPS: Speech Contrastive Representations of Acoustic and Phonetic Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vall%C3%A9s-P%C3%A9rez%2C+I">Ivan Valls-Prez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beringer%2C+G">Grzegorz Beringer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilinski%2C+P">Piotr Bilinski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cook%2C+G">Gary Cook</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barra-Chicote%2C+R">Roberto Barra-Chicote</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In proceedings of the 26th European Conference on Artificial Intelligence ECAI 2023. 8 pages + 1 appendix page
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.14383 title=Abstract>arXiv:2307.14383</a> (replaced) [<a href=https://arxiv.org/pdf/2307.14383 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.14383 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Large-Scale Feasibility Study of Screen-based 3D Visualization and Augmented Reality Tools for Human Anatomy Education: Exploring Gender Perspectives in Learning Experience
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barmaki%2C+R+L">Roghayeh Leila Barmaki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K">Kangsoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Zhang Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qile Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+K">Kevin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pearlman%2C+R">Rebecca Pearlman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work is accepted and presented at IEEE International Conference on Artificial Intelligence &amp; extended and Virtual Reality (AIxVR 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.15176 title=Abstract>arXiv:2307.15176</a> (replaced) [<a href=https://arxiv.org/pdf/2307.15176 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.15176 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RCT Rejection Sampling for Causal Estimation Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keith%2C+K+A">Katherine A. Keith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feldman%2C+S">Sergey Feldman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jurgens%2C+D">David Jurgens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bragg%2C+J">Jonathan Bragg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya%2C+R">Rohit Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and data at <a href=https://github.com/kakeith/rct_rejection_sampling>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Transactions on Machine Learning Research (TMLR) 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.02126 title=Abstract>arXiv:2308.02126</a> (replaced) [<a href=https://arxiv.org/pdf/2308.02126 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.02126 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cognitive TransFuser: Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+H">Hwan-Soo Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+J">Jongoh Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+Y+H">Young Hoo Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+K">Kuk-Jin Yoon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jong-Hwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to RiTA 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.04836 title=Abstract>arXiv:2308.04836</a> (replaced) [<a href=https://arxiv.org/pdf/2308.04836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.04836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Surprise: Improving Exploration Through Surprise Novelty
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+H">Hung Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Do%2C+K">Kien Do</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+D">Dung Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venkatesh%2C+S">Svetha Venkatesh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages including Appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.07490 title=Abstract>arXiv:2308.07490</a> (replaced) [<a href=https://arxiv.org/pdf/2308.07490 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.07490 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BSED: Baseline Shapley-Based Explainable Detector
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuroki%2C+M">Michihiro Kuroki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamasaki%2C+T">Toshihiko Yamasaki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09997 title=Abstract>arXiv:2308.09997</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09997 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09997 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Additive Schwarz methods for semilinear elliptic problems with convex energy functionals: Convergence rate independent of nonlinearity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Park%2C+J">Jongho Park</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.11199 title=Abstract>arXiv:2308.11199</a> (replaced) [<a href=https://arxiv.org/pdf/2308.11199 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.11199 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ConcatPlexer: Additional Dim1 Batching for Faster ViTs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+D">Donghoon Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seo%2C+S">Seunghyeon Seo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon%2C+D">Donghyeon Jeon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+J">Jiho Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+C">Chaerin Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.11234 title=Abstract>arXiv:2308.11234</a> (replaced) [<a href=https://arxiv.org/pdf/2308.11234 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.11234 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhe Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Harabor%2C+D">Daniel Harabor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiaoyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stuckey%2C+P+J">Peter J. Stuckey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper was accepted for publication at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.12459 title=Abstract>arXiv:2308.12459</a> (replaced) [<a href=https://arxiv.org/pdf/2308.12459 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.12459 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistent Signal Reconstruction from Streaming Multivariate Time Series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruiz-Moreno%2C+E">Emilio Ruiz-Moreno</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=L%C3%B3pez-Ramos%2C+L+M">Luis Miguel Lpez-Ramos</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Beferull-Lozano%2C+B">Baltasar Beferull-Lozano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.12612 title=Abstract>arXiv:2308.12612</a> (replaced) [<a href=https://arxiv.org/pdf/2308.12612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.12612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Try with Simpler -- An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Junjie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+S">Shutao Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+Z">Zhihao Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+Y">Yue Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Huaan Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by TOSEM
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13282 title=Abstract>arXiv:2308.13282</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13282 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13282 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancing Distributed AC Optimal Power Flow for Integrated Transmission-Distribution Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dai%2C+X">Xinliang Dai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhai%2C+J">Junyi Zhai</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang%2C+Y">Yuning Jiang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+Y">Yi Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jones%2C+C+N">Colin N. Jones</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hagenmeyer%2C+V">Veit Hagenmeyer</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.13352 title=Abstract>arXiv:2308.13352</a> (replaced) [<a href=https://arxiv.org/pdf/2308.13352 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.13352 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Generic Machine Learning Framework for Fully-Unsupervised Anomaly Detection with Contaminated Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulmer%2C+M">Markus Ulmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zgraggen%2C+J">Jannik Zgraggen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huber%2C+L+G">Lilach Goren Huber</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00344 title=Abstract>arXiv:2309.00344</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00344 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.00344 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.00344 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Complete Dependency Pair Framework for Almost-Sure Innermost Termination of Probabilistic Term Rewriting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kassing%2C+J">Jan-Christoph Kassing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dollase%2C+S">Stefan Dollase</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Giesl%2C+J">Jrgen Giesl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2305.11741>arXiv:2305.11741</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02169 title=Abstract>arXiv:2309.02169</a> (replaced) [<a href=https://arxiv.org/e-print/2309.02169 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual Relation Alignment for Composed Image Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xintong Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaxiong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yujiao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+X">Xueming Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The architecture of our model changes, hence methodolgy and experiments changes a lot, We have significantly revised the original manuscript of the paper, so a withdraw of our original script is needed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.03160 title=Abstract>arXiv:2309.03160</a> (replaced) [<a href=https://arxiv.org/pdf/2309.03160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.03160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ResFields: Residual Neural Fields for Spatiotemporal Signals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mihajlovic%2C+M">Marko Mihajlovic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prokudin%2C+S">Sergey Prokudin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> [ICLR 2024 Spotlight] Project and code at: <a href=https://markomih.github.io/ResFields/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05930 title=Abstract>arXiv:2309.05930</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05930 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05930 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combining Deep Learning and Street View Imagery to Map Smallholder Crop Types
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soler%2C+J+L">Jordi Laguarta Soler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friedel%2C+T">Thomas Friedel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sherrie Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to AAAI-24: Special Track on AI for Social Impact
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08648 title=Abstract>arXiv:2309.08648</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MAPLE: Mobile App Prediction Leveraging Large Language Model Embeddings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaokaew%2C+Y">Yonchanok Khaokaew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+H">Hao Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08929 title=Abstract>arXiv:2309.08929</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+K">Kaiyan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Q">Qiyu Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+X">Xin-Qiang Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsuruoka%2C+Y">Yoshimasa Tsuruoka</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024, main conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08958 title=Abstract>arXiv:2309.08958</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08958 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08958 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pinzhen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bogoychev%2C+N">Nikolay Bogoychev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutuzov%2C+A">Andrey Kutuzov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddow%2C+B">Barry Haddow</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heafield%2C+K">Kenneth Heafield</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to Findings of ACL: EACL 2024. Added human evaluation and shortened writing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.10896 title=Abstract>arXiv:2309.10896</a> (replaced) [<a href=https://arxiv.org/pdf/2309.10896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.10896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PLVS: A SLAM System with Points, Lines, Volumetric Mapping, and 3D Incremental Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freda%2C+L">Luigi Freda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12862 title=Abstract>arXiv:2309.12862</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12862 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12862 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Associative Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuwei Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ochiai%2C+H">Hideya Ochiai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhirong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S">Stephen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanai%2C+R">Ryota Kanai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.14150 title=Abstract>arXiv:2309.14150</a> (replaced) [<a href=https://arxiv.org/pdf/2309.14150 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.14150 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learned Contextual LiDAR Informed Visual Search in Unseen Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta%2C+R">Ryan Gupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morgenstein%2C+K">Kyle Morgenstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ortega%2C+S">Steven Ortega</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sentis%2C+L">Luis Sentis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages + references. 6 figures. 1 algorithm. 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15375 title=Abstract>arXiv:2309.15375</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15375 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15375 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PPG-to-ECG Signal Translation for Continuous Atrial Fibrillation Detection via Attention-based Deep State-Space Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vo%2C+K">Khuong Vo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Khamy%2C+M">Mostafa El-Khamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yoojin Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.15589 title=Abstract>arXiv:2309.15589</a> (replaced) [<a href=https://arxiv.org/pdf/2309.15589 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.15589 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Domain generalization across tumor types, laboratories, and species -- insights from the 2022 edition of the Mitosis Domain Generalization Challenge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stathonikos%2C+N">Nikolas Stathonikos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Donovan%2C+T+A">Taryn A. Donovan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Klopfleisch%2C+R">Robert Klopfleisch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganz%2C+J">Jonathan Ganz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ammeling%2C+J">Jonas Ammeling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilm%2C+F">Frauke Wilm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Veta%2C+M">Mitko Veta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jabari%2C+S">Samir Jabari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eckstein%2C+M">Markus Eckstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Annuscheit%2C+J">Jonas Annuscheit</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krumnow%2C+C">Christian Krumnow</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bozaba%2C+E">Engin Bozaba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cayir%2C+S">Sercan Cayir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+H">Hongyan Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X+%27">Xiang 'Anthony' Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jahanifar%2C+M">Mostafa Jahanifar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shephard%2C+A">Adam Shephard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kondo%2C+S">Satoshi Kondo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasai%2C+S">Satoshi Kasai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kotte%2C+S">Sujatha Kotte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saipradeep%2C+V">VG Saipradeep</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafarge%2C+M+W">Maxime W. Lafarge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koelzer%2C+V+H">Viktor H. Koelzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongbing Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Sen Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bertram%2C+C+A">Christof A. Bertram</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.17056 title=Abstract>arXiv:2309.17056</a> (replaced) [<a href=https://arxiv.org/pdf/2309.17056 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.17056 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReFlow-TTS: A Rectified Flow Model for High-fidelity Text-to-Speech
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+W">Wenhao Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Q">Qi Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Haodong Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+S">Shiyu Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xingjia Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICASSP2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00071 title=Abstract>arXiv:2310.00071</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ShOpt.jl: A Julia Package for Empirical Point Spread Function Characterization of JWST NIRCam Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Berman%2C+E">Edward Berman</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=McCleary%2C+J">Jacqueline McCleary</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 3 figures; submitted to the Journal of Open Source Software
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02573 title=Abstract>arXiv:2310.02573</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02573 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02573 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Collision Detection for Robots with Variable Stiffness Actuation by Using MAD-CNN: Modularized-Attention-Dilated Convolutional Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+Z">Zhenwei Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saoud%2C+L+S">Lyes Saad Saoud</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04231 title=Abstract>arXiv:2310.04231</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04231 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04231 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Indoor Positioning based on Active Radar Sensing and Passive Reflectors: Concepts &amp; Initial Results
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlachter%2C+P">Pascal Schlachter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhibin Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iqbal%2C+N">Naveed Iqbal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaofeng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hinderer%2C+S">Sven Hinderer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a work-in-progress paper at the 13th International Conference on Indoor Positioning and Indoor Navigation (IPIN 2023)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Proceedings of the Work-in-Progress Papers at the 13th
 International Conference on Indoor Positioning and Indoor Navigation
 (IPIN-WiP 2023), September 25 - 28, 2023, Nuremberg, Germany
 (https://ceur-ws.org/Vol-3581/)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04267 title=Abstract>arXiv:2310.04267</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.04267 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.04267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Categorical probability spaces, ergodic decompositions, and transitions to equilibrium
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ensarguet%2C+N">No Ensarguet</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Perrone%2C+P">Paolo Perrone</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 51 pages, part of this work appears in the dissertation of the first author submitted towards the degree of MSc in Mathematics and Foundations of Computer Science
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Probability (math.PR)</span>; Logic in Computer Science (cs.LO); Category Theory (math.CT); Dynamical Systems (math.DS)
</div>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04644 title=Abstract>arXiv:2310.04644</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04644 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04644 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural2Speech: A Transfer Learning Framework for Neural-Driven Speech Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiawei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+C">Chunxu Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+L">Li Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+L">Lu Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+E+F">Edward F. Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuanning Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in 2024 IEEE International Conference on Acoustics, Speech and Signal Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Neurons and Cognition (q-bio.NC)
</div>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04645 title=Abstract>arXiv:2310.04645</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Do self-supervised speech and language models extract similar representations as human brain?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chen%2C+P">Peili Chen</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=He%2C+L">Linyang He</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Fu%2C+L">Li Fu</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Fan%2C+L">Lu Fan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Chang%2C+E+F">Edward F. Chang</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Li%2C+Y">Yuanning Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in 2024 IEEE International Conference on Acoustics, Speech and Signal Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.05711 title=Abstract>arXiv:2310.05711</a> (replaced) [<a href=https://arxiv.org/pdf/2310.05711 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.05711 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Expressive Quantale-valued Logics for Coalgebras: an Adjunction-based Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beohar%2C+H">Harsh Beohar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gurke%2C+S">Sebastian Gurke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%B6nig%2C+B">Barbara Knig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Messing%2C+K">Karla Messing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forster%2C+J">Jonas Forster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schr%C3%B6der%2C+L">Lutz Schrder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wild%2C+P">Paul Wild</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.07966 title=Abstract>arXiv:2310.07966</a> (replaced) [<a href=https://arxiv.org/pdf/2310.07966 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.07966 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.07966 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Singular Perturbation via Contraction Theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cothren%2C+L">Liliaokeawawa Cothren</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bullo%2C+F">Francesco Bullo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dall%27Anese%2C+E">Emiliano Dall'Anese</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been submitted to IEEE Transactions on Automatic Control
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.08873 title=Abstract>arXiv:2310.08873</a> (replaced) [<a href=https://arxiv.org/pdf/2310.08873 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.08873 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+A">Anran Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+C+W">Chun Wai Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+X">Xiangyu Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+Q">Qi Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Au%2C+K+W+S">K. W. Samuel Au</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICRA 2024, 7 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09614 title=Abstract>arXiv:2310.09614</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging the Divide: Unraveling the Knowledge Gap in Data Visualization Research and Practice
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+N+W">Nam Wook Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Myers%2C+G">Grace Myers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Jinhan Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+Y">Yoonsuh Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oh%2C+C">Changhoon Oh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yea-Seul Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09617 title=Abstract>arXiv:2310.09617</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09617 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09617 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> How Good is ChatGPT in Giving Advice on Your Visualization Design?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+N+W">Nam Wook Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Myers%2C+G">Grace Myers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bach%2C+B">Benjamin Bach</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.11050 title=Abstract>arXiv:2310.11050</a> (replaced) [<a href=https://arxiv.org/pdf/2310.11050 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.11050 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-450 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.51em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-451><span class=mi id=MathJax-Span-452 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-453 style=width:0.465em;display:inline-block><span style=display:inline-block;position:relative;width:0.373em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.33em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-454><span class=mi id=MathJax-Span-455 style=font-family:MathJax_Math-italic>t</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span> CLAIR: Self-Consistency Guided Multi-Prior Learning for Dynamic Parallel MR Image Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+L">Liping Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+W">Weitian Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 3 figures, 4 tables. CMRxRecon Challenge, MICCAI 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)
</div>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.12096 title=Abstract>arXiv:2310.12096</a> (replaced) [<a href=https://arxiv.org/pdf/2310.12096 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.12096 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vital Edges for (s,t)-mincut: Efficient Algorithms, Compact Structures, and Optimal Sensitivity Oracle
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baswana%2C+S">Surender Baswana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhanja%2C+K">Koustav Bhanja</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 60 pages, 15 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)
</div>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.13139 title=Abstract>arXiv:2310.13139</a> (replaced) [<a href=https://arxiv.org/pdf/2310.13139 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.13139 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.13139 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Neural Networks with polynomial activations have limited expressivity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalife%2C+S">Sammy Khalife</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.13786 title=Abstract>arXiv:2310.13786</a> (replaced) [<a href=https://arxiv.org/pdf/2310.13786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.13786 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.13786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fundamental Limits of Membership Inference Attacks on Machine Learning Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Aubinais%2C+E">Eric Aubinais</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Gassiat%2C+E">Elisabeth Gassiat</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14087 title=Abstract>arXiv:2310.14087</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14087 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.14087 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Specialized Semismooth Newton Method for Kernel-Based Optimal Transport
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+T">Tianyi Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cuturi%2C+M">Marco Cuturi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AISTATS 2024; Fix some inaccuracy in the definition and proof; 24 pages, 36 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.16592 title=Abstract>arXiv:2310.16592</a> (replaced) [<a href=https://arxiv.org/pdf/2310.16592 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.16592 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Over-the-air Federated Policy Gradient
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Huiwen Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Lingying Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at IEEE ICC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.19413 title=Abstract>arXiv:2310.19413</a> (replaced) [<a href=https://arxiv.org/pdf/2310.19413 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.19413 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CARPE-ID: Continuously Adaptable Re-identification for Personalized Robot Assistance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rollo%2C+F">Federico Rollo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zunino%2C+A">Andrea Zunino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsagarakis%2C+N">Nikolaos Tsagarakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoffman%2C+E+M">Enrico Mingo Hoffman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ajoudani%2C+A">Arash Ajoudani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.19620 title=Abstract>arXiv:2310.19620</a> (replaced) [<a href=https://arxiv.org/pdf/2310.19620 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.19620 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Trajectory Models are Scalable Motion Predictors and Planners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qiao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shiduo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+D">Danjiao Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jingzhe Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Derun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+S">Simian Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+N">Ningyi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+G">Guangzhi Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20381 title=Abstract>arXiv:2310.20381</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20381 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.20381 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Systematic Evaluation of GPT-4V's Multimodal Capability for Medical Image Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yingshu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yunyi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+X">Xinyu Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+L">Leyang Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Longyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.20703 title=Abstract>arXiv:2310.20703</a> (replaced) [<a href=https://arxiv.org/pdf/2310.20703 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.20703 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Vanishing Gradients in Reinforcement Finetuning of Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razin%2C+N">Noam Razin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hattie Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saremi%2C+O">Omid Saremi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thilak%2C+V">Vimal Thilak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bradley%2C+A">Arwen Bradley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakkiran%2C+P">Preetum Nakkiran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Susskind%2C+J">Joshua Susskind</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Littwin%2C+E">Etai Littwin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.01886 title=Abstract>arXiv:2311.01886</a> (replaced) [<a href=https://arxiv.org/pdf/2311.01886 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.01886 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xilai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaosong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+T">Tao Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xiaoqi Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wuyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Haishu Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.03628 title=Abstract>arXiv:2311.03628</a> (replaced) [<a href=https://arxiv.org/pdf/2311.03628 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.03628 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reinforcement Twinning: from digital twins to model-based reinforcement learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schena%2C+L">Lorenzo Schena</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Marques%2C+P">Pedro Marques</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Poletti%2C+R">Romain Poletti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ahizi%2C+S">Samuel Ahizi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Van+den+Berghe%2C+J">Jan Van den Berghe</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mendez%2C+M+A">Miguel A. Mendez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted Journal of Computational Science
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04065 title=Abstract>arXiv:2311.04065</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04065 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04065 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Study of the One-Dimensional Heat-Conduction Equation with Radiation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Halic%2C+M">Mihai Halic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)
</div>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04135 title=Abstract>arXiv:2311.04135</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04135 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04135 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Random Natural Gradient
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kolotouros%2C+I">Ioannis Kolotouros</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wallden%2C+P">Petros Wallden</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 7 figures, v2 minor corrections
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)
</div>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04788 title=Abstract>arXiv:2311.04788</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04788 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04788 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TinyAirNet: TinyML Model Transmission for Energy-efficient Wireless IoT Image Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shiraishi%2C+J">Junya Shiraishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thorsager%2C+M">Mathias Thorsager</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 4 figures, Submitted for possible publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06643 title=Abstract>arXiv:2311.06643</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+B+C">Badhan Chandra Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amini%2C+M+H">M. Hadi Amini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanzhao Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> V1
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09048 title=Abstract>arXiv:2311.09048</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09048 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.09048 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GRASP: A novel benchmark for evaluating language GRounding And Situated Physics understanding in multimodal language models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jassim%2C+S">Serwan Jassim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holubar%2C+M">Mario Holubar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Richter%2C+A">Annika Richter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolff%2C+C">Cornelius Wolff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ohmer%2C+X">Xenia Ohmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruni%2C+E">Elia Bruni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.09452 title=Abstract>arXiv:2311.09452</a> (replaced) [<a href=https://arxiv.org/pdf/2311.09452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.09452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Close the Gates to an Inhuman Future: How and why we should choose to not develop superhuman general-purpose artificial intelligence
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aguirre%2C+A">Anthony Aguirre</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, revised version including new figure and table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11319 title=Abstract>arXiv:2311.11319</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GeoSAM: Fine-tuning SAM with Sparse and Dense Visual Prompting for Automated Segmentation of Mobility Infrastructure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sultan%2C+R+I">Rafi Ibn Sultan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chengyin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khanduri%2C+P">Prashant Khanduri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brocanelli%2C+M">Marco Brocanelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dongxiao Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.12076 title=Abstract>arXiv:2311.12076</a> (replaced) [<a href=https://arxiv.org/pdf/2311.12076 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.12076 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Few-shot Out-of-Distribution Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+J">Jiuqing Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yongbin Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Heng Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cen%2C+J">Jun Cen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yifan Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+S">Sook Yoon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+P+D">Park Dong Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.12831 title=Abstract>arXiv:2311.12831</a> (replaced) [<a href=https://arxiv.org/pdf/2311.12831 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.12831 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ECNR: Efficient Compressive Neural Representation of Time-Varying Volumetric Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+K">Kaiyuan Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaoli Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE PacificVis 2024 (conference papers track)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14097 title=Abstract>arXiv:2311.14097</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ACT: Adversarial Consistency Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+F">Fei Kong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+J">Jinhao Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+H">Hao Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Renjing Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+H">Hengtao Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaoshuang Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K">Kaidi Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.15220 title=Abstract>arXiv:2311.15220</a> (replaced) [<a href=https://arxiv.org/pdf/2311.15220 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2311.15220 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2311.15220 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimum Self Random Number Generation Rate and Its Application to Rate Distortion Perception Function
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nomura%2C+R">Ryo Nomura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.15623 title=Abstract>arXiv:2311.15623</a> (replaced) [<a href=https://arxiv.org/pdf/2311.15623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.15623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Injecting linguistic knowledge into BERT for Dialogue State Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+X">Xiaohan Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xixin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00949 title=Abstract>arXiv:2312.00949</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00949 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.00949 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hyperparameter Optimization for Large Language Model Instruction-Tuning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tribes%2C+C">Christophe Tribes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benarroch-Lelong%2C+S">Sacha Benarroch-Lelong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+P">Peng Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobyzev%2C+I">Ivan Kobyzev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03863 title=Abstract>arXiv:2312.03863</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03863 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03863 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Large Language Models: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Z">Zhongwei Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Che Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alam%2C+S">Samiul Alam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiachen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+Z">Zhongnan Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+S">Shen Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Quanlu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+M">Mosharaf Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Version 3: Added more latest papers
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06353 title=Abstract>arXiv:2312.06353</a> (replaced) [<a href=https://arxiv.org/pdf/2312.06353 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.06353 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zhen Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+B">Bingchen Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+B">Bolin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaliang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Codes are available at <a href=https://github.com/alibaba/FederatedScope/tree/FedKSeed.>this https URL</a> We will continuously update the codebase and arXiv version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.06712 title=Abstract>arXiv:2312.06712</a> (replaced) [<a href=https://arxiv.org/pdf/2312.06712 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.06712 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Separate-and-Enhance: Compositional Finetuning for Text2Image Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhipeng Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yijun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+K+K">Krishna Kumar Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu-Xiong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hebert%2C+M">Martial Hebert</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.10687 title=Abstract>arXiv:2312.10687</a> (replaced) [<a href=https://arxiv.org/pdf/2312.10687 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.10687 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MM-TTS: Multi-modal Prompt based Style Transfer for Expressive Text-to-Speech Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guan%2C+W">Wenhao Guan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+Y">Yishuang Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+T">Tao Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+H">Hukai Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+F">Feng Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lin%2C+J">Jiayan Lin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huang%2C+L">Lingyan Huang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+L">Lin Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11678 title=Abstract>arXiv:2312.11678</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11678 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11678 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Misinformation as a harm: structured approaches for fact-checking prioritization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sehat%2C+C+M">Connie Moon Sehat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Ryan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+P">Peipei Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prabhakar%2C+T">Tarunima Prabhakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to CSCW 2024, with clean up for typos and figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12431 title=Abstract>arXiv:2312.12431</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12431 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12431 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Inference Stability for Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+V">Viet Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+G">Giang Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thanh%2C+T+N">Tung Nguyen Thanh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Than%2C+K">Khoat Than</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+T">Toan Tran</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Oral presentation at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12784 title=Abstract>arXiv:2312.12784</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Cell Library Characterization for Design Technology Co-Optimization Based on Graph Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+T">Tianliang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zhihui Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xuguang Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+L">Leilai Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Low%2C+K">Kainlu Low</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12846 title=Abstract>arXiv:2312.12846</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12846 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.12846 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.12846 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-456 style=width:1.669em;display:inline-block><span style=display:inline-block;position:relative;width:1.391em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.049em,1001.39em,1.16em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-457><span class=msubsup id=MathJax-Span-458><span style=display:inline-block;position:relative;width:1.391em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.88em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mi id=MathJax-Span-459 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.049em></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.35em;left:0.975em><span class=mn id=MathJax-Span-460 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:1.114em"></span></span></nobr></span>-analysis of H3N3-2\textbf{<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-461 style=width:0.558em;display:inline-block><span style=display:inline-block;position:relative;width:0.465em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.743em,1000.47em,1.299em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-462><span class=msubsup id=MathJax-Span-463><span style=display:inline-block;position:relative;width:0.465em;height:0px><span style=position:absolute;clip:rect(3.845em,1000em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mi id=MathJax-Span-464></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-3.84em;left:0em><span class=texatom id=MathJax-Span-465><span class=mrow id=MathJax-Span-466><span class=mo id=MathJax-Span-467 style=font-size:70.7%;font-family:MathJax_Math-italic></span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.219em;border-left:0px solid;width:0px;height:0.503em"></span></span></nobr></span>}-based difference method for fractional hyperbolic equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Du%2C+R">Rui-lian Du</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+C">Changpin Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sun%2C+Z">Zhi-zhong Sun</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)
</div>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16193 title=Abstract>arXiv:2312.16193</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-border Exchange of CBDCs using Layer-2 Blockchain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gogol%2C+K">Krzysztof Gogol</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Messias%2C+J">Johnnatan Messias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlosser%2C+M">Malte Schlosser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kraner%2C+B">Benjamin Kraner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tessone%2C+C">Claudio Tessone</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper was presented at the Crypto Finance Conference (CfC) Academic Track 2024 in St. Moritz, Switzerland
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16699 title=Abstract>arXiv:2312.16699</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computational Tradeoffs of Optimization-Based Bound Tightening in ReLU Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Badilla%2C+F">Fabian Badilla</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Goycoolea%2C+M">Marcos Goycoolea</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mu%C3%B1oz%2C+G">Gonzalo Muoz</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Serra%2C+T">Thiago Serra</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17019 title=Abstract>arXiv:2312.17019</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Learning of Long-Range and Equivariant Quantum Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=%C5%A0m%C3%ADd%2C+%C5%A0">tpn md</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Bondesan%2C+R">Roberto Bondesan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 51 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00028 title=Abstract>arXiv:2401.00028</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00028 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00028 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Empirical Study of Scaling Law for OCR
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rang%2C+M">Miao Rang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+Z">Zhenni Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chuanjian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+K">Kai Han</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00819 title=Abstract>arXiv:2401.00819</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D Beamforming Through Joint Phase-Time Arrays
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yildiz%2C+O">Ozlem Yildiz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=AlAmmouri%2C+A">Ahmad AlAmmouri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+J">Jianhua Mo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+Y">Younghan Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erkip%2C+E">Elza Erkip</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jianzhong">Jianzhong</a> (Charlie)
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang">Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.01145 title=Abstract>arXiv:2401.01145</a> (replaced) [<a href=https://arxiv.org/pdf/2401.01145 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.01145 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HAAQI-Net: A non-intrusive neural music quality assessment model for hearing aids
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wisnu%2C+D+A+M+G">Dyah A. M. G. Wisnu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pratiwi%2C+E+W">Epri W. Pratiwi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rini%2C+S">Stefano Rini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zezario%2C+R+E">Ryandhimas E. Zezario</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.03811 title=Abstract>arXiv:2401.03811</a> (replaced) [<a href=https://arxiv.org/pdf/2401.03811 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.03811 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Complexity of Simplifying <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-468 style=width:0.743em;display:inline-block><span style=display:inline-block;position:relative;width:0.604em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.6em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-469><span class=texatom id=MathJax-Span-470><span class=mrow id=MathJax-Span-471><span class=mo id=MathJax-Span-472 style=font-family:MathJax_Math-italic></span></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.669em"></span></span></nobr></span>-Automata through the Alternating Cycle Decomposition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casares%2C+A">Antonio Casares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mascle%2C+C">Corto Mascle</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> v2: Results updated to apply to both automata with single and multiple colours per transition
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04286 title=Abstract>arXiv:2401.04286</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04286 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.04286 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.04286 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ko%2C+H">Hyunouk Ko</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Huo%2C+X">Xiaoming Huo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06550 title=Abstract>arXiv:2401.06550</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06550 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.06550 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.06550 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multimodal Urban Areas of Interest Generation via Remote Sensing Imagery and Geographical Prior
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+C">Chuanji Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaotuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xin Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qiqi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06633 title=Abstract>arXiv:2401.06633</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06633 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06633 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+J">Jianxun Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, Accepted to AAAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06657 title=Abstract>arXiv:2401.06657</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating Tactile Internet with QUIC: A Security and Privacy Perspective
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sengupta%2C+J">Jayasree Sengupta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dey%2C+D">Debasmita Dey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferlin%2C+S">Simone Ferlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghosh%2C+N">Nirnay Ghosh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bajpai%2C+V">Vaibhav Bajpai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 3 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07031 title=Abstract>arXiv:2401.07031</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07031 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07031 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Code Security Vulnerability Repair Using Reinforcement Learning with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+N+T">Nafis Tanveer Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karkevandi%2C+M+B">Mohammad Bahrami Karkevandi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07518 title=Abstract>arXiv:2401.07518</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07518 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07518 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xinyuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+H">Hanyue Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+X">Xuesong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+M">Ming Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+W">Weining Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A">Aoying Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08357 title=Abstract>arXiv:2401.08357</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08357 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08357 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xilai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaosong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+H">Haishu Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jinyang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08404 title=Abstract>arXiv:2401.08404</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08404 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.08404 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.08404 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Training and Comparison of nnU-Net and DeepMedic Methods for Autosegmentation of Pediatric Brain Tumors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Vossough%2C+A">Arastoo Vossough</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Khalili%2C+N">Nastaran Khalili</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Familiar%2C+A+M">Ariana M. Familiar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gandhi%2C+D">Deep Gandhi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Viswanathan%2C+K">Karthik Viswanathan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tu%2C+W">Wenxin Tu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haldar%2C+D">Debanjan Haldar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bagheri%2C+S">Sina Bagheri</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Anderson%2C+H">Hannah Anderson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haldar%2C+S">Shuvanjan Haldar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Storm%2C+P+B">Phillip B. Storm</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Resnick%2C+A">Adam Resnick</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ware%2C+J+B">Jeffrey B. Ware</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nabavizadeh%2C+A">Ali Nabavizadeh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kazerooni%2C+A+F">Anahita Fathi Kazerooni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)
</div>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08694 title=Abstract>arXiv:2401.08694</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivera%2C+M">Mauricio Rivera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Godbout%2C+J">Jean-Franois Godbout</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rabbany%2C+R">Reihaneh Rabbany</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelrine%2C+K">Kellin Pelrine</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09742 title=Abstract>arXiv:2401.09742</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09742 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09742 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Image Translation as Diffusion Visual Programmers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+C">Cheng Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+J+C">James C. Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qifan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rabbani%2C+M">Majid Rabbani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dianat%2C+S">Sohail Dianat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+R">Raghuveer Rao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y+N">Ying Nian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+D">Dongfang Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 20 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10623 title=Abstract>arXiv:2401.10623</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Maass%2C+W">Wolfgang Maass</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Agrawal%2C+A">Ankit Agrawal</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ciani%2C+A">Alessandro Ciani</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Danz%2C+S">Sven Danz</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Delgadillo%2C+A">Alejandro Delgadillo</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Ganser%2C+P">Philipp Ganser</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kienast%2C+P">Pascal Kienast</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kulig%2C+M">Marco Kulig</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=K%C3%B6nig%2C+V">Valentina Knig</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Rodellas-Gr%C3%A0cia%2C+N">Nil Rodellas-Grcia</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Rughubar%2C+R">Rivan Rughubar</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Schr%C3%B6der%2C+S">Stefan Schrder</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Stautner%2C+M">Marc Stautner</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Stein%2C+H">Hannah Stein</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Stollenwerk%2C+T">Tobias Stollenwerk</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Zeuch%2C+D">Daniel Zeuch</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Wilhelm%2C+F+K">Frank K. Wilhelm</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 3 figures. Added references, corrected affiliations
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11143 title=Abstract>arXiv:2401.11143</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioannides%2C+G">Georgios Ioannides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chadha%2C+A">Aman Chadha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elkins%2C+A">Aaron Elkins</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11160 title=Abstract>arXiv:2401.11160</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.11160 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.11160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quasi-Perfect and Distance-Optimal Codes in the Sum-Rank Metric
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, only quasi-perfect sum codes constructed
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11166 title=Abstract>arXiv:2401.11166</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11166 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11166 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ChatGPT in the classroom. Exploring its potential and limitations in a Functional Programming course
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popovici%2C+D">Dan-Matei Popovici</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Journal of Human-Computer Interaction, 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11395 title=Abstract>arXiv:2401.11395</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11395 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11395 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with Fine-Grained Feature Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Q">Qingdong He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+J">Jinlong Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhengkai Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+K">Kai Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+X">Xiaozhong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yunsheng Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11415 title=Abstract>arXiv:2401.11415</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11415 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11415 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 11 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11864 title=Abstract>arXiv:2401.11864</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11864 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11864 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Small Language Models' Mathematical Reasoning via Equation-of-Thought Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xunyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Can Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weiping Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12292 title=Abstract>arXiv:2401.12292</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GRATH: Gradual Self-Truthifying for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Weixin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+D">Dawn Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12799 title=Abstract>arXiv:2401.12799</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12799 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.12799 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.12799 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Some convergence analysis for multicontinuum homogenization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leung%2C+W+T">Wing Tat Leung</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13156 title=Abstract>arXiv:2401.13156</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13156 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13156 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local Hamiltonian decomposition and classical simulation of parametrized quantum circuits
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Adhikari%2C+B">Bibhas Adhikari</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Jha%2C+A">Aryan Jha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Symbolic Computation (cs.SC)
</div>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13192 title=Abstract>arXiv:2401.13192</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13192 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.13192 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.13192 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhelin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mrad%2C+R">Rami Mrad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+R">Runxian Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+G">Guan Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+J">Jun Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+S">Shibing Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuanping Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> I have submitted to a journal
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
</div>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13554 title=Abstract>arXiv:2401.13554</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13554 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13554 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PanAf20K: A Large Video Dataset for Wild Ape Detection and Behaviour Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brookes%2C+O">Otto Brookes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirmehdi%2C+M">Majid Mirmehdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stephens%2C+C">Colleen Stephens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Angedakin%2C+S">Samuel Angedakin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corogenes%2C+K">Katherine Corogenes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dowd%2C+D">Dervla Dowd</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dieguez%2C+P">Paula Dieguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hicks%2C+T+C">Thurston C. Hicks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jones%2C+S">Sorrel Jones</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K">Kevin Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leinert%2C+V">Vera Leinert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lapuente%2C+J">Juan Lapuente</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McCarthy%2C+M+S">Maureen S. McCarthy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meier%2C+A">Amelia Meier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murai%2C+M">Mizuki Murai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Normand%2C+E">Emmanuelle Normand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vergnes%2C+V">Virginie Vergnes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wessling%2C+E+G">Erin G. Wessling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wittig%2C+R+M">Roman M. Wittig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langergraber%2C+K">Kevin Langergraber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maldonado%2C+N">Nuria Maldonado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zuberbuhler%2C+K">Klaus Zuberbuhler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boesch%2C+C">Christophe Boesch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arandjelovic%2C+M">Mimi Arandjelovic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuhl%2C+H">Hjalmar Kuhl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burghardt%2C+T">Tilo Burghardt</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at IJCV
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14203 title=Abstract>arXiv:2401.14203</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Statistical Characterization of RIS-assisted UAV Communications in Terrestrial and Non-Terrestrial Networks Under Channel Aging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nguyen%2C+T+L">Thanh Luan Nguyen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kaddoum%2C+G">Georges Kaddoum</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Do%2C+T+N">Tri Nhu Do</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Haas%2C+Z+J">Zygmunt J. Haas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 3 figures and 7 subfigures, IEEE ICC'24 (Revision)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14278 title=Abstract>arXiv:2401.14278</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14278 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14278 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CHIRON: Accelerating Node Synchronization without Security Trade-offs in Distributed Ledgers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neiheiser%2C+R">Ray Neiheiser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babaei%2C+A">Arman Babaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexopoulos%2C+G">Giannis Alexopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kogias%2C+M">Marios Kogias</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kogias%2C+E+K">Eleftherios Kokoris Kogias</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14440 title=Abstract>arXiv:2401.14440</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14440 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14440 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arakelyan%2C+E">Erik Arakelyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhaoqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Augenstein%2C+I">Isabelle Augenstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14442 title=Abstract>arXiv:2401.14442</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14442 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14442 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Antibody Humanness Prediction using Patent Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ucar%2C+T">Talip Ucar</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ramon%2C+A">Aubin Ramon</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Oglic%2C+D">Dino Oglic</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Croasdale-Wood%2C+R">Rebecca Croasdale-Wood</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Diethe%2C+T">Tom Diethe</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sormanni%2C+P">Pietro Sormanni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 6 figures, Code: <a href=https://github.com/AstraZeneca/SelfPAD>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14489 title=Abstract>arXiv:2401.14489</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14489 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14489 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Case for Co-Designing Model Architectures with Hardware
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anthony%2C+Q">Quentin Anthony</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hatef%2C+J">Jacob Hatef</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narayanan%2C+D">Deepak Narayanan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Biderman%2C+S">Stella Biderman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bekman%2C+S">Stas Bekman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+J">Junqi Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shafi%2C+A">Aamir Shafi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Subramoni%2C+H">Hari Subramoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panda%2C+D">Dhabaleswar Panda</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14527 title=Abstract>arXiv:2401.14527</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14527 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14527 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsealing the secrets of blockchain consensus: A systematic comparison of the formal security of proof-of-work and proof-of-stake
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%81lvarez%2C+I+A">Ivn Abelln lvarez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gramlich%2C+V">Vincent Gramlich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sedlmeir%2C+J">Johannes Sedlmeir</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in the Decentralized Applications with Blockchain, DLT, and Crypto-Currencies track at ACM/SIGAPP SAC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14577 title=Abstract>arXiv:2401.14577</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14577 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14577 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Algorithm for Streaming Differentially Private Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+G">Girish Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Strohmer%2C+T">Thomas Strohmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vershynin%2C+R">Roman Vershynin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14613 title=Abstract>arXiv:2401.14613</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14613 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiplayer General Lotto game
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+B">Bonan Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+W">Weiran Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zihe Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14678 title=Abstract>arXiv:2401.14678</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14678 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14678 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt-enhanced Federated Content Representation Learning for Cross-domain Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+L">Lei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Ziang Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Junliang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hung%2C+N+Q+V">Nguyen Quoc Viet Hung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 3 figures, accepted by WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14718 title=Abstract>arXiv:2401.14718</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14718 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14718 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Survey on Video Prediction: From Deterministic to Generative Approaches
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ming%2C+R">Ruibo Ming</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhewei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+Z">Zhuoxuan Ju</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jianming Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+L">Lihui Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+S">Shuchang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15289 title=Abstract>arXiv:2401.15289</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15289 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15289 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Where's the "up"?! A Comprehensive (bottom-up) Study on the Security of Arm Cortex-M Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+X">Xi Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zheyuan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinto%2C+S">Sandro Pinto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+L">Le Guan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+N">Ning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jun Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhiqiang Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H">Hongxin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Ziming Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)
</div>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15292 title=Abstract>arXiv:2401.15292</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15292 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15292 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Block Sparse Regularization under Arbitrary Linear Transform
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furuhashi%2C+T">Takanobu Furuhashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hontani%2C+H">Hidekata Hontani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yokota%2C+T">Tatsuya Yokota</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15294 title=Abstract>arXiv:2401.15294</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15294 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15294 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15294 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integral Operator Approaches for Scattered Data Fitting on Spheres
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin%2C+S">Shao-Bo Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15378 title=Abstract>arXiv:2401.15378</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15378 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15378 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15378 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alan%2C+A+Y">Ahmet Yusuf Alan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karaarslan%2C+E">Enis Karaarslan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aydin%2C+%C3%96">mer Aydin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15443 title=Abstract>arXiv:2401.15443</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiffuserLite: Towards Real-time Diffusion Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zibin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+J">Jianye Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yifu Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+F">Fei Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yitian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Pengyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yan Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15456 title=Abstract>arXiv:2401.15456</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15456 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15456 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15456 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Product Mixing in Compact Lie Groups
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ellis%2C+D">David Ellis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kindler%2C+G">Guy Kindler</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lifshitz%2C+N">Noam Lifshitz</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 96 pages. Minor corrections
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Group Theory (math.GR); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15469 title=Abstract>arXiv:2401.15469</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15469 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15469 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wind speed super-resolution and validation: from ERA5 to CERRA via diffusion models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merizzi%2C+F">Fabio Merizzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asperti%2C+A">Andrea Asperti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colamonaco%2C+S">Stefano Colamonaco</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)
</div>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15496 title=Abstract>arXiv:2401.15496</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jianfei Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yancan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ou%2C+Y">Yimin Ou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hanyi Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yiyong Xiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15497 title=Abstract>arXiv:2401.15497</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15497 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15497 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lovato%2C+J">Juniper Lovato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmerman%2C+J">Julia Zimmerman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+I">Isabelle Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dodds%2C+P">Peter Dodds</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karson%2C+J">Jennifer Karson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15745 title=Abstract>arXiv:2401.15745</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The computation of approximate feedback Stackelberg equilibria in multi-player nonlinear constrained dynamic games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+J">Jingqi Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tomlin%2C+C">Claire Tomlin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This manuscript is currently under review by SIAM Journal on Optimization
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15885 title=Abstract>arXiv:2401.15885</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15885 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15885 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rectify the Regression Bias in Long-Tailed Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+K">Ke Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+M">Minghao Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+J">Jie Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15893 title=Abstract>arXiv:2401.15893</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15893 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15893 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Arbitrary-Scale Downscaling of Tidal Current Data Using Implicit Continuous Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dongheon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+S">Seungmyong Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ro%2C+Y">Youngmin Ro</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15912 title=Abstract>arXiv:2401.15912</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15912 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15912 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Efficient, High-Rate Scheme for Private Information Retrieval over the Gaussian MAC
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elimelech%2C+O">Or Elimelech</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen%2C+A">Asaf Cohen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15940 title=Abstract>arXiv:2401.15940</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15940 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15940 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge-Aware Code Generation with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+T">Tao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhi Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Ge Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+C">Chen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in ICPC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15970 title=Abstract>arXiv:2401.15970</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15970 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15970 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HEQuant: Marrying Homomorphic Encryption and Quantization for Communication-Efficient Private Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+T">Tianshi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Meng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Runsheng Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15977 title=Abstract>arXiv:2401.15977</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15977 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15977 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+X">Xiaoyu Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fu-Yun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bian%2C+W">Weikang Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+D">Dasong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Manyuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+K+C">Ka Chun Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=See%2C+S">Simon See</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+H">Hongwei Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jifeng Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://xiaoyushi97.github.io/Motion-I2V/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16092 title=Abstract>arXiv:2401.16092</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16092 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16092 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%A4mmerl%2C+K">Katharina Hmmerl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Libovicky%2C+J">Jindrich Libovicky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fraser%2C+A">Alexander Fraser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item517>[517]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16108 title=Abstract>arXiv:2401.16108</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Future Impact Decomposition in Request-level Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaobei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuchang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xueliang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+L">Lantao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Han Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+P">Peng Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+G">Guangming Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item518>[518]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16268 title=Abstract>arXiv:2401.16268</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16268 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A.I. In All The Wrong Places
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%B6hlen%2C+M">Marc Bhlen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+R">Ruolin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+X">Xiaoxu Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopaladinne%2C+S">Srikar Gopaladinne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorla%2C+H">Hemanth Gorla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kandukuri%2C+D">Divya Kandukuri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansfield%2C+S">Sean Mansfield</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 3 tables, 4 images
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item519>[519]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16403 title=Abstract>arXiv:2401.16403</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16403 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16403 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Thanh-Nhi Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+T">Thanh-Phong Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at the EACL 2024 Main Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item520>[520]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16416 title=Abstract>arXiv:2401.16416</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16416 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16416 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yiming Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+B">Beilei Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+L">Long Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Z">Ziqi Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengya Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item521>[521]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16468 title=Abstract>arXiv:2401.16468</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16468 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16468 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-Quality Image Restoration Following Human Instructions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geigle%2C+G">Gregor Geigle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item522>[522]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16655 title=Abstract>arXiv:2401.16655</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16655 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16655 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16655 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rademacher Complexity of Neural ODEs via Chen-Fliess Series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hanson%2C+J">Joshua Hanson</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Raginsky%2C+M">Maxim Raginsky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages; submitted to L4DC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item523>[523]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16729 title=Abstract>arXiv:2401.16729</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16729 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16729 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Widely Linear Matched Filter: A Lynchpin towards the Interpretability of Complex-valued CNNs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qingchen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhe Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babic%2C+Z">Zdenka Babic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+W">Wei Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stankovi%C4%87%2C+L">Ljubia Stankovi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandic%2C+D+P">Danilo P. Mandic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item524>[524]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16856 title=Abstract>arXiv:2401.16856</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16856 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BAR Nash Equilibrium and Application to Blockchain Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reynouard%2C+M">Maxime Reynouard</a> (LAMSADE), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laraki%2C+R">Rida Laraki</a> (UM6P, LAMSADE), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorelkina%2C+O">Olga Gorelkina</a> (UM6P)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item525>[525]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16872 title=Abstract>arXiv:2401.16872</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16872 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16872 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Scalable RISC-V Vector Processor Enabling Efficient Multi-Precision DNN Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chuanning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+C">Chao Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongfeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jun Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The work is accepted by 2024 IEEE International Symposium on Circuits and Systems (ISCAS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
</div>
</dd>
<dt><a name=item526>[526]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16977 title=Abstract>arXiv:2401.16977</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16977 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16977 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Analysis of Generalized Product Codes with Irregular Degree Distribution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+S">Sisi Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rapp%2C+L">Lukas Rapp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=J%C3%A4kel%2C+H">Holger Jkel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted to IEEE
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item527>[527]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16986 title=Abstract>arXiv:2401.16986</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16986 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16986 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Machine Learning for Cost-Effective Allocation of Development Aid
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kuzmanovic%2C+M">Milan Kuzmanovic</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Frauen%2C+D">Dennis Frauen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hatt%2C+T">Tobias Hatt</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item528>[528]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17053 title=Abstract>arXiv:2401.17053</a> (replaced) [<a href=https://arxiv.org/pdf/2401.17053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhennan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+H">Han Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+T">Taizhang Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Weixuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Senbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+R">Ruikai Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weizhe Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sato%2C+H">Hiroyuki Sato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongdong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+P">Pan Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Video: <a href="https://www.youtube.com/watch?v=PxIBtd6G0mA">this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item529>[529]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17217 title=Abstract>arXiv:2401.17217</a> (replaced) [<a href=https://arxiv.org/pdf/2401.17217 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17217 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GazeGPT: Augmenting Human Capabilities using Gaze-contingent Contextual AI for Smart Eyewear
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konrad%2C+R">Robert Konrad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padmanaban%2C+N">Nitish Padmanaban</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buckmaster%2C+J+G">J. Gabriel Buckmaster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyle%2C+K+C">Kevin C. Boyle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project video: <a href=https://youtu.be/AuDFHHTK_m8>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item530>[530]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17219 title=Abstract>arXiv:2401.17219</a> (replaced) [<a href=https://arxiv.org/pdf/2401.17219 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17219 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17219 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faster coloring and embedding in dense hypergraphs via stability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hou%2C+J">Jianfeng Hou</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+X">Xizhi Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhao%2C+H">Hongbin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> added THM 1.3
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item291>Cross-lists</a></li>
<li><a href=#item333>Replacements</a></li>
</ul>
<small>[ total of 530 entries: <b>1-530</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2401>2401</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_AMS,sans-serif class=sf-hidden></div></div>