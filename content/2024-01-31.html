<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns=http://www.w3.org/1999/xhtml lang=en style><!--
 Page saved with SingleFile 
 url: https://arxiv.org/list/cs/new 
 saved date: Wed Jan 31 2024 11:06:17 GMT+0800 (GMT+08:00)
--><meta charset=utf-8>
<title>Computer Science authors/titles "new"</title>
<style media=screen>body{margin:0;padding:0;background-color:#fff;color:#000;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif}a:link,a:visited,a:active{text-decoration:none;font-weight:normal}a:hover{text-decoration:underline}img{border:0}.primary-subject{font-weight:bold}#cu-identity{font-family:verdana,arial,helvetica,sans-serif;font-size:63.125%;color:#fff;background-color:#222;width:100%;display:flex;justify-content:space-between}#cu-logo{position:relative;left:10px;top:2px;width:300px;height:49px}#cu-logo a img{width:200px}#support-ack{top:12px;right:0%;margin:0 12px 0 0;padding:8px 0;text-align:right;font-size:120%;font-weight:normal;font-family:"Lucida Grande",helvetica,arial,verdana,sans-serif;color:#fff;width:380px}#support-ack a{color:#fff;text-decoration:none;border:none}#support-ack a:hover{background:#444}#header{background-color:#b31b1b;color:#fff;margin:0;padding:10px 0 10px 0;border-bottom:2px solid #ccc;position:relative;overflow:auto}#header h1{font-weight:bold}#header .header-breadcrumbs{margin:0;font-size:1em;padding:10px 0 .2em 10px;font-style:normal;float:left;display:inline-flex;align-items:center}#header .header-breadcrumbs span{margin-right:5px;margin-left:5px}#header a,#header a:visited{color:#fff;text-decoration:none}#header a:hover{text-decoration:underline}#header form{margin:0 12px 0 0;padding:0;text-align:right;font-size:.8em;line-height:100%}#header form input,#header form select{margin:0;padding:0}@media screen and (max-width:768px){#header h1{margin:0;padding:0 0 .2em 0}.search-block.level-right{clear:both!important}#header .header-breadcrumbs{float:none;text-align:center}}footer ul li{display:flex;align-items:center;font-size:14px}footer ul li a{font-size:13.5px}footer{background-color:hsl(0,0%,95%);color:#000;padding:1em 2em;font-size:0.9rem;-webkit-font-smoothing:antialiased;margin-top:6rem}footer a,footer a:visited{color:#000;text-decoration:none;border-bottom:1px solid transparent;line-height:1.75em}footer a:hover,footer a:active{color:#005e9d;border-bottom:1px dotted #005e9d;text-decoration:none}footer ul{padding:0;margin:0}footer .sorry-app-links .help{font-size:0.75rem;margin-bottom:0;line-height:1.75em}footer .sorry-app-links .help a,footer .sorry-app-links .help a:visited{border-bottom:1px dotted #000}footer .sorry-app-links .help a:hover,footer .sorry-app-links .help a:active{border-bottom:1px dotted #005e9d}footer .sorry-app-links svg.icon{margin-bottom:-2px!important}footer .sorry-app-links .icon.filter-black:hover,footer .sorry-app-links .icon.filter-black:active,footer .sorry-app-links a:hover .icon.filter-black,footer .sorry-app-links a:hover .icon.filter-black{fill:#005e9d!important}footer .sorry-app-links .a11y-main-link{font-size:110%;border-bottom:1px solid transparent!important;padding:0;margin:0}@media screen and (max-width:768px){footer .sorry-app-links.column{padding:0}}@media screen and (min-width:990px){}@media screen and (min-width:769px){.columns{display:flex;flex-direction:row}}.icon{width:.9rem;margin-right:.45em;margin-top:-.15rem}.help{font-family:"Lucida Grande","Helvetica Neue",Helvetica,Arial,sans-serif;display:block;font-size:0.75rem;margin-top:0.25rem}.accesskey{font-weight:bold}#content{margin:.7em;font-size:90%}@media screen and (min-width:768px){}@media screen and (max-width:330px){}@media screen and (min-width:769px){}@media screen and (min-width:550px){}@media screen and (max-width:768px){}@media screen and (max-width:768px){}@media (max-width:45em){}@media screen and (max-width:768px){}@media screen and (min-width:769px){}@media screen and (max-width:425px){}@media screen and (min-width:426px){}@media screen and (max-width:500px){}@media screen and (min-width:501px){}#dlpage .list-dateline{font-style:italic}#dlpage dd{padding-bottom:1em}#dlpage .meta{line-height:130%}#dlpage .list-identifier a{font-weight:bold}#dlpage .descriptor{display:inline}#dlpage .list-title{font-size:large;font-weight:bold;margin:.25em 0 0 0;line-height:120%}#dlpage .list-authors{font-weight:normal;font-size:110%}#dlpage .list-comments{font-weight:normal;font-size:90%}#dlpage .list-journal-ref{font-weight:normal;font-size:90%}#dlpage .list-subjects{font-size:90%}@media screen and (max-width:768px){#cu-identity{flex-direction:column}#support-ack,#cu-logo{text-align:center;width:100%;left:0px}}@media screen and (max-width:768px){}@media screen and (max-width:1023px){}@media screen and (min-width:1024px){}.button{border-width:1px;cursor:pointer;justify-content:center;padding-bottom:calc(0.5em - 1px);padding-left:1em;padding-right:1em;padding-top:calc(0.5em - 1px);text-align:center;white-space:nowrap}.column{display:block;flex-basis:0;flex-grow:1;flex-shrink:1;padding:0.75rem}@media screen and (max-width:768px){}@media screen and (min-width:769px),print{.columns:not(.is-desktop){display:flex}}@media screen and (min-width:1024px){.columns.is-desktop{display:flex}}@media screen and (min-width:769px){}svg.icon{height:1em!important}.icon.filter-black{fill:#000000}.filter-dark_grey{fill:#cccccc}a .icon{transition:fill 0.3s ease}a:hover .icon.filter-black,a:hover .icon.filter-grey,a:hover .icon.filter-blue,a:hover .icon.filter-red{fill:#ffffff}</style>
<style media=screen>@-webkit-keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@keyframes pulsate{0%{-webkit-transform:scale(.1);transform:scale(.1);opacity:0}30%{opacity:1}60%{-webkit-transform:scale(.8);transform:scale(.8);opacity:0}}@media only screen and (max-width:800px){}</style>
<style media=screen>.search-block.level-right{display:flex;justify-content:flex-end;clear:right}@media screen and (max-width:768px){.search-block.level-right{justify-content:center;clear:left}.search-block form.level-item{margin-left:12px!important}}.search-block form.level-item,.field.has-addons{display:flex}.search-block p.help{margin-bottom:0}.search-block .input,.search-block select,.search-block .button{font-size:0.75rem;line-height:1.5;height:2.25em;border-radius:2px;border:1px solid transparent}.search-block .button{margin-left:0}.search-block .input{border-color:transparent;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-bottom-right-radius:0;border-top-right-radius:0;border:0;width:100%;max-width:100%}.search-block .control{position:relative}.search-block .select::after{position:absolute;display:block;z-index:4;top:50%;right:.65em;width:0.5em;height:0.5em;content:" ";border:3px solid #0068AC;border-radius:2px;border-right:0;border-top:0;transform:rotate(-45deg);transform-origin:center;pointer-events:none;margin-top:-1.125em}.search-block .select.is-small select{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;max-width:220px;height:27px;float:right;margin:0px;background-color:#ffffff;background-image:none;-ms-word-break:normal;word-break:normal;border-color:#ccc;box-shadow:inset 0 1px 2px rgba(10,10,10,0.1);border-radius:0}.search-block .button{background-color:#711111;color:#FFF;border-color:transparent}.search-block .button:hover,.search-block .button:focus{background-color:#440A0A;color:#FFF}#header form select,#header form input{padding:0 0.5em}</style>
<link rel=alternate type=application/rss+xml title="Computer Science " href=http://arxiv.org/rss/cs>
<style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><style>.MathJax{display:inline;font-style:normal;font-weight:normal;line-height:normal;font-size:100%;text-indent:0;text-align:left;text-transform:none;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;direction:ltr;max-width:none;max-height:none;min-width:0;min-height:0;border:0;padding:0;margin:0}.MathJax:focus,body :focus .MathJax{display:inline-table}.MathJax nobr{border:0;padding:0;margin:0;max-width:none;max-height:none;min-width:0;min-height:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax span{display:inline;position:static;border:0;padding:0;margin:0;vertical-align:0;line-height:normal;text-decoration:none}.MathJax nobr{white-space:nowrap!important}.MathJax *{transition:none;-webkit-transition:none;-moz-transition:none;-ms-transition:none;-o-transition:none}@font-face{font-family:MathJax_Main;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Main-bold;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Main-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Math-italic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Caligraphic;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size1;src:url(data:application/font-woff;base64,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)format("woff")}@font-face{font-family:MathJax_Size2;src:url(data:application/font-woff;base64,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)format("woff")}.MathJax .noError{text-align:left;color:black;padding:1px 3px}</style><style>@font-face{font-family:MathJax_AMS;src:url(data:application/font-woff;base64,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)format("woff")}</style><meta name=referrer content=no-referrer><link rel="shortcut icon" href="data:image/x-icon;base64,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" type=image/x-icon><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://arxiv.org/list/cs/new><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style></head>
<body class=with-cu-identity><div style=visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal><div id=MathJax_Hidden class=sf-hidden></div></div><div id=MathJax_Message style=display:none></div>
<div id=cu-identity>
<div id=cu-logo>
<a href=https://www.cornell.edu/><img src=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 200.7 45" style="enable-background:new 0 0 200.7 45;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
	.st1{fill:#FFFFFF;stroke:#000000;stroke-width:0.1561;}
	.st2{fill:#FFFFFF;stroke:#000000;}
</style>
<g id="Layer_2_1_">
</g>
<g>
	<g id="Layer_1_1_">
		<path class="st0" d="M22.4,45C10,45,0,34.8,0,22.4S10,0,22.4,0s22.4,10,22.4,22.4C44.9,34.8,34.8,45,22.4,45z M22.4,2.5
			c-11,0-20,9-20,20s9,20,20,20s20-9,20-20C42.4,11.4,33.5,2.5,22.4,2.5z"/>
		<path class="st1" d="M17.2,24.9"/>
		<path class="st0" d="M22.4,42.3l-0.4-0.1c-0.5-0.2-13.2-5.8-13.2-15.9V8.1h27.2v18.4c0,9.7-12.6,15.3-13.2,15.6L22.4,42.3z
			 M10.8,9.9v16.3c0,8.1,9.7,13.1,11.8,14.1c2-1,11.8-6.1,11.8-13.7V10H10.8C10.8,10,10.8,9.9,10.8,9.9z"/>
		<path class="st0" d="M16.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L16.7,18.8z M14,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H14L14,11.5L14,11.5z"/>
		<path class="st0" d="M28.7,18.8l-0.2-0.1c0,0-1.5-0.9-2.3-1.5c-0.7-0.5-1.1-1.1-1.2-1.6c0-0.1,0-1.6,0-4.5v-0.6h7.7V11
			c0,2.9,0,4.4,0,4.5c0,0.6-0.4,1.1-1.1,1.6c-1,0.6-2.3,1.5-2.4,1.5L28.7,18.8z M26,11.5c0,1.6,0,3.7,0,3.9c0,0.1,0.2,0.5,0.6,0.7
			c0.6,0.4,1.5,1,2,1.2c0.5-0.2,1.5-0.9,2.1-1.2c0.2-0.1,0.6-0.4,0.6-0.6c0-0.2,0-2.2,0-3.9H26L26,11.5L26,11.5z"/>
		<rect x="9.3" y="19.1" class="st0" width="26.5" height="1.6"/>
		<g>
			<g>
				<path class="st0" d="M22.4,35.2c-0.5,0-0.7-0.4-0.9-0.5c-0.1-0.1-0.2-0.2-0.4-0.2c-0.7,0-1.2,0-1.8,0.1c-0.6,0-1.2,0.1-2.2,0.1
					s-1.7,0-1.7,0h-0.7V22.3h0.7c0.5,0,1.1,0,2.1,0c0.5,0,1-0.1,1.6-0.1c0.4,0,0.7-0.1,1.1-0.1c0.9-0.1,1.6,0.1,1.7,0.1
					c0.2,0,0.4,0.1,0.6,0.2c0.1-0.1,0.4-0.1,0.6-0.2c0,0,0.9-0.1,1.7-0.1c0.4,0,0.7,0.1,1.1,0.1c0.6,0.1,1.1,0.1,1.6,0.1
					c1,0,1.6,0,2.1,0h0.7v12.4h-0.7c0,0-0.7,0-1.7,0c-1,0-1.6-0.1-2.2-0.1c-0.6,0-1.1-0.1-1.8-0.1c-0.2,0-0.2,0-0.4,0.2
					C23.2,35,22.9,35.2,22.4,35.2z M21.2,33.1c0.6,0,1.1,0.2,1.4,0.5c0.2-0.2,0.7-0.5,1.4-0.5c0.7,0,1.4,0,2,0.1
					c0.6,0,1.2,0.1,2.1,0.1c0.4,0,0.6,0,0.9,0v-9.5c-0.4,0-0.9,0-1.4,0c-0.5,0-1.1-0.1-1.7-0.1c-0.4,0-0.7-0.1-1.1-0.1
					c-0.6-0.1-1.2,0-1.2,0c-0.1,0-0.2,0.1-0.2,0.1s0,0,0.1-0.1l-0.7-0.1l-0.7,0.1c0,0.1,0,0.1,0.1,0.1c0,0,0,0-0.2-0.1l0,0
					c0,0-0.6-0.1-1.2,0c-0.4,0-0.7,0.1-1.1,0.1c-0.6,0.1-1.2,0.1-1.7,0.1c-0.6,0-1,0-1.4,0v9.5c0.2,0,0.6,0,0.9,0
					c0.9,0,1.5-0.1,2.1-0.1C19.9,33.1,20.4,33.1,21.2,33.1z"/>
			</g>
		</g>
		<rect x="13.4" y="12.8" class="st0" width="6.4" height="1.1"/>
		<rect x="21.8" y="19.5" class="st0" width="1.5" height="21.8"/>
		<polygon class="st0" points="31.4,15.2 28.6,13.4 26,15.2 25.3,14.3 28.6,12 32,14.3 		"/>
		<path class="st2" d="M28.5,15.3"/>
		<rect x="17.2" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="17.2" y="30.3" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="25.1" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="27.7" class="st0" width="3.2" height="1.1"/>
		<rect x="24.3" y="30.3" class="st0" width="3.2" height="1.1"/>
	</g>
	<g id="Layer_3">
		<g>
			<path class="st0" d="M65.1,28.7c-1.1,0.7-3.1,1.1-4.3,1.1c-4.7,0-7.8-2.7-7.8-7.1c0-2.2,0.9-4,2.4-5.3c1.5-1.2,3.4-1.8,5.6-1.8
				c1.8,0,3.6,0.5,4.5,0.9c-0.2,1-0.4,2-0.4,2.9h-0.6v-1.5c0-0.5-0.7-0.9-1.7-1.2c-0.6-0.2-1.5-0.4-2.2-0.4c-3.7,0-5.6,2.7-5.6,6
				c0,3.9,2.6,6.4,6.5,6.4c1.5,0,3.1-0.5,3.9-1.2l0.1,0.2L65.1,28.7z"/>
			<path class="st0" d="M70,29.7c-2.4,0-4.2-2-4.2-4.5c0-2.9,1.8-5,5-5c2.4,0,4.4,2,4.4,4.4c0,2.9-2.1,5.2-5.2,5.2L70,29.7L70,29.7
				L70,29.7L70,29.7z M67.7,24.3c0,2.1,0.7,4.8,3.3,4.8c1.8,0,2.6-1.8,2.6-3.6c0-2.6-1.2-4.7-3.1-4.7C68.3,20.7,67.7,22.4,67.7,24.3
				z"/>
			<path class="st0" d="M76.8,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9L76.8,22.9z"/>
			<path class="st0" d="M85.8,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9
				c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.6v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L85.8,27.3L85.8,27.3z"/>
			<path class="st0" d="M101.9,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C100.3,20.1,101.9,21.5,101.9,23.7z M95.5,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1c0.7,0,1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C96.6,20.7,95.5,21.8,95.5,23.8z"/>
			<path class="st0" d="M103.7,17.2c0-0.5,0-0.9-0.5-0.9h-1.1v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0s-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L103.7,17.2L103.7,17.2z"/>
			<path class="st0" d="M108.7,17.2c0-0.5,0-0.9-0.5-0.9H107v-0.5c1-0.1,2.1-0.4,3.1-0.7l0.1,0.1v12.1c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1
				L108.7,17.2L108.7,17.2z"/>
			<path class="st0" d="M117.8,18.2c0-0.7,0-1.2-0.1-1.5s-0.4-0.2-0.9-0.2h-1v-0.6c1,0,2,0,2.9,0c0.9,0,1.8,0,2.8,0v0.6h-1
				c-0.5,0-0.7,0.1-0.9,0.2c-0.1,0.2-0.1,0.7-0.1,1.5v6.7c0,2.8,1.5,3.6,4,3.6c2.1,0,4-0.9,4-4v-6.3c0-0.7,0-1.2-0.1-1.5
				c-0.1-0.2-0.4-0.2-0.9-0.2h-0.9v-0.6c0.7,0,1.6,0,2.3,0c0.7,0,1.5,0,2.3,0v0.6h-0.9c-0.5,0-0.7,0.1-0.9,0.2
				c-0.1,0.2-0.1,0.7-0.1,1.5v5.6c0,4.2-1.6,5.9-5.5,5.9c-3.3,0-5.3-1-5.3-4.5L117.8,18.2L117.8,18.2L117.8,18.2z"/>
			<path class="st0" d="M133.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v1.7l0,0l1.5-1.2c0.5-0.4,0.9-0.5,1.6-0.5c2.3,0,3.2,1.2,3.2,3.4v3.8c0,0.5,0,1,0.1,1.1
				c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.5,0-1.1,0-1.6,0c-0.5,0-1.1,0-1.6,0v-5.5c0-1.6-1-2.4-2.2-2.4c-1.2,0-2.4,1-2.4,1.8
				L133.2,27.3L133.2,27.3L133.2,27.3L133.2,27.3z"/>
			<path class="st0" d="M144.9,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L144.9,27.3L144.9,27.3L144.9,27.3L144.9,27.3z M145.1,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C144.6,15.8,145.1,16.3,145.1,16.9z"/>
			<path class="st0" d="M152.3,27.3c-0.4,0.7-0.5,1.5-0.9,2.1h-1l-3.4-8c-0.1-0.2-0.2-0.6-0.6-0.6h-0.6v-0.5c0.7,0,1.5,0,2.3,0
				c0.7,0,1.5,0,2.3,0v0.5h-1c-0.4,0-0.5,0.1-0.5,0.4c0,0.1,0,0.4,0.1,0.7l2.3,5.6c0.4-0.9,0.9-1.8,1.2-2.7l0.9-2.1
				c0.2-0.6,0.4-1.1,0.4-1.5c0-0.4-0.1-0.5-0.5-0.5h-0.9v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0v0.5h-0.6c-0.5,0-0.9,0.7-1.1,1.4
				L152.3,27.3z"/>
			<path class="st0" d="M164.1,23.7c0,0.2,0,0.5,0,0.9c-1.2,0.2-2.3,0.2-3.6,0.2h-2.8c0,2.3,1.1,3.9,3.6,3.9c1,0,1.7-0.5,2.4-1
				l0.2,0.2l-0.4,0.6c-0.1,0.2-1.8,1.1-3.2,1.1c-2.9,0-4.5-1.8-4.5-4.5c0-2,0.5-3.1,1.5-3.8c0.4-0.2,0.7-0.6,1.2-0.7
				c0.7-0.4,1.2-0.5,2-0.5C162.5,20.1,164.1,21.5,164.1,23.7z M157.6,23.8V24c0.9,0.1,1.7,0.1,2.4,0.1s1.5,0,2.2,0
				c0-1.8-0.6-3.3-2.1-3.3C158.8,20.7,157.6,21.8,157.6,23.8z"/>
			<path class="st0" d="M166.3,22.9c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1v2l0,0
				l1.1-1.2c0.5-0.6,1.1-0.9,1.6-0.9c0.4,0,0.7,0.1,0.9,0.2l-0.1,2.3h-0.4c-0.2-0.5-0.6-0.9-1.4-0.9c-0.9,0-1.7,0.9-1.7,2.2v3.4
				c0,0.5,0,1,0.1,1.1c0.1,0.1,0.4,0.2,0.9,0.2h1v0.6c-1,0-1.8,0-2.8,0c-1,0-1.7,0-2.4,0v-0.6h0.9c0.4,0,0.5-0.1,0.6-0.2
				c0.1-0.2,0.1-0.6,0.1-1.1L166.3,22.9L166.3,22.9L166.3,22.9L166.3,22.9z"/>
			<path class="st0" d="M173,26.5v0.9c0,1.2,1.4,1.7,2.6,1.7c1.2,0,2.3-0.7,2.3-1.8c0-0.6-0.4-1.1-1-1.3c-0.9-0.2-2-0.5-2.9-0.7
				c-1-0.4-1.7-1-1.7-2.1c0-2.1,1.8-2.8,3.7-2.8c1,0,1.7,0.2,2.6,0.5c0,0.7-0.1,1.5-0.1,2.2h-0.5v-0.5c0-1-1.1-1.6-2.3-1.6
				c-1.7,0-2,1-2,1.6c0,0.9,0.6,1.4,2.1,1.6c2.3,0.4,3.4,1,3.4,2.4c0,2.2-2.2,3.3-4.3,3.3c-1,0-1.8-0.1-2.7-0.5
				c0.2-0.9,0.2-1.8,0.2-2.7h0.6L173,26.5L173,26.5L173,26.5L173,26.5z"/>
			<path class="st0" d="M183.2,27.3c0,0.5,0,1,0.1,1.1c0.1,0.1,0.2,0.2,0.6,0.2h0.9v0.6c-0.7,0-1.5,0-2.4,0c-1,0-1.7,0-2.4,0v-0.6
				h0.9c0.4,0,0.5-0.1,0.6-0.2c0.1-0.2,0.1-0.6,0.1-1.1v-4.4c0-0.6,0-1.1-0.1-1.2c-0.1-0.1-0.4-0.2-0.7-0.2h-0.7v-0.5
				c1.1-0.1,2.3-0.5,3.1-0.9l0.1,0.1L183.2,27.3L183.2,27.3L183.2,27.3L183.2,27.3z M183.4,16.9c0,0.6-0.5,1.1-1.1,1.1
				c-0.6,0-1.1-0.5-1.1-1.1s0.5-1.1,1.1-1.1C182.8,15.8,183.4,16.3,183.4,16.9z"/>
			<path class="st0" d="M184.5,22v-0.4l1.5-0.7v-1.3c0-0.5,0-1-0.1-1.6c0.7-0.2,1.4-0.5,1.7-0.7l0.2,0.2c-0.1,0.9-0.2,2-0.2,2.8V21
				l2.7-0.1l-0.1,1.1h-2.4v5.2c0,0.9,0.2,1.4,1.1,1.4c0.5,0,0.9-0.2,1.1-0.4l0.2,0.4l-1,1c-0.1,0.2-0.9,0.2-1.2,0.2
				c-1,0-2-0.5-2-2.1v-5.7L184.5,22z"/>
			<path class="st0" d="M198.3,22c0.1-0.2,0.1-0.4,0.1-0.5c0-0.4-0.2-0.5-0.9-0.5H197v-0.5c0.6,0,1.2,0,1.8,0c0.6,0,1.2,0,1.8,0V21
				h-0.5c-0.5,0-0.9,0.6-1.6,2.3l-3.9,9.2c-0.6,1.5-1.3,2.4-2.9,2.4c-0.4,0-0.7-0.1-1-0.2l0.5-1.5h0.2c0.2,0.2,0.7,0.5,1,0.5l0,0
				c1.1-0.1,1.7-1.7,2.1-2.6l0.5-1.2l-3.2-8c-0.4-0.7-0.6-1-1-1h-0.4v-0.5c0.7,0,1.5,0,2.3,0c0.7,0,1.5,0,2.3,0V21h-0.7
				c-0.4,0-0.6,0.1-0.6,0.5c0,0.2,0,0.5,0.1,0.7l2.2,5.4L198.3,22z"/>
		</g>
	</g>
</g>
</svg>
 alt="Cornell University" width=200 border=0></a>
</div>
<div id=support-ack>
<a href=https://confluence.cornell.edu/x/ALlRF>We gratefully acknowledge support from<br> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id=header>
<h1 class=header-breadcrumbs><a href=https://arxiv.org/><img src=data:image/svg+xml;base64,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 aria-label=logo alt="arxiv logo" width=85 style=width:85px;margin-right:8px></a> <span>&gt;</span> <a href=https://arxiv.org/list/cs/recent>cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method=GET action=https://arxiv.org/search _lpchecked=1>
<div class="field has-addons">
<div class=control>
<input class="input is-small" type=text name=query placeholder=Search... aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited=yes value>
<p class=help><a href=https://arxiv.org/help>Help</a> | <a href=https://arxiv.org/search/advanced>Advanced Search</a></p>
</div>
<div class=control>
<div class="select is-small">
<select name=searchtype aria-label="Field to search">
<option value=all selected>All fields</option>
<option value=title>Title</option>
<option value=author>Author</option>
<option value=abstract>Abstract</option>
<option value=comments>Comments</option>
<option value=journal_ref>Journal reference</option>
<option value=acm_class>ACM classification</option>
<option value=msc_class>MSC classification</option>
<option value=report_num>Report number</option>
<option value=paper_id>arXiv identifier</option>
<option value=doi>DOI</option>
<option value=orcid>ORCID</option>
<option value=author_id>arXiv author ID</option>
<option value=help>Help pages</option>
<option value=full_text>Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id=content>
<div id=dlpage>
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class=list-dateline>Submissions received from Mon 29 Jan 24 to Tue 30 Jan 24, announced Wed, 31 Jan 24</div>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item391>Cross-lists</a></li>
<li><a href=#item432>Replacements</a></li>
</ul>
<small>[ total of 654 entries: <b>1-654</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
<h3>New submissions for Wed, 31 Jan 24</h3>
<dl>
<dt><a name=item1>[1]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16425 title=Abstract>arXiv:2401.16425</a> [<a href=https://arxiv.org/pdf/2401.16425 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16425 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16425 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analog Circuit Sizing Using Machine Learning Based Transistor Circuit Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rajeoni%2C+A+B">Alireza Bagheri Rajeoni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Master's Thesis, University of Akron (2021). Link: <a href="http://rave.ohiolink.edu/etdc/view?acc_num=akron1609428170125214">this http URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Other Computer Science (cs.OH)</span>
</div>
<p class=mathjax>In this work, a new method for designing an analog circuit for deep
sub-micron CMOS fabrication processes is proposed. The proposed method
leverages the regression algorithms with the transistor circuit model to size a
transistor in 0.18 um technology fast and without using simulation software.
Threshold voltage, output resistance, and the product of mobility and oxide
capacitance are key parameters in the transistor circuit model to size a
transistor. For nano-scale transistors, however, these parameters are nonlinear
with respect to electrical and physical characteristics of transistors and
circuit simulator is needed to find the value of these parameters and therefore
the design time increases. Regression analysis is utilized to predict values of
these parameters. We demonstrate the performance of the proposed method by
designing a Current Feedback Instrumentational Amplifier (CFIA). We show that
the presented method accomplishes higher than 90% accuracy in predicting the
desired value of W. It reduces the design time over 97% compared to
conventional methods. The designed circuit using the proposed method consumes
5.76 uW power and has a Common Mode Rejection Ratio (CMRR) of 35.83 dB and it
results in achieving 8.17 V/V gain.
</p>
</div>
</dd>
<dt><a name=item2>[2]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16426 title=Abstract>arXiv:2401.16426</a> [<a href=https://arxiv.org/pdf/2401.16426 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16426 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16426 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Informal Safety Guarantees for Simulated Optimizers Through Extrapolation from Partial Simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marks%2C+L">Luke Marks</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 0 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Self-supervised learning is the backbone of state of the art language
modeling. It has been argued that training with predictive loss on a
self-supervised dataset causes simulators: entities that internally represent
possible configurations of real-world systems. Under this assumption, a
mathematical model for simulators is built based in the Cartesian frames model
of embedded agents, which is extended to multi-agent worlds through scaling a
two-dimensional frame to arbitrary dimensions, where literature prior chooses
to instead use operations on frames. This variant leveraging scaling
dimensionality is named the Cartesian object, and is used to represent
simulations (where individual simulacra are the agents and devices in that
object). Around the Cartesian object, functions like token selection and
simulation complexity are accounted for in formalizing the behavior of a
simulator, and used to show (through the L\"obian obstacle) that a proof of
alignment between simulacra by inspection of design is impossible in the
simulator context. Following this, a scheme is proposed and termed Partial
Simulation Extrapolation aimed at circumventing the L\"obian obstacle through
the evaluation of low-complexity simulations.
</p>
</div>
</dd>
<dt><a name=item3>[3]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16427 title=Abstract>arXiv:2401.16427</a> [<a href=https://arxiv.org/pdf/2401.16427 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16427 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16427 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mitigating Position Bias with Regularization for Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Fairness is a popular research topic in recent years. A research topic
closely related to fairness is bias and debiasing. Among different types of
bias problems, position bias is one of the most widely encountered symptoms.
Position bias means that recommended items on top of the recommendation list
has a higher likelihood to be clicked than items on bottom of the same list. To
mitigate this problem, we propose to use regularization technique to reduce the
bias effect. In the experiment section, we prove that our method is superior to
other modern algorithms.
</p>
</div>
</dd>
<dt><a name=item4>[4]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16429 title=Abstract>arXiv:2401.16429</a> [<a href=https://arxiv.org/pdf/2401.16429 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16429 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16429 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadi%2C+M">M. Mohammadi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruijn%2C+L+M">L. M. Bruijn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wieling%2C+M">M. Wieling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vols%2C+M">M. Vols</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Digital Libraries (cs.DL); Machine Learning (cs.LG)
</div>
<p class=mathjax>As legal case law databases such as HUDOC continue to grow rapidly, it has
become essential for legal researchers to find efficient methods to handle such
large-scale data sets. Such case law databases usually consist of the textual
content of cases together with the citations between them. This paper focuses
on case law from the European Court of Human Rights on Article 8 of the
European Convention of Human Rights, the right to respect private and family
life, home and correspondence. In this study, we demonstrate and compare the
potential of topic modelling and citation network to find and organize case law
on Article 8 based on their general themes and citation patterns, respectively.
Additionally, we explore whether combining these two techniques leads to better
results compared to the application of only one of the methods. We evaluate the
effectiveness of the combined method on a unique manually collected and
annotated dataset of Aricle 8 case law on evictions. The results of our
experiments show that our combined (text and citation-based) approach provides
the best results in finding and grouping case law, providing scholars with an
effective way to extract and analyse relevant cases on a specific issue.
</p>
</div>
</dd>
<dt><a name=item5>[5]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16430 title=Abstract>arXiv:2401.16430</a> [<a href=https://arxiv.org/pdf/2401.16430 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16430 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Information Retrieval and Extraction Tool for Covid-19 Related Papers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pivetta%2C+M+V+L">Marcos V. L. Pivetta</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Background: The COVID-19 pandemic has caused severe impacts on health systems
worldwide. Its critical nature and the increased interest of individuals and
organizations to develop countermeasures to the problem has led to a surge of
new studies in scientific journals. Objetive: We sought to develop a tool that
incorporates, in a novel way, aspects of Information Retrieval (IR) and
Extraction (IE) applied to the COVID-19 Open Research Dataset (CORD-19). The
main focus of this paper is to provide researchers with a better search tool
for COVID-19 related papers, helping them find reference papers and hightlight
relevant entities in text. Method: We applied Latent Dirichlet Allocation (LDA)
to model, based on research aspects, the topics of all English abstracts in
CORD-19. Relevant named entities of each abstract were extracted and linked to
the corresponding UMLS concept. Regular expressions and the K-Nearest Neighbors
algorithm were used to rank relevant papers. Results: Our tool has shown the
potential to assist researchers by automating a topic-based search of CORD-19
papers. Nonetheless, we identified that more fine-tuned topic modeling
parameters and increased accuracy of the research aspect classifier model could
lead to a more accurate and reliable tool. Conclusion: We emphasize the need of
new automated tools to help researchers find relevant COVID-19 documents, in
addition to automatically extracting useful information contained in them. Our
work suggests that combining different algorithms and models could lead to new
ways of browsing COVID-19 paper data.
</p>
</div>
</dd>
<dt><a name=item6>[6]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16432 title=Abstract>arXiv:2401.16432</a> [<a href=https://arxiv.org/pdf/2401.16432 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16432 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving conversion rate prediction via self-supervised pre-training in online advertising
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shtoff%2C+A">Alex Shtoff</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan%2C+Y">Yohay Kaplan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raviv%2C+A">Ariel Raviv</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>The task of predicting conversion rates (CVR) lies at the heart of online
advertising systems aiming to optimize bids to meet advertiser performance
requirements. Even with the recent rise of deep neural networks, these
predictions are often made by factorization machines (FM), especially in
commercial settings where inference latency is key. These models are trained
using the logistic regression framework on labeled tabular data formed from
past user activity that is relevant to the task at hand.
<br>Many advertisers only care about click-attributed conversions. A major
challenge in training models that predict conversions-given-clicks comes from
data sparsity - clicks are rare, conversions attributed to clicks are even
rarer. However, mitigating sparsity by adding conversions that are not
click-attributed to the training set impairs model calibration. Since
calibration is critical to achieving advertiser goals, this is infeasible.
<br>In this work we use the well-known idea of self-supervised pre-training, and
use an auxiliary auto-encoder model trained on all conversion events, both
click-attributed and not, as a feature extractor to enrich the main CVR
prediction model. Since the main model does not train on non click-attributed
conversions, this does not impair calibration. We adapt the basic
self-supervised pre-training idea to our online advertising setup by using a
loss function designed for tabular data, facilitating continual learning by
ensuring auto-encoder stability, and incorporating a neural network into a
large-scale real-time ad auction that ranks tens of thousands of ads, under
strict latency constraints, and without incurring a major engineering cost. We
show improvements both offline, during training, and in an online A/B test.
Following its success in A/B tests, our solution is now fully deployed to the
Yahoo native advertising system.
</p>
</div>
</dd>
<dt><a name=item7>[7]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16433 title=Abstract>arXiv:2401.16433</a> [<a href=https://arxiv.org/pdf/2401.16433 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16433 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Within-basket Recommendation via Neural Pattern Associator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+K">Kai Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+T">Tianshu Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+L">Lan Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+G">Ga Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liblong%2C+A">Aaron Liblong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fehervari%2C+I">Istvan Fehervari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=An%2C+R">Ruijian An</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+J">Jawad Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishra%2C+H">Harshit Mishra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pujari%2C+C">Charu Pujari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Within-basket recommendation (WBR) refers to the task of recommending items
to the end of completing a non-empty shopping basket during a shopping session.
While the latest innovations in this space demonstrate remarkable performance
improvement on benchmark datasets, they often overlook the complexity of user
behaviors in practice, such as 1) co-existence of multiple shopping intentions,
2) multi-granularity of such intentions, and 3) interleaving behavior
(switching intentions) in a shopping session. This paper presents Neural
Pattern Associator (NPA), a deep item-association-mining model that explicitly
models the aforementioned factors. Specifically, inspired by vector
quantization, the NPA model learns to encode common user intentions (or
item-combination patterns) as quantized representations (a.k.a. codebook),
which permits identification of users's shopping intentions via
attention-driven lookup during the reasoning phase. This yields coherent and
self-interpretable recommendations. We evaluated the proposed NPA model across
multiple extensive datasets, encompassing the domains of grocery e-commerce
(shopping basket completion) and music (playlist extension), where our
quantitative evaluations show that the NPA model significantly outperforms a
wide range of existing WBR solutions, reflecting the benefit of explicitly
modeling complex user intentions.
</p>
</div>
</dd>
<dt><a name=item8>[8]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16434 title=Abstract>arXiv:2401.16434</a> [<a href=https://arxiv.org/pdf/2401.16434 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16434 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16434 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A novel ANROA based control approach for grid-tied multi-functional solar energy conversion system
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Prasad%2C+D">Dinanath Prasad</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kumar%2C+N">Narendra Kumar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sharma%2C+R">Rakhi Sharma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Malik%2C+H">Hasmat Malik</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=M%C3%A1rquez%2C+F+P+G">Fausto Pedro García Márquez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=P%C3%A9rez%2C+J+M+P">Jesús María Pinar Pérez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The paper was published in Energy Reports journal (ELSEVIER). Cite as: Prasad, D., Kumar, N., Sharma, R., Malik, H., M\'arquez, F. P. G., &amp; Pinar-P\'erez, J. M. (2023). A novel ANROA based control approach for grid-tied multi-functional solar energy conversion system. Energy Reports, 9, 2044-2057
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Energy Reports (2023) Elsevier
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)
</div>
<p class=mathjax>An adaptive control approach for a three-phase grid-interfaced solar
photovoltaic system based on the new Neuro-Fuzzy Inference System with Rain
Optimization Algorithm (ANROA) methodology is proposed and discussed in this
manuscript. This method incorporates an Adaptive Neuro-fuzzy Inference System
(ANFIS) with a Rain Optimization Algorithm (ROA). The ANFIS controller has
excellent maximum tracking capability because it includes features of both
neural and fuzzy techniques. The ROA technique is in charge of controlling the
voltage source converter switching. Avoiding power quality problems including
voltage fluctuations, harmonics, and flickers as well as unbalanced loads and
reactive power usage is the major goal. Besides, the proposed method performs
at zero voltage regulation and unity power factor modes. The suggested control
approach has been modeled and simulated, and its performance has been assessed
using existing alternative methods. A statistical analysis of proposed and
existing techniques has been also presented and discussed. The results of the
simulations demonstrate that, when compared to alternative approaches, the
suggested strategy may properly and effectively identify the best global
solutions. Furthermore, the system's robustness has been studied by using
MATLAB/SIMULINK environment and experimentally by Field Programmable Gate
Arrays Controller (FPGA)-based Hardware-in-Loop (HLL).
</p>
</div>
</dd>
<dt><a name=item9>[9]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16435 title=Abstract>arXiv:2401.16435</a> [<a href=https://arxiv.org/pdf/2401.16435 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16435 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Heuristics for the Run-length Encoded Burrows-Wheeler Transform Alphabet Ordering Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Major%2C+L">Lily Major</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Clare%2C+A">Amanda Clare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daykin%2C+J+W">Jacqueline W. Daykin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mora%2C+B">Benjamin Mora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zarges%2C+C">Christine Zarges</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>
</div>
<p class=mathjax>The Burrows-Wheeler Transform (BWT) is a string transformation technique
widely used in areas such as bioinformatics and file compression. Many
applications combine a run-length encoding (RLE) with the BWT in a way which
preserves the ability to query the compressed data efficiently. However, these
methods may not take full advantage of the compressibility of the BWT as they
do not modify the alphabet ordering for the sorting step embedded in computing
the BWT. Indeed, any such alteration of the alphabet ordering can have a
considerable impact on the output of the BWT, in particular on the number of
runs. For an alphabet <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-1-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.64em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-2><span class=mi id=MathJax-Span-3 style=font-family:MathJax_Main>Σ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> containing <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-2-Frame tabindex=0><nobr><span class=math id=MathJax-Span-4 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-5><span class=mi id=MathJax-Span-6 style=font-family:MathJax_Math-italic>σ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> characters, the space of all
alphabet orderings is of size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-3-Frame tabindex=0><nobr><span class=math id=MathJax-Span-7 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.81em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-8><span class=mi id=MathJax-Span-9 style=font-family:MathJax_Math-italic>σ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-10 style=font-family:MathJax_Main>!</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. While for small alphabets an
exhaustive investigation is possible, finding the optimal ordering for larger
alphabets is not feasible. Therefore, there is a need for a more informed
search strategy than brute-force sampling the entire space, which motivates a
new heuristic approach. In this paper, we explore the non-trivial cases for the
problem of minimizing the size of a run-length encoded BWT (RLBWT) via
selecting a new ordering for the alphabet. We show that random sampling of the
space of alphabet orderings usually gives sub-optimal orderings for compression
and that a local search strategy can provide a large improvement in relatively
few steps. We also inspect a selection of initial alphabet orderings, including
ASCII, letter appearance, and letter frequency. While this alphabet ordering
problem is computationally hard we demonstrate gain in compressibility.
</p>
</div>
</dd>
<dt><a name=item10>[10]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16438 title=Abstract>arXiv:2401.16438</a> [<a href=https://arxiv.org/pdf/2401.16438 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16438 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Do deep neural networks utilize the weight space efficiently?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koyun%2C+O+C">Onur Can Koyun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=T%C3%B6reyin%2C+B+U">Behçet Uğur Töreyin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Deep learning models like Transformers and Convolutional Neural Networks
(CNNs) have revolutionized various domains, but their parameter-intensive
nature hampers deployment in resource-constrained settings. In this paper, we
introduce a novel concept utilizes column space and row space of weight
matrices, which allows for a substantial reduction in model parameters without
compromising performance. Leveraging this paradigm, we achieve
parameter-efficient deep learning models.. Our approach applies to both
Bottleneck and Attention layers, effectively halving the parameters while
incurring only minor performance degradation. Extensive experiments conducted
on the ImageNet dataset with ViT and ResNet50 demonstrate the effectiveness of
our method, showcasing competitive performance when compared to traditional
models. This approach not only addresses the pressing demand for parameter
efficient deep learning solutions but also holds great promise for practical
deployment in real-world scenarios.
</p>
</div>
</dd>
<dt><a name=item11>[11]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16439 title=Abstract>arXiv:2401.16439</a> [<a href=https://arxiv.org/pdf/2401.16439 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16439 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16439 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Polynomial time auditing of statistical subgroup fairness for Gaussian data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+D">Daniel Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jizhou Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Juba%2C+B">Brendan Juba</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computers and Society (cs.CY)
</div>
<p class=mathjax>We study the problem of auditing classifiers with the notion of statistical
subgroup fairness. Kearns et al. (2018) has shown that the problem of auditing
combinatorial subgroups fairness is as hard as agnostic learning. Essentially
all work on remedying statistical measures of discrimination against subgroups
assumes access to an oracle for this problem, despite the fact that no
efficient algorithms are known for it. If we assume the data distribution is
Gaussian, or even merely log-concave, then a recent line of work has discovered
efficient agnostic learning algorithms for halfspaces. Unfortunately, the
boosting-style reductions given by Kearns et al. required the agnostic learning
algorithm to succeed on reweighted distributions that may not be log-concave,
even if the original data distribution was. In this work, we give positive and
negative results on auditing for the Gaussian distribution: On the positive
side, we an alternative approach to leverage these advances in agnostic
learning and thereby obtain the first polynomial-time approximation scheme
(PTAS) for auditing nontrivial combinatorial subgroup fairness: we show how to
audit statistical notions of fairness over homogeneous halfspace subgroups when
the features are Gaussian. On the negative side, we find that under
cryptographic assumptions, no polynomial-time algorithm can guarantee any
nontrivial auditing, even under Gaussian feature distributions, for general
halfspace subgroups.
</p>
</div>
</dd>
<dt><a name=item12>[12]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16440 title=Abstract>arXiv:2401.16440</a> [<a href=https://arxiv.org/pdf/2401.16440 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16440 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mashiat%2C+T">Tasfia Mashiat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DiChristofano%2C+A">Alex DiChristofano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fowler%2C+P+J">Patrick J. Fowler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+S">Sanmay Das</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>There has been considerable recent interest in scoring properties on the
basis of eviction risk. The success of methods for eviction prediction is
typically evaluated using different measures of predictive accuracy. However,
the underlying goal of such prediction is to direct appropriate assistance to
households that may be at greater risk so they remain stably housed. Thus, we
must ask the question of how useful such predictions are in targeting outreach
efforts - informing action. In this paper, we investigate this question using a
novel dataset that matches information on properties, evictions, and owners. We
perform an eviction prediction task to produce risk scores and then use these
risk scores to plan targeted outreach policies. We show that the risk scores
are, in fact, useful, enabling a theoretical team of caseworkers to reach more
eviction-prone properties in the same amount of time, compared to outreach
policies that are either neighborhood-based or focus on buildings with a recent
history of evictions. We also discuss the importance of neighborhood and
ownership features in both risk prediction and targeted outreach.
</p>
</div>
</dd>
<dt><a name=item13>[13]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16441 title=Abstract>arXiv:2401.16441</a> [<a href=https://arxiv.org/pdf/2401.16441 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16441 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FaKnow: A Unified Library for Fake News Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yiyuan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongjun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jialiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+M">Ming Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+J">Jiali Wei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Over the past years, a large number of fake news detection algorithms based
on deep learning have emerged. However, they are often developed under
different frameworks, each mandating distinct utilization methodologies,
consequently hindering reproducibility. Additionally, a substantial amount of
redundancy characterizes the code development of such fake news detection
models. To address these concerns, we propose FaKnow, a unified and
comprehensive fake news detection algorithm library. It encompasses a variety
of widely used fake news detection models, categorized as content-based and
social context-based approaches. This library covers the full spectrum of the
model training and evaluation process, effectively organizing the data, models,
and training procedures within a unified framework. Furthermore, it furnishes a
series of auxiliary functionalities and tools, including visualization, and
logging. Our work contributes to the standardization and unification of fake
news detection research, concurrently facilitating the endeavors of researchers
in this field. The open-source code and documentation can be accessed at
https://github.com/NPURG/FaKnow and https://faknow.readthedocs.io,
respectively.
</p>
</div>
</dd>
<dt><a name=item14>[14]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16443 title=Abstract>arXiv:2401.16443</a> [<a href=https://arxiv.org/pdf/2401.16443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingjun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zafar%2C+N">Numan Zafar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+S">Sean Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AIxVR 2024 poster paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>As VR devices become more prevalent in the consumer space, VR applications
are likely to be increasingly used by users unfamiliar with VR. Detecting the
familiarity level of a user with VR as an interaction medium provides the
potential of providing on-demand training for acclimatization and prevents the
user from being burdened by the VR environment in accomplishing their tasks. In
this work, we present preliminary results of using deep classifiers to conduct
automatic detection of familiarity with VR by using hand tracking of the user
as they interact with a numeric passcode entry panel to unlock a VR door. We
use a VR door as we envision it to the first point of entry to collaborative
virtual spaces, such as meeting rooms, offices, or clinics. Users who are
unfamiliar with VR will have used their hands to open doors with passcode entry
panels in the real world. Thus, while the user may not be familiar with VR,
they would be familiar with the task of opening the door. Using a pilot dataset
consisting of 7 users familiar with VR, and 7 not familiar with VR, we acquire
highest accuracy of 88.03\% when 6 test users, 3 familiar and 3 not familiar,
are evaluated with classifiers trained using data from the remaining 8 users.
Our results indicate potential for using user movement data to detect
familiarity for the simple yet important task of secure passcode-based access.
</p>
</div>
</dd>
<dt><a name=item15>[15]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16444 title=Abstract>arXiv:2401.16444</a> [<a href=https://arxiv.org/pdf/2401.16444 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16444 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yiming Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Feiyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+Z">Zhenjie Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+D">Dehua Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Weixuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenjin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Siqin Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xianliang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhui Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jing Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Q">Qiang Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+W">Wei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Lanxiao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2304.11632>arXiv:2304.11632</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Existing game AI research mainly focuses on enhancing agents' abilities to
win games, but this does not inherently make humans have a better experience
when collaborating with these agents. For example, agents may dominate the
collaboration and exhibit unintended or detrimental behaviors, leading to poor
experiences for their human partners. In other words, most game AI agents are
modeled in a "self-centered" manner. In this paper, we propose a
"human-centered" modeling scheme for collaborative agents that aims to enhance
the experience of humans. Specifically, we model the experience of humans as
the goals they expect to achieve during the task. We expect that agents should
learn to enhance the extent to which humans achieve these goals while
maintaining agents' original abilities (e.g., winning games). To achieve this,
we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG
approach introduces a "baseline", which corresponds to the extent to which
humans primitively achieve their goals, and encourages agents to learn
behaviors that can effectively enhance humans in achieving their goals better.
We evaluate the RLHG agent in the popular Multi-player Online Battle Arena
(MOBA) game, Honor of Kings, by conducting real-world human-agent tests. Both
objective performance and subjective preference results show that the RLHG
agent provides participants better gaming experience.
</p>
</div>
</dd>
<dt><a name=item16>[16]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16445 title=Abstract>arXiv:2401.16445</a> [<a href=https://arxiv.org/pdf/2401.16445 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16445 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OMPGPT: A Generative Pre-trained Transformer Model for OpenMP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Le Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+A">Arijit Bhattacharjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahmed%2C+N">Nesreen Ahmed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oren%2C+G">Gal Oren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vo%2C+V">Vy Vo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs), as epitomized by models like ChatGPT, have
revolutionized the field of natural language processing (NLP). Along with this
trend, code-based large language models such as StarCoder, WizardCoder, and
CodeLlama have emerged, trained extensively on vast repositories of code data.
Yet, inherent in their design, these models primarily focus on generative tasks
like code generation, code completion, and comment generation, and general
support for multiple programming languages. While the generic abilities of code
LLMs are useful for many programmers, the area of high-performance computing
(HPC) has a narrower set of requirements that make a smaller and more
domain-specific LM a smarter choice. This paper introduces OMPGPT, a novel
model meticulously designed to harness the inherent strengths of language
models for OpenMP pragma generation. Furthermore, we adopt and adapt prompt
engineering techniques from the NLP domain to create chain-of-OMP, an
innovative strategy designed to enhance OMPGPT's effectiveness. Our extensive
evaluations demonstrate that OMPGPT outperforms existing large language models
specialized in OpenMP tasks and maintains a notably smaller size, aligning it
more closely with the typical hardware constraints of HPC environments. We
consider our contribution as a pivotal bridge, connecting the advantage of
language models with the specific demands of HPC tasks. The success of OMPGPT
lays a solid foundation, suggesting its potential applicability and
adaptability to a wider range of HPC tasks, thereby opening new avenues in the
field of computational efficiency and effectiveness.
</p>
</div>
</dd>
<dt><a name=item17>[17]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16446 title=Abstract>arXiv:2401.16446</a> [<a href=https://arxiv.org/pdf/2401.16446 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16446 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16446 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Framework of Resilient Transmission Network Reconfiguration Considering Cyber-Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+C">Chao Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liang%2C+G">Gaoqi Liang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Weller%2C+S+R">Steven R. Weller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+S">Shaoyan Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+J">Junhua Zhao</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dong%2C+Z">Zhaoyang Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Fast and reliable transmission network reconfiguration is critical in
improving power grid resilience to cyber-attacks. If the network
reconfiguration following cyber-attacks is imperfect, secondary incidents may
delay or interrupt post-attack restoration of the power grid. This paper
proposes a framework of resilient transmission network reconfiguration, taking
into account the impacts of cyber-attacks in the network reconfiguration
process. First, the mechanism of cyber-attack propagation is analyzed based on
the characteristics of network reconfiguration. Second, systematic resilience
indices are specially extracted in which the impact of cyber-attacks on network
reconfiguration is quantified. These indices are defined in terms of the
restoration characteristics of the transmission power system. Third,
representative cyber-attack incidents motivate an optimization-based model of
resilient transmission network reconfiguration, and an optimal reconstruction
scheme is obtained. Finally, simulation results based on the IEEE 39-bus system
verify the feasibility and effectiveness of the proposed framework in enhancing
power grid resilience to cyber-attacks.
</p>
</div>
</dd>
<dt><a name=item18>[18]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16448 title=Abstract>arXiv:2401.16448</a> [<a href=https://arxiv.org/pdf/2401.16448 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16448 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+W">Weimin Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaichen Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutta%2C+R+G">Raj Gautam Dutta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xiaolong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+G">Gang Qu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages. 1 figure
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 Asian Hardware Oriented Security and Trust Symposium
 (AsianHOST), Tianjin, China, 2023, pp. 1-6
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper presents LLM4SecHW, a novel framework for hardware debugging that
leverages domain specific Large Language Model (LLM). Despite the success of
LLMs in automating various software development tasks, their application in the
hardware security domain has been limited due to the constraints of commercial
LLMs and the scarcity of domain specific data. To address these challenges, we
propose a unique approach to compile a dataset of open source hardware design
defects and their remediation steps, utilizing version control data. This
dataset provides a substantial foundation for training machine learning models
for hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this
dataset, enabling the identification and rectification of bugs in hardware
designs. This pioneering approach offers a reference workflow for the
application of fine tuning domain specific LLMs in other research areas. We
evaluate the performance of our proposed system on various open source hardware
designs, demonstrating its efficacy in accurately identifying and correcting
defects. Our work brings a new perspective on automating the quality control
process in hardware design.
</p>
</div>
</dd>
<dt><a name=item19>[19]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16449 title=Abstract>arXiv:2401.16449</a> [<a href=https://arxiv.org/pdf/2401.16449 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16449 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI in Energy Digital Twining: A Reinforcement Learning-based Adaptive Digital Twin Model for Green Cities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cakir%2C+L+V">Lal Verda Cakir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duran%2C+K">Kubra Duran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thomson%2C+C">Craig Thomson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Broadbent%2C+M">Matthew Broadbent</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Canberk%2C+B">Berk Canberk</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Digital Twins (DT) have become crucial to achieve sustainable and effective
smart urban solutions. However, current DT modelling techniques cannot support
the dynamicity of these smart city environments. This is caused by the lack of
right-time data capturing in traditional approaches, resulting in inaccurate
modelling and high resource and energy consumption challenges. To fill this
gap, we explore spatiotemporal graphs and propose the Reinforcement
Learning-based Adaptive Twining (RL-AT) mechanism with Deep Q Networks (DQN).
By doing so, our study contributes to advancing Green Cities and showcases
tangible benefits in accuracy, synchronisation, resource optimization, and
energy efficiency. As a result, we note the spatiotemporal graphs are able to
offer a consistent accuracy and 55% higher querying performance when
implemented using graph databases. In addition, our model demonstrates
right-time data capturing with 20% lower overhead and 25% lower energy
consumption.
</p>
</div>
</dd>
<dt><a name=item20>[20]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16450 title=Abstract>arXiv:2401.16450</a> [<a href=https://arxiv.org/pdf/2401.16450 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16450 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Calista Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+A">Alyssa Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vyasamudri%2C+S">Suchir Vyasamudri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Puype%2C+E">Eugenie Puype</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamal%2C+S">Sayem Kamal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+J+B">Juan Belza Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheema%2C+S">Salar Cheema</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lutz%2C+M">Michael Lutz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)
</div>
<p class=mathjax>With the increasing need for inclusive and user-friendly technology, web
accessibility is crucial to ensuring equal access to online content for
individuals with disabilities, including visual, auditory, cognitive, or motor
impairments. Despite the existence of accessibility guidelines and standards
such as Web Content Accessibility Guidelines (WCAG) and the Web Accessibility
Initiative (W3C), over 90\% of websites still fail to meet the necessary
accessibility requirements. For web users with disabilities, there exists a
need for a tool to automatically fix web page accessibility errors. While
research has demonstrated methods to find and target accessibility errors, no
research has focused on effectively correcting such violations. This paper
presents a novel approach to correcting accessibility violations on the web by
modifying the document object model (DOM) in real time with foundation models.
Leveraging accessibility error information, large language models (LLMs), and
prompt engineering techniques, we achieved greater than a 51\% reduction in
accessibility violation errors after corrections on our novel benchmark:
ACCESS. Our work demonstrates a valuable approach toward the direction of
inclusive web content, and provides directions for future research to explore
advanced methods to automate web accessibility.
</p>
</div>
</dd>
<dt><a name=item21>[21]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16452 title=Abstract>arXiv:2401.16452</a> [<a href=https://arxiv.org/pdf/2401.16452 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16452 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Context-Former: Stitching via Latent Conditioned Sequence Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziqi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jingzehua Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+Z">Zifeng Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinxin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=wang%2C+D">Donglin wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Offline reinforcement learning (RL) algorithms can improve the decision
making via stitching sub-optimal trajectories to obtain more optimal ones. This
capability is a crucial factor in enabling RL to learn policies that are
superior to the behavioral policy. On the other hand, Decision Transformer (DT)
abstracts the decision-making as sequence modeling, showcasing competitive
performance on offline RL benchmarks, however, recent studies demonstrate that
DT lacks of stitching capability, thus exploit stitching capability for DT is
vital to further improve its performance. In order to endow stitching
capability to DT, we abstract trajectory stitching as expert matching and
introduce our approach, ContextFormer, which integrates contextual
information-based imitation learning (IL) and sequence modeling to stitch
sub-optimal trajectory fragments by emulating the representations of a limited
number of expert trajectories. To validate our claim, we conduct experiments
from two perspectives: 1) We conduct extensive experiments on D4RL benchmarks
under the settings of IL, and experimental results demonstrate ContextFormer
can achieve competitive performance in multi-IL settings. 2) More importantly,
we conduct a comparison of ContextFormer with diverse competitive DT variants
using identical training datasets. The experimental results unveiled
ContextFormer's superiority, as it outperformed all other variants, showcasing
its remarkable performance.
</p>
</div>
</dd>
<dt><a name=item22>[22]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16453 title=Abstract>arXiv:2401.16453</a> [<a href=https://arxiv.org/pdf/2401.16453 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16453 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16453 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+W">Wang Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Doudou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+B">Baichao Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jianli Xiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Long-term traffic prediction has always been a challenging task due to its
dynamic temporal dependencies and complex spatial dependencies. In this paper,
we propose a model that combines hybrid Transformer and spatio-temporal
self-supervised learning. The model enhances its robustness by applying
adaptive data augmentation techniques at the sequence-level and graph-level of
the traffic data. It utilizes Transformer to overcome the limitations of
recurrent neural networks in capturing long-term sequences, and employs
Chebyshev polynomial graph convolution to capture complex spatial dependencies.
Furthermore, considering the impact of spatio-temporal heterogeneity on traffic
speed, we design two self-supervised learning tasks to model the temporal and
spatial heterogeneity, thereby improving the accuracy and generalization
ability of the model. Experimental evaluations are conducted on two real-world
datasets, PeMS04 and PeMS08, and the results are visualized and analyzed,
demonstrating the superior performance of the proposed model.
</p>
</div>
</dd>
<dt><a name=item23>[23]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16454 title=Abstract>arXiv:2401.16454</a> [<a href=https://arxiv.org/pdf/2401.16454 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16454 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhole%2C+K+D">Kaustubh D. Dhole</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Simulation of Conversational Intelligence in Chat, EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)
</div>
<p class=mathjax>An effective multi-turn instruction-following assistant can be developed by
creating a simulator that can generate useful interaction data. Apart from
relying on its intrinsic weights, an ideal user simulator should also be able
to bootstrap external knowledge rapidly in its raw form to simulate the
multifarious diversity of text available over the internet. Previous user
simulators generally lacked diversity, were mostly closed domain, and
necessitated rigid schema making them inefficient to rapidly scale to
incorporate external knowledge. In this regard, we introduce, Kaucus, a
Knowledge-Augmented User Simulator framework, to outline a process of creating
diverse user simulators, that can seamlessly exploit external knowledge as well
as benefit downstream assistant model training. Through two GPT-J based
simulators viz., a Retrieval Augmented Simulator and a Summary Controlled
Simulator we generate diverse simulator-assistant interactions. Through reward
and preference model-based evaluations, we find that these interactions serve
as useful training data and create more helpful downstream assistants. We also
find that incorporating knowledge through retrieval augmentation or summary
control helps create better assistants.
</p>
</div>
</dd>
<dt><a name=item24>[24]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16456 title=Abstract>arXiv:2401.16456</a> [<a href=https://arxiv.org/pdf/2401.16456 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16456 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yun%2C+S">Seokju Yun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ro%2C+Y">Youngmin Ro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint, Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, efficient Vision Transformers have shown great performance with low
latency on resource-constrained devices. Conventionally, they use 4x4 patch
embeddings and a 4-stage structure at the macro level, while utilizing
sophisticated attention with multi-head configuration at the micro level. This
paper aims to address computational redundancy at all design levels in a
memory-efficient manner. We discover that using larger-stride patchify stem not
only reduces memory access costs but also achieves competitive performance by
leveraging token representations with reduced spatial redundancy from the early
stages. Furthermore, our preliminary analyses suggest that attention layers in
the early stages can be substituted with convolutions, and several attention
heads in the latter stages are computationally redundant. To handle this, we
introduce a single-head attention module that inherently prevents head
redundancy and simultaneously boosts accuracy by parallelly combining global
and local information. Building upon our solutions, we introduce SHViT, a
Single-Head Vision Transformer that obtains the state-of-the-art speed-accuracy
tradeoff. For example, on ImageNet-1k, our SHViT-S4 is 3.3x, 8.1x, and 2.4x
faster than MobileViTv2 x1.0 on GPU, CPU, and iPhone12 mobile device,
respectively, while being 1.3% more accurate. For object detection and instance
segmentation on MS COCO using Mask-RCNN head, our model achieves performance
comparable to FastViT-SA12 while exhibiting 3.8x and 2.0x lower backbone
latency on GPU and mobile device, respectively.
</p>
</div>
</dd>
<dt><a name=item25>[25]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16457 title=Abstract>arXiv:2401.16457</a> [<a href=https://arxiv.org/pdf/2401.16457 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16457 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masoudian%2C+S">Shahed Masoudian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Volaucnik%2C+C">Cornelia Volaucnik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schedl%2C+M">Markus Schedl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masoudian%2C+S">Shahed Masoudian</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
<p class=mathjax>Bias mitigation of Language Models has been the topic of many studies with a
recent focus on learning separate modules like adapters for on-demand
debiasing. Besides optimizing for a modularized debiased model, it is often
critical in practice to control the degree of bias reduction at inference time,
e.g., in order to tune for a desired performance-fairness trade-off in search
results or to control the strength of debiasing in classification tasks. In
this paper, we introduce Controllable Gate Adapter (ConGater), a novel modular
gating mechanism with adjustable sensitivity parameters, which allows for a
gradual transition from the biased state of the model to the fully debiased
version at inference time. We demonstrate ConGater performance by (1)
conducting adversarial debiasing experiments with three different models on
three classification tasks with four protected attributes, and (2) reducing the
bias of search results through fairness list-wise regularization to enable
adjusting a trade-off between performance and fairness metrics. Our experiments
on the classification tasks show that compared to baselines of the same
caliber, ConGater can maintain higher task performance while containing less
information regarding the attributes. Our results on the retrieval task show
that the fully debiased ConGater can achieve the same fairness performance
while maintaining more than twice as high task performance than recent strong
baselines. Overall, besides strong performance ConGater enables the continuous
transitioning between biased and debiased states of models, enhancing
personalization of use and interpretability through controllability.
</p>
</div>
</dd>
<dt><a name=item26>[26]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16459 title=Abstract>arXiv:2401.16459</a> [<a href=https://arxiv.org/pdf/2401.16459 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16459 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bridging Generative and Discriminative Models for Unified Visual Perception with Diffusion Priors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+S">Shiyin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+M">Mingrui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+K">Kun Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Nannan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages,11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The remarkable prowess of diffusion models in image generation has spurred
efforts to extend their application beyond generative tasks. However, a
persistent challenge exists in lacking a unified approach to apply diffusion
models to visual perception tasks with diverse semantic granularity
requirements. Our purpose is to establish a unified visual perception
framework, capitalizing on the potential synergies between generative and
discriminative models. In this paper, we propose Vermouth, a simple yet
effective framework comprising a pre-trained Stable Diffusion (SD) model
containing rich generative priors, a unified head (U-head) capable of
integrating hierarchical representations, and an adapted expert providing
discriminative priors. Comprehensive investigations unveil potential
characteristics of Vermouth, such as varying granularity of perception
concealed in latent variables at distinct time steps and various U-net stages.
We emphasize that there is no necessity for incorporating a heavyweight or
intricate decoder to transform diffusion models into potent representation
learners. Extensive comparative evaluations against tailored discriminative
models showcase the efficacy of our approach on zero-shot sketch-based image
retrieval (ZS-SBIR), few-shot classification, and open-vocabulary semantic
segmentation tasks. The promising results demonstrate the potential of
diffusion models as formidable learners, establishing their significance in
furnishing informative and robust visual representations.
</p>
</div>
</dd>
<dt><a name=item27>[27]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16461 title=Abstract>arXiv:2401.16461</a> [<a href=https://arxiv.org/pdf/2401.16461 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16461 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tzeng%2C+S">Sz-Ting Tzeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ajmeri%2C+N">Nirav Ajmeri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+M+P">Munindar P. Singh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 11 figures, 5 tables (and supplementary material with code availability and additional results), accepted at AAMAS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>A multiagent system can be viewed as a society of autonomous agents, whose
interactions can be effectively regulated via social norms. In general, the
norms of a society are not hardcoded but emerge from the agents' interactions.
Specifically, how the agents in a society react to each other's behavior and
respond to the reactions of others determines which norms emerge in the
society. We think of these reactions by an agent to the satisfactory or
unsatisfactory behaviors of another agent as communications from the first
agent to the second agent. Understanding these communications is a kind of
social intelligence: these communications provide natural drivers for norm
emergence by pushing agents toward certain behaviors, which can become
established as norms. Whereas it is well-known that sanctioning can lead to the
emergence of norms, we posit that a broader kind of social intelligence can
prove more effective in promoting cooperation in a multiagent system.
<br>Accordingly, we develop Nest, a framework that models social intelligence in
the form of a wider variety of communications and understanding of them than in
previous work. To evaluate Nest, we develop a simulated pandemic environment
and conduct simulation experiments to compare Nest with baselines considering a
combination of three kinds of social communication: sanction, tell, and hint.
<br>We find that societies formed of Nest agents achieve norms faster; moreover,
Nest agents effectively avoid undesirable consequences, which are negative
sanctions and deviation from goals, and yield higher satisfaction for
themselves than baseline agents despite requiring only an equivalent amount of
information.
</p>
</div>
</dd>
<dt><a name=item28>[28]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16462 title=Abstract>arXiv:2401.16462</a> [<a href=https://arxiv.org/pdf/2401.16462 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16462 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+E">En Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yanyan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+K">Kaixiang Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+Y">Yuxin Chu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The problem of the Remaining Useful Life (RUL) prediction, aiming at
providing an accurate estimate of the remaining time from the current
predicting moment to the complete failure of the device, has gained significant
attention from researchers in recent years. In this paper, to overcome the
shortcomings of rigid combination for temporal and spatial features in most
existing RUL prediction approaches, a spatial-temporal homogeneous feature
extractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wise
progressive feature fusion is employed to ensure the homogeneity of
spatial-temporal features and enhance the prediction accuracy. Secondly, the
Feature Space Global Relationship Invariance (FSGRI) training method is
introduced based on supervised contrastive learning. This method maintains the
consistency of relationships among sample features with their degradation
patterns during model training, simplifying the subsequently regression task in
the output layer and improving the model's performance in RUL prediction.
Finally, the effectiveness of the proposed method is validated through
comparisons with other latest research works on the C-MAPSS dataset. The
Dual-Mixer model demonstrates superiority across most metrics, while the FSGRI
training method shows an average improvement of 7.00% and 2.41% in RMSE and
MAPE, respectively, for all baseline models. Our experiments and model code are
publicly available at https://github.com/fuen1590/PhmDeepLearningProjects.
</p>
</div>
</dd>
<dt><a name=item29>[29]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16463 title=Abstract>arXiv:2401.16463</a> [<a href=https://arxiv.org/pdf/2401.16463 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16463 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Print-N-Grip: A Disposable, Compliant, Scalable and One-Shot 3D-Printed Multi-Fingered Robotic Hand
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laron%2C+A">Alon Laron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sne%2C+E">Eran Sne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perets%2C+Y">Yaron Perets</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Robotic hands are an important tool for replacing humans in handling toxic or
radioactive materials. However, these are usually highly expensive, and in many
cases, once they are contaminated, they cannot be re-used. Some solutions cope
with this challenge by 3D printing parts of a tendon-based hand. However,
fabrication requires additional assembly steps. Therefore, a novice user may
have difficulties fabricating a hand upon contamination of the previous one. We
propose the Print-N-Grip (PNG) hand which is a tendon-based underactuated
mechanism able to adapt to the shape of objects. The hand is fabricated through
one-shot 3D printing with no additional engineering effort, and can accommodate
a number of fingers as desired by the practitioner. Due to its low cost, the
PNG hand can easily be detached from a universal base for disposing upon
contamination, and replaced by a newly printed one. In addition, the PNG hand
is scalable such that one can effortlessly resize the computerized model and
print. We present the design of the PNG hand along with experiments to show the
capabilities and high durability of the hand.
</p>
</div>
</dd>
<dt><a name=item30>[30]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16464 title=Abstract>arXiv:2401.16464</a> [<a href=https://arxiv.org/pdf/2401.16464 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16464 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Regret Free Slot Allocation in Billboard Advertisement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ali%2C+D">Dildar Ali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+S">Suman Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prasad%2C+Y">Yamuna Prasad</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 Pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Databases (cs.DB); Machine Learning (cs.LG); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Creating and maximizing influence among the customers is one of the central
goals of an advertiser, and hence, remains an active area of research in recent
times. In this advertisement technique, the advertisers approach an influence
provider for a specific number of views of their content on a payment basis.
Now, if the influence provider can provide the required number of views or
more, he will receive the full, else a partial payment. In the context of an
influence provider, it is a loss for him if he offers more or less views. This
is formalized as 'Regret', and naturally, in the context of the influence
provider, the goal will be to minimize this quantity. In this paper, we solve
this problem in the context of billboard advertisement and pose it as a
discrete optimization problem. We propose four efficient solution approaches
for this problem and analyze them to understand their time and space
complexity. We implement all the solution methodologies with real-life datasets
and compare the obtained results with the existing solution approaches from the
literature. We observe that the proposed solutions lead to less regret while
taking less computational time.
</p>
</div>
</dd>
<dt><a name=item31>[31]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16465 title=Abstract>arXiv:2401.16465</a> [<a href=https://arxiv.org/pdf/2401.16465 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16465 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DressCode: Autoregressively Sewing and Generating Garments from Text Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K">Kai He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+K">Kaixin Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qixuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jingyi Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
<p class=mathjax>Apparel's significant role in human appearance underscores the importance of
garment digitalization for digital human creation. Recent advances in 3D
content creation are pivotal for digital human creation. Nonetheless, garment
generation from text guidance is still nascent. We introduce a text-driven 3D
garment generation framework, DressCode, which aims to democratize design for
novices and offer immense potential in fashion design, virtual try-on, and
digital human creation. For our framework, we first introduce SewingGPT, a
GPT-based architecture integrating cross-attention with text-conditioned
embedding to generate sewing patterns with text guidance. We also tailored a
pre-trained Stable Diffusion for high-quality, tile-based PBR texture
generation. By leveraging a large language model, our framework generates
CG-friendly garments through natural language interaction. Our method also
facilitates pattern completion and texture editing, simplifying the process for
designers by user-friendly interaction. With comprehensive evaluations and
comparisons with other state-of-the-art methods, our method showcases the best
quality and alignment with input prompts. User studies further validate our
high-quality rendering results, highlighting its practical utility and
potential in production settings.
</p>
</div>
</dd>
<dt><a name=item32>[32]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16467 title=Abstract>arXiv:2401.16467</a> [<a href=https://arxiv.org/pdf/2401.16467 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16467 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReGAL: Refactoring Programs to Discover Generalizable Abstractions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stengel-Eskin%2C+E">Elias Stengel-Eskin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prasad%2C+A">Archiki Prasad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages; First two authors contributed equally; Code: <a href=https://github.com/esteng/regal_program_learning>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>While large language models (LLMs) are increasingly being used for program
synthesis, they lack the global view needed to develop useful abstractions;
they generally predict programs one at a time, often repeating the same
functionality. Generating redundant code from scratch is both inefficient and
error-prone. To address this, we propose Refactoring for Generalizable
Abstraction Learning (ReGAL), a gradient-free method for learning a library of
reusable functions via code refactorization, i.e. restructuring code without
changing its execution output. ReGAL learns from a small set of existing
programs, iteratively verifying and refining its abstractions via execution. We
find that the shared function libraries discovered by ReGAL make programs
easier to predict across diverse domains. On three datasets (LOGO graphics
generation, Date reasoning, and TextCraft, a Minecraft-based text game), both
open-source and proprietary LLMs improve in accuracy when predicting programs
with ReGAL functions. For CodeLlama-13B, ReGAL results in absolute accuracy
increases of 11.5% on graphics, 26.1% on date understanding, and 8.1% on
TextCraft, outperforming GPT-3.5 in two of three domains. Our analysis reveals
ReGAL's abstractions encapsulate frequently-used subroutines as well as
environment dynamics.
</p>
</div>
</dd>
<dt><a name=item33>[33]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16468 title=Abstract>arXiv:2401.16468</a> [<a href=https://arxiv.org/pdf/2401.16468 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16468 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> High-Quality Image Restoration Following Human Instructions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geigle%2C+G">Gregor Geigle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Image restoration is a fundamental problem that involves recovering a
high-quality clean image from its degraded observation. All-In-One image
restoration models can effectively restore images from various types and levels
of degradation using degradation-specific information as prompts to guide the
restoration model. In this work, we present the first approach that uses
human-written instructions to guide the image restoration model. Given natural
language prompts, our model can recover high-quality images from their degraded
counterparts, considering multiple degradation types. Our method, InstructIR,
achieves state-of-the-art results on several restoration tasks including image
denoising, deraining, deblurring, dehazing, and (low-light) image enhancement.
InstructIR improves +1dB over previous all-in-one restoration methods.
Moreover, our dataset and results represent a novel benchmark for new research
on text-guided image restoration and enhancement. Our code, datasets and models
are available at: https://github.com/mv-lab/InstructIR
</p>
</div>
</dd>
<dt><a name=item34>[34]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16475 title=Abstract>arXiv:2401.16475</a> [<a href=https://arxiv.org/pdf/2401.16475 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16475 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trienes%2C+J">Jan Trienes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joseph%2C+S">Sebastian Joseph</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schl%C3%B6tterer%2C+J">Jörg Schlötterer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seifert%2C+C">Christin Seifert</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+K">Kyle Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J+J">Junyi Jessy Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Text simplification aims to make technical texts more accessible to laypeople
but often results in deletion of information and vagueness. This work proposes
InfoLossQA, a framework to characterize and recover simplification-induced
information loss in form of question-and-answer (QA) pairs. Building on the
theory of Question Under Discussion, the QA pairs are designed to help readers
deepen their knowledge of a text. We conduct a range of experiments with this
framework. First, we collect a dataset of 1,000 linguist-curated QA pairs
derived from 104 LLM simplifications of scientific abstracts of medical
studies. Our analyses of this data reveal that information loss occurs
frequently, and that the QA pairs give a high-level overview of what
information was lost. Second, we devise two methods for this task: end-to-end
prompting of open-source and commercial language models, and a natural language
inference pipeline. With a novel evaluation framework considering the
correctness of QA pairs and their linguistic suitability, our expert evaluation
reveals that models struggle to reliably identify information loss and applying
similar standards as humans at what constitutes information loss.
</p>
</div>
</dd>
<dt><a name=item35>[35]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16492 title=Abstract>arXiv:2401.16492</a> [<a href=https://arxiv.org/pdf/2401.16492 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16492 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GPU Cluster Scheduling for Network-Sensitive Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+A">Aakash Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhasi%2C+V+M">Vivek M. Bhasi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+S">Sonali Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kesidis%2C+G">George Kesidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kandemir%2C+M+T">Mahmut T. Kandemir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+C+R">Chita R. Das</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)
</div>
<p class=mathjax>We propose a novel GPU-cluster scheduler for distributed DL (DDL) workloads
that enables proximity based consolidation of GPU resources based on the DDL
jobs' sensitivities to the anticipated communication-network delays. Our
scheduler consists of three major components: (i) a classical delay scheduling
algorithm to facilitate job placement and consolidation; (ii) a
network-sensitive job preemption strategy; and (iii) an "auto-tuner" mechanism
to optimize delay timers for effective delay scheduling. Additionally, to
enable a cost-effective methodology for large-scale experiments, we develop a
data-driven DDL cluster simulation platform. Employing the simulation platform
we compare against several state-of-the-art alternatives on real-world workload
traces to demonstrate the benefits of our design. Our scheduler can provide
improvement of up to 69% in end-to-end Makespan for training all jobs compared
to the prevailing consolidation-based scheduling methods, while reducing the
average job completion time by up to 83% and minimizing the communication
overheads by up to 98% under congested networking conditions.
</p>
</div>
</dd>
<dt><a name=item36>[36]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16496 title=Abstract>arXiv:2401.16496</a> [<a href=https://arxiv.org/pdf/2401.16496 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16496 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Refined Inverse Rigging: A Balanced Approach to High-fidelity Blendshape Animation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rackovi%C4%87%2C+S">Stevo Racković</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soares%2C+C">Cláudia Soares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jakoveti%C4%87%2C+D">Dušan Jakovetić</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>
</div>
<p class=mathjax>In this paper, we present an advanced approach to solving the inverse rig
problem in blendshape animation, using high-quality corrective blendshapes. Our
algorithm introduces novel enhancements in three key areas: ensuring high data
fidelity in reconstructed meshes, achieving greater sparsity in weight
distributions, and facilitating smoother frame-to-frame transitions. While the
incorporation of corrective terms is a known practice, our method
differentiates itself by employing a unique combination of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-4-Frame tabindex=0><nobr><span class=math id=MathJax-Span-11 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.75em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-12><span class=msubsup id=MathJax-Span-13><span style=display:inline-block;position:relative;width:0.755em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-14 style=font-family:MathJax_Math-italic>l</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.292em><span class=mn id=MathJax-Span-15 style=font-size:70.7%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> norm
regularization for sparsity and a temporal smoothness constraint through
roughness penalty, focusing on the sum of second differences in consecutive
frame weights. A significant innovation in our approach is the temporal
decoupling of blendshapes, which permits simultaneous optimization across
entire animation sequences. This feature sets our work apart from existing
methods and contributes to a more efficient and effective solution. Our
algorithm exhibits a marked improvement in maintaining data fidelity and
ensuring smooth frame transitions when compared to prior approaches that either
lack smoothness regularization or rely solely on linear blendshape models. In
addition to superior mesh resemblance and smoothness, our method offers
practical benefits, including reduced computational complexity and execution
time, achieved through a novel parallelization strategy using clustering
methods. Our results not only advance the state of the art in terms of
fidelity, sparsity, and smoothness in inverse rigging but also introduce
significant efficiency improvements. The source code will be made available
upon acceptance of the paper.
</p>
</div>
</dd>
<dt><a name=item37>[37]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16497 title=Abstract>arXiv:2401.16497</a> [<a href=https://arxiv.org/pdf/2401.16497 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16497 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16497 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Discriminative Bayesian Gaussian Process Latent Variable Model for High-Dimensional Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziaei%2C+N">Navid Ziaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nazari%2C+B">Behzad Nazari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yousefi%2C+A">Ali Yousefi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 33 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Extracting meaningful information from high-dimensional data poses a
formidable modeling challenge, particularly when the data is obscured by noise
or represented through different modalities. In this research, we propose a
novel non-parametric modeling approach, leveraging the Gaussian Process (GP),
to characterize high-dimensional data by mapping it to a latent low-dimensional
manifold. This model, named the Latent Discriminative Generative Decoder
(LDGD), utilizes both the data (or its features) and associated labels (such as
category or stimulus) in the manifold discovery process. To infer the latent
variables, we derive a Bayesian solution, allowing LDGD to effectively capture
inherent uncertainties in the data while enhancing the model's predictive
accuracy and robustness. We demonstrate the application of LDGD on both
synthetic and benchmark datasets. Not only does LDGD infer the manifold
accurately, but its prediction accuracy in anticipating labels surpasses
state-of-the-art approaches. We have introduced inducing points to reduce the
computational complexity of Gaussian Processes (GPs) for large datasets. This
enhancement facilitates batch training, allowing for more efficient processing
and scalability in handling extensive data collections. Additionally, we
illustrate that LDGD achieves higher accuracy in predicting labels and operates
effectively with a limited training dataset, underscoring its efficiency and
effectiveness in scenarios where data availability is constrained. These
attributes set the stage for the development of non-parametric modeling
approaches in the analysis of high-dimensional data; especially in fields where
data are both high-dimensional and complex.
</p>
</div>
</dd>
<dt><a name=item38>[38]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16500 title=Abstract>arXiv:2401.16500</a> [<a href=https://arxiv.org/pdf/2401.16500 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16500 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Error detection using pneumatic logic
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoang%2C+S">Shane Hoang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shehada%2C+M">Mabel Shehada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patel%2C+Z">Zinal Patel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+M">Minh-Huy Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karydis%2C+K">Konstantinos Karydis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brisk%2C+P">Philip Brisk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grover%2C+W+H">William H. Grover</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 23 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Instrumentation and Detectors (physics.ins-det)
</div>
<p class=mathjax>Pneumatic systems are common in manufacturing, healthcare, transportation,
robotics, and many other fields. Failures in these systems can have very
serious consequences, particularly if they go undetected. In this work, we
present an air-powered error detector device that can detect and respond to
failures in pneumatically actuated systems. The device contains 21 monolithic
membrane valves that act like transistors in a pneumatic logic "circuit" that
uses vacuum to represent TRUE and atmospheric pressure as FALSE. Three
pneumatic exclusive-OR (XOR) gates are used to calculate the parity bit
corresponding to the values of several control bits. If the calculated value of
the parity bit differs from the expected value, then an error (like a leak or a
blocked air line) has been detected and the device outputs a pneumatic error
signal which can in turn be used to alert a user, shut down the system, or take
some other action. As a proof-of-concept, we used our pneumatic error detector
to monitor the operation of a medical device, an intermittent pneumatic
compression (IPC) device commonly used to prevent the formation of
life-threatening blood clots in the wearer's legs. Experiments confirm that
when the IPC device was damaged, the pneumatic error detector immediately
recognized the error (a leak) and alerted the wearer using sound. By providing
a simple and low-cost way to add fault detection to pneumatic actuation systems
without using sensors, our pneumatic error detector can promote safety and
reliability across the wide range of pneumatic systems.
</p>
</div>
</dd>
<dt><a name=item39>[39]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16501 title=Abstract>arXiv:2401.16501</a> [<a href=https://arxiv.org/pdf/2401.16501 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16501 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16501 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+T">Tony Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+M">Mason Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiajie Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Post%2C+C">Chase Post</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Charles%2C+E">Elijah Charles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmitz%2C+T">Tony Schmitz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper presents a modeling effort to explore the underlying physics of
temperature evolution during additive friction stir deposition (AFSD) by a
human-AI teaming approach. AFSD is an emerging solid-state additive
manufacturing technology that deposits materials without melting. However, both
process modeling and modeling of the AFSD tool are at an early stage. In this
paper, a human-AI teaming approach is proposed to combine models based on first
principles with AI. The resulting human-informed machine learning method,
denoted as AFSD-Physics, can effectively learn the governing equations of
temperature evolution at the tool and the build from in-process measurements.
Experiments are designed and conducted to collect in-process measurements for
the deposition of aluminum 7075 with a total of 30 layers. The acquired
governing equations are physically interpretable models with low computational
cost and high accuracy. Model predictions show good agreement with the
measurements. Experimental validation with new process parameters demonstrates
the model's generalizability and potential for use in tool temperature control
and process optimization.
</p>
</div>
</dd>
<dt><a name=item40>[40]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16504 title=Abstract>arXiv:2401.16504</a> [<a href=https://arxiv.org/pdf/2401.16504 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16504 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Effect of recommending users and opinions on the network connectivity and idea generation process
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pandey%2C+S">Sriniwas Pandey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sayama%2C+H">Hiroki Sayama</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 3 Figuers
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>The growing reliance on online services underscores the crucial role of
recommendation systems, especially on social media platforms seeking increased
user engagement. This study investigates how recommendation systems influence
the impact of personal behavioral traits on social network dynamics. It
explores the interplay between homophily, users' openness to novel ideas, and
recommendation-driven exposure to new opinions. Additionally, the research
examines the impact of recommendation systems on the diversity of newly
generated ideas, shedding light on the challenges and opportunities in
designing effective systems that balance the exploration of new ideas with the
risk of reinforcing biases or filtering valuable, unconventional concepts.
</p>
</div>
</dd>
<dt><a name=item41>[41]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16509 title=Abstract>arXiv:2401.16509</a> [<a href=https://arxiv.org/pdf/2401.16509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dissecting users' needs for search result explanations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Juneja%2C+P">Prerna Juneja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenjuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith-Renner%2C+A+M">Alison Marie Smith-Renner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lamba%2C+H">Hemank Lamba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tetreault%2C+J">Joel Tetreault</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaimes%2C+A">Alex Jaimes</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>There is a growing demand for transparency in search engines to understand
how search results are curated and to enhance users' trust. Prior research has
introduced search result explanations with a focus on how to explain, assuming
explanations are beneficial. Our study takes a step back to examine if search
explanations are needed and when they are likely to provide benefits.
Additionally, we summarize key characteristics of helpful explanations and
share users' perspectives on explanation features provided by Google and Bing.
Interviews with non-technical individuals reveal that users do not always seek
or understand search explanations and mostly desire them for complex and
critical tasks. They find Google's search explanations too obvious but
appreciate the ability to contest search results. Based on our findings, we
offer design recommendations for search engines and explanations to help users
better evaluate search results and enhance their search experience.
</p>
</div>
</dd>
<dt><a name=item42>[42]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16515 title=Abstract>arXiv:2401.16515</a> [<a href=https://arxiv.org/pdf/2401.16515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Electro-Optic Analog Memory for Neuromorphic Photonic Computing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lam%2C+S">Sean Lam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaled%2C+A">Ahmed Khaled</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bilodeau%2C+S">Simon Bilodeau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marquez%2C+B+A">Bicky A. Marquez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prucnal%2C+P+R">Paul R. Prucnal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chrostowski%2C+L">Lukas Chrostowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shastri%2C+B+J">Bhavin J. Shastri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shekhar%2C+S">Sudip Shekhar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Emerging Technologies (cs.ET)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY); Optics (physics.optics)
</div>
<p class=mathjax>Artificial intelligence (AI) has seen remarkable advancements across various
domains, including natural language processing, computer vision, autonomous
vehicles, and biology. However, the rapid expansion of AI technologies has
escalated the demand for more powerful computing resources. As digital
computing approaches fundamental limits, neuromorphic photonics emerges as a
promising platform to complement existing digital systems. In neuromorphic
photonic computing, photonic devices are controlled using analog signals. This
necessitates the use of digital-to-analog converters (DAC) and
analog-to-digital converters (ADC) for interfacing with these devices during
inference and training. However, data movement between memory and these
converters in conventional von Neumann computing architectures consumes energy.
To address this, analog memory co-located with photonic computing devices is
proposed. This approach aims to reduce the reliance on DACs and ADCs and
minimize data movement to enhance compute efficiency. This paper demonstrates a
monolithically integrated neuromorphic photonic circuit with co-located
capacitive analog memory and compares various analog memory technologies for
neuromorphic photonic computing using the MNIST dataset as a benchmark.
</p>
</div>
</dd>
<dt><a name=item43>[43]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16519 title=Abstract>arXiv:2401.16519</a> [<a href=https://arxiv.org/pdf/2401.16519 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16519 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extending the kinematic theory of rapid movements with new primitives
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaz%2C+M">Moises Diaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quintana%2C+J+J">Jose J. Quintana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted version: published on Pattern Recognition Letters [ISSN 0167-8655], v. 167, p. 181-188, (Marzo 2023)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Pattern Recognition Letters, 167, 181-188,2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The Kinematic Theory of rapid movements, and its associated Sigma-Lognormal,
model 2D spatiotemporal trajectories. It is constructed mainly as a temporal
overlap of curves between virtual target points. Specifically, it uses an arc
and a lognormal as primitives for the representation of the trajectory and
velocity, respectively. This paper proposes developing this model, in what we
call the Kinematic Theory Transform, which establishes a mathematical framework
that allows further primitives to be used. Mainly, we evaluate Euler curves to
link virtual target points and Gaussian, Beta, Gamma, Double-bounded lognormal,
and Generalized Extreme Value functions to model the bell-shaped velocity
profile. Using these primitives, we report reconstruction results with
spatiotemporal trajectories executed by human beings, animals, and
anthropomorphic robots.
</p>
</div>
</dd>
<dt><a name=item44>[44]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16520 title=Abstract>arXiv:2401.16520</a> [<a href=https://arxiv.org/pdf/2401.16520 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16520 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MT-HCCAR: Multi-Task Deep Learning with Hierarchical Classification and Attention-based Regression for Cloud Property Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xingyan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sayer%2C+A+M">Andrew M. Sayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+I+T">Ian T. Carroll</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 3 figures, submitted to 40th IEEE International Conference on Data Engineering (ICDE 2024, website: <a href=https://icde2024.github.io/CFP_research.html>this https URL</a>)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)
</div>
<p class=mathjax>In the realm of Earth science, effective cloud property retrieval,
encompassing cloud masking, cloud phase classification, and cloud optical
thickness (COT) prediction, remains pivotal. Traditional methodologies
necessitate distinct models for each sensor instrument due to their unique
spectral characteristics. Recent strides in Earth Science research have
embraced machine learning and deep learning techniques to extract features from
satellite datasets' spectral observations. However, prevailing approaches lack
novel architectures accounting for hierarchical relationships among retrieval
tasks. Moreover, considering the spectral diversity among existing sensors, the
development of models with robust generalization capabilities over different
sensor datasets is imperative. Surprisingly, there is a dearth of methodologies
addressing the selection of an optimal model for diverse datasets. In response,
this paper introduces MT-HCCAR, an end-to-end deep learning model employing
multi-task learning to simultaneously tackle cloud masking, cloud phase
retrieval (classification tasks), and COT prediction (a regression task). The
MT-HCCAR integrates a hierarchical classification network (HC) and a
classification-assisted attention-based regression network (CAR), enhancing
precision and robustness in cloud labeling and COT prediction. Additionally, a
comprehensive model selection method rooted in K-fold cross-validation, one
standard error rule, and two introduced performance scores is proposed to
select the optimal model over three simulated satellite datasets OCI, VIIRS,
and ABI. The experiments comparing MT-HCCAR with baseline methods, the ablation
studies, and the model selection affirm the superiority and the generalization
capabilities of MT-HCCAR.
</p>
</div>
</dd>
<dt><a name=item45>[45]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16521 title=Abstract>arXiv:2401.16521</a> [<a href=https://arxiv.org/pdf/2401.16521 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16521 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16521 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhengguang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This work undertakes studies to evaluate Interpretability Methods for
Time-Series Deep Learning. Sensitivity analysis assesses how input changes
affect the output, constituting a key component of interpretation. Among the
post-hoc interpretation methods such as back-propagation, perturbation, and
approximation, my work will investigate perturbation-based sensitivity Analysis
methods on modern Transformer models to benchmark their performances.
Specifically, my work answers three research questions: 1) Do different
sensitivity analysis (SA) methods yield comparable outputs and attribute
importance rankings? 2) Using the same sensitivity analysis method, do
different Deep Learning (DL) models impact the output of the sensitivity
analysis? 3) How well do the results from sensitivity analysis methods align
with the ground truth?
</p>
</div>
</dd>
<dt><a name=item46>[46]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16522 title=Abstract>arXiv:2401.16522</a> [<a href=https://arxiv.org/pdf/2401.16522 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16522 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dropout Concrete Autoencoder for Band Selection on HSI Scenes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ahishali%2C+M">Mete Ahishali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Deep learning-based informative band selection methods on hyperspectral
images (HSI) recently have gained intense attention to eliminate spectral
correlation and redundancies. However, the existing deep learning-based methods
either need additional post-processing strategies to select the descriptive
bands or optimize the model indirectly, due to the parameterization inability
of discrete variables for the selection procedure. To overcome these
limitations, this work proposes a novel end-to-end network for informative band
selection. The proposed network is inspired by the advances in concrete
autoencoder (CAE) and dropout feature ranking strategy. Different from the
traditional deep learning-based methods, the proposed network is trained
directly given the required band subset eliminating the need for further
post-processing. Experimental results on four HSI scenes show that the proposed
dropout CAE achieves substantial and effective performance levels outperforming
the competing methods.
</p>
</div>
</dd>
<dt><a name=item47>[47]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16526 title=Abstract>arXiv:2401.16526</a> [<a href=https://arxiv.org/pdf/2401.16526 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16526 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FPGA Technology Mapping Using Sketch-Guided Program Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+G+H">Gus Henry Smith</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kushigian%2C+B">Ben Kushigian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Canumalla%2C+V">Vishal Canumalla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+A">Andrew Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyubomirsky%2C+S">Steven Lyubomirsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porncharoenwase%2C+S">Sorawee Porncharoenwase</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Just%2C+R">René Just</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernstein%2C+G+L">Gilbert Louis Bernstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tatlock%2C+Z">Zachary Tatlock</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Programming Languages (cs.PL)
</div>
<p class=mathjax>FPGA technology mapping is the process of implementing a hardware design
expressed in high-level HDL (hardware design language) code using the
low-level, architecture-specific primitives of the target FPGA. As FPGAs become
increasingly heterogeneous, achieving high performance requires hardware
synthesis tools that better support mapping to complex, highly configurable
primitives like digital signal processors (DSPs). Current tools support DSP
mapping via handwritten special-case mapping rules, which are laborious to
write, error-prone, and often overlook mapping opportunities. We introduce
Lakeroad, a principled approach to technology mapping via sketch-guided program
synthesis. Lakeroad leverages two techniques -- architecture-independent sketch
templates and semantics extraction from HDL -- to provide extensible technology
mapping with stronger correctness guarantees and higher coverage of mapping
opportunities than state-of-the-art tools. Across representative
microbenchmarks, Lakeroad produces 2--3.5<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-5-Frame tabindex=0><nobr><span class=math id=MathJax-Span-16 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-17><span class=mo id=MathJax-Span-18 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> the number of optimal
mappings compared to proprietary state-of-the-art tools and 6--44<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-6-Frame tabindex=0><nobr><span class=math id=MathJax-Span-19 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-20><span class=mo id=MathJax-Span-21 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> the
number of optimal mappings compared to popular open-source tools, while also
providing correctness guarantees not given by any other tool.
</p>
</div>
</dd>
<dt><a name=item48>[48]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16529 title=Abstract>arXiv:2401.16529</a> [<a href=https://arxiv.org/pdf/2401.16529 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16529 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unleashing the Power of Preemptive Priority-based Scheduling for Real-Time GPU Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yidi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Cong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+D">Daniel Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyoseung Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)
</div>
<p class=mathjax>Scheduling real-time tasks that utilize GPUs with analyzable guarantees poses
a significant challenge due to the intricate interaction between CPU and GPU
resources, as well as the complex GPU hardware and software stack. While much
research has been conducted in the real-time research community, several
limitations persist, including the absence or limited availability of
preemption, extended blocking times, and/or the need for extensive
modifications to program code. In this paper, we propose two novel techniques,
namely the kernel thread and IOCTL-based approaches, to enable preemptive
priority-based scheduling for real-time GPU tasks. Our approaches exert control
over GPU context scheduling at the device driver level and enable preemptive
GPU scheduling based on task priorities. The kernel thread-based approach
achieves this without requiring modifications to user-level programs, while the
IOCTL-based approach needs only a single macro at the boundaries of GPU access
segments. In addition, we provide a comprehensive response time analysis that
takes into account overlaps between different task segments, mitigating
pessimism in worst-case estimates. Through empirical evaluations and case
studies, we demonstrate the effectiveness of the proposed approaches in
improving taskset schedulability and timeliness of real-time tasks. The results
highlight significant improvements over prior work, with up to 40\% higher
schedulability, while also achieving predictable worst-case behavior on Nvidia
Jetson embedded platforms.
</p>
</div>
</dd>
<dt><a name=item49>[49]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16530 title=Abstract>arXiv:2401.16530</a> [<a href=https://arxiv.org/pdf/2401.16530 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16530 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RL-Based Hyperparameter Selection for Spectrum Sensing With CNNs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehrabian%2C+A">Amir Mehrabian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabbaghian%2C+M">Maryam Sabbaghian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Communications, Jan. 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Selection of hyperparameters in deep neural networks is a challenging problem
due to the wide search space and emergence of various layers with specific
hyperparameters. There exists an absence of consideration for the neural
architecture selection of convolutional neural networks (CNNs) for spectrum
sensing. Here, we develop a method using reinforcement learning and Q-learning
to systematically search and evaluate various architectures for generated
datasets including different signals and channels in the spectrum sensing
problem. We show by extensive simulations that CNN-based detectors proposed by
our developed method outperform several detectors in the literature. For the
most complex dataset, the proposed approach provides 9% enhancement in accuracy
at the cost of higher computational complexity. Furthermore, a novel method
using multi-armed bandit model for selection of the sensing time is proposed to
achieve higher throughput and accuracy while minimizing the consumed energy.
The method dynamically adjusts the sensing time under the time-varying
condition of the channel without prior information. We demonstrate through a
simulated scenario that the proposed method improves the achieved reward by
about 20% compared to the conventional policies. Consequently, this study
effectively manages the selection of important hyperparameters for CNN-based
detectors offering superior performance of cognitive radio network.
</p>
</div>
</dd>
<dt><a name=item50>[50]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16534 title=Abstract>arXiv:2401.16534</a> [<a href=https://arxiv.org/pdf/2401.16534 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16534 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Democratizing the Creation of Animatable Facial Avatars
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yilin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Omens%2C+D">Dalton Omens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+H">Haodi He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fedkiw%2C+R">Ron Fedkiw</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>In high-end visual effects pipelines, a customized (and expensive) light
stage system is (typically) used to scan an actor in order to acquire both
geometry and texture for various expressions. Aiming towards democratization,
we propose a novel pipeline for obtaining geometry and texture as well as
enough expression information to build a customized person-specific animation
rig without using a light stage or any other high-end hardware (or manual
cleanup). A key novel idea consists of warping real-world images to align with
the geometry of a template avatar and subsequently projecting the warped image
into the template avatar's texture; importantly, this allows us to leverage
baked-in real-world lighting/texture information in order to create surrogate
facial features (and bridge the domain gap) for the sake of geometry
reconstruction. Not only can our method be used to obtain a neutral expression
geometry and de-lit texture, but it can also be used to improve avatars after
they have been imported into an animation system (noting that such imports tend
to be lossy, while also hallucinating various features). Since a default
animation rig will contain template expressions that do not correctly
correspond to those of a particular individual, we use a Simon Says approach to
capture various expressions and build a person-specific animation rig (that
moves like they do). Our aforementioned warping/projection method has high
enough efficacy to reconstruct geometry corresponding to each expressions.
</p>
</div>
</dd>
<dt><a name=item51>[51]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16536 title=Abstract>arXiv:2401.16536</a> [<a href=https://arxiv.org/pdf/2401.16536 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16536 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Saccade-Contingent Rendering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwak%2C+Y">Yuna Kwak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Penner%2C+E">Eric Penner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeedpour-Parizi%2C+M+R">Mohammad R. Saeedpour-Parizi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mercier%2C+O">Olivier Mercier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiuyun Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murdison%2C+T+S">T. Scott Murdison</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guan%2C+P">Phillip Guan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> main paper and supplementary materials
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Battery-constrained power consumption, compute limitations, and high frame
rate requirements in head-mounted displays present unique challenges in the
drive to present increasingly immersive and comfortable imagery in virtual
reality. However, humans are not equally sensitive to all regions of the visual
field, and perceptually-optimized rendering techniques are increasingly
utilized to address these bottlenecks. Many of these techniques are
gaze-contingent and often render reduced detail away from a user's fixation.
Such techniques are dependent on spatio-temporally-accurate gaze tracking and
can result in obvious visual artifacts when eye tracking is inaccurate. In this
work we present a gaze-contingent rendering technique which only requires
saccade detection, bypassing the need for highly-accurate eye tracking. In our
first experiment, we show that visual acuity is reduced for several hundred
milliseconds after a saccade. In our second experiment, we use these results to
reduce the rendered image resolution after saccades in a controlled
psychophysical setup, and find that observers cannot discriminate between
saccade-contingent reduced-resolution rendering and full-resolution rendering.
Finally, in our third experiment, we introduce a 90 pixels per degree headset
and validate our saccade-contingent rendering method under typical VR viewing
conditions.
</p>
</div>
</dd>
<dt><a name=item52>[52]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16537 title=Abstract>arXiv:2401.16537</a> [<a href=https://arxiv.org/pdf/2401.16537 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16537 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16537 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Observation Time Window Segmentation for Administrative Data Machine Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taib%2C+M">Musa Taib</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Messier%2C+G+G">Geoffrey G. Messier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Utilizing administrative data to predict outcomes is an important application
area of machine learning, particularly in healthcare. Most administrative data
records are timestamped and the pattern of records over time is a key input for
machine learning models. This paper explores how best to divide the observation
window of a machine learning model into time segments or "bins". A
computationally efficient process is presented that identifies which data
features benefit most from smaller, higher resolution time segments. Results
generated on healthcare and housing/homelessness administrative data
demonstrate that optimizing the time bin size of these high priority features
while using a single time bin for the other features achieves machine learning
models that are simpler and quicker to train. This approach also achieves
similar and sometimes better performance than more complex models that default
to representing all data features with the same time resolution.
</p>
</div>
</dd>
<dt><a name=item53>[53]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16540 title=Abstract>arXiv:2401.16540</a> [<a href=https://arxiv.org/pdf/2401.16540 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16540 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16540 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Combinatorial Group Testing: Bridging the Gap between Union-Free and Disjunctive Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goshkoder%2C+D">Daniil Goshkoder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Polyanskii%2C+N">Nikita Polyanskii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vorobyev%2C+I">Ilya Vorobyev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This work focuses on non-adaptive group testing, with a primary goal of
efficiently identifying a set of at most <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-7-Frame tabindex=0><nobr><span class=math id=MathJax-Span-22 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-23><span class=mi id=MathJax-Span-24 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> defective elements among a given
set of elements using the fewest possible number of tests. Non-adaptive
combinatorial group testing often employs disjunctive codes and union-free
codes. This paper discusses union-free codes with fast decoding (UFFD codes), a
recently introduced class of union-free codes that combine the best of both
worlds -- the linear complexity decoding of disjunctive codes and the fewest
number of tests of union-free codes. In our study, we distinguish two
subclasses of these codes -- one subclass, denoted as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-8-Frame tabindex=0><nobr><span class=math id=MathJax-Span-25 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-26><span class=mo id=MathJax-Span-27 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-28 style=font-family:MathJax_Main>=</span><span class=mi id=MathJax-Span-29 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-30 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-UFFD codes, can be
used when the number of defectives <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-9-Frame tabindex=0><nobr><span class=math id=MathJax-Span-31 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-32><span class=mi id=MathJax-Span-33 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a priori known, whereas <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-10-Frame tabindex=0><nobr><span class=math id=MathJax-Span-34 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-35><span class=mo id=MathJax-Span-36 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-37 style=font-family:MathJax_Main>≤</span><span class=mi id=MathJax-Span-38 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-39 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-UFFD codes works for any subset of at most <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-11-Frame tabindex=0><nobr><span class=math id=MathJax-Span-40 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-41><span class=mi id=MathJax-Span-42 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> defectives. Previous studies
have established a lower bound on the rate of these codes for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-12-Frame tabindex=0><nobr><span class=math id=MathJax-Span-43 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-44><span class=mi id=MathJax-Span-45 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-46 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-47 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. Our
contribution lies in deriving new lower bounds on the rate for both <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-13-Frame tabindex=0><nobr><span class=math id=MathJax-Span-48 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-49><span class=mo id=MathJax-Span-50 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-51 style=font-family:MathJax_Main>=</span><span class=mi id=MathJax-Span-52 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-53 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>- and
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-14-Frame tabindex=0><nobr><span class=math id=MathJax-Span-54 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-55><span class=mo id=MathJax-Span-56 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-57 style=font-family:MathJax_Main>≤</span><span class=mi id=MathJax-Span-58 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-59 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-UFFD codes for an arbitrary number <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-15-Frame tabindex=0><nobr><span class=math id=MathJax-Span-60 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-61><span class=mi id=MathJax-Span-62 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-63 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-64 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> of defectives. Our
results show that for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-16-Frame tabindex=0><nobr><span class=math id=MathJax-Span-65 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.07em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-66><span class=mi id=MathJax-Span-67 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-68 style=font-family:MathJax_Main;padding-left:0.292em>→</span><span class=mi id=MathJax-Span-69 style=font-family:MathJax_Main;padding-left:0.292em>∞</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, the rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-17-Frame tabindex=0><nobr><span class=math id=MathJax-Span-70 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-71><span class=mo id=MathJax-Span-72 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-73 style=font-family:MathJax_Main>=</span><span class=mi id=MathJax-Span-74 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-75 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-UFFD codes is twice as
large as the best-known lower bound on the rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-18-Frame tabindex=0><nobr><span class=math id=MathJax-Span-76 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-77><span class=mi id=MathJax-Span-78 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-disjunctive codes. In
addition, the rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-19-Frame tabindex=0><nobr><span class=math id=MathJax-Span-79 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.26em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-80><span class=mo id=MathJax-Span-81 style=font-family:MathJax_Main>(</span><span class=mo id=MathJax-Span-82 style=font-family:MathJax_Main>≤</span><span class=mi id=MathJax-Span-83 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-84 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-UFFD code is shown to be better than the known
lower bound on the rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-20-Frame tabindex=0><nobr><span class=math id=MathJax-Span-85 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-86><span class=mi id=MathJax-Span-87 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-disjunctive codes for small values of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-21-Frame tabindex=0><nobr><span class=math id=MathJax-Span-88 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-89><span class=mi id=MathJax-Span-90 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item54>[54]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16541 title=Abstract>arXiv:2401.16541</a> [<a href=https://arxiv.org/pdf/2401.16541 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16541 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GuReT: Distinguishing Guilt and Regret related Text
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butt%2C+S">Sabur Butt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balouchzahi%2C+F">Fazlourrahman Balouchzahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meque%2C+A+G+M">Abdul Gafar Manuel Meque</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amjad%2C+M">Maaz Amjad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cancino%2C+H+G+C">Hector G. Ceballos Cancino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sidorov%2C+G">Grigori Sidorov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gelbukh%2C+A">Alexander Gelbukh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The intricate relationship between human decision-making and emotions,
particularly guilt and regret, has significant implications on behavior and
well-being. Yet, these emotions subtle distinctions and interplay are often
overlooked in computational models. This paper introduces a dataset tailored to
dissect the relationship between guilt and regret and their unique textual
markers, filling a notable gap in affective computing research. Our approach
treats guilt and regret recognition as a binary classification task and employs
three machine learning and six transformer-based deep learning techniques to
benchmark the newly created dataset. The study further implements innovative
reasoning methods like chain-of-thought and tree-of-thought to assess the
models interpretive logic. The results indicate a clear performance edge for
transformer-based models, achieving a 90.4% macro F1 score compared to the
85.3% scored by the best machine learning classifier, demonstrating their
superior capability in distinguishing complex emotional states.
</p>
</div>
</dd>
<dt><a name=item55>[55]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16543 title=Abstract>arXiv:2401.16543</a> [<a href=https://arxiv.org/pdf/2401.16543 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16543 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> KFVM-WENO: A high-order accurate kernel-based finite volume method for compressible hydrodynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=May%2C+I+C+T">Ian C. T. May</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+D">Dongwook Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to ApJ. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2304.03823>arXiv:2304.03823</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>This paper presents a fully multidimensional kernel-based reconstruction
scheme for finite volume methods applied to systems of hyperbolic conservation
laws, with a particular emphasis on the compressible Euler equations.
Non-oscillatory reconstruction is achieved through an adaptive order weighted
essentially non-oscillatory (WENO-AO) method cast into a form suited to
multidimensional reconstruction. A kernel-based approach inspired by radial
basis functions (RBF) and Gaussian process (GP) modeling, which we call
KFVM-WENO, is presented here. This approach allows the creation of a scheme of
arbitrary order of accuracy with simply defined multidimensional stencils and
substencils. Furthermore, the fully multidimensional nature of the
reconstruction allows for a more straightforward extension to higher spatial
dimensions and removes the need for complicated boundary conditions on
intermediate quantities in modified dimension-by-dimension methods. In
addition, a new simple-yet-effective set of reconstruction variables is
introduced, which could be useful in existing schemes with little modification.
The proposed scheme is applied to a suite of stringent and informative
benchmark problems to demonstrate its efficacy and utility. A highly parallel
multi-GPU implementation using Kokkos and the message passing interface (MPI)
is also provided.
</p>
</div>
</dd>
<dt><a name=item56>[56]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16545 title=Abstract>arXiv:2401.16545</a> [<a href=https://arxiv.org/pdf/2401.16545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16545 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Public Cloud Infrastructure for Real-time Connected Vehicle Speed Advisory at a Signalized Corridor
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+H">Hsien-Wen Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salek%2C+M+S">M Sabbir Salek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhury%2C+M">Mashrur Chowdhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shue%2C+M">Mitch Shue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Apon%2C+A+W">Amy W. Apon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>In this study, we developed a real-time connected vehicle (CV) speed advisory
application that uses public cloud services and tested it on a simulated
signalized corridor for different roadway traffic conditions. First, we
developed a scalable serverless cloud computing architecture leveraging public
cloud services offered by Amazon Web Services (AWS) to support the requirements
of a real-time CV application. Second, we developed an optimization-based
real-time CV speed advisory algorithm by taking a modular design approach,
which makes the application automatically scalable and deployable in the cloud
using the serverless architecture. Third, we developed a cloud-in-the-loop
simulation testbed using AWS and an open-source microscopic roadway traffic
simulator called Simulation of Urban Mobility (SUMO). Our analyses based on
different roadway traffic conditions showed that the serverless CV speed
advisory application meets the latency requirement of real-time CV mobility
applications. Besides, our serverless CV speed advisory application reduced the
average stopped delay (by 77%) and the aggregated risk of collision (by 21%) at
signalized intersection of a corridor. These prove the feasibility as well as
the efficacy of utilizing public cloud infrastructure to implement real-time
roadway traffic management applications in a CV environment.
</p>
</div>
</dd>
<dt><a name=item57>[57]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16547 title=Abstract>arXiv:2401.16547</a> [<a href=https://arxiv.org/pdf/2401.16547 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16547 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generating Bindings in MPICH
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hui Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raffenetti%2C+K">Ken Raffenetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bland%2C+W">Wesley Bland</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yanfei Guo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The MPI Forum has recently adopted a Python scripting engine for generating
the API text in the standard document. As a by-product, it made available
reliable and rich descriptions of all MPI functions that are suited for
scripting tools. Using these extracted API information, we developed a Python
code generation toolbox to generate the language binding layers in MPICH. The
toolbox replaces nearly 70,000 lines of manually maintained C and Fortran 2008
binding code with around 5,000 lines of Python scripts plus some simple
configuration. In addition to completely eliminating code duplication in the
binding layer and avoiding bugs from manual code copying , the code generation
also minimizes the effort for API extension and code instrumentation. This is
demonstrated in our implementation of MPI-4 large count functions and the
prototyping of a next generation MPI profiling interface, QMPI.
</p>
</div>
</dd>
<dt><a name=item58>[58]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16549 title=Abstract>arXiv:2401.16549</a> [<a href=https://arxiv.org/pdf/2401.16549 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16549 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16549 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Learning for Multi-Label Learning: A Comprehensive Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tarekegn%2C+A+N">Adane Nega Tarekegn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ullah%2C+M">Mohib Ullah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheikh%2C+F+A">Faouzi Alaya Cheikh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 12 figures, 5 tables. This paper is submitted to IEEE Transactions on Knowledge and Data Engineering and it is currently under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Multi-label learning is a rapidly growing research area that aims to predict
multiple labels from a single input data point. In the era of big data, tasks
involving multi-label classification (MLC) or ranking present significant and
intricate challenges, capturing considerable attention in diverse domains.
Inherent difficulties in MLC include dealing with high-dimensional data,
addressing label correlations, and handling partial labels, for which
conventional methods prove ineffective. Recent years have witnessed a notable
increase in adopting deep learning (DL) techniques to address these challenges
more effectively in MLC. Notably, there is a burgeoning effort to harness the
robust learning capabilities of DL for improved modelling of label dependencies
and other challenges in MLC. However, it is noteworthy that comprehensive
studies specifically dedicated to DL for multi-label learning are limited.
Thus, this survey aims to thoroughly review recent progress in DL for
multi-label learning, along with a summary of open research problems in MLC.
The review consolidates existing research efforts in DL for MLC,including deep
neural networks, transformers, autoencoders, and convolutional and recurrent
architectures. Finally, the study presents a comparative analysis of the
existing methods to provide insightful observations and stimulate future
research directions in this domain.
</p>
</div>
</dd>
<dt><a name=item59>[59]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16551 title=Abstract>arXiv:2401.16551</a> [<a href=https://arxiv.org/pdf/2401.16551 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16551 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Frustrated with MPI+Threads? Try MPIxThreads!
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hui Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raffenetti%2C+K">Ken Raffenetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junchao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yanfei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thakur%2C+R">Rajeev Thakur</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>MPI+Threads, embodied by the MPI/OpenMP hybrid programming model, is a
parallel programming paradigm where threads are used for on-node shared-memory
parallelization and MPI is used for multi-node distributed-memory
parallelization. OpenMP provides an incremental approach to parallelize code,
while MPI, with its isolated address space and explicit messaging API, affords
straightforward paths to obtain good parallel performance. However, MPI+Threads
is not an ideal solution. Since MPI is unaware of the thread context, it cannot
be used for interthread communication. This results in duplicated efforts to
create separate and sometimes nested solutions for similar parallel tasks. In
addition, because the MPI library is required to obey message-ordering
semantics, mixing threads and MPI via MPI_THREAD_MULTIPLE can easily result in
miserable performance due to accidental serializations.
<br>We propose a new MPI extension, MPIX Thread Communicator (threadcomm), that
allows threads to be assigned distinct MPI ranks within thread parallel
regions. The threadcomm extension combines both MPI processes and OpenMP
threads to form a unified parallel environment. We show that this MPIxThreads
(MPI Multiply Threads) paradigm allows OpenMP and MPI to work together in a
complementary way to achieve both cleaner codes and better performance.
</p>
</div>
</dd>
<dt><a name=item60>[60]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16552 title=Abstract>arXiv:2401.16552</a> [<a href=https://arxiv.org/pdf/2401.16552 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16552 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ONDA: ONline Database Architect
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laranjeiro%2C+N">Nuno Laranjeiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pinto%2C+A+M">Alexandre Miguel Pinto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>Database modeling is a key activity towards the fulfillment of storage
requirements. Despite the availability of several database modeling tools for
developers, these often come with associated costs, setup complexities,
usability challenges, or dependency on specific operating systems. In this
paper we present ONDA, a web-based tool developed at the University of Coimbra,
that allows the creation of Entity-Relationship diagrams, visualization of
physical models, and generation of SQL code for various database engines. ONDA
is freely available at https://onda.dei.uc.pt and was created with the
intention of supporting teaching activities at university-level database
courses. At the time of writing, the tool being used by more than three hundred
university students every academic year.
</p>
</div>
</dd>
<dt><a name=item61>[61]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16553 title=Abstract>arXiv:2401.16553</a> [<a href=https://arxiv.org/pdf/2401.16553 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16553 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SelectLLM: Can LLMs Select Important Instructions to Annotate?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parkar%2C+R+S">Ritik Sachin Parkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J+I">Jong Inn Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> First Authors: Ritik Sachin Parkar and Jaehyung Kim | Second Author: Jong Inn Park | PI: Dongyeop Kang
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Training large language models (LLMs) with a large and diverse instruction
dataset aligns the models to comprehend and follow human instructions. Recent
works have shown that using a small set of high-quality instructions can
outperform using large yet more noisy ones. Because instructions are unlabeled
and their responses are natural text, traditional active learning schemes with
the model's confidence cannot be directly applied to the selection of unlabeled
instructions. In this work, we propose a novel method for instruction
selection, called SelectLLM, that leverages LLMs for the selection of
high-quality instructions. Our high-level idea is to use LLMs to estimate the
usefulness and impactfulness of each instruction without the corresponding
labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing
the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to
multiple clusters, and then prompting LLMs to choose high-quality instructions
within each cluster. SelectLLM showed comparable or slightly better performance
on the popular instruction benchmarks, compared to the recent state-of-the-art
selection methods. All code and data are publicly available
(https://github.com/minnesotanlp/select-llm).
</p>
</div>
</dd>
<dt><a name=item62>[62]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16557 title=Abstract>arXiv:2401.16557</a> [<a href=https://arxiv.org/pdf/2401.16557 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16557 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16557 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discontinuous PWM Strategy with Frequency Modulation for Vibration Reduction in Asynchronous Machines
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ruiz-Gonzalez%2C+A">A Ruiz-Gonzalez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Heredia-Larrubia%2C+J">JR Heredia-Larrubia</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Perez-Hidalgo%2C+F">FM Perez-Hidalgo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Meco-Gutierrez%2C+M">M Meco-Gutierrez</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Machines: Machinery and Automation Vol.11 n7 Pag.705 (2023/7/3)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The objective of this research is to mitigate vibrations in induction motors.
To achieve this goal, a discontinuous pulse width modulation (PWM) control
strategy based on carrier wave modulation is proposed for multilevel inverters.
This study provides justification for the reduction of machine vibrations
compared to existing control techniques documented in the technical literature.
Additionally, the proposed technique offers the advantage of attenuating the
Total Harmonic Distortion of the multilevel inverter's output voltage while
simultaneously achieving a higher RMS value for the same DC level. By modifying
a parameter of the carrier wave, the control strategy allows for variations in
the electrical spectrum while avoiding natural mechanical resonance
frequencies, thereby reducing motor vibrations. Laboratory results
demonstrating the application of different modulation strategies in a
multilevel inverter for an induction motor and a comparison with the presented
strategy are provided
</p>
</div>
</dd>
<dt><a name=item63>[63]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16558 title=Abstract>arXiv:2401.16558</a> [<a href=https://arxiv.org/pdf/2401.16558 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16558 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumann%2C+T">Terrence Neumann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Sooyong Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De-Arteaga%2C+M">Maria De-Arteaga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fazelpour%2C+S">Sina Fazelpour</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lease%2C+M">Matthew Lease</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>The pervasive spread of misinformation and disinformation poses a significant
threat to society. Professional fact-checkers play a key role in addressing
this threat, but the vast scale of the problem forces them to prioritize their
limited resources. This prioritization may consider a range of factors, such as
varying risks of harm posed to specific groups of people. In this work, we
investigate potential implications of using a large language model (LLM) to
facilitate such prioritization. Because fact-checking impacts a wide range of
diverse segments of society, it is important that diverse views are represented
in the claim prioritization process. This paper examines whether a LLM can
reflect the views of various groups when assessing the harms of misinformation,
focusing on gender as a primary variable. We pose two central questions: (1) To
what extent do prompts with explicit gender references reflect gender
differences in opinion in the United States on topics of social relevance? and
(2) To what extent do gender-neutral prompts align with gendered viewpoints on
those topics? To analyze these questions, we present the TopicMisinfo dataset,
containing 160 fact-checked claims from diverse topics, supplemented by nearly
1600 human annotations with subjective perceptions and annotator demographics.
Analyzing responses to gender-specific and neutral prompts, we find that GPT
3.5-Turbo reflects empirically observed gender differences in opinion but
amplifies the extent of these differences. These findings illuminate AI's
complex role in moderating online communication, with implications for
fact-checkers, algorithm designers, and the use of crowd-workers as annotators.
We also release the TopicMisinfo dataset to support continuing research in the
community.
</p>
</div>
</dd>
<dt><a name=item64>[64]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16559 title=Abstract>arXiv:2401.16559</a> [<a href=https://arxiv.org/pdf/2401.16559 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16559 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IEEE BigData 2023 Keystroke Verification Challenge (KVC)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stragapede%2C+G">Giuseppe Stragapede</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morales%2C+A">Aythami Morales</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeAndres-Tame%2C+I">Ivan DeAndres-Tame</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damer%2C+N">Naser Damer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia%2C+J">Javier-Ortega Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonzalez%2C+N">Nahuel Gonzalez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shadrikov%2C+A">Andrei Shadrikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gordin%2C+D">Dmitrii Gordin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmitt%2C+L">Leon Schmitt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wimmer%2C+D">Daniel Wimmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossmann%2C+C">Christoph Grossmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krieger%2C+J">Joerdis Krieger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heinz%2C+F">Florian Heinz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krestel%2C+R">Ron Krestel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mayer%2C+C">Christoffer Mayer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haberl%2C+S">Simon Haberl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gschrey%2C+H">Helena Gschrey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamagishi%2C+Y">Yosuke Yamagishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saha%2C+S">Sanjay Saha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rasnayaka%2C+S">Sanka Rasnayaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wickramanayake%2C+S">Sandareka Wickramanayake</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%2C+T">Terence Sim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gutfeter%2C+W">Weronika Gutfeter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baran%2C+A">Adam Baran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Krzyszton%2C+M">Mateusz Krzyszton</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaskola%2C+P">Przemyslaw Jaskola</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 10 pages, 2 figures. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.06000>arXiv:2311.06000</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper describes the results of the IEEE BigData 2023 Keystroke
Verification Challenge (KVC), that considers the biometric verification
performance of Keystroke Dynamics (KD), captured as tweet-long sequences of
variable transcript text from over 185,000 subjects. The data are obtained from
two of the largest public databases of KD up to date, the Aalto Desktop and
Mobile Keystroke Databases, guaranteeing a minimum amount of data per subject,
age and gender annotations, absence of corrupted data, and avoiding excessively
unbalanced subject distributions with respect to the considered demographic
attributes. Several neural architectures were proposed by the participants,
leading to global Equal Error Rates (EERs) as low as 3.33% and 3.61% achieved
by the best team respectively in the desktop and mobile scenario, outperforming
the current state of the art biometric verification performance for KD. Hosted
on CodaLab, the KVC will be made ongoing to represent a useful tool for the
research community to compare different approaches under the same experimental
conditions and to deepen the knowledge of the field.
</p>
</div>
</dd>
<dt><a name=item65>[65]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16560 title=Abstract>arXiv:2401.16560</a> [<a href=https://arxiv.org/pdf/2401.16560 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16560 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaborative Manipulation of Deformable Objects with Predictive Obstacle Avoidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aksoy%2C+B">Burak Aksoy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+J">John Wen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Manipulating deformable objects arises in daily life and numerous
applications. Despite phenomenal advances in industrial robotics, manipulation
of deformable objects remains mostly a manual task. This is because of the high
number of internal degrees of freedom and the complexity of predicting its
motion. In this paper, we apply the computationally efficient position-based
dynamics method to predict object motion and distance to obstacles. This
distance is incorporated in a control barrier function for the resolved motion
kinematic control for one or more robots to adjust their motion to avoid
colliding with the obstacles. The controller has been applied in simulations to
1D and 2D deformable objects with varying numbers of assistant agents,
demonstrating its versatility across different object types and multi-agent
systems. Results indicate the feasibility of real-time collision avoidance
through deformable object simulation, minimizing path tracking error while
maintaining a predefined minimum distance from obstacles and preventing
overstretching of the deformable object. The implementation is performed in
ROS, allowing ready portability to different applications.
</p>
</div>
</dd>
<dt><a name=item66>[66]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16561 title=Abstract>arXiv:2401.16561</a> [<a href=https://arxiv.org/pdf/2401.16561 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16561 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16561 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-class Regret Detection in Hindi Devanagari Script
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+R">Renuka Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagpal%2C+S">Sushama Nagpal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sabharwal%2C+S">Sangeeta Sabharwal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butt%2C+S">Sabur Butt</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The number of Hindi speakers on social media has increased dramatically in
recent years. Regret is a common emotional experience in our everyday life.
Many speakers on social media, share their regretful experiences and opinions
regularly. It might cause a re-evaluation of one's choices and a desire to make
a different option if given the chance. As a result, knowing the source of
regret is critical for investigating its impact on behavior and
decision-making. This study focuses on regret and how it is expressed,
specifically in Hindi, on various social media platforms. In our study, we
present a novel dataset from three different sources, where each sentence has
been manually classified into one of three classes "Regret by action", "Regret
by inaction", and "No regret". Next, we use this dataset to investigate the
linguistic expressions of regret in Hindi text and also identify the textual
domains that are most frequently associated with regret. Our findings indicate
that individuals on social media platforms frequently express regret for both
past inactions and actions, particularly within the domain of interpersonal
relationships. We use a pre-trained BERT model to generate word embeddings for
the Hindi dataset and also compare deep learning models with conventional
machine learning models in order to demonstrate accuracy. Our results show that
BERT embedding with CNN consistently surpassed other models. This described the
effectiveness of BERT for conveying the context and meaning of words in the
regret domain.
</p>
</div>
</dd>
<dt><a name=item67>[67]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16562 title=Abstract>arXiv:2401.16562</a> [<a href=https://arxiv.org/pdf/2401.16562 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16562 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Keep Your Friends Close, and Your Enemies Closer: Structural Properties of Negative Relationships on Twitter
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tacchi%2C+J">Jack Tacchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boldrini%2C+C">Chiara Boldrini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conti%2C+M">Marco Conti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>The Ego Network Model (ENM) is a model for the structural organisation of
relationships, rooted in evolutionary anthropology, that is found ubiquitously
in social contexts. It takes the perspective of a single user (Ego) and
organises their contacts (Alters) into a series of (typically 5) concentric
circles of decreasing intimacy and increasing size. Alters are sorted based on
their tie strength to the Ego, however, this is difficult to measure directly.
Traditionally, the interaction frequency has been used as a proxy but this
misses the qualitative aspects of connections, such as signs (i.e. polarity),
which have been shown to provide extremely useful information. However, the
sign of an online social relationship is usually an implicit piece of
information, which needs to be estimated by interaction data from Online Social
Networks (OSNs), making sign prediction in OSNs a research challenge in and of
itself. This work aims to bring the ENM into the signed networks domain by
investigating the interplay of signed connections with the ENM. This paper
delivers 2 main contributions. Firstly, a new and data-efficient method of
signing relationships between individuals using sentiment analysis and,
secondly, we provide an in-depth look at the properties of Signed Ego Networks
(SENs), using 9 Twitter datasets of various categories of users. We find that
negative connections are generally over-represented in the active part of the
Ego Networks, suggesting that Twitter greatly over-emphasises negative
relationships with respect to "offline" social networks. Further, users who use
social networks for professional reasons have an even greater share of negative
connections.
</p>
</div>
</dd>
<dt><a name=item68>[68]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16566 title=Abstract>arXiv:2401.16566</a> [<a href=https://arxiv.org/pdf/2401.16566 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16566 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Excitation Trajectory Optimization for Dynamic Parameter Identification Using Virtual Constraints in Hands-on Robotic System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+H">Huanyu Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huber%2C+M">Martin Huber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mower%2C+C+E">Christopher E. Mower</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhe Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Changsheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+X">Xingguang Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bergeles%2C+C">Christos Bergeles</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper proposes a novel, more computationally efficient method for
optimizing robot excitation trajectories for dynamic parameter identification,
emphasizing self-collision avoidance. This addresses the system identification
challenges for getting high-quality training data associated with
co-manipulated robotic arms that can be equipped with a variety of tools, a
common scenario in industrial but also clinical and research contexts.
Utilizing the Unified Robotics Description Format (URDF) to implement a
symbolic Python implementation of the Recursive Newton-Euler Algorithm (RNEA),
the approach aids in dynamically estimating parameters such as inertia using
regression analyses on data from real robots. The excitation trajectory was
evaluated and achieved on par criteria when compared to state-of-the-art
reported results which didn't consider self-collision and tool calibrations.
Furthermore, physical Human-Robot Interaction (pHRI) admittance control
experiments were conducted in a surgical context to evaluate the derived
inverse dynamics model showing a 30.1\% workload reduction by the NASA TLX
questionnaire.
</p>
</div>
</dd>
<dt><a name=item69>[69]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16568 title=Abstract>arXiv:2401.16568</a> [<a href=https://arxiv.org/pdf/2401.16568 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16568 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16568 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stochastic Hybrid System Modeling and State Estimation of Modern Power Systems under Contingency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yuan%2C+S">Shuo Yuan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+L+Y">Le Yi Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yin%2C+G">George Yin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nazari%2C+M+H">Masoud H. Nazari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper introduces a stochastic hybrid system (SHS) framework in state
space model to capture sensor, communication, and system contingencies in
modern power systems (MPS). Within this new framework, the paper concentrates
on the development of state estimation methods and algorithms to provide
reliable state estimation under randomly intermittent and noisy sensor data.
MPSs employ diversified measurement devices for monitoring system operations
that are subject to random measurement errors and rely on communication
networks to transmit data whose channels encounter random packet loss and
interruptions. The contingency and noise form two distinct and interacting
stochastic processes that have a significant impact on state estimation
accuracy and reliability. This paper formulates stochastic hybrid system models
for MPSs, introduces coordinated observer design algorithms for state
estimation, and establishes their convergence and reliability properties. A
further study reveals a fundamental design tradeoff between convergence rates
and steady-state error variances. Simulation studies on the IEEE 5-bus system
and IEEE 33-bus system are used to illustrate the modeling methods, observer
design algorithms, convergence properties, performance evaluations, and impact
sensor system selections.
</p>
</div>
</dd>
<dt><a name=item70>[70]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16569 title=Abstract>arXiv:2401.16569</a> [<a href=https://arxiv.org/pdf/2401.16569 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16569 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16569 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wheeler%2C+D">Dylan Wheeler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+B">Balasubramaniam Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Communication with the goal of accurately conveying meaning, rather than
accurately transmitting symbols, has become an area of growing interest. This
paradigm, termed semantic communication, typically leverages modern
developments in artificial intelligence and machine learning to improve the
efficiency and robustness of communication systems. However, a standard model
for capturing and quantifying the details of "meaning" is lacking, with many
leading approaches to semantic communication adopting a black-box framework
with little understanding of what exactly the model is learning. One solution
is to utilize the conceptual spaces framework, which models meaning explicitly
in a geometric manner. Though prior work studying semantic communication with
conceptual spaces has shown promising results, these previous attempts involve
hand-crafting a conceptual space model, severely limiting the scalability and
practicality of the approach. In this work, we develop a framework for learning
a domain of a conceptual space model using only the raw data with high-level
property labels. In experiments using the MNIST and CelebA datasets, we show
that the domains learned using the framework maintain semantic similarity
relations and possess interpretable dimensions.
</p>
</div>
</dd>
<dt><a name=item71>[71]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16572 title=Abstract>arXiv:2401.16572</a> [<a href=https://arxiv.org/pdf/2401.16572 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16572 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Embedding Elites: Examining the Use of Tweets Embedded in Online News Articles across Reliable and Fringe Outlets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horne%2C+B+D">Benjamin D. Horne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phillips%2C+S">Summer Phillips</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koontz%2C+N">Nelia Koontz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> MeLa Lab Preliminary Findings Report
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>This study examines the use of embedded tweets in online news media. In
particular, we add to the previous literature by exploring embedded tweets
across reliable and unreliable news outlets. We use a mixed-method analysis to
examine how the function and frequency of embedded tweets change across outlet
reliability and news topic. We find that, no matter the outlet reliability,
embedded tweets are most often used to relay the opinions of elites, to
syndicate information from another news source, or to self-cite information an
outlet previously produced. Our results also show some notable differences
between reliable media and fringe media's use of tweets. Namely, fringe media
embed tweets more and use those tweets as the source of news more than reliable
media. Our work adds to the literature on hybrid media systems and the
normalization of social media in journalism.
</p>
</div>
</dd>
<dt><a name=item72>[72]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16574 title=Abstract>arXiv:2401.16574</a> [<a href=https://arxiv.org/pdf/2401.16574 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16574 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Strong Convergence of a Random Actions Model in Opinion Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abrahamsson%2C+O">Olle Abrahamsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Danev%2C+D">Danyo Danev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 9 figures and 1 table. Accepted at IEEE Transactions on Signal and Information Processing over Networks
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
<p class=mathjax>We study an opinion dynamics model in which each agent takes a random
Bernoulli distributed action whose probability is updated at each discrete time
step, and we prove that this model converges almost surely to consensus. We
also provide a detailed critique of a claimed proof of this result in the
literature. We generalize the result by proving that the assumption of
irreducibility in the original model is not necessary. Furthermore, we prove as
a corollary of the generalized result that the almost sure convergence to
consensus holds also in the presence of a stubborn agent which never changes
its opinion. In addition, we show that the model, in both the original and
generalized cases, converges to consensus also in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-22-Frame tabindex=0><nobr><span class=math id=MathJax-Span-91 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-92><span class=mi id=MathJax-Span-93 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>th mean.
</p>
</div>
</dd>
<dt><a name=item73>[73]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16575 title=Abstract>arXiv:2401.16575</a> [<a href=https://arxiv.org/pdf/2401.16575 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16575 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Beyond Image-Text Matching: Verb Understanding in Multimodal Transformers Using Guided Masking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Be%C5%88ov%C3%A1%2C+I">Ivana Beňová</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%C5%A1eck%C3%A1%2C+J">Jana Košecká</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gregor%2C+M">Michal Gregor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tamajka%2C+M">Martin Tamajka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vesel%C3%BD%2C+M">Marcel Veselý</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%A0imko%2C+M">Marián Šimko</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages of text, 11 pages total, 7 figures, 3 tables, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The dominant probing approaches rely on the zero-shot performance of
image-text matching tasks to gain a finer-grained understanding of the
representations learned by recent multimodal image-language transformer models.
The evaluation is carried out on carefully curated datasets focusing on
counting, relations, attributes, and others. This work introduces an
alternative probing strategy called guided masking. The proposed approach
ablates different modalities using masking and assesses the model's ability to
predict the masked word with high accuracy. We focus on studying multimodal
models that consider regions of interest (ROI) features obtained by object
detectors as input tokens. We probe the understanding of verbs using guided
masking on ViLBERT, LXMERT, UNITER, and VisualBERT and show that these models
can predict the correct verb with high accuracy. This contrasts with previous
conclusions drawn from image-text matching probing techniques that frequently
fail in situations requiring verb understanding. The code for all experiments
will be publicly available https://github.com/ivana-13/guided_masking.
</p>
</div>
</dd>
<dt><a name=item74>[74]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16577 title=Abstract>arXiv:2401.16577</a> [<a href=https://arxiv.org/pdf/2401.16577 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16577 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLMs as On-demand Customizable Service
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarkar%2C+S">Souvika Sarkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babar%2C+M+F">Mohammad Fakhruddin Babar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hasan%2C+M">Monowar Hasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karmaker%2C+S+K">Shubhra Kanti Karmaker</a> (Santu)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs) have demonstrated remarkable language
understanding and generation capabilities. However, training, deploying, and
accessing these models pose notable challenges, including resource-intensive
demands, extended training durations, and scalability issues. To address these
issues, we introduce a concept of hierarchical, distributed LLM architecture
that aims at enhancing the accessibility and deployability of LLMs across
heterogeneous computing platforms, including general-purpose computers (e.g.,
laptops) and IoT-style devices (e.g., embedded systems). By introducing a
"layered" approach, the proposed architecture enables on-demand accessibility
to LLMs as a customizable service. This approach also ensures optimal
trade-offs between the available computational resources and the user's
application needs. We envision that the concept of hierarchical LLM will
empower extensive, crowd-sourced user bases to harness the capabilities of
LLMs, thereby fostering advancements in AI technology in general.
</p>
</div>
</dd>
<dt><a name=item75>[75]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16578 title=Abstract>arXiv:2401.16578</a> [<a href=https://arxiv.org/pdf/2401.16578 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16578 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qingqing Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiuying Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Q">Qiao Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+B">Benjamin Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mukherjee%2C+P">Pritam Mukherjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+X">Xin Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Summers%2C+R+M">Ronald M Summers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In radiology, Artificial Intelligence (AI) has significantly advanced report
generation, but automatic evaluation of these AI-produced reports remains
challenging. Current metrics, such as Conventional Natural Language Generation
(NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic
intricacies of clinical contexts or overemphasize clinical details, undermining
report clarity. To overcome these issues, our proposed method synergizes the
expertise of professional radiologists with Large Language Models (LLMs), like
GPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain
of Thought (CoT) reasoning, our approach aligns LLM evaluations with
radiologist standards, enabling detailed comparisons between human and AI
generated reports. This is further enhanced by a Regression model that
aggregates sentence evaluation scores. Experimental results show that our
''Detailed GPT-4 (5-shot)'' model achieves a 0.48 score, outperforming the
METEOR metric by 0.19, while our ''Regressed GPT-4'' model shows even greater
alignment with expert evaluations, exceeding the best existing metric by a 0.35
margin. Moreover, the robustness of our explanations has been validated through
a thorough iterative strategy. We plan to publicly release annotations from
radiology experts, setting a new standard for accuracy in future assessments.
This underscores the potential of our approach in enhancing the quality
assessment of AI-driven medical reports.
</p>
</div>
</dd>
<dt><a name=item76>[76]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16579 title=Abstract>arXiv:2401.16579</a> [<a href=https://arxiv.org/pdf/2401.16579 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16579 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On Channel Simulation with Causal Rejection Samplers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goc%2C+D">Daniel Goc</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Flamich%2C+G">Gergely Flamich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>One-shot channel simulation has recently emerged as a promising alternative
to quantization and entropy coding in machine-learning-based lossy data
compression schemes. However, while there are several potential applications of
channel simulation - lossy compression with realism constraints or differential
privacy, to name a few - little is known about its fundamental limitations. In
this paper, we restrict our attention to a subclass of channel simulation
protocols called causal rejection samplers (CRS), establish new, tighter lower
bounds on their expected runtime and codelength, and demonstrate the bounds'
achievability. Concretely, for an arbitrary CRS, let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-23-Frame tabindex=0><nobr><span class=math id=MathJax-Span-94 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-95><span class=mi id=MathJax-Span-96 style=font-family:MathJax_Math-italic>Q</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-24-Frame tabindex=0><nobr><span class=math id=MathJax-Span-97 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-98><span class=mi id=MathJax-Span-99 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> denote a
target and proposal distribution supplied as input, and let <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-25-Frame tabindex=0><nobr><span class=math id=MathJax-Span-100 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-101><span class=mi id=MathJax-Span-102 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> be the number
of samples examined by the algorithm. We show that the expected runtime
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-26-Frame tabindex=0><nobr><span class=math id=MathJax-Span-103 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1002.03em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-104><span class=texatom id=MathJax-Span-105><span class=mrow id=MathJax-Span-106><span class=mi id=MathJax-Span-107 style=font-family:MathJax_AMS>E</span></span></span><span class=mo id=MathJax-Span-108 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-109 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-110 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> of any CRS scales at least as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-27-Frame tabindex=0><nobr><span class=math id=MathJax-Span-111 style=width:8.51em;display:inline-block><span style=display:inline-block;position:relative;width:7.063em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.95em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-112><span class=msubsup id=MathJax-Span-113><span style=display:inline-block;position:relative;width:1.97em;height:0px><span style=position:absolute;clip:rect(3.359em,1001.51em,4.343em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-114 style=font-family:MathJax_Main>exp</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.508em><span class=mn id=MathJax-Span-115 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-116></span><span class=mo id=MathJax-Span-117 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-118><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-119 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-120 style=font-size:70.7%;font-family:MathJax_Main>∞</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-121 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-122 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-123><span class=mrow id=MathJax-Span-124><span class=mo id=MathJax-Span-125 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-126><span class=mrow id=MathJax-Span-127><span class=mo id=MathJax-Span-128 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-129 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-130 style=font-family:MathJax_Main>]</span><span class=mo id=MathJax-Span-131 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-28-Frame tabindex=0><nobr><span class=math id=MathJax-Span-132 style=width:5.153em;display:inline-block><span style=display:inline-block;position:relative;width:4.285em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.17em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-133><span class=msubsup id=MathJax-Span-134><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-135 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=mi id=MathJax-Span-136 style=font-size:70.7%;font-family:MathJax_Main>∞</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-137 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-138 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-139><span class=mrow id=MathJax-Span-140><span class=mo id=MathJax-Span-141 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-142><span class=mrow id=MathJax-Span-143><span class=mo id=MathJax-Span-144 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-145 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-146 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is the R\'enyi <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-29-Frame tabindex=0><nobr><span class=math id=MathJax-Span-147 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.93em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-148><span class=mi id=MathJax-Span-149 style=font-family:MathJax_Main>∞</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-divergence. Regarding the
codelength, we show that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-30-Frame tabindex=0><nobr><span class=math id=MathJax-Span-150 style=width:17.133em;display:inline-block><span style=display:inline-block;position:relative;width:14.239em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1014.12em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-151><span class=msubsup id=MathJax-Span-152><span style=display:inline-block;position:relative;width:2.028em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-153 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-154><span class=mrow id=MathJax-Span-155><span class=mi id=MathJax-Span-156 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mi id=MathJax-Span-157 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-158 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-159 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-160><span class=mrow id=MathJax-Span-161><span class=mo id=MathJax-Span-162 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-163><span class=mrow id=MathJax-Span-164><span class=mo id=MathJax-Span-165 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-166 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-167 style=font-family:MathJax_Main>]</span><span class=mo id=MathJax-Span-168 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=msubsup id=MathJax-Span-169 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-170 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-171><span class=mrow id=MathJax-Span-172><span class=mi id=MathJax-Span-173 style=font-size:70.7%;font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-174 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-175 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-176 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-177><span class=mrow id=MathJax-Span-178><span class=mo id=MathJax-Span-179 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-180><span class=mrow id=MathJax-Span-181><span class=mo id=MathJax-Span-182 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-183 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-184 style=font-family:MathJax_Main>]</span><span class=mo id=MathJax-Span-185 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=texatom id=MathJax-Span-186 style=padding-left:0.292em><span class=mrow id=MathJax-Span-187><span class=mi id=MathJax-Span-188 style=font-family:MathJax_AMS>H</span></span></span><span class=mo id=MathJax-Span-189 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-190 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-191 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-31-Frame tabindex=0><nobr><span class=math id=MathJax-Span-192 style=width:5.501em;display:inline-block><span style=display:inline-block;position:relative;width:4.575em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.46em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-193><span class=msubsup id=MathJax-Span-194><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-195 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-196><span class=mrow id=MathJax-Span-197><span class=mi id=MathJax-Span-198 style=font-size:70.7%;font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-199 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-200 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-201 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-202><span class=mrow id=MathJax-Span-203><span class=mo id=MathJax-Span-204 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-205><span class=mrow id=MathJax-Span-206><span class=mo id=MathJax-Span-207 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-208 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-209 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is a new quantity we call the channel
simulation divergence. Furthermore, we prove that our new lower bound, unlike
the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-32-Frame tabindex=0><nobr><span class=math id=MathJax-Span-210 style=width:5.674em;display:inline-block><span style=display:inline-block;position:relative;width:4.69em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.58em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-211><span class=msubsup id=MathJax-Span-212><span style=display:inline-block;position:relative;width:2.028em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-213 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-214><span class=mrow id=MathJax-Span-215><span class=mi id=MathJax-Span-216 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mi id=MathJax-Span-217 style=font-size:70.7%;font-family:MathJax_Math-italic>L</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-218 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-219 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-220><span class=mrow id=MathJax-Span-221><span class=mo id=MathJax-Span-222 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-223><span class=mrow id=MathJax-Span-224><span class=mo id=MathJax-Span-225 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-226 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-227 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> lower bound, is achievable tightly, i.e. there is a CRS
such that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-33-Frame tabindex=0><nobr><span class=math id=MathJax-Span-228 style=width:16.959em;display:inline-block><span style=display:inline-block;position:relative;width:14.123em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.508em,1014.01em,2.839em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-229><span class=texatom id=MathJax-Span-230><span class=mrow id=MathJax-Span-231><span class=mi id=MathJax-Span-232 style=font-family:MathJax_AMS>H</span></span></span><span class=mo id=MathJax-Span-233 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-234 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-235 style=font-family:MathJax_Main>]</span><span class=mo id=MathJax-Span-236 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=msubsup id=MathJax-Span-237 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.81em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-238 style=font-family:MathJax_Math-italic>D</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.813em><span class=texatom id=MathJax-Span-239><span class=mrow id=MathJax-Span-240><span class=mi id=MathJax-Span-241 style=font-size:70.7%;font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-242 style=font-size:70.7%;font-family:MathJax_Math-italic>S<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-243 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-244 style=font-family:MathJax_Math-italic>Q</span><span class=texatom id=MathJax-Span-245><span class=mrow id=MathJax-Span-246><span class=mo id=MathJax-Span-247 style=font-family:MathJax_Main>|</span></span></span><span class=texatom id=MathJax-Span-248><span class=mrow id=MathJax-Span-249><span class=mo id=MathJax-Span-250 style=font-family:MathJax_Main>|</span></span></span><span class=mi id=MathJax-Span-251 style=font-family:MathJax_Math-italic>P<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-252 style=font-family:MathJax_Main>]</span><span class=mo id=MathJax-Span-253 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=msubsup id=MathJax-Span-254 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-255 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.276em><span class=mn id=MathJax-Span-256 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-257></span><span class=mo id=MathJax-Span-258 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-259 style=font-family:MathJax_Math-italic>e</span><span class=mo id=MathJax-Span-260 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-261 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-262 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. Finally, we
conduct numerical studies of the asymptotic scaling of the codelength of
Gaussian and Laplace channel simulation algorithms.
</p>
</div>
</dd>
<dt><a name=item77>[77]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16580 title=Abstract>arXiv:2401.16580</a> [<a href=https://arxiv.org/pdf/2401.16580 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16580 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaejin Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kee%2C+S">Seho Kee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Janakiram%2C+M">Mani Janakiram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Runger%2C+G">George Runger</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
<p class=mathjax>Job shop scheduling problems are one of the most important and challenging
combinatorial optimization problems that have been tackled mainly by exact or
approximate solution approaches. However, finding an exact solution can be
infeasible for real-world problems, and even with an approximate solution
approach, it can require a prohibitive amount of time to find a near-optimal
solution, and the found solutions are not applicable to new problems in
general. To address these challenges, we propose an attention-based
reinforcement learning method for the class of job shop scheduling problems by
integrating policy gradient reinforcement learning with a modified transformer
architecture. An important result is that our trained learners in the proposed
method can be reused to solve large-scale problems not used in training and
demonstrate that our approach outperforms the results of recent studies and
widely adopted heuristic rules.
</p>
</div>
</dd>
<dt><a name=item78>[78]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16582 title=Abstract>arXiv:2401.16582</a> [<a href=https://arxiv.org/pdf/2401.16582 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16582 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Massively Multilingual Text Translation For Low-Resource Languages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhong Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 191 pages. Published on Dec 20, 2023. Ph.D. thesis @ Language Technology Institute, School of Computer Science, Carnegie Mellon University. <a href=https://doi.org/10.1184/R1/24992787.v1>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Translation into severely low-resource languages has both the cultural goal
of saving and reviving those languages and the humanitarian goal of assisting
the everyday needs of local communities that are accelerated by the recent
COVID-19 pandemic. In many humanitarian efforts, translation into severely
low-resource languages often does not require a universal translation engine,
but a dedicated text-specific translation engine. For example, healthcare
records, hygienic procedures, government communication, emergency procedures
and religious texts are all limited texts. While generic translation engines
for all languages do not exist, translation of multilingually known limited
texts into new, low-resource languages may be possible and reduce human
translation effort. We attempt to leverage translation resources from
rich-resource languages to efficiently produce best possible translation
quality for well known texts, which are available in multiple languages, in a
new, low-resource language. To reach this goal, we argue that in translating a
closed text into low-resource languages, generalization to out-of-domain texts
is not necessary, but generalization to new languages is. Performance gain
comes from massive source parallelism by careful choice of close-by language
families, style-consistent corpus-level paraphrases within the same language
and strategic adaptation of existing large pretrained multilingual models to
the domain first and then to the language. Such performance gain makes it
possible for machine translation systems to collaborate with human translators
to expedite the translation process into new, low-resource languages.
</p>
</div>
</dd>
<dt><a name=item79>[79]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16583 title=Abstract>arXiv:2401.16583</a> [<a href=https://arxiv.org/pdf/2401.16583 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16583 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Oblivious ML Accelerators using Hardware Security Extensions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=ElAtali%2C+H">Hossam ElAtali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jekel%2C+J+Z">John Z. Jekel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gunn%2C+L+J">Lachlan J. Gunn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asokan%2C+N">N. Asokan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Outsourced computation can put client data confidentiality at risk. Existing
solutions are either inefficient or insufficiently secure: cryptographic
techniques like fully-homomorphic encryption incur significant overheads, even
with hardware assistance, while the complexity of hardware-assisted trusted
execution environments has been exploited to leak secret data.
<br>Recent proposals such as BliMe and OISA show how dynamic information flow
tracking (DIFT) enforced in hardware can protect client data efficiently. They
are designed to protect CPU-only workloads. However, many outsourced computing
applications, like machine learning, make extensive use of accelerators.
<br>We address this gap with Dolma, which applies DIFT to the Gemmini matrix
multiplication accelerator, efficiently guaranteeing client data
confidentiality, even in the presence of malicious/vulnerable software and side
channel attacks on the server. We show that accelerators can allow DIFT logic
optimizations that significantly reduce area overhead compared with
general-purpose processor architectures. Dolma is integrated with the BliMe
framework to achieve end-to-end security guarantees. We evaluate Dolma on an
FPGA using a ResNet-50 DNN model and show that it incurs low overheads for
large configurations (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-34-Frame tabindex=0><nobr><span class=math id=MathJax-Span-263 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.09em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-264><span class=mn id=MathJax-Span-265 style=font-family:MathJax_Main>4.4</span><span class=mi id=MathJax-Span-266 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-35-Frame tabindex=0><nobr><span class=math id=MathJax-Span-267 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-268><span class=mn id=MathJax-Span-269 style=font-family:MathJax_Main>16.7</span><span class=mi id=MathJax-Span-270 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-36-Frame tabindex=0><nobr><span class=math id=MathJax-Span-271 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-272><span class=mn id=MathJax-Span-273 style=font-family:MathJax_Main>16.5</span><span class=mi id=MathJax-Span-274 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> for performance, resource
usage and power, respectively, with a 32x32 configuration).
</p>
</div>
</dd>
<dt><a name=item80>[80]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16584 title=Abstract>arXiv:2401.16584</a> [<a href=https://arxiv.org/pdf/2401.16584 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16584 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16584 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inter-instance Data Impacts in Business Processes: A Model-based Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evron%2C+Y">Yotam Evron</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsoury%2C+A">Arava Tsoury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zamansky%2C+A">Anna Zamansky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reinhartz-Berger%2C+I">Iris Reinhartz-Berger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soffer%2C+P">Pnina Soffer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 2 figures and 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>A business process model represents the expected behavior of a set of process
instances (cases). The process instances may be executed in parallel and may
affect each other through data or resources. In particular, changes in values
of data shared by process instances may affect a set of process instances and
require some operations in response. Such potential effects do not explicitly
appear in the process model. This paper addresses possible impacts that may be
affected through shared data across process instances and suggests how to
analyze them at design time (when the actual process instances do not yet
exist). The suggested method uses both a process model and a (relational) data
model in order to identify potential inter-instance data impact sets. These
sets may guide process users in tracking the impacts of data changes and
supporting their handling at runtime. They can also assist process designers in
exploring possible constraints over data. The applicability of the method was
evaluated using three different realistic processes. Using a process expert, we
further assessed the usefulness of the method, revealing some useful insights
for coping with unexpected data-related changes suggested by our approach.
</p>
</div>
</dd>
<dt><a name=item81>[81]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16585 title=Abstract>arXiv:2401.16585</a> [<a href=https://arxiv.org/pdf/2401.16585 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16585 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pick and Place Planning is Better than Pick Planning then Place Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shanthi%2C+M+D">Mohanraj Devendran Shanthi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hermans%2C+T">Tucker Hermans</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 14 figures, IEEE RA-L
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Robotic pick and place stands at the heart of autonomous manipulation. When
conducted in cluttered or complex environments robots must jointly reason about
the selected grasp and desired placement locations to ensure success. While
several works have examined this joint pick-and-place problem, none have fully
leveraged recent learning-based approaches for multi-fingered grasp planning.
We present a modular algorithm for joint pick and place planning that can make
use of state of the art grasp classifiers for planning multi-fingered grasps
for novel objects from partial view point clouds. We demonstrate our joint pick
and place formulation with several costs associated with different placement
tasks. Experiments on pick and place tasks with cluttered scenes using a
physical robot show that our joint inference method is more successful than a
sequential pick then place approach, while also achieving better placement
configurations.
</p>
</div>
</dd>
<dt><a name=item82>[82]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16587 title=Abstract>arXiv:2401.16587</a> [<a href=https://arxiv.org/pdf/2401.16587 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16587 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Linguistic Comparison between Human and ChatGPT-Generated Conversations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandler%2C+M">Morgan Sandler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choung%2C+H">Hyesun Choung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ross%2C+A">Arun Ross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=David%2C+P">Prabu David</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint. Pending review and feedback from ICPRAI2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
<p class=mathjax>This study explores linguistic differences between human and LLM-generated
dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the
EmpathicDialogues dataset. The research employs Linguistic Inquiry and Word
Count (LIWC) analysis, comparing ChatGPT-generated conversations with human
conversations across 118 linguistic categories. Results show greater
variability and authenticity in human dialogues, but ChatGPT excels in
categories such as social processes, analytical style, cognition, attentional
focus, and positive emotional tone, reinforcing recent findings of LLMs being
"more human than human." However, no significant difference was found in
positive or negative affect between ChatGPT and human dialogues. Classifier
analysis of dialogue embeddings indicates implicit coding of the valence of
affect despite no explicit mention of affect in the conversations. The research
also contributes a novel, companion ChatGPT-generated dataset of conversations
between two independent chatbots, which were designed to replicate a corpus of
human conversations available for open access and used widely in AI research on
language modeling. Our findings increase understanding of ChatGPT's linguistic
capabilities and inform ongoing efforts to distinguish between human and
LLM-generated text, which is critical in detecting AI-generated fakes,
misinformation, and disinformation.
</p>
</div>
</dd>
<dt><a name=item83>[83]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16589 title=Abstract>arXiv:2401.16589</a> [<a href=https://arxiv.org/pdf/2401.16589 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16589 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence Labeling Tasks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+B">Bolei Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+E">Ercong Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuzhou Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmid%2C+H">Helmut Schmid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=F%C3%A4rber%2C+M">Michael Färber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kreuter%2C+F">Frauke Kreuter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%BCtze%2C+H">Hinrich Schütze</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Prompt-based methods have been successfully applied to multilingual
pretrained language models for zero-shot cross-lingual understanding. However,
most previous studies primarily focused on sentence-level classification tasks,
and only a few considered token-level labeling tasks such as Named Entity
Recognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose
Token-Level Prompt Decomposition (ToPro), which facilitates the prompt-based
method for token-level sequence labeling tasks. The ToPro method decomposes an
input sentence into single tokens and applies one prompt template to each
token. Our experiments on multilingual NER and POS tagging datasets demonstrate
that ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning
in zero-shot cross-lingual transfer, especially for languages that are
typologically different from the source language English. Our method also
attains state-of-the-art performance when employed with the mT5 model. Besides,
our exploratory study in multilingual large language models shows that ToPro
performs much better than the current in-context learning method. Overall, the
performance improvements show that ToPro could potentially serve as a novel and
simple benchmarking method for sequence labeling tasks.
</p>
</div>
</dd>
<dt><a name=item84>[84]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16594 title=Abstract>arXiv:2401.16594</a> [<a href=https://arxiv.org/pdf/2401.16594 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16594 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistent algorithms for multi-label classification with macro-at-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-37-Frame tabindex=0><nobr><span class=math id=MathJax-Span-275 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.51em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-276><span class=mi id=MathJax-Span-277 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span> metrics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schultheis%2C+E">Erik Schultheis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kot%C5%82owski%2C+W">Wojciech Kotłowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wydmuch%2C+M">Marek Wydmuch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babbar%2C+R">Rohit Babbar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borman%2C+S">Strom Borman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dembczy%C5%84ski%2C+K">Krzysztof Dembczyński</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the authors' version of the work accepted to ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>We consider the optimization of complex performance metrics in multi-label
classification under the population utility framework. We mainly focus on
metrics linearly decomposable into a sum of binary classification utilities
applied separately to each label with an additional requirement of exactly <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-38-Frame tabindex=0><nobr><span class=math id=MathJax-Span-278 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-279><span class=mi id=MathJax-Span-280 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
labels predicted for each instance. These "macro-at-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-39-Frame tabindex=0><nobr><span class=math id=MathJax-Span-281 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-282><span class=mi id=MathJax-Span-283 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>" metrics possess
desired properties for extreme classification problems with long tail labels.
Unfortunately, the at-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-40-Frame tabindex=0><nobr><span class=math id=MathJax-Span-284 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-285><span class=mi id=MathJax-Span-286 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> constraint couples the otherwise independent binary
classification tasks, leading to a much more challenging optimization problem
than standard macro-averages. We provide a statistical framework to study this
problem, prove the existence and the form of the optimal classifier, and
propose a statistically consistent and practical learning algorithm based on
the Frank-Wolfe method. Interestingly, our main results concern even more
general metrics being non-linear functions of label-wise confusion matrices.
Empirical results provide evidence for the competitive performance of the
proposed approach.
</p>
</div>
</dd>
<dt><a name=item85>[85]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16599 title=Abstract>arXiv:2401.16599</a> [<a href=https://arxiv.org/pdf/2401.16599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReLoki: Infrastructure-free Distributed Relative Localization using On-board UWB Antenna Arrays
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mathew%2C+J+P">Joseph Prince Mathew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nowzari%2C+C">Cameron Nowzari</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Coordination of multi-robot systems require some form of localization between
agents, but most methods today rely on some external infrastructure. Ultra Wide
Band (UWB) sensing has gained popularity in relative localization applications,
and we see many implementations that use cooperative agents augmenting UWB
range measurements with other sensing modalities (e.g., ViO, IMU, VSLAM) for
infrastructure-free relative localization. A lesser researched option is using
Angle of Arrival (AoA) readings obtained from UWB Antenna pairs to perform
relative localization. In this paper we present a UWB platform called ReLoki
that can be used for ranging and AoA-based relative localization in~3D. ReLoki
enables any message sent from a transmitting agent to be localized by using a
Regular Tetrahedral Antenna Array (RTA). As a full scale proof of concept, we
deploy ReLoki on a 3-robot system and compare its performance in terms of
accuracy and speed with prior methods.
</p>
</div>
</dd>
<dt><a name=item86>[86]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16600 title=Abstract>arXiv:2401.16600</a> [<a href=https://arxiv.org/pdf/2401.16600 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16600 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Depth Anything in Medical Images: A Comparative Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J+J">John J. Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acar%2C+A">Ayberk Acar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henry%2C+C">Callahan Henry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J+Y">Jie Ying Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 2 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Monocular depth estimation (MDE) is a critical component of many medical
tracking and mapping algorithms, particularly from endoscopic or laparoscopic
video. However, because ground truth depth maps cannot be acquired from real
patient data, supervised learning is not a viable approach to predict depth
maps for medical scenes. Although self-supervised learning for MDE has recently
gained attention, the outputs are difficult to evaluate reliably and each MDE's
generalizability to other patients and anatomies is limited. This work
evaluates the zero-shot performance of the newly released Depth Anything Model
on medical endoscopic and laparoscopic scenes. We compare the accuracy and
inference speeds of Depth Anything with other MDE models trained on general
scenes as well as in-domain models trained on endoscopic data. Our findings
show that although the zero-shot capability of Depth Anything is quite
impressive, it is not necessarily better than other models in both speed and
performance. We hope that this study can spark further research in employing
foundation models for MDE in medical scenes.
</p>
</div>
</dd>
<dt><a name=item87>[87]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16603 title=Abstract>arXiv:2401.16603</a> [<a href=https://arxiv.org/pdf/2401.16603 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16603 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LeftoverLocals: Listening to LLM Responses Through Leaked GPU Local Memory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sorensen%2C+T">Tyler Sorensen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khlaaf%2C+H">Heidy Khlaaf</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>This paper describes LeftoverLocals: a vulnerability that allows data
recovery from GPU memory created by another process on Apple, Qualcomm, and AMD
GPUs. LeftoverLocals impacts the security posture of GPU applications, with
particular significance to LLMs and ML models that run on impacted GPUs. By
recovering local memory, an optimized GPU memory region, we built a PoC where
an attacker can listen into another user's interactive LLM session (e.g.,
llama.cpp) across process or container boundaries.
</p>
</div>
</dd>
<dt><a name=item88>[88]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16605 title=Abstract>arXiv:2401.16605</a> [<a href=https://arxiv.org/pdf/2401.16605 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16605 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16605 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Robust and Scalable Dispatch Modeling of Long-Duration Energy Storage
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guerra%2C+O+J">Omar J. Guerra</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Dalvi%2C+S">Sourabh Dalvi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Thatte%2C+A+A">Amogh A. Thatte</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cowiestoll%2C+B">Brady Cowiestoll</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jorgenson%2C+J">Jennie Jorgenson</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hodge%2C+B">Bri-Mathias Hodge</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 45 pages, 16 figures, Submitted to Renewable and Sustainable Energy Reviews
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Existing modeling approaches for long-duration energy storage (LDES) are
often based either on an oversimplified representation of power system
operations or limited representation of storage technologies, e.g., evaluation
of only a single application. This manuscript presents an overview of the
challenges of modeling LDES technologies, as well as a discussion regarding the
capabilities and limitations of existing approaches. We used two test power
systems with high shares of both solar photovoltaics- and wind (70% - 90%
annual variable renewable energy shares) to assess LDES dispatch approaches.
Our results estimate that better dispatch modeling of LDES could increase the
associated operational value by 4% - 14% and increase the standard capacity
credit by 14% - 34%. Thus, a better LDES dispatch could represent significant
cost saving opportunities for electric utilities and system operators. In
addition, existing LDES dispatch modeling approaches were tested in terms of
both improved system value (e.g., based on production cost and standard
capacity credit) and scalability (e.g., based on central processing unit time
and peak memory usage). Both copper plate and nodal representations of the
power system were considered. Although the end volume target dispatch approach,
i.e., based on mid-term scheduling, showed promising performance in terms of
both improved system value and scalability, there is a need for robust and
scalable dispatch approaches for LDES in transmission-constrained electric
grids. Moreover, more research is required to better understand the optimal
operation of LDES considering extreme climate/weather events, reliability
applications, and power system operational uncertainties.
</p>
</div>
</dd>
<dt><a name=item89>[89]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16610 title=Abstract>arXiv:2401.16610</a> [<a href=https://arxiv.org/pdf/2401.16610 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16610 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perceptions of Moderators as a Large-Scale Measure of Online Community Governance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weld%2C+G">Galen Weld</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leibmann%2C+L">Leon Leibmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A+X">Amy X. Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Althoff%2C+T">Tim Althoff</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 12 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)
</div>
<p class=mathjax>Millions of online communities are governed by volunteer moderators, who
shape their communities by setting and enforcing rules, recruiting additional
moderators, and participating in the community themselves. These moderators
must regularly make decisions about how to govern, yet it is challenging to
determine what governance strategies are most successful, as measuring the
`success' of governance is complex and nuanced. Furthermore, the incredible
diversity in community topic, size, and membership all but guarantee that there
is no `one-size-fits-all' solution for community governance. In this work, we
measure governance by assessing how community members publicly discuss their
own moderators. We quantify perceptions of moderators through 1.89 million
labeled posts and comments made on reddit over an 18 month period, and relate
these perceptions to characteristics of community governance and to different
actions that community moderators can take. We identify key differences between
different types of communities, and highlight promising strategies for
moderator teams. Amongst other findings, we show that positive perceptions of
moderators are associated with other measures of community health, and that
strict rule enforcement is perceived more favorably for certain topics, such as
news communities, than others. We investigate what kinds of moderators have the
most positive impact on the community when they join the mod team, and find
that moderators who are active community members before and during their mod
tenures result in the largest improvement of community members' perceptions of
moderators. We make all our models, datasets, and code public.
</p>
</div>
</dd>
<dt><a name=item90>[90]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16618 title=Abstract>arXiv:2401.16618</a> [<a href=https://arxiv.org/pdf/2401.16618 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16618 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lotfi%2C+F">Faraz Lotfi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Virji%2C+K">Khalil Virji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dudek%2C+N">Nicholas Dudek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In this paper, we present an exploration and assessment of employing a
centralized deep Q-network (DQN) controller as a substitute for the prevalent
use of PID controllers in the context of 6DOF swimming robots. Our primary
focus centers on illustrating this transition with the specific case of
underwater object tracking. DQN offers advantages such as data efficiency and
off-policy learning, while remaining simpler to implement than other
reinforcement learning methods. Given the absence of a dynamic model for our
robot, we propose an RL agent to control this multi-input-multi-output (MIMO)
system, where a centralized controller may offer more robust control than
distinct PIDs. Our approach involves initially using classical controllers for
safe exploration, then gradually shifting to DQN to take full control of the
robot.
<br>We divide the underwater tracking task into vision and control modules. We
use established methods for vision-based tracking and introduce a centralized
DQN controller. By transmitting bounding box data from the vision module to the
control module, we enable adaptation to various objects and effortless vision
system replacement. Furthermore, dealing with low-dimensional data facilitates
cost-effective online learning for the controller. Our experiments, conducted
within a Unity-based simulator, validate the effectiveness of a centralized RL
agent over separated PID controllers, showcasing the applicability of our
framework for training the underwater RL agent and improved performance
compared to traditional control methods. The code for both real and simulation
implementations is at https://github.com/FARAZLOTFI/underwater-object-tracking.
</p>
</div>
</dd>
<dt><a name=item91>[91]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16623 title=Abstract>arXiv:2401.16623</a> [<a href=https://arxiv.org/pdf/2401.16623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Optimal Grammars for RNA Structures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Onokpasa%2C+E">Evarista Onokpasa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wild%2C+S">Sebastian Wild</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+P+W+H">Prudence W. H. Wong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> to be presented at DCC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>In past work (Onokpasa, Wild, Wong, DCC 2023), we showed that (a) for joint
compression of RNA sequence and structure, stochastic context-free grammars are
the best known compressors and (b) that grammars which have better compression
ability also show better performance in ab initio structure prediction.
Previous grammars were manually curated by human experts. In this work, we
develop a framework for automatic and systematic search algorithms for
stochastic grammars with better compression (and prediction) ability for RNA.
We perform an exhaustive search of small grammars and identify grammars that
surpass the performance of human-expert grammars.
</p>
</div>
</dd>
<dt><a name=item92>[92]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16625 title=Abstract>arXiv:2401.16625</a> [<a href=https://arxiv.org/pdf/2401.16625 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16625 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahi%2C+G+K">Gautam Kishore Shahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal%2C+A+K">Amit Kumar Jaiswal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandl%2C+T">Thomas Mandl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in the IR4Good Track at the 46th European Conference on Information Retrieval (ECIR) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Social and Information Networks (cs.SI)
</div>
<p class=mathjax>We contribute the first publicly available dataset of factual claims from
different platforms and fake YouTube videos on the 2023 Israel-Hamas war for
automatic fake YouTube video classification. The FakeClaim data is collected
from 60 fact-checking organizations in 30 languages and enriched with metadata
from the fact-checking organizations curated by trained journalists specialized
in fact-checking. Further, we classify fake videos within the subset of YouTube
videos using textual information and user comments. We used a pre-trained model
to classify each video with different feature combinations. Our best-performing
fine-tuned language model, Universal Sentence Encoder (USE), achieves a Macro
F1 of 87\%, which shows that the trained model can be helpful for debunking
fake videos using the comments from the user discussion. The dataset is
available on Github\footnote{https://github.com/Gautamshahi/FakeClaim}
</p>
</div>
</dd>
<dt><a name=item93>[93]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16626 title=Abstract>arXiv:2401.16626</a> [<a href=https://arxiv.org/pdf/2401.16626 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16626 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16626 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Implications of Zoning Ordinances for Rural Utility-Scale Solar Deployment and Power System Decarbonization in the Great Lakes Region
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Owusu-Obeng%2C+P+Y">Papa Yaw Owusu-Obeng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mills%2C+S+B">Sarah Banas Mills</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Craig%2C+M+T">Michael T. Craig</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Local zoning ordinances across the United States have the impact of
restricting development of energy infrastructure, including utility-scale solar
photovoltaics. While these ordinances may be developed for legitimate purposes
to protect public health and safety, they could impede or increase costs of
power sector decarbonization. We quantify the role of utility-scale solar
zoning ordinances on power sector decarbonization across the Great Lakes region
(Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin) by integrating
6,300 rural community zoning ordinances into a power system planning model.
Relative to no ordinances, solar zoning ordinances reduce total potential
deployment of solar PV by 52% (or 1.6 TW) across our region. Currently,
however, the biggest zoning barrier to deployment is zoning ordinances which
are silent on utility-scale solar. Deployment restrictions translate to up to 4
GW greater investment needs and 5.6% greater PV investment costs to achieve a
10% PV generation target. Starker shifts occur at the state level, e.g.
Wisconsin sees a 40% reduction in PV investments due to zoning restrictions.
Our results underscore the need for planning that aligns local zoning laws with
state and regional goals.
</p>
</div>
</dd>
<dt><a name=item94>[94]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16628 title=Abstract>arXiv:2401.16628</a> [<a href=https://arxiv.org/pdf/2401.16628 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16628 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16628 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A New Approach to Harnessing Side Information in Multi-Server Private Information Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+N">Ningze Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heidarzadeh%2C+A">Anoosheh Heidarzadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sprintson%2C+A">Alex Sprintson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper presents new solutions for Private Information Retrieval (PIR)
with side information. This problem is motivated by PIR settings in which a
client has side information about the data held by the servers and would like
to leverage this information in order to improve the download rate. The problem
of PIR with side information has been the subject of several recent studies
that presented achievability schemes as well as converses for both multi-server
and single-server settings. However, the solutions for the multi-server
settings adapted from the solutions for the single-server setting in a rather
straightforward manner, relying on the concept of super-messages. Such
solutions require an exponential degree of sub-packetization (in terms of the
number of messages).
<br>This paper makes the following contributions. First, we revisit the PIR
problem with side information and present a new approach to leverage side
information in the context of PIR. The key idea of our approach is a randomized
algorithm to determine the linear combinations of the sub-packets that need to
be recovered from each server. In addition, our approach takes advantage of the
fact that the identity of the side information messages does not need to be
kept private, and, as a result, the information retrieval scheme does not need
to be symmetric. Second, we present schemes for PIR with side information that
achieve a higher rate than previously proposed solutions and require a
significantly lower degree of sub-packetization (linear in the number of
servers). Our scheme not only achieves the highest known download rate for the
problem at hand but also invalidates a previously claimed converse bound on the
maximum achievable download rate.
</p>
</div>
</dd>
<dt><a name=item95>[95]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16630 title=Abstract>arXiv:2401.16630</a> [<a href=https://arxiv.org/pdf/2401.16630 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16630 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16630 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Achieving Capacity of PIR with Private Side Information with Low Sub-packetization and without MDS Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erhili%2C+L">Leila Erhili</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heidarzadeh%2C+A">Anoosheh Heidarzadeh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper revisits the problem of multi-server Private Information Retrieval
with Private Side Information (PIR-PSI). In this problem, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-41-Frame tabindex=0><nobr><span class=math id=MathJax-Span-287 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-288><span class=mi id=MathJax-Span-289 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> non-colluding
servers store identical copies of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-42-Frame tabindex=0><nobr><span class=math id=MathJax-Span-290 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-291><span class=mi id=MathJax-Span-292 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> messages, each comprising <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-43-Frame tabindex=0><nobr><span class=math id=MathJax-Span-293 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-294><span class=mi id=MathJax-Span-295 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> symbols
from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-44-Frame tabindex=0><nobr><span class=math id=MathJax-Span-296 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-297><span class=msubsup id=MathJax-Span-298><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-299><span class=mrow id=MathJax-Span-300><span class=mi id=MathJax-Span-301 style=font-family:MathJax_AMS>F</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=mi id=MathJax-Span-302 style=font-size:70.7%;font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, and a user, who knows <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-45-Frame tabindex=0><nobr><span class=math id=MathJax-Span-303 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-304><span class=mi id=MathJax-Span-305 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> of these messages, wants to
retrieve one of the remaining <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-46-Frame tabindex=0><nobr><span class=math id=MathJax-Span-306 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.19em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-307><span class=mi id=MathJax-Span-308 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-309 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-310 style=font-family:MathJax_Math-italic;padding-left:0.234em>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> messages. The user's goal is to retrieve
the desired message by downloading the minimum amount of information from the
servers while revealing no information about the identities of the desired
message and side information messages to any server. The capacity of PIR-PSI,
defined as the maximum achievable download rate, was previously characterized
for all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-47-Frame tabindex=0><nobr><span class=math id=MathJax-Span-311 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-312><span class=mi id=MathJax-Span-313 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-48-Frame tabindex=0><nobr><span class=math id=MathJax-Span-314 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-315><span class=mi id=MathJax-Span-316 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-49-Frame tabindex=0><nobr><span class=math id=MathJax-Span-317 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-318><span class=mi id=MathJax-Span-319 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-50-Frame tabindex=0><nobr><span class=math id=MathJax-Span-320 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-321><span class=mi id=MathJax-Span-322 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-51-Frame tabindex=0><nobr><span class=math id=MathJax-Span-323 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-324><span class=mi id=MathJax-Span-325 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> are sufficiently large --
specifically, growing exponentially with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-52-Frame tabindex=0><nobr><span class=math id=MathJax-Span-326 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-327><span class=mi id=MathJax-Span-328 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, to ensure the divisibility of
each message into <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-53-Frame tabindex=0><nobr><span class=math id=MathJax-Span-329 style=width:2.028em;display:inline-block><span style=display:inline-block;position:relative;width:1.681em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.68em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-330><span class=msubsup id=MathJax-Span-331><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-332 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.987em><span class=mi id=MathJax-Span-333 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> sub-packets and to guarantee the existence of an MDS
code with its length and dimension being exponential in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-54-Frame tabindex=0><nobr><span class=math id=MathJax-Span-334 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-335><span class=mi id=MathJax-Span-336 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In this work, we
propose a new capacity-achieving PIR-PSI scheme that is applicable to all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-55-Frame tabindex=0><nobr><span class=math id=MathJax-Span-337 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-338><span class=mi id=MathJax-Span-339 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>,
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-56-Frame tabindex=0><nobr><span class=math id=MathJax-Span-340 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-341><span class=mi id=MathJax-Span-342 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-57-Frame tabindex=0><nobr><span class=math id=MathJax-Span-343 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1001.04em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-344><span class=mi id=MathJax-Span-345 style=font-family:MathJax_Math-italic>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-58-Frame tabindex=0><nobr><span class=math id=MathJax-Span-346 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.64em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-347><span class=mi id=MathJax-Span-348 style=font-family:MathJax_Math-italic>L</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-59-Frame tabindex=0><nobr><span class=math id=MathJax-Span-349 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-350><span class=mi id=MathJax-Span-351 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span> where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-60-Frame tabindex=0><nobr><span class=math id=MathJax-Span-352 style=width:6.021em;display:inline-block><span style=display:inline-block;position:relative;width:4.98em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.92em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-353><span class=mi id=MathJax-Span-354 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-355 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mi id=MathJax-Span-356 style=font-family:MathJax_Math-italic;padding-left:0.292em>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-357 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-358 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-61-Frame tabindex=0><nobr><span class=math id=MathJax-Span-359 style=width:5.038em;display:inline-block><span style=display:inline-block;position:relative;width:4.17em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.11em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-360><span class=mi id=MathJax-Span-361 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-362 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-363 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-364 style=font-family:MathJax_Main;padding-left:0.292em>∣</span><span class=mi id=MathJax-Span-365 style=font-family:MathJax_Math-italic;padding-left:0.292em>L</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. The proposed scheme
operates with a sub-packetization level of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-62-Frame tabindex=0><nobr><span class=math id=MathJax-Span-366 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-367><span class=mi id=MathJax-Span-368 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-369 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-370 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, independent of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-63-Frame tabindex=0><nobr><span class=math id=MathJax-Span-371 style=width:1.16em;display:inline-block><span style=display:inline-block;position:relative;width:0.929em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.93em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-372><span class=mi id=MathJax-Span-373 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and works
over any finite field without requiring an MDS code.
</p>
</div>
</dd>
<dt><a name=item96>[96]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16632 title=Abstract>arXiv:2401.16632</a> [<a href=https://arxiv.org/pdf/2401.16632 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16632 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybridized Implicit-Explicit Flux Reconstruction Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pereira%2C+C+A">Carlos A. Pereira</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vermeire%2C+B+C">Brian C. Vermeire</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>For turbulent problems of industrial scale, computational cost may become
prohibitive due to the stability constraints associated with explicit time
discretization of the underlying conservation laws. On the other hand, implicit
methods allow for larger time-step sizes but require exorbitant computational
resources. Implicit-explicit (IMEX) formulations combine both temporal
approaches, using an explicit method in nonstiff portions of the domain and
implicit in stiff portions. While these methods can be shown to be orders of
magnitude faster than typical explicit discretizations, they are still limited
by their implicit discretization in terms of cost. Hybridization reduces the
scaling of these systems to an effective lower dimension, which allows the
system to be solved at significant speedup factors compared to standard
implicit methods. This work proposes an IMEX scheme that combines hybridized
and standard flux reconstriction (FR) methods to tackle geometry-induced
stiffness. By using the so-called transmission conditions, an overall
conservative formulation can be obtained after combining both explicit FR and
hybridized implicit FR methods. We verify and apply our approach to a series of
numerical examples, including a multi-element airfoil at Reynolds number 1.7
million. Results demonstrate speedup factors of four against standard IMEX
formulations and at least 15 against standard explicit formulations for the
same problem.
</p>
</div>
</dd>
<dt><a name=item97>[97]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16633 title=Abstract>arXiv:2401.16633</a> [<a href=https://arxiv.org/pdf/2401.16633 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16633 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16633 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sivakumar%2C+M">Mithila Sivakumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Belle%2C+A+B">Alvine B. Belle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahandashti%2C+K+K">Kimya Khakzad Shahandashti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Odu%2C+O">Oluwafemi Odu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hemmati%2C+H">Hadi Hemmati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kpodjedo%2C+S">Segla Kpodjedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adesina%2C+O+O">Opeyemi O. Adesina</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The execution failure of cyber-physical systems (e.g., autonomous driving
systems, unmanned aerial systems, and robotic systems) could result in the loss
of life, severe injuries, large-scale environmental damage, property
destruction, and major economic loss. Hence, such systems usually require a
strong justification that they will effectively support critical requirements
(e.g., safety, security, and reliability) for which they were designed. Thus,
it is often mandatory to develop compelling assurance cases to support that
justification and allow regulatory bodies to certify such systems. In such
contexts, detecting assurance deficits, relying on patterns to improve the
structure of assurance cases, improving existing assurance case notations, and
(semi-)automating the generation of assurance cases are key to develop
compelling assurance cases and foster consumer acceptance. We therefore explore
challenges related to such assurance enablers and outline some potential
directions that could be explored to tackle them.
</p>
</div>
</dd>
<dt><a name=item98>[98]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16634 title=Abstract>arXiv:2401.16634</a> [<a href=https://arxiv.org/pdf/2401.16634 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16634 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Why, When, and How to Use Active Learning in Large-Data-Driven 3D Object Detection for Safe Autonomous Driving: An Empirical Exploration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greer%2C+R">Ross Greer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniussen%2C+B">Bjørk Antoniussen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andersen%2C+M+V">Mathias V. Andersen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B8gelmose%2C+A">Andreas Møgelmose</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trivedi%2C+M+M">Mohan M. Trivedi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Active learning strategies for 3D object detection in autonomous driving
datasets may help to address challenges of data imbalance, redundancy, and
high-dimensional data. We demonstrate the effectiveness of entropy querying to
select informative samples, aiming to reduce annotation costs and improve model
performance. We experiment using the BEVFusion model for 3D object detection on
the nuScenes dataset, comparing active learning to random sampling and
demonstrating that entropy querying outperforms in most cases. The method is
particularly effective in reducing the performance gap between majority and
minority classes. Class-specific analysis reveals efficient allocation of
annotated resources for limited data budgets, emphasizing the importance of
selecting diverse and informative data for model training. Our findings suggest
that entropy querying is a promising strategy for selecting data that enhances
model learning in resource-constrained environments.
</p>
</div>
</dd>
<dt><a name=item99>[99]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16635 title=Abstract>arXiv:2401.16635</a> [<a href=https://arxiv.org/pdf/2401.16635 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16635 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Sunli Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yikang Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhiqing Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gan%2C+C">Chuang Gan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
</div>
<p class=mathjax>Reinforcement Learning from Human Feedback (RLHF) is a widely adopted
approach for aligning large language models with human values. However, RLHF
relies on a reward model that is trained with a limited amount of human
preference data, which could lead to inaccurate predictions. As a result, RLHF
may produce outputs that are misaligned with human values. To mitigate this
issue, we contribute a reward ensemble method that allows the reward model to
make more accurate predictions. As using an ensemble of large language
model-based reward models can be computationally and resource-expensive, we
explore efficient ensemble methods including linear-layer ensemble and
LoRA-based ensemble. Empirically, we run Best-of-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-64-Frame tabindex=0><nobr><span class=math id=MathJax-Span-374 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-375><span class=mi id=MathJax-Span-376 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and Proximal Policy
Optimization with our ensembled reward models, and verify that our ensemble
methods help improve the alignment performance of RLHF outputs.
</p>
</div>
</dd>
<dt><a name=item100>[100]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16637 title=Abstract>arXiv:2401.16637</a> [<a href=https://arxiv.org/pdf/2401.16637 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16637 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bolun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+T">Tao Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+Y">Yao Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Ge Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhi Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+C">Chen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for the 32nd ACM Symposium on the Foundations of Software Engineering (FSE 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Code completion aims to enhance programming productivity by predicting
potential code based on the current programming context. Recently, pretrained
language models (LMs) have become prominent in this field. Various approaches
have been proposed to fine-tune LMs using supervised fine-tuning (SFT)
techniques for code completion. However, the inherent exposure bias of these
models can cause errors to accumulate early in the sequence completion, leading
to even more errors in subsequent completions. To address this problem, deep
reinforcement learning (DRL) is an alternative technique for fine-tuning LMs
for code completion, which can improve the generalization capabilities and
overall performance. Nevertheless, integrating DRL-based strategies into code
completion faces two major challenges: 1) The dynamic nature of the code
context requires the completion model to quickly adapt to changes, which poses
difficulties for conventional DRL strategies that focus on delayed rewarding of
the final code state. 2) It is difficult to evaluate the correctness of partial
code, thus the reward redistribution-based strategies cannot be adapted to code
completion. To tackle these challenges, we propose IRCoCo, a code
completion-specific DRL-based fine-tuning framework. This framework is designed
to provide immediate rewards as feedback for detecting dynamic context changes
arising from continuous edits during code completion. With the aid of immediate
feedback, the fine-tuned LM can gain a more precise understanding of the
current context, thereby enabling effective adjustment of the LM and optimizing
code completion in a more refined manner. Experimental results demonstrate that
fine-tuning pretrained LMs with IRCoCo leads to significant improvements in the
code completion task, outperforming both SFT-based and other DRL-based
baselines.
</p>
</div>
</dd>
<dt><a name=item101>[101]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16638 title=Abstract>arXiv:2401.16638</a> [<a href=https://arxiv.org/pdf/2401.16638 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16638 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tytarenko%2C+S">Stepan Tytarenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amin%2C+M+R">Mohammad Ruhul Amin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 3 figures, 5 tables, To be published in 2024 AAAI workshop on Responsible Language Models (ReLM)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Fine-tuning large pre-trained language models (LLMs) on particular datasets
is a commonly employed strategy in Natural Language Processing (NLP)
classification tasks. However, this approach usually results in a loss of
models generalizability. In this paper, we present a framework that allows for
maintaining generalizability, and enhances the performance on the downstream
task by utilizing task-specific context attribution. We show that a linear
transformation of the text representation from any transformer model using the
task-specific concept operator results in a projection onto the latent concept
space, referred to as context attribution in this paper. The specific concept
operator is optimized during the supervised learning stage via novel loss
functions. The proposed framework demonstrates that context attribution of the
text representation for each task objective can improve the capacity of the
discriminator function and thus achieve better performance for the
classification task. Experimental results on three datasets, namely HateXplain,
IMDB reviews, and Social Media Attributions, illustrate that the proposed model
attains superior accuracy and generalizability. Specifically, for the
non-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement in
accuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,
fine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy and
F1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERT
fine-tuned on the IMDB dataset in conjunction with the proposed model improves
the F1-score on the HateXplain dataset by 7%. For the Social Media Attributions
dataset of YouTube comments, we observe 5.2% increase in F1-metric. The
proposed framework is implemented with PyTorch and provided open-source on
GitHub.
</p>
</div>
</dd>
<dt><a name=item102>[102]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16640 title=Abstract>arXiv:2401.16640</a> [<a href=https://arxiv.org/pdf/2401.16640 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16640 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corr%C3%AAa%2C+N+K">Nicholas Kluge Corrêa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Falk%2C+S">Sophia Falk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fatimah%2C+S">Shiza Fatimah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sen%2C+A">Aniket Sen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Oliveira%2C+N">Nythamar de Oliveira</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Large language models (LLMs) have significantly advanced natural language
processing, but their progress has yet to be equal across languages. While most
LLMs are trained in high-resource languages like English, multilingual models
generally underperform monolingual ones. Additionally, aspects of their
multilingual foundation sometimes restrict the byproducts they produce, like
computational demands and licensing regimes. In this study, we document the
development of open-foundation models tailored for use in low-resource
settings, their limitations, and their benefits. This is the TeenyTinyLlama
pair: two compact models for Brazilian Portuguese text generation. We release
them under the permissive Apache 2.0 license on GitHub and Hugging Face for
community use and further development. See
https://github.com/Nkluge-correa/TeenyTinyLlama
</p>
</div>
</dd>
<dt><a name=item103>[103]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16641 title=Abstract>arXiv:2401.16641</a> [<a href=https://arxiv.org/pdf/2401.16641 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16641 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Producers Equilibria and Dynamics in Engagement-Driven Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acharya%2C+K">Krishna Acharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vangala%2C+V">Varun Vangala</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingyan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziani%2C+J">Juba Ziani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>Online platforms such as YouTube, Instagram, TikTok heavily rely on
recommender systems to decide what content to show to which users. Content
producers often aim to produce material that is likely to be shown to users and
lead them to engage with said producer. To do so, producers try to align their
content with the preferences of their targeted user base. In this work, we
explore the equilibrium behavior of producers that are interested in maximizing
user engagement. We study two variants of the content-serving rule that the
platform's recommender system uses, and we show structural results on
producers' production at equilibrium. We leverage these structural results to
show that, in simple settings, we see specialization naturally arising from the
competition among producers trying to maximize user engagement. We provide a
heuristic for computing equilibria of our engagement game, and evaluate it
experimentally. We show i) the performance and convergence of our heuristic,
ii) the producer and user utilities at equilibrium, and iii) the level of
producer specialization.
</p>
</div>
</dd>
<dt><a name=item104>[104]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16643 title=Abstract>arXiv:2401.16643</a> [<a href=https://arxiv.org/pdf/2401.16643 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16643 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Game of Coding: Beyond Trusted Majorities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nodehi%2C+H+A">Hanzaleh Akbari Nodehi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cadambe%2C+V+R">Viveck R. Cadambe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maddah-Ali%2C+M+A">Mohammad Ali Maddah-Ali</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Coding theory revolves around the incorporation of redundancy into
transmitted symbols, computation tasks, and stored data to guard against
adversarial manipulation. However, error correction in coding theory is
contingent upon a strict trust assumption. In the context of computation and
storage, it is required that honest nodes outnumber adversarial ones by a
certain margin. However, in several emerging real-world cases, particularly, in
decentralized blockchain-oriented applications, such assumptions are often
unrealistic. Consequently, despite the important role of coding in addressing
significant challenges within decentralized systems, its applications become
constrained. Still, in decentralized platforms, a distinctive characteristic
emerges, offering new avenues for secure coding beyond the constraints of
conventional methods. In these scenarios, the adversary benefits when the
legitimate decoder recovers the data, and preferably with a high estimation
error. This incentive motivates them to act rationally, trying to maximize
their gains. In this paper, we propose a game theoretic formulation, called
game of coding, that captures this unique dynamic where each of the adversary
and the data collector (decoder) have a utility function to optimize. The
utility functions reflect the fact that both the data collector and the
adversary are interested to increase the chance of data being recoverable at
the data collector. Moreover, the utility functions express the interest of the
data collector to estimate the input with lower estimation error, but the
opposite interest of the adversary. As a first, still highly non-trivial step,
we characterize the equilibrium of the game for the repetition code with
repetition factor of 2, for a wide class of utility functions with minimal
assumptions.
</p>
</div>
</dd>
<dt><a name=item105>[105]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16645 title=Abstract>arXiv:2401.16645</a> [<a href=https://arxiv.org/pdf/2401.16645 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16645 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Speeding up and reducing memory usage for scientific machine learning via mixed precision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayford%2C+J">Joel Hayford</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldman-Wetzler%2C+J">Jacob Goldman-Wetzler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+E">Eric Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+L">Lu Lu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Scientific machine learning (SciML) has emerged as a versatile approach to
address complex computational science and engineering problems. Within this
field, physics-informed neural networks (PINNs) and deep operator networks
(DeepONets) stand out as the leading techniques for solving partial
differential equations by incorporating both physical equations and
experimental data. However, training PINNs and DeepONets requires significant
computational resources, including long computational times and large amounts
of memory. In search of computational efficiency, training neural networks
using half precision (float16) rather than the conventional single (float32) or
double (float64) precision has gained substantial interest, given the inherent
benefits of reduced computational time and memory consumed. However, we find
that float16 cannot be applied to SciML methods, because of gradient divergence
at the start of training, weight updates going to zero, and the inability to
converge to a local minima. To overcome these limitations, we explore mixed
precision, which is an approach that combines the float16 and float32 numerical
formats to reduce memory usage and increase computational speed. Our
experiments showcase that mixed precision training not only substantially
decreases training times and memory demands but also maintains model accuracy.
We also reinforce our empirical observations with a theoretical analysis. The
research has broad implications for SciML in various computational
applications.
</p>
</div>
</dd>
<dt><a name=item106>[106]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16646 title=Abstract>arXiv:2401.16646</a> [<a href=https://arxiv.org/pdf/2401.16646 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16646 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Incoherent Probability Judgments in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jian-Qiao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Autoregressive Large Language Models (LLMs) trained for next-word prediction
have demonstrated remarkable proficiency at producing coherent text. But are
they equally adept at forming coherent probability judgments? We use
probabilistic identities and repeated judgments to assess the coherence of
probability judgments made by LLMs. Our results show that the judgments
produced by these models are often incoherent, displaying human-like systematic
deviations from the rules of probability theory. Moreover, when prompted to
judge the same event, the mean-variance relationship of probability judgments
produced by LLMs shows an inverted-U-shaped like that seen in humans. We
propose that these deviations from rationality can be explained by linking
autoregressive LLMs to implicit Bayesian inference and drawing parallels with
the Bayesian Sampler model of human probability judgments.
</p>
</div>
</dd>
<dt><a name=item107>[107]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16647 title=Abstract>arXiv:2401.16647</a> [<a href=https://arxiv.org/pdf/2401.16647 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16647 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Family of Low-Complexity Binary Codes with Constant Hamming Weights
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sasidharan%2C+B">Birenjith Sasidharan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Viterbo%2C+E">Emanuele Viterbo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dau%2C+S+H">Son Hoang Dau</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to Designs, Codes and Cryptography
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Combinatorics (math.CO)
</div>
<p class=mathjax>In this paper, we focus on the design of binary constant-weight codes that
admit low-complexity encoding and decoding algorithms, and that have size as a
power of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-65-Frame tabindex=0><nobr><span class=math id=MathJax-Span-377 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-378><span class=mn id=MathJax-Span-379 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. We construct a family of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-66-Frame tabindex=0><nobr><span class=math id=MathJax-Span-380 style=width:12.329em;display:inline-block><span style=display:inline-block;position:relative;width:10.246em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1010.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-381><span class=mo id=MathJax-Span-382 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-383 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-384 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-385 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-386 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-387 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-388 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-389 style=font-family:MathJax_Math-italic;padding-left:0.177em>M<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-390 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-391 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-392 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-393 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-394 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-395 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-396 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-397 style=font-family:MathJax_Main;padding-left:0.292em>2</span><span class=mo id=MathJax-Span-398 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> constant-weight
codes <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-67-Frame tabindex=0><nobr><span class=math id=MathJax-Span-399 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-400><span class=texatom id=MathJax-Span-401><span class=mrow id=MathJax-Span-402><span class=mi id=MathJax-Span-403 style=font-family:MathJax_Caligraphic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span class=mo id=MathJax-Span-404 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-405 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-406 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-407 style=font-family:MathJax_Math-italic;padding-left:0.177em>r</span><span class=mo id=MathJax-Span-408 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> parameterized by integers <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-68-Frame tabindex=0><nobr><span class=math id=MathJax-Span-409 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-410><span class=mi id=MathJax-Span-411 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-412 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-413 style=font-family:MathJax_Main;padding-left:0.292em>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-69-Frame tabindex=0><nobr><span class=math id=MathJax-Span-414 style=width:7.41em;display:inline-block><span style=display:inline-block;position:relative;width:6.137em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1005.96em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-415><span class=mn id=MathJax-Span-416 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-417 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-418 style=font-family:MathJax_Math-italic;padding-left:0.292em>r</span><span class=mo id=MathJax-Span-419 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mo id=MathJax-Span-420 style=font-family:MathJax_Main;padding-left:0.292em>⌊</span><span class=mfrac id=MathJax-Span-421><span style=display:inline-block;position:relative;width:1.334em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1001.16em,4.227em,-999.997em);top:-4.453em;left:50%;margin-left:-0.576em><span class=mrow id=MathJax-Span-422><span class=mi id=MathJax-Span-423 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-424 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-425 style=font-size:70.7%;font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-426 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.33em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.334em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-427 style=font-family:MathJax_Main>⌋</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.809em"></span></span></nobr></span>, by encoding information in the gaps
between successive <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-70-Frame tabindex=0><nobr><span class=math id=MathJax-Span-428 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-429><span class=mn id=MathJax-Span-430 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>'s of a vector. The code has weight <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-71-Frame tabindex=0><nobr><span class=math id=MathJax-Span-431 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.49em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-432><span class=mi id=MathJax-Span-433 style=font-family:MathJax_Math-italic>w</span><span class=mo id=MathJax-Span-434 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-435 style=font-family:MathJax_Main;padding-left:0.292em>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and
combinatorial dimension <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-72-Frame tabindex=0><nobr><span class=math id=MathJax-Span-436 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-437><span class=mi id=MathJax-Span-438 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> that scales quadratically with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-73-Frame tabindex=0><nobr><span class=math id=MathJax-Span-439 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-440><span class=mi id=MathJax-Span-441 style=font-family:MathJax_Main>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. The encoding
time is linear in the input size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-74-Frame tabindex=0><nobr><span class=math id=MathJax-Span-442 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-443><span class=mi id=MathJax-Span-444 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and the decoding time is poly-logarithmic
in the input size <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-75-Frame tabindex=0><nobr><span class=math id=MathJax-Span-445 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-446><span class=mi id=MathJax-Span-447 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>, discounting the linear time spent on parsing the input.
Encoding and decoding algorithms of similar codes known in either
information-theoretic or combinatorial literature require computation of large
number of binomial coefficients. Our algorithms fully eliminate the need to
evaluate binomial coefficients. While the code has a natural price to pay in
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-76-Frame tabindex=0><nobr><span class=math id=MathJax-Span-448 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-449><span class=mi id=MathJax-Span-450 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, it performs fairly well against the information-theoretic upper bound
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-77-Frame tabindex=0><nobr><span class=math id=MathJax-Span-451 style=width:5.038em;display:inline-block><span style=display:inline-block;position:relative;width:4.17em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1004em,2.781em,-999.997em);top:-2.254em;left:0em><span class=mrow id=MathJax-Span-452><span class=mo id=MathJax-Span-453 style=font-family:MathJax_Main>⌊</span><span class=msubsup id=MathJax-Span-454><span style=display:inline-block;position:relative;width:1.681em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.28em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-455 style=font-family:MathJax_Main>log</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.759em;left:1.276em><span class=mn id=MathJax-Span-456 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-457></span><span class=texatom id=MathJax-Span-458 style=padding-left:0.177em><span class=mrow id=MathJax-Span-459><span class=mrow id=MathJax-Span-460><span class=TeXmathchoice id=MathJax-Span-461><span class=texatom id=MathJax-Span-462><span class=mrow id=MathJax-Span-463><span class=mo id=MathJax-Span-464 style=vertical-align:0em><span style=font-family:MathJax_Size1>(</span></span></span></span></span><span class=mfrac id=MathJax-Span-465><span style=display:inline-block;position:relative;width:0.524em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.41em,4.17em,-999.997em);top:-4.453em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-466 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.47em,4.17em,-999.997em);top:-3.643em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-467 style=font-size:70.7%;font-family:MathJax_Math-italic>w</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=TeXmathchoice id=MathJax-Span-468><span class=texatom id=MathJax-Span-469><span class=mrow id=MathJax-Span-470><span class=mo id=MathJax-Span-471 style=vertical-align:0em><span style=font-family:MathJax_Size1>)</span></span></span></span></span></span></span></span><span class=mo id=MathJax-Span-472 style=font-family:MathJax_Main>⌋</span></span><span style=display:inline-block;width:0px;height:2.26em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>. When <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-78-Frame tabindex=0><nobr><span class=math id=MathJax-Span-473 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-474><span class=mi id=MathJax-Span-475 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-476 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-477 style=font-family:MathJax_Main;padding-left:0.292em>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, the code is optimal
achieving the upper bound; when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-79-Frame tabindex=0><nobr><span class=math id=MathJax-Span-478 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-479><span class=mi id=MathJax-Span-480 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-481 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mn id=MathJax-Span-482 style=font-family:MathJax_Main;padding-left:0.292em>4</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, it is one bit away from the upper
bound, and as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-80-Frame tabindex=0><nobr><span class=math id=MathJax-Span-483 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-484><span class=mi id=MathJax-Span-485 style=font-family:MathJax_Main>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> grows it is order-optimal in the sense that the ratio of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-81-Frame tabindex=0><nobr><span class=math id=MathJax-Span-486 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-487><span class=mi id=MathJax-Span-488 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> with its upper bound becomes a constant <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-82-Frame tabindex=0><nobr><span class=math id=MathJax-Span-489 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.04em,1.565em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-490><span class=mfrac id=MathJax-Span-491><span style=display:inline-block;position:relative;width:0.813em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.344em><span class=mn id=MathJax-Span-492 style=font-size:70.7%;font-family:MathJax_Main>11</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.7em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.344em><span class=mn id=MathJax-Span-493 style=font-size:70.7%;font-family:MathJax_Main>16</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.81em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.813em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span> when <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-83-Frame tabindex=0><nobr><span class=math id=MathJax-Span-494 style=width:5.153em;display:inline-block><span style=display:inline-block;position:relative;width:4.285em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1004.11em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-495><span class=mi id=MathJax-Span-496 style=font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-497 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mo id=MathJax-Span-498 style=font-family:MathJax_Main;padding-left:0.292em>⌊</span><span class=mfrac id=MathJax-Span-499><span style=display:inline-block;position:relative;width:1.334em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1001.16em,4.227em,-999.997em);top:-4.453em;left:50%;margin-left:-0.576em><span class=mrow id=MathJax-Span-500><span class=mi id=MathJax-Span-501 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-502 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-503 style=font-size:70.7%;font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-504 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.33em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.334em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-505 style=font-family:MathJax_Main>⌋</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.809em"></span></span></nobr></span>. With the same or even lower complexity, we derive
new codes permitting a wider range of parameters by modifying <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-84-Frame tabindex=0><nobr><span class=math id=MathJax-Span-506 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.32em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-507><span class=texatom id=MathJax-Span-508><span class=mrow id=MathJax-Span-509><span class=mi id=MathJax-Span-510 style=font-family:MathJax_Caligraphic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span class=mo id=MathJax-Span-511 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-512 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-513 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-514 style=font-family:MathJax_Math-italic;padding-left:0.177em>r</span><span class=mo id=MathJax-Span-515 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> in two different ways. The code derived using the first approach has the
same blocklength <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-85-Frame tabindex=0><nobr><span class=math id=MathJax-Span-516 style=width:3.417em;display:inline-block><span style=display:inline-block;position:relative;width:2.839em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1002.84em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-517><span class=mi id=MathJax-Span-518 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-519 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-520 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-521 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-522 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span>, but weight <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-86-Frame tabindex=0><nobr><span class=math id=MathJax-Span-523 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.7em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-524><span class=mi id=MathJax-Span-525 style=font-family:MathJax_Math-italic>w</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> is allowed to vary from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-87-Frame tabindex=0><nobr><span class=math id=MathJax-Span-526 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.09em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-527><span class=mi id=MathJax-Span-528 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-529 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mn id=MathJax-Span-530 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> to
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-88-Frame tabindex=0><nobr><span class=math id=MathJax-Span-531 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-532><span class=mn id=MathJax-Span-533 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In the second approach, the weight remains fixed as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-89-Frame tabindex=0><nobr><span class=math id=MathJax-Span-534 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.49em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-535><span class=mi id=MathJax-Span-536 style=font-family:MathJax_Math-italic>w</span><span class=mo id=MathJax-Span-537 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-538 style=font-family:MathJax_Main;padding-left:0.292em>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, but the
blocklength is reduced to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-90-Frame tabindex=0><nobr><span class=math id=MathJax-Span-539 style=width:8.105em;display:inline-block><span style=display:inline-block;position:relative;width:6.716em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1006.66em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-540><span class=mi id=MathJax-Span-541 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-542 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=msubsup id=MathJax-Span-543 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-544 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-545 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-546 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=msubsup id=MathJax-Span-547 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-548 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=mi id=MathJax-Span-549 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-550 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-551 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. For certain selected values of
parameters, these modified codes have an optimal <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-91-Frame tabindex=0><nobr><span class=math id=MathJax-Span-552 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-553><span class=mi id=MathJax-Span-554 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item108>[108]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16649 title=Abstract>arXiv:2401.16649</a> [<a href=https://arxiv.org/pdf/2401.16649 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16649 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Using Motion Forecasting for Behavior-Based Virtual Reality (VR) Authentication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mingjun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+S">Sean Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AIxVR 2024 Best Paper Award
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)
</div>
<p class=mathjax>Task-based behavioral biometric authentication of users interacting in
virtual reality (VR) environments enables seamless continuous authentication by
using only the motion trajectories of the person's body as a unique signature.
Deep learning-based approaches for behavioral biometrics show high accuracy
when using complete or near complete portions of the user trajectory, but show
lower performance when using smaller segments from the start of the task. Thus,
any systems designed with existing techniques are vulnerable while waiting for
future segments of motion trajectories to become available. In this work, we
present the first approach that predicts future user behavior using
Transformer-based forecasting and using the forecasted trajectory to perform
user authentication. Our work leverages the notion that given the current
trajectory of a user in a task-based environment we can predict the future
trajectory of the user as they are unlikely to dramatically shift their
behavior since it would preclude the user from successfully completing their
task goal. Using the publicly available 41-subject ball throwing dataset of
Miller et al. we show improvement in user authentication when using forecasted
data. When compared to no forecasting, our approach reduces the authentication
equal error rate (EER) by an average of 23.85% and a maximum reduction of
36.14%.
</p>
</div>
</dd>
<dt><a name=item109>[109]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16650 title=Abstract>arXiv:2401.16650</a> [<a href=https://arxiv.org/pdf/2401.16650 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16650 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Augmenting Replay in World Models for Continual Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Luke Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuhlmann%2C+L">Levin Kuhlmann</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kowadlo%2C+G">Gideon Kowadlo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>In continual RL, the environment of a reinforcement learning (RL) agent
undergoes change. A successful system should appropriately balance the
conflicting requirements of retaining agent performance on already learned
tasks, stability, whilst learning new tasks, plasticity. The first-in-first-out
buffer is commonly used to enhance learning in such settings but requires
significant memory. We explore the application of an augmentation to this
buffer which alleviates the memory constraints, and use it with a world model
model-based reinforcement learning algorithm, to evaluate its effectiveness in
facilitating continual learning. We evaluate the effectiveness of our method in
Procgen and Atari RL benchmarks and show that the distribution matching
augmentation to the replay-buffer used in the context of latent world models
can successfully prevent catastrophic forgetting with significantly reduced
computational overhead. Yet, we also find such a solution to not be entirely
infallible, and other failure modes such as the opposite -- lacking plasticity
and being unable to learn a new task -- to be a potential limitation in
continual learning systems.
</p>
</div>
</dd>
<dt><a name=item110>[110]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16653 title=Abstract>arXiv:2401.16653</a> [<a href=https://arxiv.org/pdf/2401.16653 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16653 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ILBiT: Imitation Learning for Robot Using Position and Torque Information based on Bilateral Control with Transformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kobayashi%2C+M">Masato Kobayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buamanee%2C+T">Thanpimon Buamanee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uranishi%2C+Y">Yuki Uranishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takemura%2C+H">Haruo Takemura</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Autonomous manipulation in robot arms is a complex and evolving field of
study in robotics. This paper introduces an innovative approach to this
challenge by focusing on imitation learning (IL). Unlike traditional imitation
methods, our approach uses IL based on bilateral control, allowing for more
precise and adaptable robot movements. The conventional IL based on bilateral
control method have relied on Long Short-Term Memory (LSTM) networks. In this
paper, we present the IL for robot using position and torque information based
on Bilateral control with Transformer (ILBiT). This proposed method employs the
Transformer model, known for its robust performance in handling diverse
datasets and its capability to surpass LSTM's limitations, especially in tasks
requiring detailed force adjustments. A standout feature of ILBiT is its
high-frequency operation at 100 Hz, which significantly improves the system's
adaptability and response to varying environments and objects of different
hardness levels. The effectiveness of the Transformer-based ILBiT method can be
seen through comprehensive real-world experiments.
</p>
</div>
</dd>
<dt><a name=item111>[111]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16654 title=Abstract>arXiv:2401.16654</a> [<a href=https://arxiv.org/pdf/2401.16654 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16654 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling BLV Developers with LLM-driven Code Debugging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saben%2C+C">Clark Saben</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandrasekar%2C+P">Prashant Chandrasekar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>BLVRUN is a command line shell script designed to offer developers within the
BLV community a succinct and insightful overview of traceback errors. Its
primary function involves parsing errors and utilizing a refined large language
model to generate informative error summaries. In terms of performance, our
model rivals that of well-known models like ChatGPT or AI-chatbot plug-ins
tailored for specific Integrated Development Environments (IDEs). Importantly,
BLV users can seamlessly integrate this tool into their existing development
workflows, eliminating the need for any modifications or adaptations to
facilitate debugging tasks.
</p>
</div>
</dd>
<dt><a name=item112>[112]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16656 title=Abstract>arXiv:2401.16656</a> [<a href=https://arxiv.org/pdf/2401.16656 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16656 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gradient-Based Language Model Red Teaming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wichers%2C+N">Nevan Wichers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Denison%2C+C">Carson Denison</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beirami%2C+A">Ahmad Beirami</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 main conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Red teaming is a common strategy for identifying weaknesses in generative
language models (LMs), where adversarial prompts are produced that trigger an
LM to generate unsafe responses. Red teaming is instrumental for both model
alignment and evaluation, but is labor-intensive and difficult to scale when
done by humans. In this paper, we present Gradient-Based Red Teaming (GBRT), a
red teaming method for automatically generating diverse prompts that are likely
to cause an LM to output unsafe responses. GBRT is a form of prompt learning,
trained by scoring an LM response with a safety classifier and then
backpropagating through the frozen safety classifier and LM to update the
prompt. To improve the coherence of input prompts, we introduce two variants
that add a realism loss and fine-tune a pretrained model to generate the
prompts instead of learning the prompts directly. Our experiments show that
GBRT is more effective at finding prompts that trigger an LM to generate unsafe
responses than a strong reinforcement learning-based red teaming approach, and
succeeds even when the LM has been fine-tuned to produce safer outputs.
</p>
</div>
</dd>
<dt><a name=item113>[113]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16657 title=Abstract>arXiv:2401.16657</a> [<a href=https://arxiv.org/pdf/2401.16657 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16657 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jian-Qiao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+H">Haijiang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Simulating sampling algorithms with people has proven a useful method for
efficiently probing and understanding their mental representations. We propose
that the same methods can be used to study the representations of Large
Language Models (LLMs). While one can always directly prompt either humans or
LLMs to disclose their mental representations introspectively, we show that
increased efficiency can be achieved by using LLMs as elements of a sampling
algorithm. We explore the extent to which we recover human-like representations
when LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo
(MCMC). We found a significant increase in efficiency and performance using
adaptive sampling algorithms based on MCMC. We also highlight the potential of
our method to yield a more general method of conducting Bayesian inference
\textit{with} LLMs.
</p>
</div>
</dd>
<dt><a name=item114>[114]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16658 title=Abstract>arXiv:2401.16658</a> [<a href=https://arxiv.org/pdf/2401.16658 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16658 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16658 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">William Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arora%2C+S">Siddhant Arora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+B">Brian Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sudo%2C+Y">Yui Sudo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shakeel%2C+M">Muhammad Shakeel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+K">Kwanghee Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiatong Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+X">Xuankai Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project webpage: <a href=https://www.wavlab.org/activities/2024/owsm/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Recent studies have advocated for fully open foundation models to promote
transparency and open science. As an initial step, the Open Whisper-style
Speech Model (OWSM) reproduced OpenAI's Whisper using publicly available data
and open-source toolkits. With the aim of reproducing Whisper, the previous
OWSM v1 through v3 models were still based on Transformer, which might lead to
inferior performance compared to other state-of-the-art speech encoders. In
this work, we aim to improve the performance and efficiency of OWSM without
extra training data. We present E-Branchformer based OWSM v3.1 models at two
scales, i.e., 100M and 1B. The 1B model is the largest E-Branchformer based
speech model that has been made publicly available. It outperforms the previous
OWSM v3 in a vast majority of evaluation benchmarks, while demonstrating up to
25% faster inference speed. We publicly release the data preparation scripts,
pre-trained models and training logs.
</p>
</div>
</dd>
<dt><a name=item115>[115]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16659 title=Abstract>arXiv:2401.16659</a> [<a href=https://arxiv.org/pdf/2401.16659 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16659 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> History-Aware Conversational Dense Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mo%2C+F">Fengran Mo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+C">Chen Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+K">Kelong Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tianyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Z">Zhan Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaiyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>Conversational search facilitates complex information retrieval by enabling
multi-turn interactions between users and the system. Supporting such
interactions requires a comprehensive understanding of the conversational
inputs to formulate a good search query based on historical information. In
particular, the search query should include the relevant information from the
previous conversation turns. However, current approaches for conversational
dense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retriever
using the whole conversational search session, which can be lengthy and noisy.
Moreover, existing approaches are limited by the amount of manual supervision
signals in the existing datasets. To address the aforementioned issues, we
propose a History-Aware Conversational Dense Retrieval (HAConvDR) system, which
incorporates two ideas: context-denoised query reformulation and automatic
mining of supervision signals based on the actual impact of historical turns.
Experiments on two public conversational search datasets demonstrate the
improved history modeling capability of HAConvDR, in particular for long
conversations with topic shifts.
</p>
</div>
</dd>
<dt><a name=item116>[116]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16661 title=Abstract>arXiv:2401.16661</a> [<a href=https://arxiv.org/pdf/2401.16661 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16661 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16661 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalization of LiNGAM that allows confounding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suzuki%2C+J">Joe Suzuki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+T">Tian-Le Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)
</div>
<p class=mathjax>LiNGAM determines the variable order from cause to effect using additive
noise models, but it faces challenges with confounding. Previous methods
maintained LiNGAM's fundamental structure while trying to identify and address
variables affected by confounding. As a result, these methods required
significant computational resources regardless of the presence of confounding,
and they did not ensure the detection of all confounding types. In contrast,
this paper enhances LiNGAM by introducing LiNGAM-MMI, a method that quantifies
the magnitude of confounding using KL divergence and arranges the variables to
minimize its impact. This method efficiently achieves a globally optimal
variable order through the shortest path problem formulation. LiNGAM-MMI
processes data as efficiently as traditional LiNGAM in scenarios without
confounding while effectively addressing confounding situations. Our
experimental results suggest that LiNGAM-MMI more accurately determines the
correct variable order, both in the presence and absence of confounding.
</p>
</div>
</dd>
<dt><a name=item117>[117]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16663 title=Abstract>arXiv:2401.16663</a> [<a href=https://arxiv.org/pdf/2401.16663 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16663 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VR-GS: A Physical Dynamics-Aware Interactive Gaussian Splatting System in Virtual Reality
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Ying Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C">Chang Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+T">Tianyi Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yutao Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huamin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Minchen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lau%2C+H">Henry Lau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+F">Feng Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+C">Chenfanfu Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>As consumer Virtual Reality (VR) and Mixed Reality (MR) technologies gain
momentum, there's a growing focus on the development of engagements with 3D
virtual content. Unfortunately, traditional techniques for content creation,
editing, and interaction within these virtual spaces are fraught with
difficulties. They tend to be not only engineering-intensive but also require
extensive expertise, which adds to the frustration and inefficiency in virtual
object manipulation. Our proposed VR-GS system represents a leap forward in
human-centered 3D content interaction, offering a seamless and intuitive user
experience. By developing a physical dynamics-aware interactive Gaussian
Splatting in a Virtual Reality setting, and constructing a highly efficient
two-level embedding strategy alongside deformable body simulations, VR-GS
ensures real-time execution with highly realistic dynamic responses. The
components of our Virtual Reality system are designed for high efficiency and
effectiveness, starting from detailed scene reconstruction and object
segmentation, advancing through multi-view image in-painting, and extending to
interactive physics-based editing. The system also incorporates real-time
deformation embedding and dynamic shadow casting, ensuring a comprehensive and
engaging virtual experience.Our project page is available at:
https://yingjiang96.github.io/VR-GS/.
</p>
</div>
</dd>
<dt><a name=item118>[118]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16664 title=Abstract>arXiv:2401.16664</a> [<a href=https://arxiv.org/pdf/2401.16664 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16664 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16664 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fast Dual-Regularized Autoencoder for Sparse Biological Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poleksic%2C+A">Aleksandar Poleksic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Relationship inference from sparse data is an important task with
applications ranging from product recommendation to drug discovery. A recently
proposed linear model for sparse matrix completion has demonstrated surprising
advantage in speed and accuracy over more sophisticated recommender systems
algorithms. Here we extend the linear model to develop a shallow autoencoder
for the dual neighborhood-regularized matrix completion problem. We demonstrate
the speed and accuracy advantage of our approach over the existing
state-of-the-art in predicting drug-target interactions and drug-disease
associations.
</p>
</div>
</dd>
<dt><a name=item119>[119]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16668 title=Abstract>arXiv:2401.16668</a> [<a href=https://arxiv.org/pdf/2401.16668 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16668 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies for Reducing Smartphone Overuse
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+T">Tao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+H">Hongxiao Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuhai Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+A">Anhong Guo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Smartphone overuse poses risks to people's physical and mental health.
However, current intervention techniques mainly focus on explicitly changing
screen content (i.e., output) and often fail to persistently reduce smartphone
overuse due to being over-restrictive or over-flexible. We present the design
and implementation of InteractOut, a suite of implicit input manipulation
techniques that leverage interaction proxies to weakly inhibit the natural
execution of common user gestures on mobile devices. We present a design space
for input manipulations and demonstrate 8 Android implementations of input
interventions. We first conducted a pilot lab study (N=30) to evaluate the
usability of these interventions. Based on the results, we then performed a
5-week within-subject field experiment (N=42) to evaluate InteractOut in
real-world scenarios. Compared to the traditional and common timed lockout
technique, InteractOut significantly reduced the usage time by an additional
15.0% and opening frequency by 17.0% on participant-selected target apps.
InteractOut also achieved a 25.4% higher user acceptance rate, and resulted in
less frustration and better user experience according to participants'
subjective feedback. InteractOut demonstrates a new direction for smartphone
overuse intervention and serves as a strong complementary set of techniques
with existing methods.
</p>
</div>
</dd>
<dt><a name=item120>[120]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16669 title=Abstract>arXiv:2401.16669</a> [<a href=https://arxiv.org/pdf/2401.16669 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16669 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16669 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Is Artificial Intelligence Providing the Second Revolution for Weather Forecasting?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ling%2C+F">Fenghua Ling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang%2C+L">Lin Ouyang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larbi%2C+B+R">Boufeniza Redouane Larbi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+J">Jing-Jia Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+T">Tao Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+X">Xiaohui Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph); Geophysics (physics.geo-ph)
</div>
<p class=mathjax>The rapid advancement of artificial intelligence technologies, particularly
in recent years, has led to the emergence of several large parameter artificial
intelligence weather forecast models. These models represent a significant
breakthrough, overcoming the limitations of traditional numerical weather
prediction models and indicating a potential second revolution for weather
forecast. This study explores the evolution of these advanced artificial
intelligence forecast models, and based on the identified commonalities,
proposes the "Three Large Rules" for their development. We discuss the
potential of artificial intelligence in revolutionizing numerical weather
prediction, briefly outlining the underlying reasons for this potential.
Additionally, we explore key areas for future development prospects for large
artificial intelligence weather forecast models, integrating the entire
numerical prediction process. Through an example that combines a large
artificial intelligence model with ocean wave forecasting, we illustrate how
forecasters can adapt and leverage the advanced artificial intelligence model.
While acknowledging the high accuracy, computational efficiency, and ease of
deployment of large artificial intelligence forecast models, we emphasize the
irreplaceable values of traditional numerical forecasts. We believe that the
optimal future of weather forecasting lies in achieving a seamless integration
of artificial intelligence and traditional numerical models. Such a synthesis
is anticipated to offer a more comprehensive and reliable approach for future
weather forecasting.
</p>
</div>
</dd>
<dt><a name=item121>[121]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16672 title=Abstract>arXiv:2401.16672</a> [<a href=https://arxiv.org/pdf/2401.16672 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16672 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16672 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AutoIE: An Automated Framework for Information Extraction from Scientific Literature
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yangyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shoubin Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)
</div>
<p class=mathjax>In the rapidly evolving field of scientific research, efficiently extracting
key information from the burgeoning volume of scientific papers remains a
formidable challenge. This paper introduces an innovative framework designed to
automate the extraction of vital data from scientific PDF documents, enabling
researchers to discern future research trajectories more readily. AutoIE
uniquely integrates four novel components: (1) A multi-semantic feature
fusion-based approach for PDF document layout analysis; (2) Advanced functional
block recognition in scientific texts; (3) A synergistic technique for
extracting and correlating information on molecular sieve synthesis; (4) An
online learning paradigm tailored for molecular sieve literature. Our SBERT
model achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE
datasets. In addition, a practical application of AutoIE in the petrochemical
molecular sieve synthesis domain demonstrates its efficacy, evidenced by an
impressive 78\% accuracy rate. This research paves the way for enhanced data
management and interpretation in molecular sieve synthesis. It is a valuable
asset for seasoned experts and newcomers in this specialized field.
</p>
</div>
</dd>
<dt><a name=item122>[122]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16677 title=Abstract>arXiv:2401.16677</a> [<a href=https://arxiv.org/pdf/2401.16677 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16677 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> T3: Transparent Tracking &amp; Triggering for Fine-grained Overlap of Compute &amp; Collectives
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pati%2C+S">Suchita Pati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aga%2C+S">Shaizeen Aga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Islam%2C+M">Mahzabeen Islam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jayasena%2C+N">Nuwan Jayasena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinclair%2C+M+D">Matthew D. Sinclair</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear at the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)
</div>
<p class=mathjax>Large Language Models increasingly rely on distributed techniques for their
training and inference. These techniques require communication across devices
which can reduce scaling efficiency as the number of devices increases. While
some distributed techniques can overlap, and thus, hide this communication with
independent computations, techniques such as Tensor Parallelism (TP) inherently
serialize communication with model execution. One approach to hide this
serialized communication is to interleave it with the producer operation (of
the communicated data) in a fine-grained manner. However, this fine-grained
interleaving of communication and computation in software can be difficult.
Furthermore, as with any concurrent execution, it requires compute and memory
resources to be shared between computation and communication, causing resource
contention that reduces overlapping efficacy.
<br>To overcome these challenges, we propose T3 which applies hardware-software
co-design to transparently overlap serialized communication while minimizing
resource contention with compute. T3 transparently fuses producer operations
with the subsequent communication via a simple configuration of the producer's
output address space and requires minor software changes. At the hardware
level, T3 adds a lightweight track and trigger mechanism to orchestrate the
producer's compute, and communication. It further uses compute-enhanced
memories for communication's attendant compute. As a result, T3 reduces
resource contention, and efficiently overlaps serialized communication with
computation. For important Transformer models like T-NLG, T3 speeds up
communication-heavy sublayers by 30% geomean (max 47%) and reduces data
movement by 22% geomean (max 36%). Furthermore, T3's benefits persist as models
scale: geomean 29% for sublayers in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-92-Frame tabindex=0><nobr><span class=math id=MathJax-Span-555 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.681em,1000.7em,2.26em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-556><span class=mo id=MathJax-Span-557 style=font-family:MathJax_Main>∼</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:0.073em;border-left:0px solid;width:0px;height:0.42em"></span></span></nobr></span>500-billion parameter models, PALM
and MT-NLG.
</p>
</div>
</dd>
<dt><a name=item123>[123]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16678 title=Abstract>arXiv:2401.16678</a> [<a href=https://arxiv.org/pdf/2401.16678 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16678 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Detection and Understanding of Fictional Discourse
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piper%2C+A">Andrew Piper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Haiqi Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we present a variety of classification experiments related to
the task of fictional discourse detection. We utilize a diverse array of
datasets, including contemporary professionally published fiction, historical
fiction from the Hathi Trust, fanfiction, stories from Reddit, folk tales,
GPT-generated stories, and anglophone world literature. Additionally, we
introduce a new feature set of word "supersenses" that facilitate the goal of
semantic generalization. The detection of fictional discourse can help enrich
our knowledge of large cultural heritage archives and assist with the process
of understanding the distinctive qualities of fictional storytelling more
broadly.
</p>
</div>
</dd>
<dt><a name=item124>[124]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16682 title=Abstract>arXiv:2401.16682</a> [<a href=https://arxiv.org/pdf/2401.16682 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16682 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recent Advances in Model-Based Fault Diagnosis for Lithium-Ion Batteries: A Comprehensive Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xu%2C+Y">Yiming Xu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ge%2C+X">Xiaohua Ge</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+R">Ruohan Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Shen%2C+W">Weixiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to Renewable and Sustainable Energy Reviews on 09-Jan-2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Lithium-ion batteries (LIBs) have found wide applications in a variety of
fields such as electrified transportation, stationary storage and portable
electronics devices. A battery management system (BMS) is critical to ensure
the reliability, efficiency and longevity of LIBs. Recent research has
witnessed the emergence of model-based fault diagnosis methods in advanced
BMSs. This paper provides a comprehensive review on the model-based fault
diagnosis methods for LIBs. First, the widely explored battery models in the
existing literature are classified into physics-based electrochemical models
and electrical equivalent circuit models. Second, a general state-space
representation that describes electrical dynamics of a faulty battery is
presented. The formulation of the state vectors and the identification of the
parameter matrices are then elaborated. Third, the fault mechanisms of both
battery faults (incl. overcharege/overdischarge faults, connection faults,
short circuit faults) and sensor faults (incl. voltage sensor faults and
current sensor faults) are discussed. Furthermore, different types of modeling
uncertainties, such as modeling errors and measurement noises, aging effects,
measurement outliers, are elaborated. An emphasis is then placed on the
observer design (incl. online state observers and offline state observers). The
algorithm implementation of typical state observers for battery fault diagnosis
is also put forward. Finally, discussion and outlook are offered to envision
some possible future research directions.
</p>
</div>
</dd>
<dt><a name=item125>[125]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16685 title=Abstract>arXiv:2401.16685</a> [<a href=https://arxiv.org/pdf/2401.16685 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16685 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Communication-Efficient Multimodal Federated Learning: Joint Modality and Client Selection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+L">Liangqi Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+D">Dong-Jun Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Su Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Upadhyay%2C+D">Devesh Upadhyay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2310.07048>arXiv:2310.07048</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Multimodal federated learning (FL) aims to enrich model training in FL
settings where clients are collecting measurements across multiple modalities.
However, key challenges to multimodal FL remain unaddressed, particularly in
heterogeneous network settings where: (i) the set of modalities collected by
each client will be diverse, and (ii) communication limitations prevent clients
from uploading all their locally trained modality models to the server. In this
paper, we propose multimodal Federated learning with joint Modality and Client
selection (mmFedMC), a new FL methodology that can tackle the above-mentioned
challenges in multimodal settings. The joint selection algorithm incorporates
two main components: (a) A modality selection methodology for each client,
which weighs (i) the impact of the modality, gauged by Shapley value analysis,
(ii) the modality model size as a gauge of communication overhead, against
(iii) the frequency of modality model updates, denoted recency, to enhance
generalizability. (b) A client selection strategy for the server based on the
local loss of modality model at each client. Experiments on five real-world
datasets demonstrate the ability of mmFedMC to achieve comparable accuracy to
several baselines while reducing the communication overhead by over 20x. A demo
video of our methodology is available at https://liangqiy.com/mmfedmc/.
</p>
</div>
</dd>
<dt><a name=item126>[126]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16687 title=Abstract>arXiv:2401.16687</a> [<a href=https://arxiv.org/pdf/2401.16687 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16687 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+L">Lulu Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shengshan Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+R">Ruizhi Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shengqing Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+D">Dezhong Yao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Collaborative learning (CL) is a distributed learning framework that aims to
protect user privacy by allowing users to jointly train a model by sharing
their gradient updates only. However, gradient inversion attacks (GIAs), which
recover users' training data from shared gradients, impose severe privacy
threats to CL. Existing defense methods adopt different techniques, e.g.,
differential privacy, cryptography, and perturbation defenses, to defend
against the GIAs. Nevertheless, all current defense methods suffer from a poor
trade-off between privacy, utility, and efficiency. To mitigate the weaknesses
of existing solutions, we propose a novel defense method, Dual Gradient Pruning
(DGP), based on gradient pruning, which can improve communication efficiency
while preserving the utility and privacy of CL. Specifically, DGP slightly
changes gradient pruning with a stronger privacy guarantee. And DGP can also
significantly improve communication efficiency with a theoretical analysis of
its convergence and generalization. Our extensive experiments show that DGP can
effectively defend against the most powerful GIAs and reduce the communication
cost without sacrificing the model's utility.
</p>
</div>
</dd>
<dt><a name=item127>[127]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16688 title=Abstract>arXiv:2401.16688</a> [<a href=https://arxiv.org/pdf/2401.16688 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16688 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Characterization of Magnetic Labyrinthine Structures through Junctions and Terminals Detection using Template Matching and CNN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Okubo%2C+V+Y">Vinícius Yu Okubo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shimizu%2C+K">Kotaro Shimizu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shivaram%2C+B+S">B. S. Shivaram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H+Y">Hae Yong Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 6 figures, submitted to IEEE Access
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In material sciences, characterizing faults in periodic structures is vital
for understanding material properties. To characterize magnetic labyrinthine
patterns, it is necessary to accurately identify junctions and terminals, often
featuring over a thousand closely packed defects per image. This study
introduces a new technique called TM-CNN (Template Matching - Convolutional
Neural Network) designed to detect a multitude of small objects in images, such
as defects in magnetic labyrinthine patterns. TM-CNN was used to identify these
structures in 444 experimental images, and the results were explored to deepen
the understanding of magnetic materials. It employs a two-stage detection
approach combining template matching, used in initial detection, with a
convolutional neural network, used to eliminate incorrect identifications. To
train a CNN classifier, it is necessary to create a large number of training
images. This difficulty prevents the use of CNN in many practical applications.
TM-CNN significantly reduces the manual workload for creating training images
by automatically making most of the annotations and leaving only a small number
of corrections to human reviewers. In testing, TM-CNN achieved an impressive F1
score of 0.988, far outperforming traditional template matching and CNN-based
object detection algorithms.
</p>
</div>
</dd>
<dt><a name=item128>[128]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16690 title=Abstract>arXiv:2401.16690</a> [<a href=https://arxiv.org/pdf/2401.16690 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16690 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Detailed Historical and Statistical Analysis of the Influence of Hardware Artifacts on SPEC Integer Benchmark Performance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yueyao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furman%2C+S">Samuel Furman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hardy%2C+N">Nicolas Hardy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ellis%2C+M">Margaret Ellis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Back%2C+G">Godmar Back</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+Y">Yili Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cameron%2C+K">Kirk Cameron</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 32 pages; 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Applications (stat.AP)
</div>
<p class=mathjax>The Standard Performance Evaluation Corporation (SPEC) CPU benchmark has been
widely used as a measure of computing performance for decades. The SPEC is an
industry-standardized, CPU-intensive benchmark suite and the collective data
provide a proxy for the history of worldwide CPU and system performance. Past
efforts have not provided or enabled answers to questions such as, how has the
SPEC benchmark suite evolved empirically over time and what micro-architecture
artifacts have had the most influence on performance? -- have any
micro-benchmarks within the suite had undue influence on the results and
comparisons among the codes? -- can the answers to these questions provide
insights to the future of computer system performance? To answer these
questions, we detail our historical and statistical analysis of specific
hardware artifacts (clock frequencies, core counts, etc.) on the performance of
the SPEC benchmarks since 1995. We discuss in detail several methods to
normalize across benchmark evolutions. We perform both isolated and collective
sensitivity analyses for various hardware artifacts and we identify one
benchmark (libquantum) that had somewhat undue influence on performance
outcomes. We also present the use of SPEC data to predict future performance.
</p>
</div>
</dd>
<dt><a name=item129>[129]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16692 title=Abstract>arXiv:2401.16692</a> [<a href=https://arxiv.org/pdf/2401.16692 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16692 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Calibration-then-Calculation: A Variance Reduced Metric Framework in Deep Click-Through Rate Prediction Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+Y">Yewen Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+N">Nian Si</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+X">Xiangchen Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Deep learning has been widely adopted across various fields, but there has
been little focus on evaluating the performance of deep learning pipelines.
With the increased use of large datasets and complex models, it has become
common to run the training process only once and compare the result to previous
benchmarks. However, this procedure can lead to imprecise comparisons due to
the variance in neural network evaluation metrics. The metric variance comes
from the randomness inherent in the training process of deep learning
pipelines. Traditional solutions such as running the training process multiple
times are usually not feasible in deep learning due to computational
limitations. In this paper, we propose a new metric framework, Calibrated Loss
Metric, that addresses this issue by reducing the variance in its vanilla
counterpart. As a result, the new metric has a higher accuracy to detect
effective modeling improvement. Our approach is supported by theoretical
justifications and extensive experimental validations in the context of Deep
Click-Through Rate Prediction Models.
</p>
</div>
</dd>
<dt><a name=item130>[130]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16694 title=Abstract>arXiv:2401.16694</a> [<a href=https://arxiv.org/pdf/2401.16694 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16694 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EdgeOL: Efficient in-situ Online Learning on Edge Devices
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+G">Geng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yawen Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yue Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Chao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jones%2C+A+K">Alex K. Jones</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jingtong Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xulong Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Emerging applications, such as robot-assisted eldercare and object
recognition, generally employ deep learning neural networks (DNNs) models and
naturally require: i) handling streaming-in inference requests and ii) adapting
to possible deployment scenario changes. Online model fine-tuning is widely
adopted to satisfy these needs. However, fine-tuning involves significant
energy consumption, making it challenging to deploy on edge devices. In this
paper, we propose EdgeOL, an edge online learning framework that optimizes
inference accuracy, fine-tuning execution time, and energy efficiency through
both inter-tuning and intra-tuning optimizations. Experimental results show
that, on average, EdgeOL reduces overall fine-tuning execution time by 82%,
energy consumption by 74%, and improves average inference accuracy by 1.70%
over the immediate online learning strategy.
</p>
</div>
</dd>
<dt><a name=item131>[131]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16699 title=Abstract>arXiv:2401.16699</a> [<a href=https://arxiv.org/pdf/2401.16699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Unified Interactive Visual Grounding in The Wild
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jie Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanbo Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+Q">Qingyi Si</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yifeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+X">Xuguang Lan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+T">Tao Kong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Interactive visual grounding in Human-Robot Interaction (HRI) is challenging
yet practical due to the inevitable ambiguity in natural languages. It requires
robots to disambiguate the user input by active information gathering. Previous
approaches often rely on predefined templates to ask disambiguation questions,
resulting in performance reduction in realistic interactive scenarios. In this
paper, we propose TiO, an end-to-end system for interactive visual grounding in
human-robot interaction. Benefiting from a unified formulation of visual
dialogue and grounding, our method can be trained on a joint of extensive
public data, and show superior generality to diversified and challenging
open-world scenarios. In the experiments, we validate TiO on GuessWhat?! and
InViG benchmarks, setting new state-of-the-art performance by a clear margin.
Moreover, we conduct HRI experiments on the carefully selected 150 challenging
scenes as well as real-robot platforms. Results show that our method
demonstrates superior generality to diversified visual and language inputs with
a high success rate. Codes and demos are available at
https://github.com/jxu124/TiO.
</p>
</div>
</dd>
<dt><a name=item132>[132]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16700 title=Abstract>arXiv:2401.16700</a> [<a href=https://arxiv.org/pdf/2401.16700 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16700 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Precise 3D Human Pose Estimation with Multi-Perspective Spatial-Temporal Relational Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xina Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+W">Weijie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+X">Xiaoting Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+H">Hao Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>3D human pose estimation captures the human joint points in three-dimensional
space while keeping the depth information and physical structure. That is
essential for applications that require precise pose information, such as
human-computer interaction, scene understanding, and rehabilitation training.
Due to the challenges in data collection, mainstream datasets of 3D human pose
estimation are primarily composed of multi-view video data collected in
laboratory environments, which contains rich spatial-temporal correlation
information besides the image frame content. Given the remarkable
self-attention mechanism of transformers, capable of capturing the
spatial-temporal correlation from multi-view video datasets, we propose a
multi-stage framework for 3D sequence-to-sequence (seq2seq) human pose
detection. Firstly, the spatial module represents the human pose feature by
intra-image content, while the frame-image relation module extracts temporal
relationships and 3D spatial positional relationship features between the
multi-perspective images. Secondly, the self-attention mechanism is adopted to
eliminate the interference from non-human body parts and reduce computing
resources. Our method is evaluated on Human3.6M, a popular 3D human pose
detection dataset. Experimental results demonstrate that our approach achieves
state-of-the-art performance on this dataset.
</p>
</div>
</dd>
<dt><a name=item133>[133]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16702 title=Abstract>arXiv:2401.16702</a> [<a href=https://arxiv.org/pdf/2401.16702 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16702 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-granularity Correspondence Learning from Long-term Noisy Videos
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yijie Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhenyu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jia Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+Z">Zujie Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024 (oral)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Existing video-language studies mainly focus on learning short video clips,
leaving long-term temporal dependencies rarely explored due to over-high
computational cost of modeling long videos. To address this issue, one feasible
solution is learning the correspondence between video clips and captions, which
however inevitably encounters the multi-granularity noisy correspondence (MNC)
problem. To be specific, MNC refers to the clip-caption misalignment
(coarse-grained) and frame-word misalignment (fine-grained), hindering temporal
learning and video understanding. In this paper, we propose NOise Robust
Temporal Optimal traNsport (Norton) that addresses MNC in a unified optimal
transport (OT) framework. In brief, Norton employs video-paragraph and
clip-caption contrastive losses to capture long-term dependencies based on OT.
To address coarse-grained misalignment in video-paragraph contrast, Norton
filters out the irrelevant clips and captions through an alignable prompt
bucket and realigns asynchronous clip-caption pairs based on transport
distance. To address the fine-grained misalignment, Norton incorporates a
soft-maximum operator to identify crucial words and key frames. Additionally,
Norton exploits the potential faulty negative samples in clip-caption contrast
by rectifying the alignment target with OT assignment to ensure precise
temporal modeling. Extensive experiments on video retrieval, videoQA, and
action segmentation verify the effectiveness of our method. Code is available
at https://lin-yijie.github.io/projects/Norton.
</p>
</div>
</dd>
<dt><a name=item134>[134]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16703 title=Abstract>arXiv:2401.16703</a> [<a href=https://arxiv.org/pdf/2401.16703 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16703 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Plane Wave Dynamic Model of Electric Power Networks with High Shares of Inverter-Based Resources
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sajadi%2C+A">Amirhossein Sajadi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hodge%2C+B">Bri-Mathias Hodge</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>Contemporary theories and models for electric power system stability are
predicated on a widely held assumption that the mechanical inertia of the
rotating mass of synchronous generators provides the sole contribution to
stable and synchronized operation of this class of complex networks on
subsecond timescales. Here we formulate the electromagnetic momentum of the
field around the transmission lines that transports energy and present evidence
from a real-world bulk power network that demonstrates its physical
significance. We show the classical stability model for power networks that
overlooks this property, known as the "swing equation", may become inadequate
to analyze systems with high shares of inverter-based resources, commonly known
as "low-inertia power systems". Subsequently, we introduce a plane wave dynamic
model, consistent with the structural properties of emerging power systems with
up to 100% inverter-based resources, which identifies the concept of inertia in
power grids as a time-varying component. We leverage our theory to discuss a
number of open questions in the electric power industry. Most notably, we
postulate that the changing nature of power networks with a preponderance of
variable renewable energy power plants could strengthen power network stability
in the future; a vision which is irreconcilable with the conventional theories.
</p>
</div>
</dd>
<dt><a name=item135>[135]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16707 title=Abstract>arXiv:2401.16707</a> [<a href=https://arxiv.org/pdf/2401.16707 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16707 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16707 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Redundancy in Exact Channel Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sriramu%2C+S+M">Sharang M. Sriramu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wagner%2C+A+B">Aaron B. Wagner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We consider the redundancy of the exact channel synthesis problem under an
i.i.d. assumption. Existing results provide an upper bound on the unnormalized
redundancy that is logarithmic in the block length. We show, via an improved
scheme, that the logarithmic term can be halved for most channels and
eliminated for all others. For full-support discrete memoryless channels, we
show that this is the best possible.
</p>
</div>
</dd>
<dt><a name=item136>[136]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16708 title=Abstract>arXiv:2401.16708</a> [<a href=https://arxiv.org/pdf/2401.16708 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16708 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+Y">Yung-Peng Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hung-Hsuan Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper introduces the multivariate beta mixture model (MBMM), a new
probabilistic model for soft clustering. MBMM adapts to diverse cluster shapes
because of the flexible probability density function of the multivariate beta
distribution. We introduce the properties of MBMM, describe the parameter
learning procedure, and present the experimental results, showing that MBMM
fits diverse cluster shapes on synthetic and real datasets. The code is
released anonymously at \url{https://github.com/hhchen1105/mbmm/}.
</p>
</div>
</dd>
<dt><a name=item137>[137]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16709 title=Abstract>arXiv:2401.16709</a> [<a href=https://arxiv.org/pdf/2401.16709 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16709 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16709 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Random Coding Approach to Performance Analysis of the Ordered Statistic Decoding with Local Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+J">Jifan Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiao Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper is a revision of <a href=https://doi.org/10.36227/techrxiv.22771085.v1>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper is concerned with the ordered statistic decoding with local
constraints (LC-OSD) of binary linear block codes, which is a near
maximum-likelihood decoding algorithm. Compared with the conventional OSD, the
LC-OSD significantly reduces both the maximum and the average number of
searches. The former is achieved by performing the serial list Viterbi
algorithm (SLVA) or a two-way flipping pattern tree (FPT) algorithm with local
constraints on the test error patterns, while the latter is achieved by
incorporating tailored early termination criteria. The main objective of this
paper is to explore the relationship between the performance of the LC-OSD and
decoding parameters, such as the constraint degree and the maximum list size.
To this end, we approximate the local parity-check matrix as a totally random
matrix and then estimate the performance of the LC-OSD by analyzing with a
saddlepoint approach the performance of random codes over the channels
associated with the most reliable bits (MRBs). The random coding approach
enables us to derive an upper bound on the performance and predict the average
rank of the transmitted codeword in the list delivered by the LC-OSD. This
allows us to balance the constraint degree and the maximum list size for the
average (or maximum) time complexity reduction. Simulation results show that
the approximation by random coding approach is numerically effective and
powerful. Simulation results also show that the RS codes decoded by the LC-OSD
can approach the random coding union (RCU) bounds, verifying the efficiency and
universality of the LC-OSD.
</p>
</div>
</dd>
<dt><a name=item138>[138]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16710 title=Abstract>arXiv:2401.16710</a> [<a href=https://arxiv.org/pdf/2401.16710 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16710 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Human Digital Twin Deployment at the Edge for Task Execution: A Two-Timescale Accuracy-Aware Online Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuye Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">You Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+C">Changyan Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+J">Jun Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jiawen Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xuemin">Xuemin</a> (Sherman)
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen">Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
<p class=mathjax>Human digital twin (HDT) is an emerging paradigm that bridges physical twins
(PTs) with powerful virtual twins (VTs) for assisting complex task executions
in human-centric services. In this paper, we study a two-timescale online
optimization for building HDT under an end-edge-cloud collaborative framework.
As a unique feature of HDT, we consider that PTs' corresponding VTs are
deployed on edge servers, consisting of not only generic models placed by
downloading experiential knowledge from the cloud but also customized models
updated by collecting personalized data from end devices. To maximize task
execution accuracy with stringent energy and delay constraints, and by taking
into account HDT's inherent mobility and status variation uncertainties, we
jointly and dynamically optimize VTs' construction and PTs' task offloading,
along with communication and computation resource allocations. Observing that
decision variables are asynchronous with different triggers, we propose a novel
two-timescale accuracy-aware online optimization approach (TACO). Specifically,
TACO utilizes an improved Lyapunov method to decompose the problem into
multiple instant ones, and then leverages piecewise McCormick envelopes and
block coordinate descent based algorithms, addressing two timescales
alternately. Theoretical analyses and simulations show that the proposed
approach can reach asymptotic optimum within a polynomial-time complexity, and
demonstrate its superiority over counterparts.
</p>
</div>
</dd>
<dt><a name=item139>[139]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16712 title=Abstract>arXiv:2401.16712</a> [<a href=https://arxiv.org/pdf/2401.16712 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16712 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LF Tracy: A Unified Single-Pipeline Approach for Salient Object Detection in Light Field Cameras
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teng%2C+F">Fei Teng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiawei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+K">Kunyu Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xina Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhiyong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The source code will be made publicly available at <a href=https://github.com/FeiBryantkit/LF-Tracy>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Leveraging the rich information extracted from light field (LF) cameras is
instrumental for dense prediction tasks. However, adapting light field data to
enhance Salient Object Detection (SOD) still follows the traditional RGB
methods and remains under-explored in the community. Previous approaches
predominantly employ a custom two-stream design to discover the implicit
angular feature within light field cameras, leading to significant information
isolation between different LF representations. In this study, we propose an
efficient paradigm (LF Tracy) to address this limitation. We eschew the
conventional specialized fusion and decoder architecture for a dual-stream
backbone in favor of a unified, single-pipeline approach. This comprises
firstly a simple yet effective data augmentation strategy called MixLD to
bridge the connection of spatial, depth, and implicit angular information under
different LF representations. A highly efficient information aggregation (IA)
module is then introduced to boost asymmetric feature-wise information fusion.
Owing to this innovative approach, our model surpasses the existing
state-of-the-art methods, particularly demonstrating a 23% improvement over
previous results on the latest large-scale PKU dataset. By utilizing only 28.9M
parameters, the model achieves a 10% increase in accuracy with 3M additional
parameters compared to its backbone using RGB images and an 86% rise to its
backbone using LF images. The source code will be made publicly available at
https://github.com/FeiBryantkit/LF-Tracy.
</p>
</div>
</dd>
<dt><a name=item140>[140]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16713 title=Abstract>arXiv:2401.16713</a> [<a href=https://arxiv.org/pdf/2401.16713 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16713 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prospects for inconsistency detection using large language models and sheaves
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huntsman%2C+S">Steve Huntsman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+M">Michael Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huntsman%2C+L">Ludmilla Huntsman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Algebraic Topology (math.AT)
</div>
<p class=mathjax>We demonstrate that large language models can produce reasonable numerical
ratings of the logical consistency of claims. We also outline a mathematical
approach based on sheaf theory for lifting such ratings to hypertexts such as
laws, jurisprudence, and social media and evaluating their consistency
globally. This approach is a promising avenue to increasing consistency in and
of government, as well as to combating mis- and disinformation and related
ills.
</p>
</div>
</dd>
<dt><a name=item141>[141]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16715 title=Abstract>arXiv:2401.16715</a> [<a href=https://arxiv.org/pdf/2401.16715 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16715 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16715 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Going Viral: Case Studies on the Impact of Protestware
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+Y">Youmei Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Dong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wattanakriengkrai%2C+S">Supatsara Wattanakriengkrai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Damrongsiri%2C+H">Hathaichanok Damrongsiri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treude%2C+C">Christoph Treude</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hata%2C+H">Hideaki Hata</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kula%2C+R+G">Raula Gaikovina Kula</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Maintainers are now self-sabotaging their work in order to take political or
economic stances, a practice referred to as "protestware". In this poster, we
present our approach to understand how the discourse about such an attack went
viral, how it is received by the community, and whether developers respond to
the attack in a timely manner. We study two notable protestware cases, i.e.,
Colors.js and es5-ext, comparing with discussions of a typical security
vulnerability as a baseline, i.e., Ua-parser, and perform a thematic analysis
of more than two thousand protest-related posts to extract the different
narratives when discussing protestware.
</p>
</div>
</dd>
<dt><a name=item142>[142]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16719 title=Abstract>arXiv:2401.16719</a> [<a href=https://arxiv.org/pdf/2401.16719 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16719 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OptiState: State Estimation of Legged Robots using Gated Networks with Transformer-based Vision and Kalman Filtering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schperberg%2C+A">Alexander Schperberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+Y">Yusuke Tanaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balaji%2C+B">Bharathan Balaji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+D">Dennis Hong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13-17, in Yokohama, Japan. 7 pages, 5 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)
</div>
<p class=mathjax>State estimation for legged robots is challenging due to their highly dynamic
motion and limitations imposed by sensor accuracy. By integrating Kalman
filtering, optimization, and learning-based modalities, we propose a hybrid
solution that combines proprioception and exteroceptive information for
estimating the state of the robot's trunk. Leveraging joint encoder and IMU
measurements, our Kalman filter is enhanced through a single-rigid body model
that incorporates ground reaction force control outputs from convex Model
Predictive Control optimization. The estimation is further refined through
Gated Recurrent Units, which also considers semantic insights and robot height
from a Vision Transformer autoencoder applied on depth images. This framework
not only furnishes accurate robot state estimates, including uncertainty
evaluations, but can minimize the nonlinear errors that arise from sensor
measurements and model simplifications through learning. The proposed
methodology is evaluated in hardware using a quadruped robot on various
terrains, yielding a 65% improvement on the Root Mean Squared Error compared to
our VIO SLAM baseline. Code example: https://github.com/AlexS28/OptiState
</p>
</div>
</dd>
<dt><a name=item143>[143]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16720 title=Abstract>arXiv:2401.16720</a> [<a href=https://arxiv.org/pdf/2401.16720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+G">Geng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yue Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Youtao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xulong Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>There has been a proliferation of artificial intelligence applications, where
model training is key to promising high-quality services for these
applications. However, the model training process is both time-intensive and
energy-intensive, inevitably affecting the user's demand for application
efficiency. Layer freezing, an efficient model training technique, has been
proposed to improve training efficiency. Although existing layer freezing
methods demonstrate the great potential to reduce model training costs, they
still remain shortcomings such as lacking generalizability and compromised
accuracy. For instance, existing layer freezing methods either require the
freeze configurations to be manually defined before training, which does not
apply to different networks, or use heuristic freezing criteria that is hard to
guarantee decent accuracy in different scenarios. Therefore, there lacks a
generic and smart layer freezing method that can automatically perform
``in-situation'' layer freezing for different networks during training
processes. To this end, we propose a generic and efficient training framework
(SmartFRZ). The core proposed technique in SmartFRZ is attention-guided layer
freezing, which can automatically select the appropriate layers to freeze
without compromising accuracy. Experimental results show that SmartFRZ
effectively reduces the amount of computation in training and achieves
significant training acceleration, and outperforms the state-of-the-art layer
freezing approaches.
</p>
</div>
</dd>
<dt><a name=item144>[144]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16722 title=Abstract>arXiv:2401.16722</a> [<a href=https://arxiv.org/pdf/2401.16722 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16722 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16722 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal-Landmark-Guided Image Blending for Face Morphing Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Q">Qiaoyun He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Z">Zongyong Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Z">Zuyuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qijun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IJCB2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we propose a novel approach for conducting face morphing
attacks, which utilizes optimal-landmark-guided image blending. Current face
morphing attacks can be categorized into landmark-based and generation-based
approaches. Landmark-based methods use geometric transformations to warp facial
regions according to averaged landmarks but often produce morphed images with
poor visual quality. Generation-based methods, which employ generation models
to blend multiple face images, can achieve better visual quality but are often
unsuccessful in generating morphed images that can effectively evade
state-of-the-art face recognition systems~(FRSs). Our proposed method overcomes
the limitations of previous approaches by optimizing the morphing landmarks and
using Graph Convolutional Networks (GCNs) to combine landmark and appearance
features. We model facial landmarks as nodes in a bipartite graph that is fully
connected and utilize GCNs to simulate their spatial and structural
relationships. The aim is to capture variations in facial shape and enable
accurate manipulation of facial appearance features during the warping process,
resulting in morphed facial images that are highly realistic and visually
faithful. Experiments on two public datasets prove that our method inherits the
advantages of previous landmark-based and generation-based methods and
generates morphed images with higher quality, posing a more significant threat
to state-of-the-art FRSs.
</p>
</div>
</dd>
<dt><a name=item145>[145]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16725 title=Abstract>arXiv:2401.16725</a> [<a href=https://arxiv.org/pdf/2401.16725 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16725 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploiting Equivariance in the Design of Tracking Controllers for Euler-Poincare Systems on Matrix Lie Groups
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hampsey%2C+M">Matthew Hampsey</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=van+Goor%2C+P">Pieter van Goor</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Banavar%2C+R">Ravi Banavar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint for LHMNC2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The trajectory tracking problem is a fundamental control task in the study of
mechanical systems. A key construction in tracking control is the error or
difference between an actual and desired trajectory. This construction also
lies at the heart of observer design and recent advances in the study of
equivariant systems have provided a template for global error construction that
exploits the symmetry structure of a group action if such a structure exists.
Hamiltonian systems are posed on the cotangent bundle of configuration space of
a mechanical system and symmetries for the full cotangent bundle are not
commonly used in geometric control theory. In this paper, we propose a group
structure on the cotangent bundle of a Lie group and leverage this to define
momentum and configuration errors for trajectory tracking drawing on recent
work on equivariant observer design. We show that this error definition leads
to error dynamics that are themselves ``Euler-Poincare like'' and use these to
derive simple, almost global trajectory tracking control for fully-actuated
Euler-Poincare systems on a Lie group state space.
</p>
</div>
</dd>
<dt><a name=item146>[146]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16726 title=Abstract>arXiv:2401.16726</a> [<a href=https://arxiv.org/pdf/2401.16726 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16726 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16726 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variable-Length Feedback Codes over Known and Unknown Channels with Non-vanishing Error Probabilities
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yavas%2C+R+C">Recep Can Yavas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to ISIT 2024, 14 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We study variable-length feedback (VLF) codes with noiseless feedback for
discrete memoryless channels. We present a novel non-asymptotic bound, which
analyzes the average error probability and average decoding time of our
modified Yamamoto--Itoh scheme. We then optimize the parameters of our code in
the asymptotic regime where the average error probability <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-93-Frame tabindex=0><nobr><span class=math id=MathJax-Span-558 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-559><span class=mi id=MathJax-Span-560 style=font-family:MathJax_Math-italic>ϵ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> remains a
constant as the average decoding time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-94-Frame tabindex=0><nobr><span class=math id=MathJax-Span-561 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-562><span class=mi id=MathJax-Span-563 style=font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> approaches infinity. Our second-order
achievability bound is an improvement of Polyanskiy et al.'s (2011)
achievability bound. We also universalize our code by employing the empirical
mutual information in our decoding metric and derive a second-order
achievability bound for universal VLF codes. Our results for both VLF and
universal VLF codes are extended to the additive white Gaussian noise channel
with an average power constraint. The former yields an improvement over Truong
and Tan's (2017) achievability bound. The proof of our results for universal
VLF codes uses a refined version of the method of types and an asymptotic
expansion from the nonlinear renewal theory literature.
</p>
</div>
</dd>
<dt><a name=item147>[147]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16727 title=Abstract>arXiv:2401.16727</a> [<a href=https://arxiv.org/pdf/2401.16727 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16727 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hee%2C+M+S">Ming Shan Hee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+S">Shivam Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+R">Rui Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nandi%2C+P">Palash Nandi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakraborty%2C+T">Tanmoy Chakraborty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+R+K">Roy Ka-Wei Lee</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In the evolving landscape of online communication, moderating hate speech
(HS) presents an intricate challenge, compounded by the multimodal nature of
digital content. This comprehensive survey delves into the recent strides in HS
moderation, spotlighting the burgeoning role of large language models (LLMs)
and large multimodal models (LMMs). Our exploration begins with a thorough
analysis of current literature, revealing the nuanced interplay between
textual, visual, and auditory elements in propagating HS. We uncover a notable
trend towards integrating these modalities, primarily due to the complexity and
subtlety with which HS is disseminated. A significant emphasis is placed on the
advances facilitated by LLMs and LMMs, which have begun to redefine the
boundaries of detection and moderation capabilities. We identify existing gaps
in research, particularly in the context of underrepresented languages and
cultures, and the need for solutions to handle low-resource settings. The
survey concludes with a forward-looking perspective, outlining potential
avenues for future research, including the exploration of novel AI
methodologies, the ethical governance of AI in moderation, and the development
of more nuanced, context-aware systems. This comprehensive overview aims to
catalyze further research and foster a collaborative effort towards more
sophisticated, responsible, and human-centric approaches to HS moderation in
the digital era.\footnote{ \textcolor{red}{WARNING: This paper contains
offensive examples.
</p>
</div>
</dd>
<dt><a name=item148>[148]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16729 title=Abstract>arXiv:2401.16729</a> [<a href=https://arxiv.org/pdf/2401.16729 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16729 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Widely Linear Matched Filter: A Lynchpin towards the Interpretability of Complex-valued CNNs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qingchen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhe Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babic%2C+Z">Zdenka Babic</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+W">Wei Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stankovi%C4%87%2C+L">Ljubiša Stanković</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandic%2C+D+P">Danilo P. Mandic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>A recent study on the interpretability of real-valued convolutional neural
networks (CNNs) \cite{Stankovic_Mandic_2023CNN} has revealed a direct and
physically meaningful link with the task of finding features in data through
matched filters. However, applying this paradigm to illuminate the
interpretability of complex-valued CNNs meets a formidable obstacle: the
extension of matched filtering to a general class of noncircular complex-valued
data, referred to here as the widely linear matched filter (WLMF), has been
only implicit in the literature. To this end, to establish the interpretability
of the operation of complex-valued CNNs, we introduce a general WLMF paradigm,
provide its solution and undertake analysis of its performance. For rigor, our
WLMF solution is derived without imposing any assumption on the probability
density of noise. The theoretical advantages of the WLMF over its standard
strictly linear counterpart (SLMF) are provided in terms of their output
signal-to-noise-ratios (SNRs), with WLMF consistently exhibiting enhanced SNR.
Moreover, the lower bound on the SNR gain of WLMF is derived, together with
condition to attain this bound. This serves to revisit the
convolution-activation-pooling chain in complex-valued CNNs through the lens of
matched filtering, which reveals the potential of WLMFs to provide physical
interpretability and enhance explainability of general complex-valued CNNs.
Simulations demonstrate the agreement between the theoretical and numerical
results.
</p>
</div>
</dd>
<dt><a name=item149>[149]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16731 title=Abstract>arXiv:2401.16731</a> [<a href=https://arxiv.org/pdf/2401.16731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Generating Informative Textual Description for Neurons in Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal%2C+S">Shrayani Mondal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garodia%2C+R">Rishabh Garodia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qureshi%2C+A">Arbaaz Qureshi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+T">Taesung Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+Y">Youngja Park</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Recent developments in transformer-based language models have allowed them to
capture a wide variety of world knowledge that can be adapted to downstream
tasks with limited resources. However, what pieces of information are
understood in these models is unclear, and neuron-level contributions in
identifying them are largely unknown. Conventional approaches in neuron
explainability either depend on a finite set of pre-defined descriptors or
require manual annotations for training a secondary model that can then explain
the neurons of the primary model. In this paper, we take BERT as an example and
we try to remove these constraints and propose a novel and scalable framework
that ties textual descriptions to neurons. We leverage the potential of
generative language models to discover human-interpretable descriptors present
in a dataset and use an unsupervised approach to explain neurons with these
descriptors. Through various qualitative and quantitative analyses, we
demonstrate the effectiveness of this framework in generating useful
data-specific descriptors with little human involvement in identifying the
neurons that encode these descriptors. In particular, our experiment shows that
the proposed approach achieves 75% precision@2, and 50% recall@2
</p>
</div>
</dd>
<dt><a name=item150>[150]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16732 title=Abstract>arXiv:2401.16732</a> [<a href=https://arxiv.org/pdf/2401.16732 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16732 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Flash: A Hybrid Private Inference Protocol for Deep CNNs with High Accuracy and Low Latency on CPU
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roh%2C+H">Hyeri Roh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeo%2C+J">Jinsu Yeo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ko%2C+Y">Yeongil Ko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+G">Gu-Yeon Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brooks%2C+D">David Brooks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+W">Woo-Seok Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>This paper presents Flash, an optimized private inference (PI) hybrid
protocol utilizing both homomorphic encryption (HE) and secure two-party
computation (2PC), which can reduce the end-to-end PI latency for deep CNN
models less than 1 minute with CPU. To this end, first, Flash proposes a
low-latency convolution algorithm built upon a fast slot rotation operation and
a novel data encoding scheme, which results in 4-94x performance gain over the
state-of-the-art. Second, to minimize the communication cost introduced by the
standard nonlinear activation function ReLU, Flash replaces the entire ReLUs
with the polynomial <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-95-Frame tabindex=0><nobr><span class=math id=MathJax-Span-564 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.72em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-565><span class=msubsup id=MathJax-Span-566><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-567 style=font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-568 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-569 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-570 style=font-family:MathJax_Math-italic;padding-left:0.234em>x</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> and trains deep CNN models with the new activation
function. The trained models improve the inference accuracy for CIFAR-10/100
and TinyImageNet by 16% on average (up to 40% for ResNet-32) compared to prior
art. Last, Flash proposes an efficient 2PC-based <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-96-Frame tabindex=0><nobr><span class=math id=MathJax-Span-571 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.72em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-572><span class=msubsup id=MathJax-Span-573><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-574 style=font-family:MathJax_Math-italic>x</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-575 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-576 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-577 style=font-family:MathJax_Math-italic;padding-left:0.234em>x</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> evaluation protocol
that does not require any offline communication and that reduces the total
communication cost to process the activation layer by 84-196x over the
state-of-the-art. As a result, the end-to-end PI latency of Flash implemented
on CPU is 0.02 minute for CIFAR-100 and 0.57 minute for TinyImageNet
classification, while the total data communication is 0.07GB for CIFAR-100 and
0.22GB for TinyImageNet. Flash improves the state-of-the-art PI by 16-45x in
latency and 84-196x in communication cost. Moreover, even for ImageNet, Flash
can deliver the latency less than 1 minute on CPU with the total communication
less than 1GB.
</p>
</div>
</dd>
<dt><a name=item151>[151]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16736 title=Abstract>arXiv:2401.16736</a> [<a href=https://arxiv.org/pdf/2401.16736 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16736 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Engineering A Large Language Model From Scratch
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Software Engineering (cs.SE)
</div>
<p class=mathjax>The proliferation of deep learning in natural language processing (NLP) has
led to the development and release of innovative technologies capable of
understanding and generating human language with remarkable proficiency.
Atinuke, a Transformer-based neural network, optimises performance across
various language tasks by utilising a unique configuration. The architecture
interweaves layers for processing sequential data with attention mechanisms to
draw meaningful affinities between inputs and outputs. Due to the configuration
of its topology and hyperparameter tuning, it can emulate human-like language
by extracting features and learning complex mappings. Atinuke is modular,
extensible, and integrates seamlessly with existing machine learning pipelines.
Advanced matrix operations like softmax, embeddings, and multi-head attention
enable nuanced handling of textual, acoustic, and visual signals. By unifying
modern deep learning techniques with software design principles and
mathematical theory, the system achieves state-of-the-art results on natural
language tasks whilst remaining interpretable and robust.
</p>
</div>
</dd>
<dt><a name=item152>[152]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16741 title=Abstract>arXiv:2401.16741</a> [<a href=https://arxiv.org/pdf/2401.16741 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16741 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MESA: Matching Everything by Segmenting Anything
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yesheng Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xu Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Feature matching is a crucial task in the field of computer vision, which
involves finding correspondences between images. Previous studies achieve
remarkable performance using learning-based feature comparison. However, the
pervasive presence of matching redundancy between images gives rise to
unnecessary and error-prone computations in these methods, imposing limitations
on their accuracy. To address this issue, we propose MESA, a novel approach to
establish precise area (or region) matches for efficient matching redundancy
reduction. MESA first leverages the advanced image understanding capability of
SAM, a state-of-the-art foundation model for image segmentation, to obtain
image areas with implicit semantic. Then, a multi-relational graph is proposed
to model the spatial structure of these areas and construct their scale
hierarchy. Based on graphical models derived from the graph, the area matching
is reformulated as an energy minimization task and effectively resolved.
Extensive experiments demonstrate that MESA yields substantial precision
improvement for multiple point matchers in indoor and outdoor downstream tasks,
e.g. +13.61% for DKM in indoor pose estimation.
</p>
</div>
</dd>
<dt><a name=item153>[153]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16742 title=Abstract>arXiv:2401.16742</a> [<a href=https://arxiv.org/pdf/2401.16742 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16742 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI-based closed-loop fMRI system
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kasahara%2C+M">Mikihiro Kasahara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oka%2C+T">Taiki Oka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taschereau-Dumouchel%2C+V">Vincent Taschereau-Dumouchel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawato%2C+M">Mitsuo Kawato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takakura%2C+H">Hiroki Takakura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cortese%2C+A">Aurelio Cortese</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)
</div>
<p class=mathjax>While generative AI is now widespread and useful in society, there are
potential risks of misuse, e.g., unconsciously influencing cognitive processes
or decision-making. Although this causes a security problem in the cognitive
domain, there has been no research about neural and computational mechanisms
counteracting the impact of malicious generative AI in humans. We propose
DecNefGAN, a novel framework that combines a generative adversarial system and
a neural reinforcement model. More specifically, DecNefGAN bridges human and
generative AI in a closed-loop system, with the AI creating stimuli that induce
specific mental states, thus exerting external control over neural activity.
The objective of the human is the opposite, to compete and reach an orthogonal
mental state. This framework can contribute to elucidating how the human brain
responds to and counteracts the potential influence of generative AI.
</p>
</div>
</dd>
<dt><a name=item154>[154]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16743 title=Abstract>arXiv:2401.16743</a> [<a href=https://arxiv.org/pdf/2401.16743 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16743 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16743 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Group Multicasting Systems Using Multiple RISs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Hyeongtaek Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moon%2C+S">Seungsik Moon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+Y">Youngjoo Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oh%2C+J">Jaeky Oh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung%2C+J">Jaehoon Chung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+J">Junil Choi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE Transactions on Wireless Communications
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, practical utilization of multiple distributed reconfigurable
intelligent surfaces (RISs), which are able to conduct group-specific
operations, for multi-group multicasting systems is investigated. To tackle the
inter-group interference issue in the multi-group multicasting systems, the
block diagonalization (BD)-based beamforming is considered first. Without any
inter-group interference after the BD operation, the multiple distributed RISs
are operated to maximize the minimum rate for each group. Since the
computational complexity of the BD-based beamforming can be too high, a
multicasting tailored zero-forcing (MTZF) beamforming technique is proposed to
efficiently suppress the inter-group interference, and the novel design for the
multiple RISs that makes up for the inevitable loss of MTZF beamforming is also
described. Effective closed-form solutions for the loss minimizing RIS
operations are obtained with basic linear operations, making the proposed MTZF
beamforming-based RIS design highly practical. Numerical results show that the
BD-based approach has ability to achieve high sum-rate, but it is useful only
when the base station deploys large antenna arrays. Even with the small number
of antennas, the MTZF beamforming-based approach outperforms the other schemes
in terms of the sum-rate while the technique requires low computational
complexity. The results also prove that the proposed techniques can work with
the minimum rate requirement for each group.
</p>
</div>
</dd>
<dt><a name=item155>[155]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16744 title=Abstract>arXiv:2401.16744</a> [<a href=https://arxiv.org/pdf/2401.16744 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16744 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ShaRP: Explaining Rankings with Shapley Values
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pliatsika%2C+V">Venetia Pliatsika</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fonseca%2C+J">Joao Fonseca</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tilun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stoyanovich%2C+J">Julia Stoyanovich</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)
</div>
<p class=mathjax>Algorithmic decisions in critical domains such as hiring, college admissions,
and lending are often based on rankings. Because of the impact these decisions
have on individuals, organizations, and population groups, there is a need to
understand them: to know whether the decisions are abiding by the law, to help
individuals improve their rankings, and to design better ranking procedures.
<br>In this paper, we present ShaRP (Shapley for Rankings and Preferences), a
framework that explains the contributions of features to different aspects of a
ranked outcome, and is based on Shapley values. Using ShaRP, we show that even
when the scoring function used by an algorithmic ranker is known and linear,
the weight of each feature does not correspond to its Shapley value
contribution. The contributions instead depend on the feature distributions,
and on the subtle local interactions between the scoring features. ShaRP builds
on the Quantitative Input Influence framework, and can compute the
contributions of features for multiple Quantities of Interest, including score,
rank, pair-wise preference, and top-k. Because it relies on black-box access to
the ranker, ShaRP can be used to explain both score-based and learned ranking
models. We show results of an extensive experimental validation of ShaRP using
real and synthetic datasets, showcasing its usefulness for qualitative
analysis.
</p>
</div>
</dd>
<dt><a name=item156>[156]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16745 title=Abstract>arXiv:2401.16745</a> [<a href=https://arxiv.org/pdf/2401.16745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwan%2C+W">Wai-Chung Kwan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xingshan Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yuxin Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yufei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Liangyou Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+L">Lifeng Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xin Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qun Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code and data are available at <a href=https://github.com/KwanWaiChung/MT-Eval>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Large language models (LLMs) are increasingly relied upon for complex
multi-turn conversations across diverse real-world applications. However,
existing benchmarks predominantly focus on single-turn evaluations, overlooking
the models' capabilities in multi-turn interactions. To address this gap, we
introduce MT-Eval, a comprehensive benchmark designed to evaluate multi-turn
conversational abilities. By analyzing human-LLM conversations, we categorize
interaction patterns into four types: recollection, expansion, refinement, and
follow-up. We construct multi-turn queries for each category either by
augmenting existing datasets or by creating new examples with GPT-4 to avoid
data leakage. To study the factors impacting multi-turn abilities, we create
single-turn versions of the 1170 multi-turn queries and compare performance.
Our evaluation of 11 well-known LLMs shows that while closed-source models
generally surpass open-source ones, certain open-source models exceed
GPT-3.5-Turbo in specific tasks. We observe significant performance degradation
in multi-turn settings compared to single-turn settings in most models, which
is not correlated with the models' fundamental capabilities. Moreover, we
identify the distance to relevant content and susceptibility to error
propagation as the key factors influencing multi-turn performance. MT-Eval is
released publicly to encourage future research towards more robust
conversational models.
</p>
</div>
</dd>
<dt><a name=item157>[157]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16748 title=Abstract>arXiv:2401.16748</a> [<a href=https://arxiv.org/pdf/2401.16748 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16748 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saruar%2C+S+S">S. S. Saruar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nusrat">Nusrat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadia">Sadia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Racism is an alarming phenomenon in our country as well as all over the
world. Every day we have come across some racist comments in our daily life and
virtual life. Though we can eradicate this racism from virtual life (such as
Social Media). In this paper, we have tried to detect those racist comments
with NLP and deep learning techniques. We have built a novel dataset in the
Bengali Language. Further, we annotated the dataset and conducted data label
validation. After extensive utilization of deep learning methodologies, we have
successfully achieved text detection with an impressive accuracy rate of
87.94\% using the Ensemble approach. We have applied RNN and LSTM models using
BERT Embeddings. However, the MCNN-LSTM model performed highest among all those
models. Lastly, the Ensemble approach has been followed to combine all the
model results to increase overall performance.
</p>
</div>
</dd>
<dt><a name=item158>[158]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16751 title=Abstract>arXiv:2401.16751</a> [<a href=https://arxiv.org/pdf/2401.16751 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16751 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16751 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simultaneous Computation and Communication over MAC
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frey%2C+M">Matthias Frey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bjelakovi%C4%87%2C+I">Igor Bjelaković</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gastpar%2C+M+C">Michael C. Gastpar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jingge Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We study communication over a Gaussian multiple-access channel (MAC) with two
types of transmitters: Digital transmitters hold a message from a discrete set
that needs to be communicated to the receiver. Analog transmitters hold
sequences of analog values, and some function of these distributed values (but
not the values themselves) need to be conveyed to the receiver. For the digital
messages, it is required that they can be decoded error free at the receiver
with high probability while the recovered analog function values have to
satisfy a fidelity criterion such as an upper bound on mean squared error (MSE)
or a certain maximum error with a given confidence. For the case in which the
computed function for the analog transmitters is a sum of values in [-1,1], we
derive inner and outer bounds for the tradeoff of digital and analog rates of
communication under peak and average power constraints for digital transmitters
and a peak power constraint for analog transmitters. We then extend the
achievability part of our result to a larger class of functions that includes
all linear, but also some non-linear functions.
</p>
</div>
</dd>
<dt><a name=item159>[159]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16753 title=Abstract>arXiv:2401.16753</a> [<a href=https://arxiv.org/pdf/2401.16753 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16753 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xurui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Ziming Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+F">Feng Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>This paper studies zero-shot anomaly classification (AC) and segmentation
(AS) in industrial vision. We reveal that the abundant normal and abnormal cues
implicit in unlabeled test images can be exploited for anomaly determination,
which is ignored by prior methods. Our key observation is that for the
industrial product images, the normal image patches could find a relatively
large number of similar patches in other unlabeled images, while the abnormal
ones only have a few similar patches. We leverage such a discriminative
characteristic to design a novel zero-shot AC/AS method by Mutual Scoring
(MuSc) of the unlabeled images, which does not need any training or prompts.
Specifically, we perform Local Neighborhood Aggregation with Multiple Degrees
(LNAMD) to obtain the patch features that are capable of representing anomalies
in varying sizes. Then we propose the Mutual Scoring Mechanism (MSM) to
leverage the unlabeled test images to assign the anomaly score to each other.
Furthermore, we present an optimization approach named Re-scoring with
Constrained Image-level Neighborhood (RsCIN) for image-level anomaly
classification to suppress the false positives caused by noises in normal
images. The superior performance on the challenging MVTec AD and VisA datasets
demonstrates the effectiveness of our approach. Compared with the
state-of-the-art zero-shot approaches, MuSc achieves a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-97-Frame tabindex=0><nobr><span class=math id=MathJax-Span-578 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.95em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-579><span class=texatom id=MathJax-Span-580><span class=mrow id=MathJax-Span-581><span class=mtext id=MathJax-Span-582 style=font-family:MathJax_Main-bold>21.1%</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> PRO
absolute gain (from 72.7% to 93.8%) on MVTec AD, a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-98-Frame tabindex=0><nobr><span class=math id=MathJax-Span-583 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.95em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-584><span class=texatom id=MathJax-Span-585><span class=mrow id=MathJax-Span-586><span class=mtext id=MathJax-Span-587 style=font-family:MathJax_Main-bold>19.4%</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> pixel-AP
gain and a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-99-Frame tabindex=0><nobr><span class=math id=MathJax-Span-588 style=width:3.649em;display:inline-block><span style=display:inline-block;position:relative;width:3.012em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.95em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-589><span class=texatom id=MathJax-Span-590><span class=mrow id=MathJax-Span-591><span class=mtext id=MathJax-Span-592 style=font-family:MathJax_Main-bold>14.7%</span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> pixel-AUROC gain on VisA. In addition, our
zero-shot approach outperforms most of the few-shot approaches and is
comparable to some one-class methods. Code is available at
https://github.com/xrli-U/MuSc.
</p>
</div>
</dd>
<dt><a name=item160>[160]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16754 title=Abstract>arXiv:2401.16754</a> [<a href=https://arxiv.org/pdf/2401.16754 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16754 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> AI Oversight and Human Mistakes: Evidence from Centre Court
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Almog%2C+D">David Almog</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gauriot%2C+R">Romain Gauriot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Page%2C+L">Lionel Page</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin%2C+D">Daniel Martin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); General Economics (econ.GN)
</div>
<p class=mathjax>Powered by the increasing predictive capabilities of machine learning
algorithms, artificial intelligence (AI) systems have begun to be used to
overrule human mistakes in many settings. We provide the first field evidence
this AI oversight carries psychological costs that can impact human
decision-making. We investigate one of the highest visibility settings in which
AI oversight has occurred: the Hawk-Eye review of umpires in top tennis
tournaments. We find that umpires lowered their overall mistake rate after the
introduction of Hawk-Eye review, in line with rational inattention given
psychological costs of being overruled by AI. We also find that umpires
increased the rate at which they called balls in, which produced a shift from
making Type II errors (calling a ball out when in) to Type I errors (calling a
ball in when out). We structurally estimate the psychological costs of being
overruled by AI using a model of rational inattentive umpires, and our results
suggest that because of these costs, umpires cared twice as much about Type II
errors under AI oversight.
</p>
</div>
</dd>
<dt><a name=item161>[161]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16755 title=Abstract>arXiv:2401.16755</a> [<a href=https://arxiv.org/pdf/2401.16755 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16755 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diffusion model for relational inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Shuhan Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Ziqiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fujiwara%2C+K">Kantaro Fujiwara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+G">Gouhei Tanaka</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Dynamical behaviors of complex interacting systems, including brain
activities, financial price movements, and physical collective phenomena, are
associated with underlying interactions between the system's components. The
issue of uncovering interaction relations in such systems using observable
dynamics is called relational inference. In this study, we propose a Diffusion
model for Relational Inference (DiffRI), inspired by a self-supervised method
for probabilistic time series imputation. DiffRI learns to infer the
probability of the presence of connections between components through
conditional diffusion modeling. Experiments on both simulated and quasi-real
datasets show that DiffRI is highly competent compared with other
state-of-the-art models in discovering ground truth interactions in an
unsupervised manner. Our code will be made public soon.
</p>
</div>
</dd>
<dt><a name=item162>[162]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16757 title=Abstract>arXiv:2401.16757</a> [<a href=https://arxiv.org/pdf/2401.16757 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16757 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+J">Jiani Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zimu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenjiang Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 19 figures, accepted by IEEE Transactions on Mobile Computing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>Executing deep neural networks (DNNs) on edge artificial intelligence (AI)
devices enables various autonomous mobile computing applications. However, the
memory budget of edge AI devices restricts the number and complexity of DNNs
allowed in such applications. Existing solutions, such as model compression or
cloud offloading, reduce the memory footprint of DNN inference at the cost of
decreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN
into blocks and swap them in and out in order, such that large DNNs can execute
within a small memory budget. Nevertheless, naive swapping on edge AI devices
induces significant delays due to the redundant memory operations in the DNN
development ecosystem for edge AI devices. To this end, we develop SwapNet, an
efficient DNN block swapping middleware for edge AI devices. We systematically
eliminate the unnecessary memory operations during block swapping while
retaining compatible with the deep learning frameworks, GPU backends, and
hardware architectures of edge AI devices. We further showcase the utility of
SwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inference
tasks in three applications demonstrate that SwapNet achieves almost the same
latency as the case with sufficient memory even when DNNs demand 2.32x to 5.81x
memory beyond the available budget. The design of SwapNet also provides novel
and feasible insights for deploying large language models (LLMs) on edge AI
devices in the future.
</p>
</div>
</dd>
<dt><a name=item163>[163]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16759 title=Abstract>arXiv:2401.16759</a> [<a href=https://arxiv.org/pdf/2401.16759 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16759 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16759 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sandi: A System for Accountability and Applications in Direct Communication
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Durak%2C+F+B">F. Betül Durak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laine%2C+K">Kim Laine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Langowski%2C+S">Simon Langowski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moreno%2C+R+C">Radames Cruz Moreno</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>We construct a system, Sandi, to bring trust in online communication between
parties that share little or no context. Sandi is based on a unique ``somewhat
monotone'' privacy-preserving reputation system, with strong privacy and
security properties. Registered senders request cryptographic tags from Sandi,
which they attach to their messages. Message receivers do not need registered
accounts, but they can use a sender's score to decide how much the sender
should be trusted. If a receiver finds the message inappropriate, they can use
the tag to report the sender to Sandi, thus decreasing the sender's score. The
design of Sandi ensures compatibility with any communication system that allows
for small binary data transmission.
<br>Sandi aims to benefit both senders and receivers. Senders benefit, as
receivers are more likely to react to their messages with reputation scores
attached. Receivers benefit, as they can make better choices in who to interact
with based on indisputable evidence from prior receivers.
<br>Sandi does not require senders or receivers to maintain long-term secret
keys. We provide a score integrity guarantee for the senders, a full
communication privacy guarantee for the senders and receivers, a report privacy
guarantee to protect reporting receivers, and an unlinkability guarantee to
protect senders.
<br>Finally, we provide a game-theoretic analysis for the sender. We prove that,
for any score function satisfying a list of properties, Sandi drives rational
senders towards a strategy, which reduces the amount of inappropriate messages.
</p>
</div>
</dd>
<dt><a name=item164>[164]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16760 title=Abstract>arXiv:2401.16760</a> [<a href=https://arxiv.org/pdf/2401.16760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> One-Step Forward and Backtrack: Overcoming Zig-Zagging in Loss-Aware Quantization Training
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lianbo Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuee Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jianlun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+G">Guo Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 13 figures,accepted by AAAI-24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Weight quantization is an effective technique to compress deep neural
networks for their deployment on edge devices with limited resources.
Traditional loss-aware quantization methods commonly use the quantized gradient
to replace the full-precision gradient. However, we discover that the gradient
error will lead to an unexpected zig-zagging-like issue in the gradient descent
learning procedures, where the gradient directions rapidly oscillate or
zig-zag, and such issue seriously slows down the model convergence.
Accordingly, this paper proposes a one-step forward and backtrack way for
loss-aware quantization to get more accurate and stable gradient direction to
defy this issue. During the gradient descent learning, a one-step forward
search is designed to find the trial gradient of the next-step, which is
adopted to adjust the gradient of current step towards the direction of fast
convergence. After that, we backtrack the current step to update the
full-precision and quantized weights through the current-step gradient and the
trial gradient. A series of theoretical analysis and experiments on benchmark
deep models have demonstrated the effectiveness and competitiveness of the
proposed method, and our method especially outperforms others on the
convergence performance.
</p>
</div>
</dd>
<dt><a name=item165>[165]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16762 title=Abstract>arXiv:2401.16762</a> [<a href=https://arxiv.org/pdf/2401.16762 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16762 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Pick-and-Draw: Training-free Semantic Guidance for Text-to-Image Personalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lv%2C+H">Henglei Lv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jiayu Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Liang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Diffusion-based text-to-image personalization have achieved great success in
generating subjects specified by users among various contexts. Even though,
existing finetuning-based methods still suffer from model overfitting, which
greatly harms the generative diversity, especially when given subject images
are few. To this end, we propose Pick-and-Draw, a training-free semantic
guidance approach to boost identity consistency and generative diversity for
personalization methods. Our approach consists of two components: appearance
picking guidance and layout drawing guidance. As for the former, we construct
an appearance palette with visual features from the reference image, where we
pick local patterns for generating the specified subject with consistent
identity. As for layout drawing, we outline the subject's contour by referring
to a generative template from the vanilla diffusion model, and inherit the
strong image prior to synthesize diverse contexts according to different text
conditions. The proposed approach can be applied to any personalized diffusion
models and requires as few as a single reference image. Qualitative and
quantitative experiments show that Pick-and-Draw consistently improves identity
consistency and generative diversity, pushing the trade-off between subject
fidelity and image-text fidelity to a new Pareto frontier.
</p>
</div>
</dd>
<dt><a name=item166>[166]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16763 title=Abstract>arXiv:2401.16763</a> [<a href=https://arxiv.org/pdf/2401.16763 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16763 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What is a limit of structure-preserving numerical methods for compressible flows?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lukacova-Medvidova%2C+M">Maria Lukacova-Medvidova</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=She%2C+B">Bangwei She</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yuan%2C+Y">Yuhuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 6 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We present an overview of recent developments on the convergence analysis of
numerical methods for inviscid multidimensional compressible flows that
preserve underlying physical structures. We introduce the concept of
generalized solutions, the so-called dissipative solutions, and explain their
relationship to other commonly used solution concepts. In numerical experiments
we apply K-convergence of numerical solutions and approximate turbulent
solutions together with the Reynolds stress defect and the energy defect.
</p>
</div>
</dd>
<dt><a name=item167>[167]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16764 title=Abstract>arXiv:2401.16764</a> [<a href=https://arxiv.org/pdf/2401.16764 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16764 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BoostDream: Efficient Refining for High-Quality Text-to-3D Generation from Multi-View Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yonghao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shunan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+H">Huai Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haorui Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Witnessing the evolution of text-to-image diffusion models, significant
strides have been made in text-to-3D generation. Currently, two primary
paradigms dominate the field of text-to-3D: the feed-forward generation
solutions, capable of swiftly producing 3D assets but often yielding coarse
results, and the Score Distillation Sampling (SDS) based solutions, known for
generating high-fidelity 3D assets albeit at a slower pace. The synergistic
integration of these methods holds substantial promise for advancing 3D
generation techniques. In this paper, we present BoostDream, a highly efficient
plug-and-play 3D refining method designed to transform coarse 3D assets into
high-quality. The BoostDream framework comprises three distinct processes: (1)
We introduce 3D model distillation that fits differentiable representations
from the 3D assets obtained through feed-forward generation. (2) A novel
multi-view SDS loss is designed, which utilizes a multi-view aware 2D diffusion
model to refine the 3D assets. (3) We propose to use prompt and multi-view
consistent normal maps as guidance in refinement.Our extensive experiment is
conducted on different differentiable 3D representations, revealing that
BoostDream excels in generating high-quality 3D assets rapidly, overcoming the
Janus problem compared to conventional SDS-based methods. This breakthrough
signifies a substantial advancement in both the efficiency and quality of 3D
generation processes.
</p>
</div>
</dd>
<dt><a name=item168>[168]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16765 title=Abstract>arXiv:2401.16765</a> [<a href=https://arxiv.org/pdf/2401.16765 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16765 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Cross-Language Investigation into Jailbreak Attacks in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jie Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C">Chongyang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+L">Ling Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xiaoning Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yaowen Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yinxing Xue</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs) have become increasingly popular for their
advanced text generation capabilities across various domains. However, like any
software, they face security challenges, including the risk of 'jailbreak'
attacks that manipulate LLMs to produce prohibited content. A particularly
underexplored area is the Multilingual Jailbreak attack, where malicious
questions are translated into various languages to evade safety filters.
Currently, there is a lack of comprehensive empirical studies addressing this
specific threat.
<br>To address this research gap, we conducted an extensive empirical study on
Multilingual Jailbreak attacks. We developed a novel semantic-preserving
algorithm to create a multilingual jailbreak dataset and conducted an
exhaustive evaluation on both widely-used open-source and commercial LLMs,
including GPT-4 and LLaMa. Additionally, we performed interpretability analysis
to uncover patterns in Multilingual Jailbreak attacks and implemented a
fine-tuning mitigation method. Our findings reveal that our mitigation strategy
significantly enhances model defense, reducing the attack success rate by
96.2%. This study provides valuable insights into understanding and mitigating
Multilingual Jailbreak attacks.
</p>
</div>
</dd>
<dt><a name=item169>[169]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16766 title=Abstract>arXiv:2401.16766</a> [<a href=https://arxiv.org/pdf/2401.16766 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16766 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+P">Pu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Siyue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xue Lin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published in AdvML 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Deep Neural Network (DNN) models when implemented on executing devices as the
inference engines are susceptible to Fault Injection Attacks (FIAs) that
manipulate model parameters to disrupt inference execution with disastrous
performance. This work introduces Contrastive Learning (CL) of visual
representations i.e., a self-supervised learning approach into the deep
learning training and inference pipeline to implement DNN inference engines
with self-resilience under FIAs. Our proposed CL based FIA Detection and
Recovery (CFDR) framework features (i) real-time detection with only a single
batch of testing data and (ii) fast recovery effective even with only a small
amount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on
multiple types of FIAs, our CFDR shows promising detection and recovery
effectiveness.
</p>
</div>
</dd>
<dt><a name=item170>[170]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16771 title=Abstract>arXiv:2401.16771</a> [<a href=https://arxiv.org/pdf/2401.16771 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16771 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16771 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MolPLA: A Molecular Pretraining Framework for Learning Cores, R-Groups and their Linker Joints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gim%2C+M">Mogan Gim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jueon Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+S">Soyon Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Sanghoon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baek%2C+S">Seungheun Baek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J">Junhyun Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+N">Ngoc-Quang Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+J">Jaewoo Kang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Molecular core structures and R-groups are essential concepts in drug
development. Integration of these concepts with conventional graph pre-training
approaches can promote deeper understanding in molecules. We propose MolPLA, a
novel pre-training framework that employs masked graph contrastive learning in
understanding the underlying decomposable parts inmolecules that implicate
their core structure and peripheral R-groups. Furthermore, we formulate an
additional framework that grants MolPLA the ability to help chemists find
replaceable R-groups in lead optimization scenarios. Experimental results on
molecular property prediction show that MolPLA exhibits predictability
comparable to current state-of-the-art models. Qualitative analysis implicate
that MolPLA is capable of distinguishing core and R-group sub-structures,
identifying decomposable regions in molecules and contributing to lead
optimization scenarios by rationally suggesting R-group replacements given
various query core templates. The code implementation for MolPLA and its
pre-trained model checkpoint is available at https://github.com/dmis-lab/MolPLA
</p>
</div>
</dd>
<dt><a name=item171>[171]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16772 title=Abstract>arXiv:2401.16772</a> [<a href=https://arxiv.org/pdf/2401.16772 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16772 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furuyama%2C+R">Ryoma Furuyama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuyoshi%2C+D">Daiki Kuyoshi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamane%2C+S">Satoshi Yamane</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 4 figures. arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2001.06808>arXiv:2001.06808</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Imitation learning is often used in addition to reinforcement learning in
environments where reward design is difficult or where the reward is sparse,
but it is difficult to be able to imitate well in unknown states from a small
amount of expert data and sampling data. Supervised learning methods such as
Behavioral Cloning do not require sampling data, but usually suffer from
distribution shift. The methods based on reinforcement learning, such as
inverse reinforcement learning and Generative Adversarial imitation learning
(GAIL), can learn from only a few expert data. However, they often need to
interact with the environment. Soft Q imitation learning (SQIL) addressed the
problems, and it was shown that it could learn efficiently by combining
Behavioral Cloning and soft Q-learning with constant rewards. In order to make
this algorithm more robust to distribution shift, we propose more efficient and
robust algorithm by adding to this method a reward function based on
adversarial inverse reinforcement learning that rewards the agent for
performing actions in status similar to the demo. We call this algorithm
Discriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCo
environments.
</p>
</div>
</dd>
<dt><a name=item172>[172]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16775 title=Abstract>arXiv:2401.16775</a> [<a href=https://arxiv.org/pdf/2401.16775 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16775 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Activity Detection for Massive Connectivity in Cell-free Networks with Unknown Large-scale Fading, Channel Statistics, Noise Variance, and Activity Probability: A Bayesian Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Q">Qingfeng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+L">Lei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yik-Chung Wu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Activity detection is an important task in the next generation grant-free
multiple access. While there are a number of existing algorithms designed for
this purpose, they mostly require precise information about the network, such
as large-scale fading coefficients, small-scale fading channel statistics,
noise variance at the access points, and user activity probability. Acquiring
these information would take a significant overhead and their estimated values
might not be accurate. This problem is even more severe in cell-free networks
as there are many of these parameters to be acquired. Therefore, this paper
sets out to investigate the activity detection problem without the
above-mentioned information. In order to handle so many unknown parameters,
this paper employs the Bayesian approach, where the unknown variables are
endowed with prior distributions which effectively act as regularizations.
Together with the likelihood function, a maximum a posteriori (MAP) estimator
and a variational inference algorithm are derived. Extensive simulations
demonstrate that the proposed methods, even without the knowledge of these
system parameters, perform better than existing state-of-the-art methods, such
as covariance-based and approximate message passing methods.
</p>
</div>
</dd>
<dt><a name=item173>[173]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16777 title=Abstract>arXiv:2401.16777</a> [<a href=https://arxiv.org/pdf/2401.16777 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16777 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Addressing Distribution Shift in Time Series Forecasting with Instance Normalization Flows
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+W">Wei Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+S">Shun Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengyang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+R">Rui Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bian%2C+J">Jiang Bian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Due to non-stationarity of time series, the distribution shift problem
largely hinders the performance of time series forecasting. Existing solutions
either fail for the shifts beyond simple statistics or the limited
compatibility with forecasting models. In this paper, we propose a general
decoupled formulation for time series forecasting, with no reliance on fixed
statistics and no restriction on forecasting architectures. Then, we make such
a formulation formalized into a bi-level optimization problem, to enable the
joint learning of the transformation (outer loop) and forecasting (inner loop).
Moreover, the special requirements of expressiveness and bi-direction for the
transformation motivate us to propose instance normalization flows (IN-Flow), a
novel invertible network for time series transformation. Extensive experiments
demonstrate our method consistently outperforms state-of-the-art baselines on
both synthetic and real-world data.
</p>
</div>
</dd>
<dt><a name=item174>[174]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16778 title=Abstract>arXiv:2401.16778</a> [<a href=https://arxiv.org/pdf/2401.16778 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16778 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Secure ISAC MIMO Systems: Exploiting Interference With Bayesian Cramér-Rao Bound Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+N">Nanchi Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+F">Fan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Masouros%2C+C">Christos Masouros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yifeng Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qinyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 4 figures, submitted for journal publication
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>In this paper, we present a signaling design for secure integrated sensing
and communication (ISAC) systems comprising a dual-functional multi-input
multi-output (MIMO) base station (BS) that simultaneously communicates with
multiple users while detecting targets present in their vicinity, which are
regarded as potential eavesdroppers. In particular, assuming that the
distribution of each parameter to be estimated is known \textit{a priori}, we
focus on optimizing the targets' sensing performance. To this end, we derive
and minimize the Bayesian Cram\'er-Rao bound (BCRB), while ensuring certain
communication quality of service (QoS) by exploiting constructive interference
(CI). The latter scheme enforces that the received signals at the eavesdropping
targets fall into the destructive region of the signal constellation, to
deteriorate their decoding probability, thus enhancing the ISAC's system
physical-layer security (PLS) capability. To tackle the nonconvexity of the
formulated problem, a tailored successive convex approximation method is
proposed for its efficient solution. Our extensive numerical results verify the
effectiveness of the proposed secure ISAC design showing that the proposed
algorithm outperforms block-level precoding techniques.
</p>
</div>
</dd>
<dt><a name=item175>[175]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16784 title=Abstract>arXiv:2401.16784</a> [<a href=https://arxiv.org/pdf/2401.16784 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16784 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Fairness Learning under Distribution Shifts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yibo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xing%2C+Y">Yujie Xing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+S">Shaohua Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruijia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yaoqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by WWW 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>Graph neural networks (GNNs) have achieved remarkable performance on
graph-structured data. However, GNNs may inherit prejudice from the training
data and make discriminatory predictions based on sensitive attributes, such as
gender and race. Recently, there has been an increasing interest in ensuring
fairness on GNNs, but all of them are under the assumption that the training
and testing data are under the same distribution, i.e., training data and
testing data are from the same graph. Will graph fairness performance decrease
under distribution shifts? How does distribution shifts affect graph fairness
learning? All these open questions are largely unexplored from a theoretical
perspective. To answer these questions, we first theoretically identify the
factors that determine bias on a graph. Subsequently, we explore the factors
influencing fairness on testing graphs, with a noteworthy factor being the
representation distances of certain groups between the training and testing
graph. Motivated by our theoretical analysis, we propose our framework
FatraGNN. Specifically, to guarantee fairness performance on unknown testing
graphs, we propose a graph generator to produce numerous graphs with
significant bias and under different distributions. Then we minimize the
representation distances for each certain group between the training graph and
generated graphs. This empowers our model to achieve high classification and
fairness performance even on generated graphs with significant bias, thereby
effectively handling unknown testing graphs. Experiments on real-world and
semi-synthetic datasets demonstrate the effectiveness of our model in terms of
both accuracy and fairness.
</p>
</div>
</dd>
<dt><a name=item176>[176]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16785 title=Abstract>arXiv:2401.16785</a> [<a href=https://arxiv.org/pdf/2401.16785 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16785 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Efficiency and Robustness in Support Vector Regression with HawkEye Loss
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akhtar%2C+M">Mushir Akhtar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanveer%2C+M">M. Tanveer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arshad%2C+M">Mohd. Arshad</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Support vector regression (SVR) has garnered significant popularity over the
past two decades owing to its wide range of applications across various fields.
Despite its versatility, SVR encounters challenges when confronted with
outliers and noise, primarily due to the use of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-100-Frame tabindex=0><nobr><span class=math id=MathJax-Span-593 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-594><span class=mi id=MathJax-Span-595 style=font-family:MathJax_Math-italic>ε</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-insensitive
loss function. To address this limitation, SVR with bounded loss functions has
emerged as an appealing alternative, offering enhanced generalization
performance and robustness. Notably, recent developments focus on designing
bounded loss functions with smooth characteristics, facilitating the adoption
of gradient-based optimization algorithms. However, it's crucial to highlight
that these bounded and smooth loss functions do not possess an insensitive
zone. In this paper, we address the aforementioned constraints by introducing a
novel symmetric loss function named the HawkEye loss function. It is worth
noting that the HawkEye loss function stands out as the first loss function in
SVR literature to be bounded, smooth, and simultaneously possess an insensitive
zone. Leveraging this breakthrough, we integrate the HawkEye loss function into
the least squares framework of SVR and yield a new fast and robust model termed
HE-LSSVR. The optimization problem inherent to HE-LSSVR is addressed by
harnessing the adaptive moment estimation (Adam) algorithm, known for its
adaptive learning rate and efficacy in handling large-scale problems. To our
knowledge, this is the first time Adam has been employed to solve an SVR
problem. To empirically validate the proposed HE-LSSVR model, we evaluate it on
UCI, synthetic, and time series datasets. The experimental outcomes
unequivocally reveal the superiority of the HE-LSSVR model both in terms of its
remarkable generalization performance and its efficiency in training time.
</p>
</div>
</dd>
<dt><a name=item177>[177]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16786 title=Abstract>arXiv:2401.16786</a> [<a href=https://arxiv.org/pdf/2401.16786 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16786 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16786 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WikiTexVC: MediaWiki's native LaTeX to MathML converter for Wikipedia
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stegm%C3%BCller%2C+J">Johannes Stegmüller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schubotz%2C+M">Moritz Schubotz</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
<p class=mathjax>MediaWiki and Wikipedia authors usually use LaTeX to define mathematical
formulas in the wiki text markup. In the Wikimedia ecosystem, these formulas
were processed by a long cascade of web services and finally delivered to
users' browsers in rendered form for visually readable representation as SVG.
<br>With the latest developments of supporting MathML Core in Chromium-based
browsers, MathML continues its path to be a de facto standard markup language
for mathematical notation in the web. Conveying formulas in MathML enables
semantic annotation and machine readability for extended interpretation of
mathematical content, in example for accessibility technologies.
<br>With this work, we present WikiTexVC, a novel method for validating LaTeX
formulas from wiki texts and converting them to MathML, which is directly
integrated into MediaWiki. This mitigates the shortcomings of previously used
rendering methods in MediaWiki in terms of robustness, maintainability and
performance. In addition, there is no need for a multitude of web services
running in the background, but processing takes place directly within MediaWiki
instances. We validated this method with an extended dataset of over 300k
formulas which have been incorporated as automated tests to the MediaWiki
continuous integration instances. Furthermore, we conducted an evaluation with
423 formulas, comparing the tree edit distance for produced parse trees to
other MathML renderers. Our method has been made available Open Source and can
be used on German Wikipedia and is delivered with recent MediaWiki versions. As
a practical example of enabling semantic annotations within our method, we
present a new macro that adds content to formula disambiguation to facilitate
accessibility for visually impaired people.
</p>
</div>
</dd>
<dt><a name=item178>[178]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16788 title=Abstract>arXiv:2401.16788</a> [<a href=https://arxiv.org/pdf/2401.16788 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16788 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chern%2C+S">Steffi Chern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chern%2C+E">Ethan Chern</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neubig%2C+G">Graham Neubig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Despite the utility of Large Language Models (LLMs) across a wide range of
tasks and scenarios, developing a method for reliably evaluating LLMs across
varied contexts continues to be challenging. Modern evaluation approaches often
use LLMs to assess responses generated by LLMs. However, the meta-evaluation
conducted to assess the effectiveness of these LLMs as evaluators is typically
constrained by the coverage of existing benchmarks or requires extensive human
annotation. This underscores the urgency of methods for scalable
meta-evaluation that can effectively, reliably, and efficiently evaluate the
performance of LLMs as evaluators across diverse tasks and scenarios,
particularly in potentially new, user-defined scenarios. To fill this gap, we
propose ScaleEval, an agent-debate-assisted meta-evaluation framework that
leverages the capabilities of multiple communicative LLM agents. This framework
supports multi-round discussions to assist human annotators in discerning the
most capable LLMs as evaluators, which significantly eases their workload in
cases that used to require large-scale annotations during meta-evaluation. We
release the code for our framework, which is publicly available at:
\url{https://github.com/GAIR-NLP/scaleeval}.
</p>
</div>
</dd>
<dt><a name=item179>[179]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16791 title=Abstract>arXiv:2401.16791</a> [<a href=https://arxiv.org/pdf/2401.16791 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16791 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerated Cloud for Artificial Intelligence (ACAI)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+D">Dachi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+W">Weitian Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+C">Chen Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sakr%2C+M">Majd Sakr</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Training an effective Machine learning (ML) model is an iterative process
that requires effort in multiple dimensions. Vertically, a single pipeline
typically includes an initial ETL (Extract, Transform, Load) of raw datasets, a
model training stage, and an evaluation stage where the practitioners obtain
statistics of the model performance. Horizontally, many such pipelines may be
required to find the best model within a search space of model configurations.
Many practitioners resort to maintaining logs manually and writing simple glue
code to automate the workflow. However, carrying out this process on the cloud
is not a trivial task in terms of resource provisioning, data management, and
bookkeeping of job histories to make sure the results are reproducible. We
propose an end-to-end cloud-based machine learning platform, Accelerated Cloud
for AI (ACAI), to help improve the productivity of ML practitioners. ACAI
achieves this goal by enabling cloud-based storage of indexed, labeled, and
searchable data, as well as automatic resource provisioning, job scheduling,
and experiment tracking. Specifically, ACAI provides practitioners (1) a data
lake for storing versioned datasets and their corresponding metadata, and (2)
an execution engine for executing ML jobs on the cloud with automatic resource
provisioning (auto-provision), logging and provenance tracking. To evaluate
ACAI, we test the efficacy of our auto-provisioner on the MNIST handwritten
digit classification task, and we study the usability of our system using
experiments and interviews. We show that our auto-provisioner produces a 1.7x
speed-up and 39% cost reduction, and our system reduces experiment time for ML
scientists by 20% on typical ML use cases.
</p>
</div>
</dd>
<dt><a name=item180>[180]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16792 title=Abstract>arXiv:2401.16792</a> [<a href=https://arxiv.org/pdf/2401.16792 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16792 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WideSA: A High Array Utilization Mapping Scheme for Uniform Recurrences on the Versal ACAP Architecture
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+T">Tuo Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+B">Bizhao Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+G">Guojie Luo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> DATE24 (To appear)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>The Versal Adaptive Compute Acceleration Platform (ACAP) is a new
architecture that combines AI Engines (AIEs) with reconfigurable fabric. This
architecture offers significant acceleration potential for uniform recurrences
in various domains, such as deep learning, high-performance computation, and
signal processing. However, efficiently mapping these computations onto the
Versal ACAP architecture while achieving high utilization of AIEs poses a
challenge.
<br>To address this issue, we propose a mapping scheme called \fname, which aims
to accelerate uniform recurrences on the Versal ACAP architecture by leveraging
the features of both the hardware and the computations. Considering the array
architecture of AIEs, our approach utilizes space-time transformations based on
the polyhedral model to generate legally optimized systolic array mappings.
Concurrently, we have developed a routing-aware PLIO assignment algorithm
tailored for communication on the AIE array, and the algorithm aims at
successful compilation while maximizing array utilization. Furthermore, we
introduce an automatic mapping framework. This framework is designed to
generate the corresponding executable code for uniform recurrences, which
encompasses the AIE kernel program, programmable logic bitstreams, and the host
program. The experimental results validate the effectiveness of our mapping
scheme. Specifically, when applying our scheme to matrix multiplication
computations on the VCK5000 board, we achieve a throughput of 4.15TOPS on float
data type, which is 1.11<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-101-Frame tabindex=0><nobr><span class=math id=MathJax-Span-596 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-597><span class=mo id=MathJax-Span-598 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> higher compared to the state-of-the-art
accelerator on the Versal ACAP architecture.
</p>
</div>
</dd>
<dt><a name=item181>[181]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16793 title=Abstract>arXiv:2401.16793</a> [<a href=https://arxiv.org/pdf/2401.16793 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16793 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Stability of Datatic Control Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Y">Yujie Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zheng%2C+Z">Zhilong Zheng</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>The development of feedback controllers is undergoing a paradigm shift from
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-102-Frame tabindex=0><nobr><span class=math id=MathJax-Span-599 style=width:3.996em;display:inline-block><span style=display:inline-block;position:relative;width:3.302em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1003.3em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-600><span class=texatom id=MathJax-Span-601><span class=mrow id=MathJax-Span-602><span class=mtext id=MathJax-Span-603 style=font-family:MathJax_Main-italic>modelic</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> (model-driven) control to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-103-Frame tabindex=0><nobr><span class=math id=MathJax-Span-604 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.102em,1002.95em,2.144em,-999.997em);top:-1.965em;left:0em><span class=mrow id=MathJax-Span-605><span class=texatom id=MathJax-Span-606><span class=mrow id=MathJax-Span-607><span class=mtext id=MathJax-Span-608 style=font-family:MathJax_Main-italic>datatic</span></span></span></span><span style=display:inline-block;width:0px;height:1.97em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> (data-driven)
control. Stability, as a fundamental property in control, is less well studied
in datatic control paradigm. The difficulty is that traditional stability
criteria rely on explicit system models, which are not available in those
systems with datatic description. Some pioneering works explore stability
criteria for datatic systems with special forms such as linear systems,
homogeneous systems, and polynomial systems. However, these systems imply too
strong assumptions on the inherent connection among data points, which do not
hold in general nonlinear systems. This paper proposes a stability verification
algorithm for general datatic control systems called <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-104-Frame tabindex=0><nobr><span class=math id=MathJax-Span-609 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-610><span class=mi id=MathJax-Span-611 style=font-family:MathJax_Math-italic>η<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-testing. Our
stability criterion only relies on a weak assumption of Lipschitz continuity so
as to extend information from known data points to unmeasured regions. This
information restricts the time derivative of any unknown state to the
intersection of a set of closed balls. Inside the intersection, the worst-case
time derivative of Lyapunov function is estimated by solving a quadratically
constrained linear program (QCLP). By comparing the optimal values of QCLPs to
zero in the whole state space, a sufficient condition of system stability can
be checked. We test our algorithm on three datatic control systems, including
both linear and nonlinear ones. Results show that our algorithm successfully
verifies the stability, instability, and critical stability of tested systems.
</p>
</div>
</dd>
<dt><a name=item182>[182]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16795 title=Abstract>arXiv:2401.16795</a> [<a href=https://arxiv.org/pdf/2401.16795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Insights-based AI-driven Football Transfer Fee Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sulimov%2C+D">Daniil Sulimov</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>We developed an artificial intelligence approach to predict the transfer fee
of a football player. This model can help clubs make better decisions about
which players to buy and sell, which can lead to improved performance and
increased club budgets. Having collected data on player performance, transfer
fees, and other factors that might affect a player's value, we then used this
data to train a machine learning model that can accurately predict a player's
impact on the game. We further passed the obtained results as one of the
features to the predictor of transfer fees. The model can help clubs identify
players who are undervalued and who could be sold for a profit. It can also
help clubs avoid overpaying for players. We believe that our model can be a
valuable tool for football clubs. It can help them make better decisions about
player recruitment and transfers.
</p>
</div>
</dd>
<dt><a name=item183>[183]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16796 title=Abstract>arXiv:2401.16796</a> [<a href=https://arxiv.org/pdf/2401.16796 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16796 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liao%2C+W">Weibin Liao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yinghao Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zixiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chu%2C+X">Xu Chu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yasha Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Liantao Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Analyzing the health status of patients based on Electronic Health Records
(EHR) is a fundamental research problem in medical informatics. The presence of
extensive missing values in EHR makes it challenging for deep neural networks
to directly model the patient's health status based on EHR. Existing deep
learning training protocols require the use of statistical information or
imputation models to reconstruct missing values; however, the protocols inject
non-realistic data into downstream EHR analysis models, significantly limiting
model performance. This paper introduces Learnable Prompt as Pseudo Imputation
(PAI) as a new training protocol. PAI no longer introduces any imputed data but
constructs a learnable prompt to model the implicit preferences of the
downstream model for missing values, resulting in a significant performance
improvement for all EHR analysis models. Additionally, our experiments show
that PAI exhibits higher robustness in situations of data insufficiency and
high missing rates. More importantly, in a real-world application involving
cross-institutional data with zero-shot evaluation, PAI demonstrates stronger
model generalization capabilities for non-overlapping features.
</p>
</div>
</dd>
<dt><a name=item184>[184]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16797 title=Abstract>arXiv:2401.16797</a> [<a href=https://arxiv.org/pdf/2401.16797 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16797 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Compiler Transformation Robustness with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanzhao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+F">Fei Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>This paper presents a framework that integrates Large Language Models (LLMs)
into translation validation, targeting LLVM compiler transformations where
formal verification tools are insufficient. Our framework first utilizes
existing formal verification frameworks for translation validation. In this
work, we use Alive2, a well-known tool in LLVM compiler verification, as an
example. When formal verification frameworks are unable to confirm a
transformation's soundness, our framework employs fine-tuned LLMs for
prediction. It applies fuzzing to transformations predicted as potentially
unsound by the LLMs due to return value or memory inconsistencies, aiming to
find counterexamples. In cases where transformations are unsound for other
reasons or sound, or if no counterexamples emerge, the framework directly
reports these outcomes without further fuzzing. This methodology has shown
effectiveness in complex areas like deep-learning accelerator design, where
traditional tools struggle.
</p>
</div>
</dd>
<dt><a name=item185>[185]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16800 title=Abstract>arXiv:2401.16800</a> [<a href=https://arxiv.org/pdf/2401.16800 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16800 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Algorithm for Node Feature Forecasting in Temporal Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+A+U">Aniq Ur Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Coon%2C+J+P">Justin P. Coon</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 25 equations, 9 figures, 13 tables, 3 Algorithms
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Systems and Control (eess.SY)
</div>
<p class=mathjax>In this paper, we propose an online algorithm "mspace" for forecasting node
features in temporal graphs, which adeptly captures spatial cross-correlation
among different nodes as well as the temporal autocorrelation within a node.
The algorithm can be used for both probabilistic and deterministic multi-step
forecasting, making it applicable for estimation and generation tasks.
Comparative evaluations against various baselines, including graph neural
network (GNN) based models and classical Kalman filters, demonstrate that
mspace performs at par with the state-of-the-art and even surpasses them on
some datasets. Importantly, mspace demonstrates consistent robustness across
datasets with varying training sizes, a notable advantage over GNN-based
methods requiring abundant training samples to learn the spatiotemporal trends
in the data effectively. Therefore, employing mspace is advantageous in
scenarios where the training sample availability is limited. Additionally, we
establish theoretical bounds on multi-step forecasting error of mspace and show
that it scales as <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-105-Frame tabindex=0><nobr><span class=math id=MathJax-Span-612 style=width:2.376em;display:inline-block><span style=display:inline-block;position:relative;width:1.97em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.86em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-613><span class=mi id=MathJax-Span-614 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-615 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-616 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-617 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-106-Frame tabindex=0><nobr><span class=math id=MathJax-Span-618 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.26em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-619><span class=mi id=MathJax-Span-620 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>-step forecast.
</p>
</div>
</dd>
<dt><a name=item186>[186]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16801 title=Abstract>arXiv:2401.16801</a> [<a href=https://arxiv.org/pdf/2401.16801 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16801 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Kinematic Optimization of a Robotic Arm for Automation Tasks with Human Demonstration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meir%2C+I">Inbar Meir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bechar%2C+A">Avital Bechar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 IEEE Conference on Robotics and Automation (ICRA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Robotic arms are highly common in various automation processes such as
manufacturing lines. However, these highly capable robots are usually degraded
to simple repetitive tasks such as pick-and-place. On the other hand, designing
an optimal robot for one specific task consumes large resources of engineering
time and costs. In this paper, we propose a novel concept for optimizing the
fitness of a robotic arm to perform a specific task based on human
demonstration. Fitness of a robot arm is a measure of its ability to follow
recorded human arm and hand paths. The optimization is conducted using a
modified variant of the Particle Swarm Optimization for the robot design
problem. In the proposed approach, we generate an optimal robot design along
with the required path to complete the task. The approach could reduce the
time-to-market of robotic arms and enable the standardization of modular
robotic parts. Novice users could easily apply a minimal robot arm to various
tasks. Two test cases of common manufacturing tasks are presented yielding
optimal designs and reduced computational effort by up to 92%.
</p>
</div>
</dd>
<dt><a name=item187>[187]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16802 title=Abstract>arXiv:2401.16802</a> [<a href=https://arxiv.org/pdf/2401.16802 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16802 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Kinesthetic-based In-Hand Object Recognition with an Underactuated Robotic Hand
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arolovitch%2C+J">Julius Arolovitch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azulay%2C+O">Osher Azulay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2024 IEEE Conference on Robotics and Automation (ICRA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Tendon-based underactuated hands are intended to be simple, compliant and
affordable. Often, they are 3D printed and do not include tactile sensors.
Hence, performing in-hand object recognition with direct touch sensing is not
feasible. Adding tactile sensors can complicate the hardware and introduce
extra costs to the robotic hand. Also, the common approach of visual perception
may not be available due to occlusions. In this paper, we explore whether
kinesthetic haptics can provide in-direct information regarding the geometry of
a grasped object during in-hand manipulation with an underactuated hand. By
solely sensing actuator positions and torques over a period of time during
motion, we show that a classifier can recognize an object from a set of trained
ones with a high success rate of almost 95%. In addition, the implementation of
a real-time majority vote during manipulation further improves recognition.
Additionally, a trained classifier is also shown to be successful in
distinguishing between shape categories rather than just specific objects.
</p>
</div>
</dd>
<dt><a name=item188>[188]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16803 title=Abstract>arXiv:2401.16803</a> [<a href=https://arxiv.org/pdf/2401.16803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PBSCSR: The Piano Bootleg Score Composer Style Recognition Dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+A">Arhan Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bunn%2C+A">Alec Bunn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+T">TJ Tsai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>This article motivates, describes, and presents the PBSCSR dataset for
studying composer style recognition of piano sheet music. Our overarching goal
was to create a dataset for studying composer style recognition that is "as
accessible as MNIST and as challenging as ImageNet." To achieve this goal, we
sample fixed-length bootleg score fragments from piano sheet music images on
IMSLP. The dataset itself contains 40,000 62x64 bootleg score images for a
9-way classification task, 100,000 62x64 bootleg score images for a 100-way
classification task, and 29,310 unlabeled variable-length bootleg score images
for pretraining. The labeled data is presented in a form that mirrors MNIST
images, in order to make it extremely easy to visualize, manipulate, and train
models in an efficient manner. Additionally, we include relevant metadata to
allow access to the underlying raw sheet music images and other related data on
IMSLP. We describe several research tasks that could be studied with the
dataset, including variations of composer style recognition in a few-shot or
zero-shot setting. For tasks that have previously proposed models, we release
code and baseline results for future works to compare against. We also discuss
open research questions that the PBSCSR data is especially well suited to
facilitate research on and areas of fruitful exploration in future work.
</p>
</div>
</dd>
<dt><a name=item189>[189]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16804 title=Abstract>arXiv:2401.16804</a> [<a href=https://arxiv.org/pdf/2401.16804 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16804 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16804 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Guessing What, Noise or Codeword?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiao Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we distinguish two guessing algorithms for decoding binary
linear codes. One is the guessing noise decoding (GND) algorithm, and the other
is the guessing codeword decoding (GCD) algorithm. We prove that the GCD is a
maximum likelihood (ML) decoding algorithm and that the GCD is more efficient
than GND for most practical applications. We also introduce several variants of
ordered statistic decoding (OSD) to trade off the complexity of the Gaussian
elimination (GE) and that of the guessing, which may find applications in
decoding short block codes in the high signal-to-noise ratio (SNR) region.
</p>
</div>
</dd>
<dt><a name=item190>[190]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16807 title=Abstract>arXiv:2401.16807</a> [<a href=https://arxiv.org/pdf/2401.16807 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16807 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosenfeld%2C+A">Ariel Rosenfeld</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Large Language Models (LLMs), exemplified by ChatGPT, have significantly
reshaped text generation, particularly in the realm of writing assistance.
While ethical considerations underscore the importance of transparently
acknowledging LLM use, especially in scientific communication, genuine
acknowledgment remains infrequent. A potential avenue to encourage accurate
acknowledging of LLM-assisted writing involves employing automated detectors.
Our evaluation of four cutting-edge LLM-generated text detectors reveals their
suboptimal performance compared to a simple ad-hoc detector designed to
identify abrupt writing style changes around the time of LLM proliferation. We
contend that the development of specialized detectors exclusively dedicated to
LLM-assisted writing detection is necessary. Such detectors could play a
crucial role in fostering more authentic recognition of LLM involvement in
scientific communication, addressing the current challenges in acknowledgment
practices.
</p>
</div>
</dd>
<dt><a name=item191>[191]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16808 title=Abstract>arXiv:2401.16808</a> [<a href=https://arxiv.org/pdf/2401.16808 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16808 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Encoding Temporal Statistical-space Priors via Augmented Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choi%2C+I">Insu Choi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koh%2C+W">Woosung Koh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+G">Gimin Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+Y">Yuntae Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> pre-print
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Modeling time series data remains a pervasive issue as the temporal dimension
is inherent to numerous domains. Despite significant strides in time series
forecasting, high noise-to-signal ratio, non-normality, non-stationarity, and
lack of data continue challenging practitioners. In response, we leverage a
simple representation augmentation technique to overcome these challenges. Our
augmented representation acts as a statistical-space prior encoded at each time
step. In response, we name our method Statistical-space Augmented
Representation (SSAR). The underlying high-dimensional data-generating process
inspires our representation augmentation. We rigorously examine the empirical
generalization performance on two data sets with two downstream temporal
learning algorithms. Our approach significantly beats all five up-to-date
baselines. Moreover, the highly modular nature of our approach can easily be
applied to various settings. Lastly, fully-fledged theoretical perspectives are
available throughout the writing for a clear and rigorous understanding.
</p>
</div>
</dd>
<dt><a name=item192>[192]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16810 title=Abstract>arXiv:2401.16810</a> [<a href=https://arxiv.org/pdf/2401.16810 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16810 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Embeddable Implicit IUVD Representation for Part-based 3D Human Surface Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Baoxing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yong Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yehui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xu Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>To reconstruct a 3D human surface from a single image, it is important to
consider human pose, shape and clothing details simultaneously. In recent
years, a combination of parametric body models (such as SMPL) that capture body
pose and shape prior, and neural implicit functions that learn flexible
clothing details, has been used to integrate the advantages of both approaches.
However, the combined representation introduces additional computation, e.g.
signed distance calculation, in 3D body feature extraction, which exacerbates
the redundancy of the implicit query-and-infer process and fails to preserve
the underlying body shape prior. To address these issues, we propose a novel
IUVD-Feedback representation, which consists of an IUVD occupancy function and
a feedback query algorithm. With this representation, the time-consuming signed
distance calculation is replaced by a simple linear transformation in the IUVD
space, leveraging the SMPL UV maps. Additionally, the redundant query points in
the query-and-infer process are reduced through a feedback mechanism. This
leads to more reasonable 3D body features and more effective query points,
successfully preserving the parametric body prior. Moreover, the IUVD-Feedback
representation can be embedded into any existing implicit human reconstruction
pipelines without modifying the trained neural networks. Experiments on
THuman2.0 dataset demonstrate that the proposed IUVD-Feedback representation
improves result robustness and achieves three times faster acceleration in the
query-and-infer process. Furthermore, this representation has the potential to
be used in generative applications by leveraging its inherited semantic
information from the parametric body model.
</p>
</div>
</dd>
<dt><a name=item193>[193]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16811 title=Abstract>arXiv:2401.16811</a> [<a href=https://arxiv.org/pdf/2401.16811 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16811 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reviving Undersampling for Long-Tailed Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+H">Hao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+Y">Yingxiao Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The training datasets used in long-tailed recognition are extremely
unbalanced, resulting in significant variation in per-class accuracy across
categories. Prior works mostly used average accuracy to evaluate their
algorithms, which easily ignores those worst-performing categories. In this
paper, we aim to enhance the accuracy of the worst-performing categories and
utilize the harmonic mean and geometric mean to assess the model's performance.
We revive the balanced undersampling idea to achieve this goal. In few-shot
learning, balanced subsets are few-shot and will surely under-fit, hence it is
not used in modern long-tailed learning. But, we find that it produces a more
equitable distribution of accuracy across categories with much higher harmonic
and geometric mean accuracy, and, but lower average accuracy. Moreover, we
devise a straightforward model ensemble strategy, which does not result in any
additional overhead and achieves improved harmonic and geometric mean while
keeping the average accuracy almost intact when compared to state-of-the-art
long-tailed learning methods. We validate the effectiveness of our approach on
widely utilized benchmark datasets for long-tailed learning. Our code is at
\href{https://github.com/yuhao318/BTM/}{https://github.com/yuhao318/BTM/}.
</p>
</div>
</dd>
<dt><a name=item194>[194]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16812 title=Abstract>arXiv:2401.16812</a> [<a href=https://arxiv.org/pdf/2401.16812 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16812 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SpeechBERTScore: Reference-Aware Automatic Evaluation of Speech Generation Leveraging NLP Evaluation Metrics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saeki%2C+T">Takaaki Saeki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takamichi%2C+S">Shinnosuke Takamichi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saruwatari%2C+H">Hiroshi Saruwatari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>While subjective assessments have been the gold standard for evaluating
speech generation, there is a growing need for objective metrics that are
highly correlated with human subjective judgments due to their cost efficiency.
This paper proposes reference-aware automatic evaluation methods for speech
generation inspired by evaluation metrics in natural language processing. The
proposed SpeechBERTScore computes the BERTScore for self-supervised dense
speech features of the generated and reference speech, which can have different
sequential lengths. We also propose SpeechBLEU and SpeechTokenDistance, which
are computed on speech discrete tokens. The evaluations on synthesized speech
show that our method correlates better with human subjective ratings than mel
cepstral distortion and a recent mean opinion score prediction model. Also,
they are effective in noisy speech evaluation and have cross-lingual
applicability.
</p>
</div>
</dd>
<dt><a name=item195>[195]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16818 title=Abstract>arXiv:2401.16818</a> [<a href=https://arxiv.org/pdf/2401.16818 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16818 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16818 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> H2O-Danube-1.8B Technical Report
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singer%2C+P">Philipp Singer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pfeiffer%2C+P">Pascal Pfeiffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Babakhin%2C+Y">Yauhen Babakhin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeblick%2C+M">Maximilian Jeblick</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dhankhar%2C+N">Nischay Dhankhar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fodor%2C+G">Gabor Fodor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ambati%2C+S+S">Sri Satish Ambati</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We present H2O-Danube-1.8B, a 1.8B language model trained on 1T tokens
following the core principles of LLama 2 and Mistral. We leverage and refine
various techniques for pre-training large language models. Although our model
is trained on significantly fewer total tokens compared to reference models of
similar size, it exhibits highly competitive metrics across a multitude of
benchmarks. We additionally release a chat model trained with supervised
fine-tuning followed by direct preference optimization. We make H2O-Danube-1.8B
openly available under Apache 2.0 license further democratizing LLMs to a wider
audience economically.
</p>
</div>
</dd>
<dt><a name=item196>[196]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16820 title=Abstract>arXiv:2401.16820</a> [<a href=https://arxiv.org/pdf/2401.16820 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16820 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Provably Robust Multi-bit Watermarking for AI-generated Text via Error Correction Code
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qu%2C+W">Wenjie Qu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+D">Dong Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Z">Zixin He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+W">Wei Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tao%2C+T">Tianyang Tao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaheng Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>Large Language Models (LLMs) have been widely deployed for their remarkable
capability to generate texts resembling human language. However, they could be
misused by criminals to create deceptive content, such as fake news and
phishing emails, which raises ethical concerns. Watermarking is a key technique
to mitigate the misuse of LLMs, which embeds a watermark (e.g., a bit string)
into a text generated by a LLM. Consequently, this enables the detection of
texts generated by a LLM as well as the tracing of generated texts to a
specific user. The major limitation of existing watermark techniques is that
they cannot accurately or efficiently extract the watermark from a text,
especially when the watermark is a long bit string. This key limitation impedes
their deployment for real-world applications, e.g., tracing generated texts to
a specific user.
<br>This work introduces a novel watermarking method for LLM-generated text
grounded in \textbf{error-correction codes} to address this challenge. We
provide strong theoretical analysis, demonstrating that under bounded
adversarial word/token edits (insertion, deletion, and substitution), our
method can correctly extract watermarks, offering a provable robustness
guarantee. This breakthrough is also evidenced by our extensive experimental
results. The experiments show that our method substantially outperforms
existing baselines in both accuracy and robustness on benchmark datasets. For
instance, when embedding a bit string of length 12 into a 200-token generated
text, our approach attains an impressive match rate of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-107-Frame tabindex=0><nobr><span class=math id=MathJax-Span-621 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-622><span class=mn id=MathJax-Span-623 style=font-family:MathJax_Main>98.4</span><span class=mi id=MathJax-Span-624 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, surpassing the
performance of Yoo et al. (state-of-the-art baseline) at <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-108-Frame tabindex=0><nobr><span class=math id=MathJax-Span-625 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-626><span class=mn id=MathJax-Span-627 style=font-family:MathJax_Main>85.6</span><span class=mi id=MathJax-Span-628 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. When
subjected to a copy-paste attack involving the injection of 50 tokens to
generated texts with 200 words, our method maintains a substantial match rate
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-109-Frame tabindex=0><nobr><span class=math id=MathJax-Span-629 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-630><span class=mn id=MathJax-Span-631 style=font-family:MathJax_Main>90.8</span><span class=mi id=MathJax-Span-632 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, while the match rate of Yoo et al. diminishes to below <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-110-Frame tabindex=0><nobr><span class=math id=MathJax-Span-633 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.8em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-634><span class=mn id=MathJax-Span-635 style=font-family:MathJax_Main>65</span><span class=mi id=MathJax-Span-636 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item197>[197]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16822 title=Abstract>arXiv:2401.16822</a> [<a href=https://arxiv.org/pdf/2401.16822 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16822 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+M">Miaoxin Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yin Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+X">Xuerui Mao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Multi-modal large language models (MLLMs) have demonstrated remarkable
success in vision and visual-language tasks within the natural image domain.
Owing to the significant diversities between the natural image and RS image
hinder the development of MLLMs in the remote sensing (RS) domain. Currently,
the unified and powerful MLLM capable of various RS visual tasks is still
under-explored. To fill the gap, a pioneer MLLM called EarthGPT is proposed for
universal RS image comprehension, which integrates various multi-sensor RS
interpretation tasks uniformly. More importantly, a large-scale multi-sensor
multi-modal RS instruction-following dataset named MMRS is carefully
constructed, which comprises 1005.842k image-text pairs based on 34 existing
diverse RS datasets and includes multi-sensor images such as optical, synthetic
aperture radar (SAR), and infrared. The MMRS addresses the issue of MLLMs
lacking RS expert knowledge and stimulates the development of MMLMs in the RS
domain. Extensive experiments demonstrate the EarthGPT's superior performance
in various RS visual interpretation tasks compared with the other specialist
models and MLLMs, which proves the effectiveness of the proposed EarthGPT and
provides a versatile paradigm for open-set reasoning tasks.
</p>
</div>
</dd>
<dt><a name=item198>[198]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16823 title=Abstract>arXiv:2401.16823</a> [<a href=https://arxiv.org/pdf/2401.16823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16823 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Application of Methods of Artificial Intelligence in Systems for Continuous Automatic Monitoring of Dust Concentration and Deposits in Mine Atmosphere
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Trubicina%2C+D">Daria Trubicina</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Varnavskiy%2C+K">Kirill Varnavskiy</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ermakov%2C+A">Alexander Ermakov</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Nepsha%2C+F">Fedor Nepsha</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kozlov%2C+R">Roman Kozlov</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Golsanami%2C+N">Naser Golsanami</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhironkin%2C+S">Sergey Zhironkin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, in Russian language
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>With the growth of coal production, the load on the production capacity of
coal enterprises also increases, which leads to a concomitant increase in dust
formation in both opencast and underground methods of mining coal deposits.
Dust, generated during drilling, blasting operations, excavation, loading,
crushing and transportation of mined rock is one of the factors that has a
negative impact on the health of mining workers and on the level of
environmental pollution with solid particles. Thus, increasing the efficiency
of controlling the concentration of solid particles in the mine atmosphere and
dust deposits is an urgent scientific and technical task. In doing so, the use
of modern digital technologies within the framework of the industry 4.0 concept
makes it possible to develop approaches that can significantly improve the
quality of monitoring the state of the mine atmosphere at coal mining
enterprises. This article provides a theoretical basis and test results for a
system for continuous automatic monitoring of dust concentration in a mine
atmosphere as the component of the multifunctional coal mine safety system. It
is shown that monitoring the state of mine workings aerological safety can be
carried out in real time through the system of the new generation using
artificial intelligence. The ability of the proposed system to measure basic
physical parameters affecting dust deposition (disperse composition, air
humidity, dust concentration and air flow velocity) is noted.
</p>
</div>
</dd>
<dt><a name=item199>[199]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16825 title=Abstract>arXiv:2401.16825</a> [<a href=https://arxiv.org/pdf/2401.16825 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16825 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Smart Fitting Room: A Generative Approach to Matching-aware Virtual Try-On
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+M">Mingzhe Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+L">Lei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+K">Kai Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xue Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+L">Lei Meng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>
</div>
<p class=mathjax>In current virtual try-on tasks, only the effect of clothing worn on a person
is depicted. In practical applications, users still need to select suitable
clothing from a vast array of individual clothing items, but existing clothes
may not be able to meet the needs of users. Additionally, some user groups may
be uncertain about what clothing combinations suit them and require clothing
selection recommendations. However, the retrieval-based recommendation methods
cannot meet users' personalized needs, so we propose the Generative Fashion
Matching-aware Virtual Try-on Framework(GMVT). We generate coordinated and
stylistically diverse clothing for users using the Generative Matching Module.
In order to effectively learn matching information, we leverage large-scale
matching dataset, and transfer this acquired knowledge to the current virtual
try-on domain. Furthermore, we utilize the Virtual Try-on Module to visualize
the generated clothing on the user's body. To validate the effectiveness of our
approach, we enlisted the expertise of fashion designers for a professional
evaluation, assessing the rationality and diversity of the clothing
combinations and conducting an evaluation matrix analysis. Our method
significantly enhances the practicality of virtual try-on, offering users a
wider range of clothing choices and an improved user experience.
</p>
</div>
</dd>
<dt><a name=item200>[200]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16826 title=Abstract>arXiv:2401.16826</a> [<a href=https://arxiv.org/pdf/2401.16826 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16826 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design of Linear Precoders for Correlated Sources in MIMO Multiple Access Channels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%C3%A1rez-Casal%2C+P">P.Suárez-Casal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonz%C3%A1lez-Coma%2C+J+P">J.P.González-Coma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fresnedo%2C+O">O.Fresnedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castedo%2C+L">L.Castedo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Communications, vol. 66, n.o 12, pp.
 6110-6122, Aug 2018
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This work focuses on distributed linear precoding when users transmit
correlated information over a fading Multiple-Input and Multiple-Output
Multiple Access Channel. Precoders are optimized in order to minimize the
sum-Mean Square Error (MSE) between the source and the estimated symbols. When
sources are correlated, minimizing the sum-MSE results in a non-convex
optimization problem. Precoders for an arbitrary number of users and transmit
and receive antennas are thus obtained via a projected steepest-descent
algorithm and a low-complexity heuristic approach. For the more restrictive
case of two single-antenna users, a closed-form expression for the minimum
sum-MSE precoders is derived. Moreover, for the scenario with a single receive
antenna and any number of users, a solution is obtained by means of a
semidefinite relaxation. Finally, we also consider precoding schemes where the
precoders are decomposed into complex scalars and unit norm vectors. Simulation
results show a significant improvement when source correlation is exploited at
precoding, especially for low SNRs and when the number of receive antennas is
lower than the number of transmitting nodes.
</p>
</div>
</dd>
<dt><a name=item201>[201]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16827 title=Abstract>arXiv:2401.16827</a> [<a href=https://arxiv.org/pdf/2401.16827 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16827 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16827 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 3D-Printed Hydraulic Fluidic Logic Circuitry for Soft Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yuxin Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xinyi Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+W">Wenhan Cao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 pages, 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Soft Condensed Matter (cond-mat.soft)
</div>
<p class=mathjax>Fluidic logic circuitry analogous to its electric counterpart could
potentially provide soft robots with machine intelligence due to its supreme
adaptability, dexterity, and seamless compatibility using state-of-the-art
additive manufacturing processes. However, conventional microfluidic channel
based circuitry suffers from limited driving force, while macroscopic pneumatic
logic lacks timely responsivity and desirable accuracy. Producing heavy duty,
highly responsive and integrated fluidic soft robotic circuitry for control and
actuation purposes for biomedical applications has yet to be accomplished in a
hydraulic manner. Here, we present a 3D printed hydraulic fluidic half-adder
system, composing of three basic hydraulic fluidic logic building blocks: AND,
OR, and NOT gates. Furthermore, a hydraulic soft robotic half-adder system is
implemented using an XOR operation and modified dual NOT gate system based on
an electrical oscillator structure. This half-adder system possesses binary
arithmetic capability as a key component of arithmetic logic unit in modern
computers. With slight modifications, it can realize the control over three
different directions of deformation of a three degree-of-freedom soft actuation
mechanism solely by changing the states of the two fluidic inputs. This
hydraulic fluidic system utilizing a small number of inputs to control multiple
distinct outputs, can alter the internal state of the circuit solely based on
external inputs, holding significant promises for the development of
microfluidics, fluidic logic, and intricate internal systems of untethered soft
robots with machine intelligence.
</p>
</div>
</dd>
<dt><a name=item202>[202]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16830 title=Abstract>arXiv:2401.16830</a> [<a href=https://arxiv.org/pdf/2401.16830 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16830 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LATENTPATCH: A Non-Parametric Approach for Face Generation and Editing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samuth%2C+B">Benjamin Samuth</a> (UNICAEN, ENSICAEN), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rabin%2C+J">Julien Rabin</a> (ENSICAEN, UNICAEN), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tschumperl%C3%A9%2C+D">David Tschumperlé</a> (ENSICAEN, UNICAEN), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jurie%2C+F">Frédéric Jurie</a> (ENSICAEN, UNICAEN)
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2023 IEEE International Conference on Image Processing (ICIP), Oct
 2023, Kuala Lumpur, Malaysia. pp.1790-1794
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper presents LatentPatch, a new method for generating realistic images
from a small dataset of only a few images. We use a lightweight model with only
a few thousand parameters. Unlike traditional few-shot generation methods that
finetune pre-trained large-scale generative models, our approach is computed
directly on the latent distribution by sequential feature matching, and is
explainable by design. Avoiding large models based on transformers, recursive
networks, or self-attention, which are not suitable for small datasets, our
method is inspired by non-parametric texture synthesis and style transfer
models, and ensures that generated image features are sampled from the source
distribution. We extend previous single-image models to work with a few images
and demonstrate that our method can generate realistic images, as well as
enable conditional sampling and image editing. We conduct experiments on face
datasets and show that our simplistic model is effective and versatile.
</p>
</div>
</dd>
<dt><a name=item203>[203]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16832 title=Abstract>arXiv:2401.16832</a> [<a href=https://arxiv.org/pdf/2401.16832 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16832 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Analysis of Knowledge Tracing performance on synthesised student data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pagonis%2C+P">Panagiotis Pagonis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartung%2C+K">Kai Hartung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+D">Di Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Georges%2C+M">Munir Georges</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gr%C3%B6ttrup%2C+S">Sören Gröttrup</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AI4AI Education workshop 2023 ( <a href=https://sme.uni-bamberg.de/ai4ai/>this https URL</a> )
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Knowledge Tracing (KT) aims to predict the future performance of students by
tracking the development of their knowledge states. Despite all the recent
progress made in this field, the application of KT models in education systems
is still restricted from the data perspectives: 1) limited access to real life
data due to data protection concerns, 2) lack of diversity in public datasets,
3) noises in benchmark datasets such as duplicate records. To resolve these
problems, we simulated student data with three statistical strategies based on
public datasets and tested their performance on two KT baselines. While we
observe only minor performance improvement with additional synthetic data, our
work shows that using only synthetic data for training can lead to similar
performance as real data.
</p>
</div>
</dd>
<dt><a name=item204>[204]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16833 title=Abstract>arXiv:2401.16833</a> [<a href=https://arxiv.org/pdf/2401.16833 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16833 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16833 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Strong Polarization for Shortened and Punctured Polar Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shuval%2C+B">Boaz Shuval</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tal%2C+I">Ido Tal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to ISIT 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Polar codes were originally specified for codelengths that are powers of two.
In many applications, it is desired to have a code that is not restricted to
such lengths. Two common strategies of modifying the length of a code are
shortening and puncturing. Simple and explicit schemes for shortening and
puncturing were introduced by Wang and Liu, and by Niu, Chen, and Lin,
respectively. In this paper, we prove that both schemes yield polar codes that
are capacity achieving. Moreover, the probability of error for both the
shortened and the punctured polar codes decreases to zero at the same
exponential rate as seminal polar codes. These claims hold for \emph{all}
codelengths large enough.
</p>
</div>
</dd>
<dt><a name=item205>[205]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16835 title=Abstract>arXiv:2401.16835</a> [<a href=https://arxiv.org/pdf/2401.16835 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16835 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16835 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient numerical approximations for a non-conservative Nonlinear Schrodinger equation appearing in wind-forced ocean waves
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Athanassoulis%2C+A">Agissilaos Athanassoulis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Katsaounis%2C+T">Theodoros Katsaounis</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kyza%2C+I">Irene Kyza</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We consider a non-conservative nonlinear Schrodinger equation (NCNLS) with
time-dependent coefficients, inspired by a water waves problem. This problem
does not have mass or energy conservation, but instead mass and energy change
in time under explicit balance laws. In this paper we extend to the particular
NCNLS two numerical schemes which are known to conserve energy and mass in the
discrete level for the cubic NLS. Both schemes are second oder accurate in
time, and we prove that their extensions satisfy discrete versions of the mass
and energy balance laws for the NCNLS. The first scheme is a relaxation scheme
that is linearly implicit. The other scheme is a modified Delfour-Fortin-Payre
scheme and it is fully implicit. Numerical results show that both schemes
capture robustly the correct values of mass and energy, even in strongly
non-conservative problems. We finally compare the two numerical schemes and
discuss their performance.
</p>
</div>
</dd>
<dt><a name=item206>[206]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16836 title=Abstract>arXiv:2401.16836</a> [<a href=https://arxiv.org/pdf/2401.16836 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16836 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coseparable Nonnegative Tensor Factorization With T-CUR Decomposition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Juefei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+L">Longxiu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yimin Wei</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>Nonnegative Matrix Factorization (NMF) is an important unsupervised learning
method to extract meaningful features from data. To address the NMF problem
within a polynomial time framework, researchers have introduced a separability
assumption, which has recently evolved into the concept of coseparability. This
advancement offers a more efficient core representation for the original data.
However, in the real world, the data is more natural to be represented as a
multi-dimensional array, such as images or videos. The NMF's application to
high-dimensional data involves vectorization, which risks losing essential
multi-dimensional correlations. To retain these inherent correlations in the
data, we turn to tensors (multidimensional arrays) and leverage the tensor
t-product. This approach extends the coseparable NMF to the tensor setting,
creating what we term coseparable Nonnegative Tensor Factorization (NTF). In
this work, we provide an alternating index selection method to select the
coseparable core. Furthermore, we validate the t-CUR sampling theory and
integrate it with the tensor Discrete Empirical Interpolation Method (t-DEIM)
to introduce an alternative, randomized index selection process. These methods
have been tested on both synthetic and facial analysis datasets. The results
demonstrate the efficiency of coseparable NTF when compared to coseparable NMF.
</p>
</div>
</dd>
<dt><a name=item207>[207]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16838 title=Abstract>arXiv:2401.16838</a> [<a href=https://arxiv.org/pdf/2401.16838 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16838 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Complete Fragment of LTL(EB)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrarotti%2C+F">Flavio Ferrarotti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rivi%C3%A8re%2C+P">Peter Rivière</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schewe%2C+K">Klaus-Dieter Schewe</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh%2C+N+K">Neeraj Kumar Singh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ameur%2C+Y+A">Yamine Aït Ameur</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>The verification of liveness conditions is an important aspect of state-based
rigorous methods. This article investigates this problem in a fragment
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-111-Frame tabindex=0><nobr><span class=math id=MathJax-Span-637 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.7em,2.607em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-638><span class=mi id=MathJax-Span-639 style=font-family:MathJax_AMS>□</span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>LTL of the logic LTL(EB), the integration of the UNTIL-fragment of
Pnueli's linear time temporal logic (LTL) and the logic of Event-B, in which
the most commonly used liveness conditions can be expressed. For this fragment
a sound set of derivation rules is developed, which is also complete under mild
restrictions for Event-B machines.
</p>
</div>
</dd>
<dt><a name=item208>[208]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16840 title=Abstract>arXiv:2401.16840</a> [<a href=https://arxiv.org/pdf/2401.16840 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16840 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Large-scale Network Emulation on Analog Neuromorphic Hardware
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arnold%2C+E">Elias Arnold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spilger%2C+P">Philipp Spilger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Straub%2C+J+V">Jan V. Straub</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+E">Eric Müller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dold%2C+D">Dominik Dold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meoni%2C+G">Gabriele Meoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schemmel%2C+J">Johannes Schemmel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>We present a novel software feature for the BrainScaleS-2 accelerated
neuromorphic platform that facilitates the emulation of partitioned large-scale
spiking neural networks. This approach is well suited for many deep spiking
neural networks, where the constraint of the largest recurrent subnetwork
fitting on the substrate or the limited fan-in of neurons is often not a
limitation in practice. We demonstrate the training of two deep spiking neural
network models, using the MNIST and EuroSAT datasets, that exceed the physical
size constraints of a single-chip BrainScaleS-2 system. The ability to emulate
and train networks larger than the substrate provides a pathway for accurate
performance evaluation in planned or scaled systems, ultimately advancing the
development and understanding of large-scale models and neuromorphic computing
architectures.
</p>
</div>
</dd>
<dt><a name=item209>[209]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16841 title=Abstract>arXiv:2401.16841</a> [<a href=https://arxiv.org/pdf/2401.16841 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16841 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> jaxsnn: Event-driven Gradient Estimation for Analog Neuromorphic Hardware
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+E">Eric Müller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Althaus%2C+M">Moritz Althaus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arnold%2C+E">Elias Arnold</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spilger%2C+P">Philipp Spilger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pehle%2C+C">Christian Pehle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schemmel%2C+J">Johannes Schemmel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>Traditional neuromorphic hardware architectures rely on event-driven
computation, where the asynchronous transmission of events, such as spikes,
triggers local computations within synapses and neurons. While machine learning
frameworks are commonly used for gradient-based training, their emphasis on
dense data structures poses challenges for processing asynchronous data such as
spike trains. This problem is particularly pronounced for typical tensor data
structures. In this context, we present a novel library (jaxsnn) built on top
of JAX, that departs from conventional machine learning frameworks by providing
flexibility in the data structures used and the handling of time, while
maintaining Autograd functionality and composability. Our library facilitates
the simulation of spiking neural networks and gradient estimation, with a focus
on compatibility with time-continuous neuromorphic backends, such as the
BrainScaleS-2 system, during the forward pass. This approach opens avenues for
more efficient and flexible training of spiking neural networks, bridging the
gap between traditional neuromorphic architectures and contemporary machine
learning frameworks.
</p>
</div>
</dd>
<dt><a name=item210>[210]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16843 title=Abstract>arXiv:2401.16843</a> [<a href=https://arxiv.org/pdf/2401.16843 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16843 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating ML-Based Anomaly Detection Across Datasets of Varied Integrity: A Case Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pekar%2C+A">Adrian Pekar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jozsa%2C+R">Richard Jozsa</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>Cybersecurity remains a critical challenge in the digital age, with network
traffic flow anomaly detection being a key pivotal instrument in the fight
against cyber threats. In this study, we address the prevalent issue of data
integrity in network traffic datasets, which are instrumental in developing
machine learning (ML) models for anomaly detection. We introduce two refined
versions of the CICIDS-2017 dataset, NFS-2023-nTE and NFS-2023-TE, processed
using NFStream to ensure methodologically sound flow expiration and labeling.
Our research contrasts the performance of the Random Forest (RF) algorithm
across the original CICIDS-2017, its refined counterparts WTMC-2021 and
CRiSIS-2022, and our NFStream-generated datasets, in both binary and
multi-class classification contexts. We observe that the RF model exhibits
exceptional robustness, achieving consistent high-performance metrics
irrespective of the underlying dataset quality, which prompts a critical
discussion on the actual impact of data integrity on ML efficacy. Our study
underscores the importance of continual refinement and methodological rigor in
dataset generation for network security research. As the landscape of network
threats evolves, so must the tools and techniques used to detect and analyze
them.
</p>
</div>
</dd>
<dt><a name=item211>[211]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16844 title=Abstract>arXiv:2401.16844</a> [<a href=https://arxiv.org/pdf/2401.16844 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16844 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Congestion Pricing for Efficiency and Equity: Theory and Applications to the San Francisco Bay Area
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maheshwari%2C+C">Chinmay Maheshwari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulkarni%2C+K">Kshitij Kulkarni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pai%2C+D">Druv Pai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiarui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+M">Manxi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sastry%2C+S">Shankar Sastry</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>; Computers and Society (cs.CY); Multiagent Systems (cs.MA); Econometrics (econ.EM); Systems and Control (eess.SY)
</div>
<p class=mathjax>Congestion pricing, while adopted by many cities to alleviate traffic
congestion, raises concerns about widening socioeconomic disparities due to its
disproportionate impact on low-income travelers. In this study, we address this
concern by proposing a new class of congestion pricing schemes that not only
minimize congestion levels but also incorporate an equity objective to reduce
cost disparities among travelers with different willingness-to-pay. Our
analysis builds on a congestion game model with heterogeneous traveler
populations. We present four pricing schemes that account for practical
considerations, such as the ability to charge differentiated tolls to various
traveler populations and the option to toll all or only a subset of edges in
the network. We evaluate our pricing schemes in the calibrated freeway network
of the San Francisco Bay Area. We demonstrate that the proposed congestion
pricing schemes improve both efficiency (in terms of reduced average travel
time) and equity (the disparities of travel costs experienced by different
populations) compared to the current pricing scheme. Moreover, our pricing
schemes also generate a total revenue comparable to the current pricing scheme.
Our results further show that pricing schemes charging differentiated prices to
traveler populations with varying willingness-to-pay lead to a more equitable
distribution of travel costs compared to those that charge a homogeneous price
to all.
</p>
</div>
</dd>
<dt><a name=item212>[212]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16845 title=Abstract>arXiv:2401.16845</a> [<a href=https://arxiv.org/pdf/2401.16845 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16845 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reading yesterday's news. Layout recognition by segmentation of historical newspaper pages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schultze%2C+C">Christian Schultze</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kerkfeld%2C+N">Niklas Kerkfeld</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuebart%2C+K">Kara Kuebart</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weber%2C+P">Princilia Weber</a> (2), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolter%2C+M">Moritz Wolter</a> (1), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Selgert%2C+F">Felix Selgert</a> (2) ((1) High-Performance Computing and Analytics (HPCA)-Lab, Universität Bonn, (2) Institut für Geschichtswissenschaft Universität Bonn)
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Dataset available at: <a href=https://gitlab.uni-bonn.de/digital-history/newspaper-dataset>this https URL</a> . Baseline code: <a href=https://github.com/NewspaperSegmentation/NewspaperImageSegmentation/tree/master>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
<p class=mathjax>Newspapers are important sources for historians interested in past societies'
cultural values, social structures, and their changes. Since the 19th century,
newspapers have been widely available and spread regionally. Today, historical
newspapers are digitized but unavailable in a separate metadata-enhanced form.
Machine-readable metadata, however, is a prerequisite for a mass statistical
analysis of this source. This paper focuses on parsing the complex layout of
historic newspaper pages, which today's machines do not understand well. We
argue for using neural networks, which require detailed annotated data in large
numbers. Our Bonn newspaper dataset consists of 486 pages of the
\textit{K\"olnische Zeitung} from the years 1866 and 1924. We propose solving
the newspaper-understanding problem by training a U-Net on our new dataset,
which delivers satisfactory performance.
</p>
</div>
</dd>
<dt><a name=item213>[213]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16852 title=Abstract>arXiv:2401.16852</a> [<a href=https://arxiv.org/pdf/2401.16852 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16852 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Checkmating One, by Using Many: Combining Mixture of Experts with MCTS to Improve in Chess
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Helfenstein%2C+F">Felix Helfenstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bl%C3%BCml%2C+J">Jannis Blüml</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Czech%2C+J">Johannes Czech</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code available under <a href=https://github.com/HelpstoneX/CrazyAra>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This paper presents a new approach that integrates deep learning with
computational chess, using both the Mixture of Experts (MoE) method and
Monte-Carlo Tree Search (MCTS). Our methodology employs a suite of specialized
models, each designed to respond to specific changes in the game's input data.
This results in a framework with sparsely activated models, which provides
significant computational benefits. Our framework combines the MoE method with
MCTS, in order to align it with the strategic phases of chess, thus departing
from the conventional ``one-for-all'' model. Instead, we utilize distinct game
phase definitions to effectively distribute computational tasks across multiple
expert neural networks. Our empirical research shows a substantial improvement
in playing strength, surpassing the traditional single-model framework. This
validates the efficacy of our integrated approach and highlights the potential
of incorporating expert knowledge and strategic principles into neural network
design. The fusion of MoE and MCTS offers a promising avenue for advancing
machine learning architectures.
</p>
</div>
</dd>
<dt><a name=item214>[214]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16853 title=Abstract>arXiv:2401.16853</a> [<a href=https://arxiv.org/pdf/2401.16853 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16853 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transmission of Spatio-Temporal Correlated Sources Over Fading Multiple Access Channels With DQLC Mappings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fresnedo%2C+O">O.Fresnedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%C3%A1rez-Casal%2C+P">P. Suárez-Casal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castedo%2C+L">L.Castedo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Communications, vol. 67, n.o 8, pp.
 5604-5617, Aug 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>The design of zero-delay Joint Source-Channel Coding (JSCC) schemes for the
transmission of correlated information over fading Multiple Access Channels
(MACs) is an interesting problem for many communication scenarios like Wireless
Sensor Networks (WSNs). Among the different JSCC schemes so far proposed for
this scenario, Distributed Quantizer Linear Coding (DQLC) represents an
appealing solution since it is able to outperform uncoded transmissions for any
correlation level at high Signal-to-Noise Ratios (SNRs) with a low
computational cost. In this paper, we extend the design of DQLC-based schemes
for fading MACs considering sphere decoding to make the optimal Minimum Mean
Squared Error (MMSE) estimation computationally affordable for an arbitrary
number of transmit users. The use of sphere decoding also allows to formulate a
practical algorithm for the optimization of DQLC-based systems. Finally,
non-linear Kalman Filtering for the DQLC is considered to jointly exploit the
temporal and spatial correlation of the source symbols. The results of computer
experiments show that the proposed DQLC scheme with the Kalman Filter decoding
approach clearly outperforms uncoded transmissions for medium and high SNRs.
</p>
</div>
</dd>
<dt><a name=item215>[215]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16856 title=Abstract>arXiv:2401.16856</a> [<a href=https://arxiv.org/pdf/2401.16856 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16856 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16856 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BAR Nash Equilibrium and Application to Blockchain Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reynouard%2C+M">Maxime Reynouard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laraki%2C+R">Rida Laraki</a> (UM6P), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gorelkina%2C+O">Olga Gorelkina</a> (UM6P)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>This paper presents a novel solution concept, called BAR Nash Equilibrium
(BARNE) and apply it to analyse the Verifier's dilemma, a fundamental problem
in blockchain. Our solution concept adapts the Nash equilibrium (NE) to
accommodate interactions among Byzantine, altruistic and rational agents, which
became known as the BAR setting in the literature. We prove the existence of
BARNE in a large class of games and introduce two natural refinements, global
and local stability. Using this equilibrium and its refinement, we analyse the
free-rider problem in the context of byzantine consensus. We demonstrate that
by incorporating fines and forced errors into a standard quorum-based
blockchain protocol, we can effectively reestablish honest behavior as a
globally stable BARNE.
</p>
</div>
</dd>
<dt><a name=item216>[216]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16858 title=Abstract>arXiv:2401.16858</a> [<a href=https://arxiv.org/pdf/2401.16858 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16858 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low-Rate, Low-Distortion Compression with Wasserstein Distortion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Y">Yang Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wagner%2C+A+B">Aaron B. Wagner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2310.03629>arXiv:2310.03629</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Wasserstein distortion is a one-parameter family of distortion measures that
was recently proposed to unify fidelity and realism constraints. After
establishing continuity results for Wasserstein in the extreme cases of pure
fidelity and pure realism, we prove the first coding theorems for compression
under Wasserstein distortion focusing on the regime in which both the rate and
the distortion are small.
</p>
</div>
</dd>
<dt><a name=item217>[217]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16861 title=Abstract>arXiv:2401.16861</a> [<a href=https://arxiv.org/pdf/2401.16861 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16861 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Repositioning the Subject within Image
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yikai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+C">Chenjie Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Q">Qiaole Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yifan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://yikai-wang.github.io/seele/>this https URL</a> Dataset: <a href=https://github.com/Yikai-Wang/ReS.>this https URL</a> Arxiv version uses small size images for fast preview. Full size PDF is available at project page
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Current image manipulation primarily centers on static manipulation, such as
replacing specific regions within an image or altering its overall style. In
this paper, we introduce an innovative dynamic manipulation task, subject
repositioning. This task involves relocating a user-specified subject to a
desired position while preserving the image's fidelity. Our research reveals
that the fundamental sub-tasks of subject repositioning, which include filling
the void left by the repositioned subject, reconstructing obscured portions of
the subject and blending the subject to be consistent with surrounding areas,
can be effectively reformulated as a unified, prompt-guided inpainting task.
Consequently, we can employ a single diffusion generative model to address
these sub-tasks using various task prompts learned through our proposed task
inversion technique. Additionally, we integrate pre-processing and
post-processing techniques to further enhance the quality of subject
repositioning. These elements together form our SEgment-gEnerate-and-bLEnd
(SEELE) framework. To assess SEELE's effectiveness in subject repositioning, we
assemble a real-world subject repositioning dataset called ReS. Our results on
ReS demonstrate the quality of repositioned image generation.
</p>
</div>
</dd>
<dt><a name=item218>[218]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16862 title=Abstract>arXiv:2401.16862</a> [<a href=https://arxiv.org/pdf/2401.16862 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16862 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+M">Ming Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chengcai Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ACML 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recently, low-resource dialogue state tracking (DST) has received increasing
attention. First obtaining state values then based on values to generate slot
types has made great progress in this task. However, obtaining state values is
still an under-studied problem. Existing extraction-based approaches cannot
capture values that require the understanding of context and are not
generalizable either. To address these issues, we propose a novel State VAlue
Generation based framework (SVAG), decomposing DST into state value generation
and domain slot generation. Specifically, we propose to generate state values
and use self-training to further improve state value generation. Moreover, we
design an estimator aiming at detecting incomplete generation and incorrect
generation for pseudo-labeled data selection during self-training. Experimental
results on the MultiWOZ 2.1 dataset show that our method which has only less
than 1 billion parameters achieves state-of-the-art performance under the data
ratio settings of 5%, 10%, and 25% when limited to models under 100 billion
parameters. Compared to models with more than 100 billion parameters, SVAG
still reaches competitive results.
</p>
</div>
</dd>
<dt><a name=item219>[219]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16863 title=Abstract>arXiv:2401.16863</a> [<a href=https://arxiv.org/pdf/2401.16863 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16863 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enabling the Digital Democratic Revival: A Research Program for Digital Democracy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossi%2C+D">Davide Grossi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hahn%2C+U">Ulrike Hahn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%A4s%2C+M">Michael Mäs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nitsche%2C+A">Andreas Nitsche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behrens%2C+J">Jan Behrens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boehmer%2C+N">Niclas Boehmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brill%2C+M">Markus Brill</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Endriss%2C+U">Ulle Endriss</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grandi%2C+U">Umberto Grandi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haret%2C+A">Adrian Haret</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heitzig%2C+J">Jobst Heitzig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Janssens%2C+N">Nicolien Janssens</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jonker%2C+C+M">Catholijn M. Jonker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keijzer%2C+M+A">Marijn A. Keijzer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kistner%2C+A">Axel Kistner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lackner%2C+M">Martin Lackner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lieben%2C+A">Alexandra Lieben</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mikhaylovskaya%2C+A">Anna Mikhaylovskaya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murukannaiah%2C+P+K">Pradeep K. Murukannaiah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Proietti%2C+C">Carlo Proietti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Revel%2C+M">Manon Revel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roum%C3%A9as%2C+%C3%89">Élise Rouméas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shapiro%2C+E">Ehud Shapiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sreedurga%2C+G">Gogulapati Sreedurga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swierczek%2C+B">Björn Swierczek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talmon%2C+N">Nimrod Talmon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Turrini%2C+P">Paolo Turrini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Terzopoulou%2C+Z">Zoi Terzopoulou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+De+Putte%2C+F">Frederik Van De Putte</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
<p class=mathjax>This white paper outlines a long-term scientific vision for the development
of digital-democracy technology. We contend that if digital democracy is to
meet the ambition of enabling a participatory renewal in our societies, then a
comprehensive multi-methods research effort is required that could, over the
years, support its development in a democratically principled, empirically and
computationally informed way. The paper is co-authored by an international and
interdisciplinary team of researchers and arose from the Lorentz Center
Workshop on ``Algorithmic Technology for Democracy'' (Leiden, October 2022).
</p>
</div>
</dd>
<dt><a name=item220>[220]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16865 title=Abstract>arXiv:2401.16865</a> [<a href=https://arxiv.org/pdf/2401.16865 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16865 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Depends-Kotlin: A Cross-Language Kotlin Dependency Extractor
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+Q">Qiong Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaotian Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+H">Huan Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Since Google introduced Kotlin as an official programming language for
developing Android apps in 2017, Kotlin has gained widespread adoption in
Android development. However, compared to Java, there is limited support for
Kotlin code dependency analysis, which is the foundation to software analysis.
To bridge this gap, we developed Depends-Kotlin to extract entities and their
dependencies in Kotlin source code. Not only does Depends-Kotlin support
extracting entities' dependencies in Kotlin code, but it can also extract
dependency relations between Kotlin and Java. The extraction of such
cross-language dependencies can help developers understand the migration
process from Java to Kotlin. Additionally, we used a Java project with
confirmed dependencies as a benchmark and converted this project to two
projects: Kotlin-only and a combination of Kotlin and Java. The dependencies in
these two projects were then extracted using our tool. The consistency observed
among dependency relations in all three projects confirms the accuracy of
Depends-Kotlin. Furthermore, the performance of Depends-Kotlin was assessed
using another three projects of varying sizes. The source code of
Depends-Kotlin and the dataset used in this demo paper have been uploaded to
https://github.com/XYZboom/depends-kotlin. We also provided a screencast
presenting Depends-Kotlin https://youtu.be/daZuXOwn1Ls.
</p>
</div>
</dd>
<dt><a name=item221>[221]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16866 title=Abstract>arXiv:2401.16866</a> [<a href=https://arxiv.org/pdf/2401.16866 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16866 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16866 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Centralized MSR Codes With Small Sub-packetization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yaqian Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>Centralized repair refers to repairing <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-112-Frame tabindex=0><nobr><span class=math id=MathJax-Span-640 style=width:2.954em;display:inline-block><span style=display:inline-block;position:relative;width:2.433em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.38em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-641><span class=mi id=MathJax-Span-642 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-643 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-644 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> node failures using <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-113-Frame tabindex=0><nobr><span class=math id=MathJax-Span-645 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-646><span class=mi id=MathJax-Span-647 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>
helper nodes in a centralized way, where the repair bandwidth is counted by the
total amount of data downloaded from the helper nodes. A centralized MSR code
is an MDS array code with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-114-Frame tabindex=0><nobr><span class=math id=MathJax-Span-648 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.2em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-649><span class=mo id=MathJax-Span-650 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-651 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-652 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-653 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-654 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-optimal repair for some <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-115-Frame tabindex=0><nobr><span class=math id=MathJax-Span-655 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-656><span class=mi id=MathJax-Span-657 style=font-family:MathJax_Math-italic>h</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-116-Frame tabindex=0><nobr><span class=math id=MathJax-Span-658 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-659><span class=mi id=MathJax-Span-660 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>. In this
paper, we present several classes of centralized MSR codes with small
sub-packetization. At first, we construct an alternative MSR code with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-117-Frame tabindex=0><nobr><span class=math id=MathJax-Span-661 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-662><span class=mo id=MathJax-Span-663 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-664 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-665 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-666 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-667 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-668 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-669 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-optimal repair for multiple repair degrees <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-118-Frame tabindex=0><nobr><span class=math id=MathJax-Span-670 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.81em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-671><span class=msubsup id=MathJax-Span-672><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-673 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-674 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> simultaneously.
Based on the code structure, we are able to construct a centralized MSR code
with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-119-Frame tabindex=0><nobr><span class=math id=MathJax-Span-675 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-676><span class=mo id=MathJax-Span-677 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-678><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-679 style=font-family:MathJax_Math-italic>h</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-680 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-681 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-682 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-683 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-684 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-685 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-optimal repair property for all possible <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-120-Frame tabindex=0><nobr><span class=math id=MathJax-Span-686 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.78em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-687><span class=mo id=MathJax-Span-688 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-689><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-690 style=font-family:MathJax_Math-italic>h</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-691 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-692 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-693 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-694 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-695 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-696 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-121-Frame tabindex=0><nobr><span class=math id=MathJax-Span-697 style=width:6.137em;display:inline-block><span style=display:inline-block;position:relative;width:5.095em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.98em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-698><span class=msubsup id=MathJax-Span-699><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-700 style=font-family:MathJax_Math-italic>h</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-701 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-702 style=font-family:MathJax_Main;padding-left:0.292em>∣</span><span class=mo id=MathJax-Span-703 style=font-family:MathJax_Main;padding-left:0.292em>(</span><span class=msubsup id=MathJax-Span-704><span style=display:inline-block;position:relative;width:0.813em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-705 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.524em><span class=mi id=MathJax-Span-706 style=font-size:70.7%;font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-707 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-708 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span><span class=mo id=MathJax-Span-709 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> simultaneously. The sub-packetization is no more than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-122-Frame tabindex=0><nobr><span class=math id=MathJax-Span-710 style=width:14.47em;display:inline-block><span style=display:inline-block;position:relative;width:12.04em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1012.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-711><span class=texatom id=MathJax-Span-712><span class=mrow id=MathJax-Span-713><span class=mi id=MathJax-Span-714 style=font-family:MathJax_Main>l</span><span class=mi id=MathJax-Span-715 style=font-family:MathJax_Main>c</span><span class=mi id=MathJax-Span-716 style=font-family:MathJax_Main>m</span></span></span><span class=mo id=MathJax-Span-717 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-718 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-719 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-720 style=font-family:MathJax_Main;padding-left:0.177em>2</span><span class=mo id=MathJax-Span-721 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-722 style=font-family:MathJax_Main;padding-left:0.177em>…</span><span class=mo id=MathJax-Span-723 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-724 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-725 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-726 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span><span class=mo id=MathJax-Span-727 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-728 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-729 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-730 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-731 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span><span class=msubsup id=MathJax-Span-732><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-733 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mi id=MathJax-Span-734 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, which is much smaller than a previous work given
by Ye and Barg (<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-123-Frame tabindex=0><nobr><span class=math id=MathJax-Span-735 style=width:11.635em;display:inline-block><span style=display:inline-block;position:relative;width:9.667em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1009.67em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-736><span class=mo id=MathJax-Span-737 style=font-family:MathJax_Main>(</span><span class=texatom id=MathJax-Span-738><span class=mrow id=MathJax-Span-739><span class=mi id=MathJax-Span-740 style=font-family:MathJax_Main>l</span><span class=mi id=MathJax-Span-741 style=font-family:MathJax_Main>c</span><span class=mi id=MathJax-Span-742 style=font-family:MathJax_Main>m</span></span></span><span class=mo id=MathJax-Span-743 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-744 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-745 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-746 style=font-family:MathJax_Main;padding-left:0.177em>2</span><span class=mo id=MathJax-Span-747 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-748 style=font-family:MathJax_Main;padding-left:0.177em>…</span><span class=mo id=MathJax-Span-749 style=font-family:MathJax_Main;padding-left:0.177em>,</span><span class=mi id=MathJax-Span-750 style=font-family:MathJax_Math-italic;padding-left:0.177em>n</span><span class=mo id=MathJax-Span-751 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-752 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span><span class=mo id=MathJax-Span-753 style=font-family:MathJax_Main>)</span><span class=msubsup id=MathJax-Span-754><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-755 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mi id=MathJax-Span-756 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>). Moreover, for general
parameters <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-124-Frame tabindex=0><nobr><span class=math id=MathJax-Span-757 style=width:7.468em;display:inline-block><span style=display:inline-block;position:relative;width:6.195em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1006.2em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-758><span class=mn id=MathJax-Span-759 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-760 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-761 style=font-family:MathJax_Math-italic;padding-left:0.292em>h</span><span class=mo id=MathJax-Span-762 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-763 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span><span class=mo id=MathJax-Span-764 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-765 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-125-Frame tabindex=0><nobr><span class=math id=MathJax-Span-766 style=width:7.468em;display:inline-block><span style=display:inline-block;position:relative;width:6.195em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1006.2em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-767><span class=mi id=MathJax-Span-768 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-769 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-770 style=font-family:MathJax_Math-italic;padding-left:0.292em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-771 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-772 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span><span class=mo id=MathJax-Span-773 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-774 style=font-family:MathJax_Math-italic;padding-left:0.234em>h</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, we further give a
centralized MSR code enabling <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-126-Frame tabindex=0><nobr><span class=math id=MathJax-Span-775 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.2em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-776><span class=mo id=MathJax-Span-777 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-778 style=font-family:MathJax_Math-italic>h</span><span class=mo id=MathJax-Span-779 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-780 style=font-family:MathJax_Math-italic;padding-left:0.177em>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-781 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-optimal repair with sub-packetization
smaller than all previous works.
</p>
</div>
</dd>
<dt><a name=item222>[222]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16867 title=Abstract>arXiv:2401.16867</a> [<a href=https://arxiv.org/pdf/2401.16867 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16867 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andreadis%2C+G">Georgios Andreadis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mulder%2C+J+I">Joas I. Mulder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bouter%2C+A">Anton Bouter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosman%2C+P+A+N">Peter A. N. Bosman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alderliesten%2C+T">Tanja Alderliesten</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Pre-print for the SPIE Medical Imaging: Image Processing Conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>The transformation model is an essential component of any deformable image
registration approach. It provides a representation of physical deformations
between images, thereby defining the range and realism of registrations that
can be found. Two types of transformation models have emerged as popular
choices: B-spline models and mesh models. Although both models have been
investigated in detail, a direct comparison has not yet been made, since the
models are optimized using very different optimization methods in practice.
B-spline models are predominantly optimized using gradient-descent methods,
while mesh models are typically optimized using finite-element method solvers
or evolutionary algorithms. Multi-objective optimization methods, which aim to
find a diverse set of high-quality trade-off registrations, are increasingly
acknowledged to be important in deformable image registration. Since these
methods search for a diverse set of registrations, they can provide a more
complete picture of the capabilities of different transformation models, making
them suitable for a comparison of models. In this work, we conduct the first
direct comparison between B-spline and mesh transformation models, by
optimizing both models with the same state-of-the-art multi-objective
optimization method, the Multi-Objective Real-Valued Gene-pool Optimal Mixing
Evolutionary Algorithm (MO-RV-GOMEA). The combination with B-spline
transformation models, moreover, is novel. We experimentally compare both
models on two different registration problems that are both based on pelvic CT
scans of cervical cancer patients, featuring large deformations. Our results,
on three cervical cancer patients, indicate that the choice of transformation
model can have a profound impact on the diversity and quality of achieved
registration outcomes.
</p>
</div>
</dd>
<dt><a name=item223>[223]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16871 title=Abstract>arXiv:2401.16871</a> [<a href=https://arxiv.org/pdf/2401.16871 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16871 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16871 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Node Flux-Linkage Synchronizing Control of Power Systems with 100% Wind Power Generation Based on Capacitor Voltage Balancing Scheme
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yanshan Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Y">Yuexi Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pei%2C+X">Xiangyu Pei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ji%2C+F">Feng Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This paper proposes a node flux-linkage synchronizing control method (NFSCM)
for power systems with 100% wind power generation based on a capacitor voltage
balancing scheme (CVBS). Different from the conventional grid-forming
controllers, NFSCM is designed to regulate inverters as virtual flux-linkage
sources. Auto-synchronization of flux-linkage vectors is achieved through the
CVBS-based NFSCM. The mismatch among the angular frequencies of flux-linkage
vectors is eliminated by regulating the tracking errors of DC-link voltages,
which establishes a negative feedback between the output frequency and active
power of the inverter. NFSCM is adaptive to weak and strong grids. It avoids
the excitation inrush currents in the step-up transformer of wind power
generators. It also eliminates the DC components of the three-phase currents,
and avoids low-frequency oscillations in active power. In order to limit the
short-circuit current of inverters, a logic-based bang-bang funnel control
(LBFC) is designed to control the switches of inverter bridges when
over-current is detected. LBFC is able to restrict various fault currents
within an acceptable range within the shortest time. LBFC and NFSCM are
designed to operate in a switched manner according to a state-dependent
switching strategy. Time-domain simulations were conducted on a 100% wind power
generation test system, and the performance of NFSCM and LBFC were
investigated.
</p>
</div>
</dd>
<dt><a name=item224>[224]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16872 title=Abstract>arXiv:2401.16872</a> [<a href=https://arxiv.org/pdf/2401.16872 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16872 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Scalable RISC-V Vector Processor Enabling Efficient Multi-Precision DNN Inference
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chuanning Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+C">Chao Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongfeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jun Lin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>RISC-V processors encounter substantial challenges in deploying
multi-precision deep neural networks (DNNs) due to their restricted precision
support, constrained throughput, and suboptimal dataflow design. To tackle
these challenges, a scalable RISC-V vector (RVV) processor, namely SPEED, is
proposed to enable efficient multi-precision DNN inference by innovations from
customized instructions, hardware architecture, and dataflow mapping. Firstly,
dedicated customized RISC-V instructions are proposed based on RVV extensions,
providing SPEED with fine-grained control over processing precision ranging
from 4 to 16 bits. Secondly, a parameterized multi-precision systolic array
unit is incorporated within the scalable module to enhance parallel processing
capability and data reuse opportunities. Finally, a mixed multi-precision
dataflow strategy, compatible with different convolution kernels and data
precision, is proposed to effectively improve data utilization and
computational efficiency. We perform synthesis of SPEED in TSMC 28nm
technology. The experimental results demonstrate that SPEED achieves a peak
throughput of 287.41 GOPS and an energy efficiency of 1335.79 GOPS/W at 4-bit
precision condition, respectively. Moreover, when compared to the pioneer
open-source vector processor Ara, SPEED provides an area efficiency improvement
of 2.04<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-127-Frame tabindex=0><nobr><span class=math id=MathJax-Span-782 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-783><span class=mo id=MathJax-Span-784 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and 1.63<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-128-Frame tabindex=0><nobr><span class=math id=MathJax-Span-785 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-786><span class=mo id=MathJax-Span-787 style=font-family:MathJax_Main>×</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> under 16-bit and 8-bit precision conditions,
respectively, which shows SPEED's significant potential for efficient
multi-precision DNN inference.
</p>
</div>
</dd>
<dt><a name=item225>[225]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16876 title=Abstract>arXiv:2401.16876</a> [<a href=https://arxiv.org/pdf/2401.16876 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16876 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-shot Classification using Hyperdimensional Computing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ruffino%2C+S">Samuele Ruffino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karunaratne%2C+G">Geethan Karunaratne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hersche%2C+M">Michael Hersche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benini%2C+L">Luca Benini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sebastian%2C+A">Abu Sebastian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahimi%2C+A">Abbas Rahimi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This is the extended version of a paper accepted in the Design, Automation, and Test in Europe Conference (DATE), 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Classification based on Zero-shot Learning (ZSL) is the ability of a model to
classify inputs into novel classes on which the model has not previously seen
any training examples. Providing an auxiliary descriptor in the form of a set
of attributes describing the new classes involved in the ZSL-based
classification is one of the favored approaches to solving this challenging
task. In this work, inspired by Hyperdimensional Computing (HDC), we propose
the use of stationary binary codebooks of symbol-like distributed
representations inside an attribute encoder to compactly represent a
computationally simple end-to-end trainable model, which we name
Hyperdimensional Computing Zero-shot Classifier~(HDC-ZSC). It consists of a
trainable image encoder, an attribute encoder based on HDC, and a similarity
kernel. We show that HDC-ZSC can be used to first perform zero-shot attribute
extraction tasks and, can later be repurposed for Zero-shot Classification
tasks with minimal architectural changes and minimal model retraining. HDC-ZSC
achieves Pareto optimal results with a 63.8% top-1 classification accuracy on
the CUB-200 dataset by having only 26.6 million trainable parameters. Compared
to two other state-of-the-art non-generative approaches, HDC-ZSC achieves 4.3%
and 9.9% better accuracy, while they require more than 1.85x and 1.72x
parameters compared to HDC-ZSC, respectively.
</p>
</div>
</dd>
<dt><a name=item226>[226]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16878 title=Abstract>arXiv:2401.16878</a> [<a href=https://arxiv.org/pdf/2401.16878 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16878 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing EEG Signal-Based Emotion Recognition with Synthetic Data: Diffusion Modeel Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siddhad%2C+G">Gourav Siddhad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iwamura%2C+M">Masakazu Iwamura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+P+P">Partha Pratim Roy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 Pages, 3 Figures, 2 Tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Emotions are crucial in human life, influencing perceptions, relationships,
behaviour, and choices. Emotion recognition using Electroencephalography (EEG)
in the Brain-Computer Interface (BCI) domain presents significant challenges,
particularly the need for extensive datasets. This study aims to generate
synthetic EEG samples that are similar to real samples but are distinct by
augmenting noise to a conditional denoising diffusion probabilistic model, thus
addressing the prevalent issue of data scarcity in EEG research. The proposed
method is tested on the DEAP dataset, showcasing a 1.94% improvement in
classification performance when using synthetic data. This is higher compared
to the traditional GAN-based and DDPM-based approaches. The proposed
diffusion-based approach for EEG data generation appears promising in refining
the accuracy of emotion recognition systems and marks a notable contribution to
EEG-based emotion recognition. Our research further evaluates the effectiveness
of state-of-the-art classifiers on EEG data, employing both real and synthetic
data with varying noise levels.
</p>
</div>
</dd>
<dt><a name=item227>[227]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16885 title=Abstract>arXiv:2401.16885</a> [<a href=https://arxiv.org/pdf/2401.16885 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16885 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16885 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Local modification of subdiffusion by initial Fickian diffusion: Multiscale modeling, analysis and computation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zheng%2C+X">Xiangcheng Zheng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+Y">Yiqun Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Qiu%2C+W">Wenlin Qiu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We propose a local modification of the standard subdiffusion model by
introducing the initial Fickian diffusion, which results in a multiscale
diffusion model. The developed model resolves the incompatibility between the
nonlocal operators in subdiffusion and the local initial conditions and thus
eliminates the initial singularity of the solutions of the subdiffusion, while
retaining its heavy tail behavior away from the initial time. The
well-posedness of the model and high-order regularity estimates of its
solutions are analyzed by resolvent estimates, based on which the numerical
discretization and analysis are performed. Numerical experiments are carried
out to substantiate the theoretical findings.
</p>
</div>
</dd>
<dt><a name=item228>[228]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16886 title=Abstract>arXiv:2401.16886</a> [<a href=https://arxiv.org/pdf/2401.16886 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16886 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16886 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CAFCT: Contextual and Attentional Feature Fusions of Convolutional Neural Networks and Transformer for Liver Tumor Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+M">Ming Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ting%2C+C">Chee-Ming Ting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ting%2C+F+F">Fung Fung Ting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phan%2C+R">Raphaël Phan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP); Applications (stat.AP)
</div>
<p class=mathjax>Medical image semantic segmentation techniques can help identify tumors
automatically from computed tomography (CT) scans. In this paper, we propose a
Contextual and Attentional feature Fusions enhanced Convolutional Neural
Network (CNN) and Transformer hybrid network (CAFCT) model for liver tumor
segmentation. In the proposed model, three other modules are introduced in the
network architecture: Attentional Feature Fusion (AFF), Atrous Spatial Pyramid
Pooling (ASPP) of DeepLabv3, and Attention Gates (AGs) to improve contextual
information related to tumor boundaries for accurate segmentation. Experimental
results show that the proposed CAFCT achieves a mean Intersection over Union
(IoU) of 90.38% and Dice score of 86.78%, respectively, on the Liver Tumor
Segmentation Benchmark (LiTS) dataset, outperforming pure CNN or Transformer
methods, e.g., Attention U-Net, and PVTFormer.
</p>
</div>
</dd>
<dt><a name=item229>[229]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16888 title=Abstract>arXiv:2401.16888</a> [<a href=https://arxiv.org/pdf/2401.16888 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16888 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16888 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Thins Ordering on Relations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voermans%2C+E">Ed Voermans</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Desharnais%2C+J">Jules Desharnais</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Backhouse%2C+R">Roland Backhouse</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>Earlier papers \cite{VB2022,VB2023a} introduced the notions of a core and an
index of a relation (an index being a special case of a core). A limited form
of the axiom of choice was postulated -- specifically that all partial
equivalence relations (pers) have an index -- and the consequences of adding
the axiom to axiom systems for point-free reasoning were explored. In this
paper, we define a partial ordering on relations, which we call the
\textsf{thins} ordering. We show that our axiom of choice is equivalent to the
property that core relations are the minimal elements of the \textsf{thins}
ordering. We also postulate a novel axiom that guarantees that, when
\textsf{thins} is restricted to non-empty pers, equivalence relations are
maximal. This and other properties of \textsf{thins} provide further evidence
that our axiom of choice is a desirable means of strengthening point-free
reasoning on relations.
<br>Although our novel axiom is valid for concrete relations and is a sufficient
condition for characterising maximality, we show that it is not a necessary
condition in the abstract point-free algebra. This leaves open the problem of
deriving a necessary and sufficient condition.
</p>
</div>
</dd>
<dt><a name=item230>[230]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16889 title=Abstract>arXiv:2401.16889</a> [<a href=https://arxiv.org/pdf/2401.16889 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16889 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhongyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X+B">Xue Bin Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Levine%2C+S">Sergey Levine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berseth%2C+G">Glen Berseth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sreenath%2C+K">Koushil Sreenath</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper presents a comprehensive study on using deep reinforcement
learning (RL) to create dynamic locomotion controllers for bipedal robots.
Going beyond focusing on a single locomotion skill, we develop a general
control solution that can be used for a range of dynamic bipedal skills, from
periodic walking and running to aperiodic jumping and standing. Our RL-based
controller incorporates a novel dual-history architecture, utilizing both a
long-term and short-term input/output (I/O) history of the robot. This control
architecture, when trained through the proposed end-to-end RL approach,
consistently outperforms other methods across a diverse range of skills in both
simulation and the real world.The study also delves into the adaptivity and
robustness introduced by the proposed RL system in developing locomotion
controllers. We demonstrate that the proposed architecture can adapt to both
time-invariant dynamics shifts and time-variant changes, such as contact
events, by effectively using the robot's I/O history. Additionally, we identify
task randomization as another key source of robustness, fostering better task
generalization and compliance to disturbances. The resulting control policies
can be successfully deployed on Cassie, a torque-controlled human-sized bipedal
robot. This work pushes the limits of agility for bipedal robots through
extensive real-world experiments. We demonstrate a diverse range of locomotion
skills, including: robust standing, versatile walking, fast running with a
demonstration of a 400-meter dash, and a diverse set of jumping skills, such as
standing long jumps and high jumps.
</p>
</div>
</dd>
<dt><a name=item231>[231]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16893 title=Abstract>arXiv:2401.16893</a> [<a href=https://arxiv.org/pdf/2401.16893 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16893 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16893 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Computational Power of Opaque Robots
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feletti%2C+C">Caterina Feletti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mambretti%2C+L">Lucia Mambretti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mereghetti%2C+C">Carlo Mereghetti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palano%2C+B">Beatrice Palano</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>In the field of distributed computing by robot swarms, the research
comprehends manifold models where robots operate in the Euclidean plane through
a sequence of look-compute-move cycles. Models under study differ for (i) the
possibility of storing constant-size information, (ii) the possibility of
communicating constant-size information, and (iii) the synchronization mode. By
varying features (i,ii), we obtain the noted four base models: OBLOT (silent
and oblivious robots), FSTA (silent and finite-state robots), FCOM (oblivious
and finite-communication robots), and LUMI (finite-state and
finite-communication robots). Combining each base model with the three main
synchronization modes (fully synchronous, semi-synchronous, and asynchronous),
we obtain the well-known 12 models. Extensive research has studied their
computational power, proving the hierarchical relations between different
models. However, only transparent robots have been considered. In this work, we
study the taxonomy of the 12 models considering collision-intolerant opaque
robots. We present six witness problems that prove the majority of the
computational relations between the 12 models. In particular, the last witness
problem depicts a peculiar issue occurring in the case of obstructed visibility
and asynchrony.
</p>
</div>
</dd>
<dt><a name=item232>[232]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16895 title=Abstract>arXiv:2401.16895</a> [<a href=https://arxiv.org/pdf/2401.16895 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16895 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-Lingual Transfer from Related Languages: Treating Low-Resource Maltese as Multilingual Code-Switching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Micallef%2C+K">Kurt Micallef</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Habash%2C+N">Nizar Habash</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borg%2C+C">Claudia Borg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eryani%2C+F">Fadhl Eryani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bouamor%2C+H">Houda Bouamor</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 camera-ready version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Although multilingual language models exhibit impressive cross-lingual
transfer capabilities on unseen languages, the performance on downstream tasks
is impacted when there is a script disparity with the languages used in the
multilingual model's pre-training data. Using transliteration offers a
straightforward yet effective means to align the script of a resource-rich
language with a target language, thereby enhancing cross-lingual transfer
capabilities. However, for mixed languages, this approach is suboptimal, since
only a subset of the language benefits from the cross-lingual transfer while
the remainder is impeded. In this work, we focus on Maltese, a Semitic
language, with substantial influences from Arabic, Italian, and English, and
notably written in Latin script. We present a novel dataset annotated with
word-level etymology. We use this dataset to train a classifier that enables us
to make informed decisions regarding the appropriate processing of each token
in the Maltese language. We contrast indiscriminate transliteration or
translation to mixing processing pipelines that only transliterate words of
Arabic origin, thereby resulting in text with a mixture of scripts. We
fine-tune the processed data on four downstream tasks and show that conditional
transliteration based on word etymology yields the best results, surpassing
fine-tuning with raw Maltese or Maltese processed with non-selective pipelines.
</p>
</div>
</dd>
<dt><a name=item233>[233]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16896 title=Abstract>arXiv:2401.16896</a> [<a href=https://arxiv.org/pdf/2401.16896 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16896 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Parallelly Sliced Optimal Transport on Spheres and on the Rotation Group
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Quellmalz%2C+M">Michael Quellmalz</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Buecher%2C+L">Léo Buecher</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Steidl%2C+G">Gabriele Steidl</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 39 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>Sliced optimal transport, which is basically a Radon transform followed by
one-dimensional optimal transport, became popular in various applications due
to its efficient computation. In this paper, we deal with sliced optimal
transport on the sphere <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-129-Frame tabindex=0><nobr><span class=math id=MathJax-Span-788 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.113em,1001.91em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-789><span class=msubsup id=MathJax-Span-790><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.52em,4.17em,-999.997em);top:-3.99em;left:0em><span class=texatom id=MathJax-Span-791><span class=mrow id=MathJax-Span-792><span class=mi id=MathJax-Span-793 style=font-family:MathJax_AMS>S</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.582em><span class=texatom id=MathJax-Span-794><span class=mrow id=MathJax-Span-795><span class=mi id=MathJax-Span-796 style=font-size:70.7%;font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-797 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-798 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> and on the rotation group SO(3). We
propose a parallel slicing procedure of the sphere which requires again only
optimal transforms on the line. We analyze the properties of the corresponding
parallelly sliced optimal transport, which provides in particular a
rotationally invariant metric on the spherical probability measures. For SO(3),
we introduce a new two-dimensional Radon transform and develop its singular
value decomposition. Based on this, we propose a sliced optimal transport on
SO(3).
<br>As Wasserstein distances were extensively used in barycenter computations, we
derive algorithms to compute the barycenters with respect to our new sliced
Wasserstein distances and provide synthetic numerical examples on the 2-sphere
that demonstrate their behavior both the free and fixed support setting of
discrete spherical measures. In terms of computational speed, they outperform
the existing methods for semicircular slicing as well as the regularized
Wasserstein barycenters.
</p>
</div>
</dd>
<dt><a name=item234>[234]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16899 title=Abstract>arXiv:2401.16899</a> [<a href=https://arxiv.org/pdf/2401.16899 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16899 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Memory-centered and Affordance-based Framework for Mobile Manipulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pohl%2C+C">Christoph Pohl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reister%2C+F">Fabian Reister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peller-Konrad%2C+F">Fabian Peller-Konrad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Performing versatile mobile manipulation actions in human-centered
environments requires highly sophisticated software frameworks that are
flexible enough to handle special use cases, yet general enough to be
applicable across different robotic systems, tasks, and environments. This
paper presents a comprehensive memory-centered, affordance-based, and modular
uni- and multi-manual grasping and mobile manipulation framework, applicable to
complex robot systems with a high number of degrees of freedom such as humanoid
robots. By representing mobile manipulation actions through affordances, i.e.,
interaction possibilities of the robot with its environment, we unify the
autonomous manipulation process for known and unknown objects in arbitrary
environments. Our framework is integrated and embedded into the memory-centric
cognitive architecture of the ARMAR humanoid robot family. This way, robots can
not only interact with the physical world but also use common knowledge about
objects, and learn and adapt manipulation strategies. We demonstrate the
applicability of the framework in real-world experiments, including grasping
known and unknown objects, object placing, and semi-autonomous bimanual
grasping of objects on two different humanoid robot platforms.
</p>
</div>
</dd>
<dt><a name=item235>[235]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16901 title=Abstract>arXiv:2401.16901</a> [<a href=https://arxiv.org/pdf/2401.16901 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16901 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Contextual Bandit and Reinforcement Learning for IRS-Assisted MU-MIMO Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pereira-Ruis%C3%A1nchez%2C+D">Dariel Pereira-Ruisánchez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fresnedo%2C+%C3%93">Óscar Fresnedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez-Ad%C3%A1n%2C+D">Darian Pérez-Adán</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castedo%2C+L">Luis Castedo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Vehicular Technology, vol. 72, n.o 7, pp.
 9099-9114, Jul 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>The combination of multiple-input multiple-output (MIMO) systems and
intelligent reflecting surfaces (IRSs) is foreseen as a critical enabler of
beyond 5G (B5G) and 6G. In this work, two different approaches are considered
for the joint optimization of the IRS phase-shift matrix and MIMO precoders of
an IRS-assisted multi-stream (MS) multi-user MIMO (MU-MIMO) system. Both
approaches aim to maximize the system sum-rate for every channel realization.
The first proposed solution is a novel contextual bandit (CB) framework with
continuous state and action spaces called deep contextual bandit-oriented deep
deterministic policy gradient (DCB-DDPG). The second is an innovative deep
reinforcement learning (DRL) formulation where the states, actions, and rewards
are selected such that the Markov decision process (MDP) property of
reinforcement learning (RL) is appropriately met. Both proposals perform
remarkably better than state-of-the-art heuristic methods in scenarios with
high multi-user interference.
</p>
</div>
</dd>
<dt><a name=item236>[236]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16906 title=Abstract>arXiv:2401.16906</a> [<a href=https://arxiv.org/pdf/2401.16906 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16906 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16906 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum-Secure Hybrid Blockchain System for DID-based Verifiable Random Function with NTRU Linkable Ring Signature
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+B+G">Bong Gon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+D">Dennis Wong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y+S">Yoon Seok Yang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 5 figures, 2023 International Journal on Cryptography and Information Security (IJCIS). arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2311.11734>arXiv:2311.11734</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Volume 13, Number 4, December 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>In this study, we present a secure smart contract-based Verifiable Random
Function (VRF) model, addressing the shortcomings of existing systems. As
quantum computing emerges, conventional public key cryptography faces potential
vulnerabilities. To enhance our VRF's robustness, we employ post-quantum
Ring-LWE encryption for generating pseudo-random sequences. Given the
computational intensity of this approach and associated on-chain gas costs, we
propose a hybrid architecture of VRF system where on-chain and off-chain can
communicate in a scalable and secure way. To ensure the validity and integrity
of the off-chain computations (e.g., Ring-LWE encryption), we employ a
quantum-secure linkable ring signature scheme on NTRU lattice and also
delegated key generation (DKG) with a secure key encapsulation mechanism (KEM).
Our decentralized VRF employs multi-party computation (MPC) with
blockchain-based decentralized identifiers (DID), ensuring the collective
efforts of enhanced randomness and security. We show the security and privacy
advantages of our proposed VRF model with the approximated estimation of
overall temporal and spatial complexities. We also evaluate our VRF MPC model's
entropy and outline its Solidity smart contract integration. This research also
provides a method to produce and verify the VRF output's proof, optimal for
scenarios necessitating randomness and validation. Lastly, using NIST SP800-22
test suite for randomness, we demonstrate the commendable result with a 97.73%
overall pass rate on 11 standard tests and 0.5459 of average p-value for the
total 176 tests.
</p>
</div>
</dd>
<dt><a name=item237>[237]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16908 title=Abstract>arXiv:2401.16908</a> [<a href=https://arxiv.org/pdf/2401.16908 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16908 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Rank-Constrained Coordinate Ascent Approach to Hybrid Precoding for the Downlink of Wideband Massive (MIMO) Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gonz%C3%A1lez-Coma%2C+J+P">José P. González-Coma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fresnedo%2C+%C3%93">Óscar Fresnedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castedo%2C+L">Luis Castedo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Vehicular Technology, vol. 72, no. 12, pp.
 15953-15966, Dec. 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>An innovative approach to hybrid analog-digital precoding for the downlink of
wideband massive MIMO systems is developed. The proposed solution, termed
Rank-Constrained Coordinate Ascent (RCCA), starts seeking the full-digital
precoder that maximizes the achievable sum-rate over all the frequency
subcarriers while constraining the rank of the overall transmit covariance
matrix. The frequency-flat constraint on the analog part of the hybrid precoder
and the non-convex nature of the rank constraint are circumvented by
transforming the original problem into a more suitable one, where a convenient
structure for the transmit covariance matrix is imposed. Such structure makes
the resulting full-digital precoder particularly adequate for its posterior
analog-digital factorization. An additional problem formulation to determine an
appropriate power allocation policy according to the rank constraint is also
provided. The numerical results show that the proposed method outperforms
baseline solutions even for practical scenarios with high spatial diversity.
</p>
</div>
</dd>
<dt><a name=item238>[238]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16911 title=Abstract>arXiv:2401.16911</a> [<a href=https://arxiv.org/pdf/2401.16911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16911 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generalized Reed-Muller codes: A new construction of information sets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bernal%2C+J+J">José Joaquín Bernal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2401.10109>arXiv:2401.10109</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In [2] we show how to construct information sets for Reed-Muller codes only
in terms of their basic parameters. In this work we deal with the corresponding
problem for q-ary Generalized Reed-Muller codes of first and second order. We
see that for first-order codes the result for binary Reed-Muller codes is also
valid, while for second-order codes, with q &gt; 2, we have to manage more complex
defining sets and we show that we get different information sets. We also
present some examples and associated open problems.
</p>
</div>
</dd>
<dt><a name=item239>[239]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16914 title=Abstract>arXiv:2401.16914</a> [<a href=https://arxiv.org/pdf/2401.16914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grega%2C+I">Ivan Grega</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batatia%2C+I">Ilyes Batatia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cs%C3%A1nyi%2C+G">Gábor Csányi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karlapati%2C+S">Sri Karlapati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deshpande%2C+V+S">Vikram S. Deshpande</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Conference on Learning Representations 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)
</div>
<p class=mathjax>Lattices are architected metamaterials whose properties strongly depend on
their geometrical design. The analogy between lattices and graphs enables the
use of graph neural networks (GNNs) as a faster surrogate model compared to
traditional methods such as finite element modelling. In this work we present a
higher-order GNN model trained to predict the fourth-order stiffness tensor of
periodic strut-based lattices. The key features of the model are (i) SE(3)
equivariance, and (ii) consistency with the thermodynamic law of conservation
of energy. We compare the model to non-equivariant models based on a number of
error metrics and demonstrate the benefits of the encoded equivariance and
energy conservation in terms of predictive performance and reduced training
requirements.
</p>
</div>
</dd>
<dt><a name=item240>[240]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16915 title=Abstract>arXiv:2401.16915</a> [<a href=https://arxiv.org/pdf/2401.16915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16915 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interactive Byzantine-Resilient Gradient Coding for General Data Assignments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+S">Shreyas Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%C3%9Fny%2C+L">Luis Maßny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hofmeister%2C+C">Christoph Hofmeister</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yaakobi%2C+E">Eitan Yaakobi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bitar%2C+R">Rawad Bitar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)
</div>
<p class=mathjax>We tackle the problem of Byzantine errors in distributed gradient descent
within the Byzantine-resilient gradient coding framework. Our proposed solution
can recover the exact full gradient in the presence of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-130-Frame tabindex=0><nobr><span class=math id=MathJax-Span-799 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-800><span class=mi id=MathJax-Span-801 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> malicious workers
with a data replication factor of only <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-131-Frame tabindex=0><nobr><span class=math id=MathJax-Span-802 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.14em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-803><span class=mi id=MathJax-Span-804 style=font-family:MathJax_Math-italic>s</span><span class=mo id=MathJax-Span-805 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-806 style=font-family:MathJax_Main;padding-left:0.234em>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>. It generalizes previous solutions
to any data assignment scheme that has a regular replication over all data
samples. The scheme detects malicious workers through additional interactive
communication and a small number of local computations at the main node,
leveraging group-wise comparisons between workers with a provably optimal
grouping strategy. The scheme requires at most <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-132-Frame tabindex=0><nobr><span class=math id=MathJax-Span-807 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-808><span class=mi id=MathJax-Span-809 style=font-family:MathJax_Math-italic>s</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> interactive rounds that
incur a total communication cost logarithmic in the number of data samples.
</p>
</div>
</dd>
<dt><a name=item241>[241]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16918 title=Abstract>arXiv:2401.16918</a> [<a href=https://arxiv.org/pdf/2401.16918 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16918 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16918 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On egalitarian values for cooperative games with a priori unions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alonso-Meijide%2C+J+M">J.M. Alonso-Meijide</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+J">J. Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Jurado%2C+I">I. García-Jurado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">J.C. Gonçalves-Dosantos</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> TOP. 2020, 28(3), 672-88
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>In this paper we extend the equal division and the equal surplus division
values for transferable utility cooperative games to the more general setup of
transferable utility cooperative games with a priori unions. In the case of the
equal surplus division value we propose three possible extensions. We provide
axiomatic characterizations of the new values. Furthermore, we apply the
proposed modifications to a particular cost sharing problem and compare the
numerical results with those obtained with the original values.
</p>
</div>
</dd>
<dt><a name=item242>[242]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16919 title=Abstract>arXiv:2401.16919</a> [<a href=https://arxiv.org/pdf/2401.16919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bit-flipping Decoder Failure Rate Estimation for (v,w)-regular Codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Annechini%2C+A">Alessandro Annechini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barenghi%2C+A">Alessandro Barenghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pelosi%2C+G">Gerardo Pelosi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>Providing closed form estimates of the decoding failure rate of iterative
decoder for low- and moderate-density parity check codes has attracted
significant interest in the research community over the years. This interest
has raised recently due to the use of iterative decoders in post-quantum
cryptosystems, where the desired decoding failure rates are impossible to
estimate via Monte Carlo simulations. In this work, we propose a new technique
to provide accurate estimates of the DFR of a two-iterations (parallel) bit
flipping decoder, which is also employable for cryptographic purposes. In doing
so, we successfully tackle the estimation of the bit flipping probabilities at
the second decoder iteration, and provide a fitting estimate for the syndrome
weight distribution at the first iteration. We numerically validate our
results, providing comparisons of the modeled and simulated weight of the
syndrome, incorrectly-guessed error bit distribution at the end of the first
iteration, and two-iteration Decoding Failure Rates (DFR), both in the floor
and waterfall regime for simulatable codes. Finally, we apply our method to
estimate the DFR of LEDAcrypt parameters, showing improvements by factors
larger than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-133-Frame tabindex=0><nobr><span class=math id=MathJax-Span-810 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.28em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-811><span class=msubsup id=MathJax-Span-812><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-813 style=font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.524em><span class=texatom id=MathJax-Span-814><span class=mrow id=MathJax-Span-815><span class=mn id=MathJax-Span-816 style=font-size:70.7%;font-family:MathJax_Main>70</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> (for NIST category <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-134-Frame tabindex=0><nobr><span class=math id=MathJax-Span-817 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-818><span class=mn id=MathJax-Span-819 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>) with respect to the previous
estimation techniques. This allows for a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-135-Frame tabindex=0><nobr><span class=math id=MathJax-Span-820 style=width:2.549em;display:inline-block><span style=display:inline-block;position:relative;width:2.086em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.03em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-821><span class=mo id=MathJax-Span-822 style=font-family:MathJax_Main>≈</span><span class=mn id=MathJax-Span-823 style=font-family:MathJax_Main;padding-left:0.292em>20</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>% shortening in public key
and ciphertext sizes, at no security loss, making the smallest ciphertext for
NIST category <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-136-Frame tabindex=0><nobr><span class=math id=MathJax-Span-824 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-825><span class=mn id=MathJax-Span-826 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> only <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-137-Frame tabindex=0><nobr><span class=math id=MathJax-Span-827 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-828><span class=mn id=MathJax-Span-829 style=font-family:MathJax_Main>6</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>% larger than the one of BIKE. We note that the
analyzed two-iterations decoder is applicable in BIKE, where swapping it with
the current black-gray decoder (and adjusting the parameters) would provide
strong IND-CCA<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-138-Frame tabindex=0><nobr><span class=math id=MathJax-Span-830 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-831><span class=mn id=MathJax-Span-832 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> guarantees.
</p>
</div>
</dd>
<dt><a name=item243>[243]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16923 title=Abstract>arXiv:2401.16923</a> [<a href=https://arxiv.org/pdf/2401.16923 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16923 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fourier Prompt Tuning for Modality-Incomplete Scene Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruiping Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+K">Kunyu Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yufan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+K">Ke Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The source code will be publicly available at <a href=https://github.com/RuipingL/MISS>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Integrating information from multiple modalities enhances the robustness of
scene perception systems in autonomous vehicles, providing a more comprehensive
and reliable sensory framework. However, the modality incompleteness in
multi-modal segmentation remains under-explored. In this work, we establish a
task called Modality-Incomplete Scene Segmentation (MISS), which encompasses
both system-level modality absence and sensor-level modality errors. To avoid
the predominant modality reliance in multi-modal fusion, we introduce a
Missing-aware Modal Switch (MMS) strategy to proactively manage missing
modalities during training. Utilizing bit-level batch-wise sampling enhances
the model's performance in both complete and incomplete testing scenarios.
Furthermore, we introduce the Fourier Prompt Tuning (FPT) method to incorporate
representative spectral information into a limited number of learnable prompts
that maintain robustness against all MISS scenarios. Akin to fine-tuning
effects but with fewer tunable parameters (1.1%). Extensive experiments prove
the efficacy of our proposed approach, showcasing an improvement of 5.84% mIoU
over the prior state-of-the-art parameter-efficient methods in modality
missing. The source code will be publicly available at
https://github.com/RuipingL/MISS.
</p>
</div>
</dd>
<dt><a name=item244>[244]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16926 title=Abstract>arXiv:2401.16926</a> [<a href=https://arxiv.org/pdf/2401.16926 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16926 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16926 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coordination Coding with Causal Encoder for Vector-valued Witsenhausen Counterexample
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+M">Mengyuan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treust%2C+M+L">Maël Le Treust</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oechtering%2C+T+J">Tobias J. Oechtering</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to 2024 IEEE International Symposium on Information Theory (ISIT 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We investigate the Witsenhausen counterexample in a continuous vector-valued
context with a causal encoder and noncausal decoder. Our main result is the
optimal single-letter condition that characterizes the set of achievable
Witsenhausen power costs and estimation costs, leveraging a modified weak
typicality approach. In particular, we accommodate our power analysis to the
causal encoder constraint, and provide an improved distortion error analysis
for the challenging estimation of the interim state. Interestingly, the idea of
dual role of control is explicitly captured by the two auxiliary random
variables.
</p>
</div>
</dd>
<dt><a name=item245>[245]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16930 title=Abstract>arXiv:2401.16930</a> [<a href=https://arxiv.org/pdf/2401.16930 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16930 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16930 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Necessary players and values
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">J.C. Gonçalves-Dosantos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Jurado%2C+I">I. García-Jurado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+J">J. Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alonso-Meijide%2C+J+M">J.M. Alonso-Meijide</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Annals of Operations Research, 2022, 318(2), 935-961
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>In this paper we introduce the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-139-Frame tabindex=0><nobr><span class=math id=MathJax-Span-833 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-834><span class=mi id=MathJax-Span-835 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value, a new value for cooperative
games with transferable utility. We also provide an axiomatic characterization
of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-140-Frame tabindex=0><nobr><span class=math id=MathJax-Span-836 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-837><span class=mi id=MathJax-Span-838 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value based on a property concerning the so-called necessary
players. A necessary players of a game is one without which the characteristic
function is zero. We illustrate the performance of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-141-Frame tabindex=0><nobr><span class=math id=MathJax-Span-839 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-840><span class=mi id=MathJax-Span-841 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value in a
particular cost allocation problem that arises when the owners of the
apartments in a building plan to install an elevator and share its installation
cost; in the resulting example we compare the proposals of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-142-Frame tabindex=0><nobr><span class=math id=MathJax-Span-842 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-843><span class=mi id=MathJax-Span-844 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value,
the equal division value and the Shapley value in two different scenarios. In
addition, we propose an extension of the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-143-Frame tabindex=0><nobr><span class=math id=MathJax-Span-845 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-846><span class=mi id=MathJax-Span-847 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value for cooperative games
with transferable utility and with a coalition structure. Finally, we provide
axiomatic characterizations of the coalitional <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-144-Frame tabindex=0><nobr><span class=math id=MathJax-Span-848 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-849><span class=mi id=MathJax-Span-850 style=font-family:MathJax_Main>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> value and of the Owen
and Banzhaf-Owen values using alternative properties concerning necessary
players.
</p>
</div>
</dd>
<dt><a name=item246>[246]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16936 title=Abstract>arXiv:2401.16936</a> [<a href=https://arxiv.org/pdf/2401.16936 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16936 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-modal Representation Learning for Cross-modal Prediction of Continuous Weather Patterns from Discrete Low-Dimensional Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qayyum%2C+A+B+A">Alif Bin Abdul Qayyum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+X">Xihaier Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Urban%2C+N+M">Nathan M. Urban</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+X">Xiaoning Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon%2C+B">Byung-Jun Yoon</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>World is looking for clean and renewable energy sources that do not pollute
the environment, in an attempt to reduce greenhouse gas emissions that
contribute to global warming. Wind energy has significant potential to not only
reduce greenhouse emission, but also meet the ever increasing demand for
energy. To enable the effective utilization of wind energy, addressing the
following three challenges in wind data analysis is crucial. Firstly, improving
data resolution in various climate conditions to ensure an ample supply of
information for assessing potential energy resources. Secondly, implementing
dimensionality reduction techniques for data collected from sensors/simulations
to efficiently manage and store large datasets. Thirdly, extrapolating wind
data from one spatial specification to another, particularly in cases where
data acquisition may be impractical or costly. We propose a deep learning based
approach to achieve multi-modal continuous resolution wind data prediction from
discontinuous wind data, along with data dimensionality reduction.
</p>
</div>
</dd>
<dt><a name=item247>[247]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16937 title=Abstract>arXiv:2401.16937</a> [<a href=https://arxiv.org/pdf/2401.16937 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16937 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Segmentation and Characterization of Macerated Fibers and Vessels Using Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qamar%2C+S">Saqib Qamar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baba%2C+A+I">Abu Imran Baba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Verger%2C+S">Stéphane Verger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andersson%2C+M">Magnus Andersson</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Purpose: Wood comprises different cell types, such as fibers and vessels,
defining its properties. Studying their shape, size, and arrangement in
microscopic images is crucial for understanding wood samples. Typically, this
involves macerating (soaking) samples in a solution to separate cells, then
spreading them on slides for imaging with a microscope that covers a wide area,
capturing thousands of cells. However, these cells often cluster and overlap in
images, making the segmentation difficult and time-consuming using standard
image-processing methods. Results: In this work, we develop an automatic deep
learning segmentation approach that utilizes the one-stage YOLOv8 model for
fast and accurate fiber and vessel segmentation and characterization in
microscopy images. The model can analyze 32640 x 25920 pixels images and
demonstrate effective cell detection and segmentation, achieving a mAP_0.5-0.95
of 78 %. To assess the model's robustness, we examined fibers from a
genetically modified tree line known for longer fibers. The outcomes were
comparable to previous manual measurements. Additionally, we created a
user-friendly web application for image analysis and provided the code for use
on Google Colab. Conclusion: By leveraging YOLOv8's advances, this work
provides a deep learning solution to enable efficient quantification and
analysis of wood cells suitable for practical applications.
</p>
</div>
</dd>
<dt><a name=item248>[248]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16938 title=Abstract>arXiv:2401.16938</a> [<a href=https://arxiv.org/pdf/2401.16938 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16938 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On egalitarian values for cooperative games with level structures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alonso-Meijide%2C+J+M">J.M. Alonso-Meijide</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costa%2C+J">J. Costa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Jurado%2C+I">I. García-Jurado</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">J.C. Gonçalves-Dosantos</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Mathematical Methods of Operations Research, 2023, 98(1), 57-73
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
<p class=mathjax>In this paper we extend the equal division and the equal surplus division
values for transferable utility cooperative games to the more general setup of
transferable utility cooperative games with level structures. In the case of
the equal surplus division value we propose three possible extensions, one of
which has already been described in the literature. We provide axiomatic
characterizations of the values considered, apply them to a particular cost
sharing problem and compare them in the framework of such an application.
</p>
</div>
</dd>
<dt><a name=item249>[249]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16945 title=Abstract>arXiv:2401.16945</a> [<a href=https://arxiv.org/pdf/2401.16945 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16945 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Resource Allocation with Non-Stationary Customers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaoyue Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+H">Hanzhang Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chou%2C+M+C">Mabel C. Chou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
<p class=mathjax>We propose a novel algorithm for online resource allocation with
non-stationary customer arrivals and unknown click-through rates. We assume
multiple types of customers arrive in a nonstationary stochastic fashion, with
unknown arrival rates in each period, and that customers' click-through rates
are unknown and can only be learned online. By leveraging results from the
stochastic contextual bandit with knapsack and online matching with adversarial
arrivals, we develop an online scheme to allocate the resources to
nonstationary customers. We prove that under mild conditions, our scheme
achieves a ``best-of-both-world'' result: the scheme has a sublinear regret
when the customer arrivals are near-stationary, and enjoys an optimal
competitive ratio under general (non-stationary) customer arrival
distributions. Finally, we conduct extensive numerical experiments to show our
approach generates near-optimal revenues for all different customer scenarios.
</p>
</div>
</dd>
<dt><a name=item250>[250]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16947 title=Abstract>arXiv:2401.16947</a> [<a href=https://arxiv.org/pdf/2401.16947 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16947 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> WGAN-AFL: Seed Generation Augmented Fuzzer with Wasserstein-GAN
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Liqun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chunan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Y">Yongxin Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+C">Chaoren Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+H">Hongcheng Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+J">Jinxin Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
<p class=mathjax>The importance of addressing security vulnerabilities is indisputable, with
software becoming crucial in sectors such as national defense and finance.
Consequently, The security issues caused by software vulnerabilities cannot be
ignored. Fuzz testing is an automated software testing technology that can
detect vulnerabilities in the software. However, most previous fuzzers
encounter challenges that fuzzing performance is sensitive to initial input
seeds. In the absence of high-quality initial input seeds, fuzzers may expend
significant resources on program path exploration, leading to a substantial
decrease in the efficiency of vulnerability detection. To address this issue,
we propose WGAN-AFL. By collecting high-quality testcases, we train a
generative adversarial network (GAN) to learn their features, thereby obtaining
high-quality initial input seeds. To overcome drawbacks like mode collapse and
training instability inherent in GANs, we utilize the Wasserstein GAN (WGAN)
architecture for training, further enhancing the quality of the generated
seeds. Experimental results demonstrate that WGAN-AFL significantly outperforms
the original AFL in terms of code coverage, new paths, and vulnerability
discovery, demonstrating the effective enhancement of seed quality by WGAN-AFL.
</p>
</div>
</dd>
<dt><a name=item251>[251]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16948 title=Abstract>arXiv:2401.16948</a> [<a href=https://arxiv.org/pdf/2401.16948 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16948 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An ARGoS plug-in for the Crazyflie drone
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stolfi%2C+D+H">Daniel H. Stolfi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Danoy%2C+G">Grégoire Danoy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages, 9 figures, 2 tables, 1 algorithm. Source code: <a href=https://gitlab.uni.lu/adars/crazyflie>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>We present a new plug-in for the ARGoS swarm robotic simulator to implement
the Crazyflie drone, including its controllers, sensors, and some expansion
decks. We have based our development on the former Spiri drone, upgrading the
position controller, adding a new speed controller, LED ring, onboard camera,
and battery discharge model. We have compared this new plug-in in terms of
accuracy and efficiency with data obtained from real Crazyflie drones. All our
experiments showed that the proposed plug-in worked well, presenting high
levels of accuracy. We believe that this is an important contribution to robot
simulations which will extend ARGoS capabilities through the use of our
proposed, open-source plug-in.
</p>
</div>
</dd>
<dt><a name=item252>[252]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16952 title=Abstract>arXiv:2401.16952</a> [<a href=https://arxiv.org/pdf/2401.16952 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16952 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lattice-Based Analog Mappings for Low-Latency Wireless Sensor Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%C3%A1rez-Casal%2C+P">Pedro Suárez-Casal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fresnedo%2C+%C3%93">Óscar Fresnedo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=P%C3%A9rez-Ad%C3%A1n%2C+D">Darian Pérez-Adán</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castedo%2C+L">Luis Castedo</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Internet of Things Journal, vol. 10, n.o 19, pp. 17137-17154,
 Oct 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We consider the transmission of spatially correlated analog information in a
wireless sensor network (WSN) through fading single-input and multiple-output
(SIMO) multiple access channels (MACs) with low-latency requirements. A
lattice-based analog joint source-channel coding (JSCC) approach is considered
where vectors of consecutive source symbols are encoded at each sensor using an
n-dimensional lattice and then transmitted to a multiantenna central node. We
derive a minimum mean square error (MMSE) decoder that accounts for both the
multidimensional structure of the encoding lattices and the spatial
correlation. In addition, a sphere decoder is considered to simplify the
required searches over the multidimensional lattices. Different lattice-based
mappings are approached and the impact of their size and density on performance
and latency is analyzed. Results show that, while meeting low-latency
constraints, lattice-based analog JSCC provides performance gains and higher
reliability with respect to the state-of-the-art JSCC schemes.
</p>
</div>
</dd>
<dt><a name=item253>[253]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16956 title=Abstract>arXiv:2401.16956</a> [<a href=https://arxiv.org/pdf/2401.16956 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16956 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BCM-Broadcast: A Byzantine-Tolerant Causal Broadcast Algorithm for Distributed Mobile Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=NamvariTazehkand%2C+L">Leila NamvariTazehkand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pashazadeh%2C+S">Saied Pashazadeh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ebnenasir%2C+A">Ali Ebnenasir</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>This paper presents an algorithm, called BCM-Broadcast, for the
implementation of causal broadcast in distributed mobile systems in the
presence of Byzantine failures. The BCM-Broadcast algorithm simultaneously
focuses on three critical challenges in distributed systems: Byzantine
failures, Causality, and Mobility. We first present a hierarchical architecture
for BCM-Broadcast. Then, we define twelve properties for BCM-Broadcast,
including validity, integrity, termination, and causality. We then show that
BCM-Broadcast satisfies all these properties. We also prove the safety of
BCM-Broadcast; i.e., no healthy process delivers a message from any Byzantine
process, assuming that the number of Byzantine processes is less than a third
of the total number of mobile nodes. Subsequently, we show that the message
complexity of BCM-Broadcast is linear. Finally, using the Poisson process, we
analyze the probability of the violation of the safety condition under
different mobility scenarios.
</p>
</div>
</dd>
<dt><a name=item254>[254]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16958 title=Abstract>arXiv:2401.16958</a> [<a href=https://arxiv.org/pdf/2401.16958 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16958 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16958 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exact SINR Analysis of Matched-filter Precoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hui Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Slock%2C+D">Dirk Slock</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elia%2C+P">Petros Elia</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper answers a fundamental question about the exact distribution of the
signal-to-interference-plus-noise ratio (SINR) under matched-filter (MF)
precoding. Specifically, we derive the exact expressions for the cumulative
distribution function (CDF) and the probability density function (PDF) of SINR
under MF precoding over Rayleigh fading channels. Based on the exact analysis,
we then rigorously prove that the SINR converges to some specific distributions
separately in high SNR and in massive MIMO. To simplify the exact result in
general cases, we develop a good approximation by modelling the interference as
a Beta distribution. We then shift to the exact analysis of the transmit rate,
and answer the fundamental question: How does the exact rate converge to the
well-known asymptotic rate in massive MIMO? After that, we propose a novel
approximation for the ergodic rate, which performs better than various existing
approximations. Finally, we present some numerical results to demonstrate the
accuracy of the derived analytical models.
</p>
</div>
</dd>
<dt><a name=item255>[255]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16960 title=Abstract>arXiv:2401.16960</a> [<a href=https://arxiv.org/pdf/2401.16960 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16960 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Linyao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hongyang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fei-Yue Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Entity alignment, which is a prerequisite for creating a more comprehensive
Knowledge Graph (KG), involves pinpointing equivalent entities across disparate
KGs. Contemporary methods for entity alignment have predominantly utilized
knowledge embedding models to procure entity embeddings that encapsulate
various similarities-structural, relational, and attributive. These embeddings
are then integrated through attention-based information fusion mechanisms.
Despite this progress, effectively harnessing multifaceted information remains
challenging due to inherent heterogeneity. Moreover, while Large Language
Models (LLMs) have exhibited exceptional performance across diverse downstream
tasks by implicitly capturing entity semantics, this implicit knowledge has yet
to be exploited for entity alignment. In this study, we propose a Large
Language Model-enhanced Entity Alignment framework (LLMEA), integrating
structural knowledge from KGs with semantic knowledge from LLMs to enhance
entity alignment. Specifically, LLMEA identifies candidate alignments for a
given entity by considering both embedding similarities between entities across
KGs and edit distances to a virtual equivalent entity. It then engages an LLM
iteratively, posing multiple multi-choice questions to draw upon the LLM's
inference capability. The final prediction of the equivalent entity is derived
from the LLM's output. Experiments conducted on three public datasets reveal
that LLMEA surpasses leading baseline models. Additional ablation studies
underscore the efficacy of our proposed framework.
</p>
</div>
</dd>
<dt><a name=item256>[256]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16965 title=Abstract>arXiv:2401.16965</a> [<a href=https://arxiv.org/pdf/2401.16965 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16965 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16965 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Design of Downlink Hybrid NOMA Transmission
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>The aim of this paper is to develop hybrid non-orthogonal multiple access
(NOMA) assisted downlink transmission. First, for the single-input
single-output (SISO) scenario, i.e., each node is equipped with a single
antenna, a novel hybrid NOMA scheme is introduced, where NOMA is implemented as
an add-on of a legacy time division multiple access (TDMA) network. Because of
the simplicity of the SISO scenario, analytical results can be developed to
reveal important properties of downlink hybrid NOMA. For example, in the case
that the users' channel gains are ordered and the durations of their time slots
are the same, downlink hybrid NOMA is shown to always outperform TDMA, which is
different from the existing conclusion for uplink hybrid NOMA. Second, the
proposed downlink SISO hybrid NOMA scheme is extended to the multiple-input
single-output (MISO) scenario, i.e., the base station has multiple antennas.
For the MISO scenario, near-field communication is considered to illustrate how
NOMA can be used as an add-on in legacy networks based on space division
multiple access and TDMA. Simulation results verify the developed analytical
results and demonstrate the superior performance of downlink hybrid NOMA
compared to conventional orthogonal multiple access.
</p>
</div>
</dd>
<dt><a name=item257>[257]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16967 title=Abstract>arXiv:2401.16967</a> [<a href=https://arxiv.org/pdf/2401.16967 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16967 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A direct finite element method for elliptic interface problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hu%2C+J">Jun Hu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ma%2C+L">Limin Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>In this paper, a direct finite element method is proposed for solving
interface problems on simple unfitted meshes. The fact that the two interface
conditions form a <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-145-Frame tabindex=0><nobr><span class=math id=MathJax-Span-851 style=width:9.494em;display:inline-block><span style=display:inline-block;position:relative;width:7.873em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.929em,1007.76em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-852><span class=msubsup id=MathJax-Span-853><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-854 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.987em><span class=texatom id=MathJax-Span-855><span class=mrow id=MathJax-Span-856><span class=mfrac id=MathJax-Span-857><span style=display:inline-block;position:relative;width:0.35em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-4.337em;left:50%;margin-left:-0.113em><span class=mn id=MathJax-Span-858 style=font-size:50%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-3.643em;left:50%;margin-left:-0.113em><span class=mn id=MathJax-Span-859 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.35em,1.276em,-999.997em);top:-1.27em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.35em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-860 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-861 style=font-family:MathJax_Main>Γ</span><span class=mo id=MathJax-Span-862 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-863 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=msubsup id=MathJax-Span-864 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:2.202em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-865 style=font-family:MathJax_Math-italic>H<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:0.987em><span class=texatom id=MathJax-Span-866><span class=mrow id=MathJax-Span-867><span class=mo id=MathJax-Span-868 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mfrac id=MathJax-Span-869><span style=display:inline-block;position:relative;width:0.35em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-4.337em;left:50%;margin-left:-0.113em><span class=mn id=MathJax-Span-870 style=font-size:50%;font-family:MathJax_Main>1</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.475em,1000.23em,4.17em,-999.997em);top:-3.643em;left:50%;margin-left:-0.113em><span class=mn id=MathJax-Span-871 style=font-size:50%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.35em,1.276em,-999.997em);top:-1.27em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.35em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-872 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-873 style=font-family:MathJax_Main>Γ</span><span class=mo id=MathJax-Span-874 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.809em"></span></span></nobr></span> pair leads
to a simple and direct weak formulation with an integral term for the mutual
interaction over the interface, and the well-posedness of this weak formulation
is proved. Based on this formulation, a direct finite element method is
proposed to solve the problem on two adjacent subdomains separated by the
interface by conforming finite element and conforming mixed finite element,
respectively. The well-posedness and an optimal a priori analysis are proved
for this direct finite element method under some reasonable assumptions. A
simple lowest order direct finite element method by using the linear element
method and the lowest order Raviart-Thomas element method is proposed and
analyzed to admit the optimal a priori error estimate by verifying the
aforementioned assumptions. Numerical tests are also conducted to verify the
theoretical results and the effectiveness of the direct finite element method.
</p>
</div>
</dd>
<dt><a name=item258>[258]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16968 title=Abstract>arXiv:2401.16968</a> [<a href=https://arxiv.org/pdf/2401.16968 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16968 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distinguishing Fictional Voices: a Study of Authorship Verification Models for Quotation Attribution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michel%2C+G">Gaspard Michel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Epure%2C+E+V">Elena V. Epure</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hennequin%2C+R">Romain Hennequin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cerisara%2C+C">Christophe Cerisara</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at EACL 2024's workshop LaTeCH-CLfL
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recent approaches to automatically detect the speaker of an utterance of
direct speech often disregard general information about characters in favor of
local information found in the context, such as surrounding mentions of
entities. In this work, we explore stylistic representations of characters
built by encoding their quotes with off-the-shelf pretrained Authorship
Verification models in a large corpus of English novels (the Project Dialogism
Novel Corpus). Results suggest that the combination of stylistic and topical
information captured in some of these models accurately distinguish characters
among each other, but does not necessarily improve over semantic-only models
when attributing quotes. However, these results vary across novels and more
investigation of stylometric models particularly tailored for literary texts
and the study of characters should be conducted.
</p>
</div>
</dd>
<dt><a name=item259>[259]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16969 title=Abstract>arXiv:2401.16969</a> [<a href=https://arxiv.org/pdf/2401.16969 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16969 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16969 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Taxonomy of Mathematical Plagiarism
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Satpute%2C+A">Ankit Satpute</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greiner-Petter%2C+A">Andre Greiner-Petter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gie%C3%9Fing%2C+N">Noah Gießing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beckenbach%2C+I">Isabel Beckenbach</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schubotz%2C+M">Moritz Schubotz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Teschke%2C+O">Olaf Teschke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aizawa%2C+A">Akiko Aizawa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gipp%2C+B">Bela Gipp</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 46th European Conference on Information Retrieval (ECIR)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Plagiarism is a pressing concern, even more so with the availability of large
language models. Existing plagiarism detection systems reliably find copied and
moderately reworded text but fail for idea plagiarism, especially in
mathematical science, which heavily uses formal mathematical notation. We make
two contributions. First, we establish a taxonomy of mathematical content reuse
by annotating potentially plagiarised 122 scientific document pairs. Second, we
analyze the best-performing approaches to detect plagiarism and mathematical
content similarity on the newly established taxonomy. We found that the
best-performing methods for plagiarism and math content similarity achieve an
overall detection score (PlagDet) of 0.06 and 0.16, respectively. The
best-performing methods failed to detect most cases from all seven newly
established math similarity types. Outlined contributions will benefit research
in plagiarism detection systems, recommender systems, question-answering
systems, and search engines. We make our experiment's code and annotated
dataset available to the community:
https://github.com/gipplab/Taxonomy-of-Mathematical-Plagiarism
</p>
</div>
</dd>
<dt><a name=item260>[260]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16971 title=Abstract>arXiv:2401.16971</a> [<a href=https://arxiv.org/pdf/2401.16971 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16971 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Autonomy Loops for Monitoring, Operational Data Analytics, Feedback, and Response in HPC Operations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boito%2C+F">Francieli Boito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brandt%2C+J">Jim Brandt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardellini%2C+V">Valeria Cardellini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carns%2C+P">Philip Carns</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ciorba%2C+F+M">Florina M. Ciorba</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Egan%2C+H">Hilary Egan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eleliemy%2C+A">Ahmed Eleliemy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gentile%2C+A">Ann Gentile</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gruber%2C+T">Thomas Gruber</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hanson%2C+J">Jeff Hanson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haus%2C+U">Utz-Uwe Haus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huck%2C+K">Kevin Huck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ilsche%2C+T">Thomas Ilsche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jakobsche%2C+T">Thomas Jakobsche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jones%2C+T">Terry Jones</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karlsson%2C+S">Sven Karlsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mueen%2C+A">Abdullah Mueen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ott%2C+M">Michael Ott</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patki%2C+T">Tapasya Patki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+I">Ivy Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raghavan%2C+K">Krishnan Raghavan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simms%2C+S">Stephen Simms</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shoga%2C+K">Kathleen Shoga</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Showerman%2C+M">Michael Showerman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tiwari%2C+D">Devesh Tiwari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilde%2C+T">Torsten Wilde</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yamamoto%2C+K">Keiji Yamamoto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Many High Performance Computing (HPC) facilities have developed and deployed
frameworks in support of continuous monitoring and operational data analytics
(MODA) to help improve efficiency and throughput. Because of the complexity and
scale of systems and workflows and the need for low-latency response to address
dynamic circumstances, automated feedback and response have the potential to be
more effective than current human-in-the-loop approaches which are laborious
and error prone. Progress has been limited, however, by factors such as the
lack of infrastructure and feedback hooks, and successful deployment is often
site- and case-specific. In this position paper we report on the outcomes and
plans from a recent Dagstuhl Seminar, seeking to carve a path for community
progress in the development of autonomous feedback loops for MODA, based on the
established formalism of similar (MAPE-K) loops in autonomous computing and
self-adaptive systems. By defining and developing such loops for significant
cases experienced across HPC sites, we seek to extract commonalities and
develop conventions that will facilitate interoperability and
interchangeability with system hardware, software, and applications across
different sites, and will motivate vendors and others to provide telemetry
interfaces and feedback hooks to enable community development and pervasive
deployment of MODA autonomy loops.
</p>
</div>
</dd>
<dt><a name=item261>[261]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16972 title=Abstract>arXiv:2401.16972</a> [<a href=https://arxiv.org/pdf/2401.16972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep 3D World Models for Multi-Image Super-Resolution Beyond Optical Flow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aira%2C+L+S">Luca Savant Aira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valsesia%2C+D">Diego Valsesia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molini%2C+A+B">Andrea Bordone Molini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fracastoro%2C+G">Giulia Fracastoro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Magli%2C+E">Enrico Magli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mirabile%2C+A">Andrea Mirabile</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
<p class=mathjax>Multi-image super-resolution (MISR) allows to increase the spatial resolution
of a low-resolution (LR) acquisition by combining multiple images carrying
complementary information in the form of sub-pixel offsets in the scene
sampling, and can be significantly more effective than its single-image
counterpart. Its main difficulty lies in accurately registering and fusing the
multi-image information. Currently studied settings, such as burst photography,
typically involve assumptions of small geometric disparity between the LR
images and rely on optical flow for image registration. We study a MISR method
that can increase the resolution of sets of images acquired with arbitrary, and
potentially wildly different, camera positions and orientations, generalizing
the currently studied MISR settings. Our proposed model, called EpiMISR, moves
away from optical flow and explicitly uses the epipolar geometry of the
acquisition process, together with transformer-based processing of radiance
feature fields to substantially improve over state-of-the-art MISR methods in
presence of large disparities in the LR images.
</p>
</div>
</dd>
<dt><a name=item262>[262]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16974 title=Abstract>arXiv:2401.16974</a> [<a href=https://arxiv.org/pdf/2401.16974 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16974 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sauter%2C+A+W+M">Andreas W.M. Sauter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Botteghi%2C+N">Nicolò Botteghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acar%2C+E">Erman Acar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plaat%2C+A">Aske Plaat</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published In Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024), Auckland, New Zealand, May 6 - 10, 2024, IFAAMAS
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Causal discovery is the challenging task of inferring causal structure from
data. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive
observations alone are not enough to distinguish correlation from causation,
there has been a recent push to incorporate interventions into machine learning
research. Reinforcement learning provides a convenient framework for such an
active approach to learning. This paper presents CORE, a deep reinforcement
learning-based approach for causal discovery and intervention planning. CORE
learns to sequentially reconstruct causal graphs from data while learning to
perform informative interventions. Our results demonstrate that CORE
generalizes to unseen graphs and efficiently uncovers causal structures.
Furthermore, CORE scales to larger graphs with up to 10 variables and
outperforms existing approaches in structure estimation accuracy and sample
efficiency. All relevant code and supplementary material can be found at
https://github.com/sa-and/CORE
</p>
</div>
</dd>
<dt><a name=item263>[263]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16975 title=Abstract>arXiv:2401.16975</a> [<a href=https://arxiv.org/pdf/2401.16975 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16975 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16975 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Method for determining the acceleration of a parallel specialised computer system based on Amdahl's law
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Filipchenko%2C+A+S">Aleksandr S. Filipchenko</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)
</div>
<p class=mathjax>The modification of Amdahl's law for the case of increment of processor
elements in a computer system is considered. The coefficient <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-146-Frame tabindex=0><nobr><span class=math id=MathJax-Span-875 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-876><span class=mi id=MathJax-Span-877 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> linking
accelerations of parallel and parallel specialized computer systems is
determined. The limiting values of the coefficient are investigated and its
theoretical maximum is calculated. It is proved that <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-147-Frame tabindex=0><nobr><span class=math id=MathJax-Span-878 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-879><span class=mi id=MathJax-Span-880 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> &gt; 1 for any positive
increment of processor elements. The obtained formulas are combined into a
single method allowing to determine the maximum theoretical acceleration of a
parallel specialized computer system in comparison with the acceleration of a
minimal parallel computer system. The method is tested on Apriori, k-nearest
neighbors, CDF 9/7, fast Fourier transform and naive Bayesian classifier
algorithms.
</p>
</div>
</dd>
<dt><a name=item264>[264]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16977 title=Abstract>arXiv:2401.16977</a> [<a href=https://arxiv.org/pdf/2401.16977 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16977 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Performance Analysis of Generalized Product Codes with Irregular Degree Distribution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Miao%2C+S">Sisi Miao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rapp%2C+L">Lukas Rapp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=J%C3%A4kel%2C+H">Holger Jäkel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> submitted to IEEE
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>This paper investigates the theoretical analysis of intrinsic message passing
decoding for generalized product codes (GPCs) with irregular degree
distributions, a generalization of product codes that allows every code bit to
be protected by a minimum of two and potentially more component codes. We
derive a random hypergraph-based asymptotic performance analysis for GPCs,
extending previous work that considered the case where every bit is protected
by exactly two component codes. The analysis offers a new tool to guide the
code design of GPCs by providing insights into the influence of degree
distributions on the performance of GPCs.
</p>
</div>
</dd>
<dt><a name=item265>[265]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16979 title=Abstract>arXiv:2401.16979</a> [<a href=https://arxiv.org/pdf/2401.16979 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16979 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Re3val: Reinforced and Reranked Generative Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+E">EuiYul Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sangryul Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+H">Haeju Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Joonkee Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thorne%2C+J">James Thorne</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 4 figures, Findings of the Association for Computational Linguistics: EACL 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Generative retrieval models encode pointers to information in a corpus as an
index within the model's parameters. These models serve as part of a larger
pipeline, where retrieved information conditions generation for
knowledge-intensive NLP tasks. However, we identify two limitations: the
generative retrieval does not account for contextual information. Secondly, the
retrieval can't be tuned for the downstream readers as decoding the page title
is a non-differentiable operation. This paper introduces Re3val, trained with
generative reranking and reinforcement learning using limited data. Re3val
leverages context acquired via Dense Passage Retrieval to rerank the retrieved
page titles and utilizes REINFORCE to maximize rewards generated by constrained
decoding. Additionally, we generate questions from our pre-training dataset to
mitigate epistemic uncertainty and bridge the domain gap between the
pre-training and fine-tuning datasets. Subsequently, we extract and rerank
contexts from the KILT database using the rerank page titles. Upon grounding
the top five reranked contexts, Re3val demonstrates the Top 1 KILT scores
compared to all other generative retrieval models across five KILT datasets.
</p>
</div>
</dd>
<dt><a name=item266>[266]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16982 title=Abstract>arXiv:2401.16982</a> [<a href=https://arxiv.org/pdf/2401.16982 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16982 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ActDroid: An active learning framework for Android malware detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muzaffar%2C+A">Ali Muzaffar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassen%2C+H+R">Hani Ragab Hassen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zantout%2C+H">Hind Zantout</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lones%2C+M+A">Michael A Lones</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>The growing popularity of Android requires malware detection systems that can
keep up with the pace of new software being released. According to a recent
study, a new piece of malware appears online every 12 seconds. To address this,
we treat Android malware detection as a streaming data problem and explore the
use of active online learning as a means of mitigating the problem of labelling
applications in a timely and cost-effective manner. Our resulting framework
achieves accuracies of up to 96\%, requires as little of 24\% of the training
data to be labelled, and compensates for concept drift that occurs between the
release and labelling of an application. We also consider the broader
practicalities of online learning within Android malware detection, and
systematically explore the trade-offs between using different static, dynamic
and hybrid feature sets to classify malware.
</p>
</div>
</dd>
<dt><a name=item267>[267]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16991 title=Abstract>arXiv:2401.16991</a> [<a href=https://arxiv.org/pdf/2401.16991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Category-wise Fine-Tuning: Resisting Incorrect Pseudo-Labels in Multi-Label Image Classification with Partial Labels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chong%2C+C+F">Chak Fong Chong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+X">Xinyi Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jielong Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yapeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ke%2C+W">Wei Ke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lam%2C+C">Chan-Tong Lam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Im%2C+S">Sio-Kei Im</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Large-scale image datasets are often partially labeled, where only a few
categories' labels are known for each image. Assigning pseudo-labels to unknown
labels to gain additional training signals has become prevalent for training
deep classification models. However, some pseudo-labels are inevitably
incorrect, leading to a notable decline in the model classification
performance. In this paper, we propose a novel method called Category-wise
Fine-Tuning (CFT), aiming to reduce model inaccuracies caused by the wrong
pseudo-labels. In particular, CFT employs known labels without pseudo-labels to
fine-tune the logistic regressions of trained models individually to calibrate
each category's model predictions. Genetic Algorithm, seldom used for training
deep models, is also utilized in CFT to maximize the classification performance
directly. CFT is applied to well-trained models, unlike most existing methods
that train models from scratch. Hence, CFT is general and compatible with
models trained with different methods and schemes, as demonstrated through
extensive experiments. CFT requires only a few seconds for each category for
calibration with consumer-grade GPUs. We achieve state-of-the-art results on
three benchmarking datasets, including the CheXpert chest X-ray competition
dataset (ensemble mAUC 93.33%, single model 91.82%), partially labeled MS-COCO
(average mAP 83.69%), and Open Image V3 (mAP 85.31%), outperforming the
previous bests by 0.28%, 2.21%, 2.50%, and 0.91%, respectively. The single
model on CheXpert has been officially evaluated by the competition server,
endorsing the correctness of the result. The outstanding results and
generalizability indicate that CFT could be substantial and prevalent for
classification model development. Code is available at:
https://github.com/maxium0526/category-wise-fine-tuning.
</p>
</div>
</dd>
<dt><a name=item268>[268]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16993 title=Abstract>arXiv:2401.16993</a> [<a href=https://arxiv.org/pdf/2401.16993 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16993 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Randomized Key Encapsulation/Consolidation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khandani%2C+A+K">Amir K. Khandani</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>This article bridges the gap between two topics used in sharing an encryption
key: (i) Key Consolidation, i.e., extracting two identical strings of bits from
two information sources with similarities (common randomness). (ii)
Quantum-safe Key Encapsulation by incorporating randomness in Public/Private
Key pairs. In the context of Key Consolidation, the proposed scheme adds to the
complexity Eve faces in extracting useful data from leaked information. In this
context, it is applied to the method proposed in [1] for establishing common
randomness from round-trip travel times in a packet data network. The proposed
method allows adapting the secrecy level to the amount of similarity in common
randomness. It can even encapsulate a Quantum-safe encryption key in the
extreme case that no common randomness is available. In the latter case, it is
shown that the proposed scheme offers improvements with respect to the McEliece
cryptosystem which currently forms the foundation for Quantum safe key
encapsulation.
<br>[1] A. K. Khandani, "Looping for Encryption Key Generation Over the Internet:
A New Frontier in Physical Layer Security," 2023 Biennial Symposium on
Communications (BSC), Montreal, QC, Canada, 2023, pp. 59-64
</p>
</div>
</dd>
<dt><a name=item269>[269]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16998 title=Abstract>arXiv:2401.16998</a> [<a href=https://arxiv.org/pdf/2401.16998 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16998 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16998 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Sherali-Adams and Weisfeiler-Leman hierarchies in (Promise Valued) Constraint Satisfaction Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barto%2C+L">Libor Barto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Butti%2C+S">Silvia Butti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dalmau%2C+V">Víctor Dalmau</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A joint extended version of <a href=https://arxiv.org/abs/2107.02956>arXiv:2107.02956</a> and <a href=https://arxiv.org/abs/2205.04805>arXiv:2205.04805</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>; Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>In this paper we study the interactions between so-called fractional
relaxations of the integer programs (IPs) which encode homomorphism and
isomorphism of relational structures. We give a combinatorial characterization
of a certain natural linear programming (LP) relaxation of homomorphism in
terms of fractional isomorphism. As a result, we show that the families of
constraint satisfaction problems (CSPs) that are solvable by such linear
program are precisely those that are closed under an equivalence relation which
we call Weisfeiler-Leman invariance. We also generalize this result to the much
broader framework of Promise Valued Constraint Satisfaction Problems, which
brings together two well-studied extensions of the CSP framework. Finally, we
consider the hierarchies of increasingly tighter relaxations of the
homomorphism and isomorphism IPs obtained by applying the Sherali-Adams and
Weisfeiler-Leman methods respectively. We extend our combinatorial
characterization of the basic LP to higher levels of the Sherali-Adams
hierarchy, and we generalize a well-known logical characterization of the
Weisfeiler-Leman test from graphs to relational structures.
</p>
</div>
</dd>
<dt><a name=item270>[270]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17005 title=Abstract>arXiv:2401.17005</a> [<a href=https://arxiv.org/pdf/2401.17005 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17005 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+W">Wontak Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+H">Hyunjun Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+D">Donghyuk Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Joo-Young Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 15 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>
</div>
<p class=mathjax>Text generation is a compelling sub-field of natural language processing,
aiming to generate human-readable text from input words. In particular, the
decoder-only generative models, such as generative pre-trained transformer
(GPT), are widely used for text generation, with two major computational
stages: summarization and generation. Unlike the summarization stage, which can
process the input tokens in parallel, the generation stage is difficult to
accelerate due to its sequential generation of output tokens through iteration.
Moreover, each iteration requires reading a whole model with little data reuse
opportunity. Therefore, the workload of transformer-based text generation is
severely memory-bound, making the external memory bandwidth system bottleneck.
In this paper, we proposed a subarray-level processing-in-memory architecture
named SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration of
transformer-based text generation. The SAL-PIM architecture includes three
architectural features. First, the SAL-PIM architecture utilizes higher
internal bandwidth by integrating multiple subarray-level arithmetic logic
units with optimized data mapping schemes. Second, the SAL-PIM architecture
adopts LUT-based linear interpolation to perform complex non-linear functions
in PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIM
in text generation. Furthermore, to validate the SAL-PIM architecture, we built
cycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nm
CMOS technology. As a result, when the input size is from 32 to 128 and the
output size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedup
and an average of 1.83 times speedup for the text generation based on the GPT-2
medium model compared to the server-level GPU.
</p>
</div>
</dd>
<dt><a name=item271>[271]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17010 title=Abstract>arXiv:2401.17010</a> [<a href=https://arxiv.org/pdf/2401.17010 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17010 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17010 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Finetuning Large Language Models for Vulnerability Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shestov%2C+A">Alexey Shestov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheshkov%2C+A">Anton Cheshkov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Levichev%2C+R">Rodion Levichev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zadorozhny%2C+P">Pavel Zadorozhny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maslov%2C+E">Evgeny Maslov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vadim%2C+C">Chibirev Vadim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bulychev%2C+E">Egor Bulychev</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper presents the results of finetuning large language models (LLMs)
for the task of detecting vulnerabilities in source code. We leverage
WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and
adapt it for vulnerability detection through further finetuning. To accelerate
training, we modify WizardCoder's training procedure, also we investigate
optimal training regimes. For the imbalanced dataset with many more negative
examples than positive, we also explore different techniques to improve
classification performance. The finetuned WizardCoder model achieves
improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability
datasets over CodeBERT-like model, demonstrating the effectiveness of adapting
pretrained LLMs for vulnerability detection in source code. The key
contributions are finetuning the state-of-the-art code LLM, WizardCoder,
increasing its training speed without the performance harm, optimizing the
training procedure and regimes, handling class imbalance, and improving
performance on difficult vulnerability detection datasets. This demonstrates
the potential for transfer learning by finetuning large pretrained language
models for specialized source code analysis tasks.
</p>
</div>
</dd>
<dt><a name=item272>[272]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17011 title=Abstract>arXiv:2401.17011</a> [<a href=https://arxiv.org/pdf/2401.17011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17011 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Age of Actuated Information and Age of Actuation in a Data-Caching Energy Harvesting Actuator
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nikkhah%2C+A">Ali Nikkhah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ephremides%2C+A">Anthony Ephremides</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>In this paper, we introduce two metrics, namely, age of actuation (AoA) and
age of actuated information (AoAI), within a discrete-time system model that
integrates data caching and energy harvesting (EH). AoA evaluates the
timeliness of actions irrespective of the age of the information, while AoAI
considers the freshness of the utilized data packet. We use Markov Chain
analysis to model the system's evolution. Furthermore, we employ
three-dimensional Markov Chain analysis to characterize the stationary
distributions for AoA and AoAI and calculate their average values. Our findings
from the analysis, validated by simulations, show that while AoAI consistently
decreases with increased data and energy packet arrival rates, AoA presents a
more complex behavior, with potential increases under conditions of limited
data or energy resources. These metrics go towards the semantics of information
and goal-oriented communications since they consider the timeliness of
utilizing the information to perform an action.
</p>
</div>
</dd>
<dt><a name=item273>[273]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17012 title=Abstract>arXiv:2401.17012</a> [<a href=https://arxiv.org/pdf/2401.17012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Algorithmic Verification of Nonlinear Superposition for Systems of First Order Ordinary Differential Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Treumova%2C+V">Veronika Treumova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyakhov%2C+D+A">Dmitry A. Lyakhov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michels%2C+D+L">Dominik L. Michels</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Numerical Analysis (math.NA); Rings and Algebras (math.RA)
</div>
<p class=mathjax>This paper belongs to a group of work in the intersection of symbolic
computation and group analysis aiming for the symbolic analysis of differential
equations. The goal is to extract important properties without finding the
explicit general solution. In this contribution, we introduce the algorithmic
verification of nonlinear superposition properties and its implementation. More
exactly, for a system of nonlinear ordinary differential equations of first
order with a polynomial right-hand side, we check if the differential system
admits a general solution by means of a superposition rule and a certain number
of particular solutions. It is based on the theory of Newton polytopes and
associated symbolic computation. The developed method provides the basis for
the identification of nonlinear superpositions within a given system and for
the construction of numerical methods which preserve important algebraic
properties at the numerical level.
</p>
</div>
</dd>
<dt><a name=item274>[274]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17013 title=Abstract>arXiv:2401.17013</a> [<a href=https://arxiv.org/pdf/2401.17013 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17013 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation of Out-of-Distribution Detection Performance on Autonomous Driving Datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Henriksson%2C+J">Jens Henriksson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berger%2C+C">Christian Berger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ursing%2C+S">Stig Ursing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borg%2C+M">Markus Borg</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint to 2023 IEEE International Conference On Artificial Intelligence Testing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Safety measures need to be systemically investigated to what extent they
evaluate the intended performance of Deep Neural Networks (DNNs) for critical
applications. Due to a lack of verification methods for high-dimensional DNNs,
a trade-off is needed between accepted performance and handling of
out-of-distribution (OOD) samples.
<br>This work evaluates rejecting outputs from semantic segmentation DNNs by
applying a Mahalanobis distance (MD) based on the most probable
class-conditional Gaussian distribution for the predicted class as an OOD
score. The evaluation follows three DNNs trained on the Cityscapes dataset and
tested on four automotive datasets and finds that classification risk can
drastically be reduced at the cost of pixel coverage, even when applied on
unseen datasets. The applicability of our findings will support legitimizing
safety measures and motivate their usage when arguing for safe usage of DNNs in
automotive perception.
</p>
</div>
</dd>
<dt><a name=item275>[275]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17014 title=Abstract>arXiv:2401.17014</a> [<a href=https://arxiv.org/pdf/2401.17014 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17014 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Near-Field Fading Channel Modeling for ELAAs: From Communication to ISAC
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiuyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yi Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elzanaty%2C+A">Ahmed Elzanaty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tafazolli%2C+R">Rahim Tafazolli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Extremely large aperture array (ELAA) is anticipated to serve as a pivotal
feature of future multiple-input multiple-output (MIMO) systems in 6G.
Near-field (NF) fading channel models are essential for reliable link-level
simulation and ELAA system design. In this article, we propose a framework
designed to generate NF fading channels for both communication and integrated
sensing and communication (ISAC) applications. The framework allows a mixed of
line of sight (LoS) and non-LoS (NLoS) links. It also considers spherical wave
model and spatially non-stationary shadow fading. Based on this framework, we
propose a three-dimensional (3D) fading channel model for ELAA systems deployed
with a uniform rectangular array (URA). It can capture the impact of sensing
object for ISAC applications. Moreover, all parameters involved in the
framework are based on specifications or measurements from the 3rd Generation
Partnership Project (3GPP) documents. Therefore, the proposed framework and
channel model have the potential to contribute to the standard in various
aspects, including ISAC, extra-large (XL-) MIMO, and reconfigurable intelligent
surface (RIS) aided MIMO systems. Finally, future directions for ELAA are
presented, including not only NF channel modeling but also the design of
next-generation transceivers.
</p>
</div>
</dd>
<dt><a name=item276>[276]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17018 title=Abstract>arXiv:2401.17018</a> [<a href=https://arxiv.org/pdf/2401.17018 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17018 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GPU-Accelerated Batch-Dynamic Subgraph Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+L">Linshan Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jie%2C+H">Hailiang Jie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yunjun Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zetao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by ICDE 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>Subgraph matching has garnered increasing attention for its diverse
real-world applications. Given the dynamic nature of real-world graphs,
addressing evolving scenarios without incurring prohibitive overheads has been
a focus of research. However, existing approaches for dynamic subgraph matching
often proceed serially, retrieving incremental matches for each updated edge
individually. This approach falls short when handling batch data updates,
leading to a decrease in system throughput. Leveraging the parallel processing
power of GPUs, which can execute a massive number of cores simultaneously, has
been widely recognized for performance acceleration in various domains.
Surprisingly, systematic exploration of subgraph matching in the context of
batch-dynamic graphs, particularly on a GPU platform, remains untouched. In
this paper, we bridge this gap by introducing an efficient framework, GAMMA
(GPU-Accelerated Batch-Dynamic Subgraph Matching). Our approach features a
DFS-based warp-centric batch-dynamic subgraph matching algorithm. To ensure
load balance in the DFS-based search, we propose warp-level work stealing via
shared memory. Additionally, we introduce coalesced search to reduce redundant
computations. Comprehensive experiments demonstrate the superior performance of
GAMMA. Compared to state-of-the-art algorithms, GAMMA showcases a performance
improvement up to hundreds of times.
</p>
</div>
</dd>
<dt><a name=item277>[277]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17019 title=Abstract>arXiv:2401.17019</a> [<a href=https://arxiv.org/pdf/2401.17019 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17019 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Generating Executable Metamorphic Relations Using Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shin%2C+S+Y">Seung Yeob Shin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pastore%2C+F">Fabrizio Pastore</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bianculli%2C+D">Domenico Bianculli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baicoianu%2C+A">Alexandra Baicoianu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Metamorphic testing (MT) has proven to be a successful solution to automating
testing and addressing the oracle problem. However, it entails manually
deriving metamorphic relations (MRs) and converting them into an executable
form; these steps are time-consuming and may prevent the adoption of MT. In
this paper, we propose an approach for automatically deriving executable MRs
(EMRs) from requirements using large language models (LLMs). Instead of merely
asking the LLM to produce EMRs, our approach relies on a few-shot prompting
strategy to instruct the LLM to perform activities in the MT process, by
providing requirements and API specifications, as one would do with software
engineers. To assess the feasibility of our approach, we conducted a
questionnaire-based survey in collaboration with Siemens Industry Software,
focusing on four of their software applications. Additionally, we evaluated the
accuracy of the generated EMRs for a web application. The outcomes of our study
are highly promising, as they demonstrate the capability of our approach to
generate MRs and EMRs that are both comprehensible and pertinent for testing
purposes.
</p>
</div>
</dd>
<dt><a name=item278>[278]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17023 title=Abstract>arXiv:2401.17023</a> [<a href=https://arxiv.org/pdf/2401.17023 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17023 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MF-MOS: A Motion-Focused Model for Moving Object Segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jintao Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+K">Kang Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhuoxu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaoyu Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chengxi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xieyuanli Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICRA2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Moving object segmentation (MOS) provides a reliable solution for detecting
traffic participants and thus is of great interest in the autonomous driving
field. Dynamic capture is always critical in the MOS problem. Previous methods
capture motion features from the range images directly. Differently, we argue
that the residual maps provide greater potential for motion information, while
range images contain rich semantic guidance. Based on this intuition, we
propose MF-MOS, a novel motion-focused model with a dual-branch structure for
LiDAR moving object segmentation. Novelly, we decouple the spatial-temporal
information by capturing the motion from residual maps and generating semantic
features from range images, which are used as movable object guidance for the
motion branch. Our straightforward yet distinctive solution can make the most
use of both range images and residual maps, thus greatly improving the
performance of the LiDAR-based MOS task. Remarkably, our MF-MOS achieved a
leading IoU of 76.7% on the MOS leaderboard of the SemanticKITTI dataset upon
submission, demonstrating the current state-of-the-art performance. The
implementation of our MF-MOS has been released at
https://github.com/SCNU-RISLAB/MF-MOS.
</p>
</div>
</dd>
<dt><a name=item279>[279]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17026 title=Abstract>arXiv:2401.17026</a> [<a href=https://arxiv.org/pdf/2401.17026 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17026 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17026 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Static and Dynamic Synthesis of Bengali and Devanagari Signatures
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chanda%2C+S">Sukalpa Chanda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diaz%2C+M">Moises Diaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+C+K">Chayan Kr. Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Majumdar%2C+A">Anirban Majumdar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acharya%2C+P">Parikshit Acharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pal%2C+U">Umapada Pal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted version. Published on IEEE Transactions on Cybernetics [ISSN 2168-2267], v. 48(10), p. 2896-2907
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Cybernetics, v. 48(10), p. 2896-2907, 2018
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Developing an automatic signature verification system is challenging and
demands a large number of training samples. This is why synthetic handwriting
generation is an emerging topic in document image analysis. Some handwriting
synthesizers use the motor equivalence model, the well-established hypothesis
from neuroscience, which analyses how a human being accomplishes movement.
Specifically, a motor equivalence model divides human actions into two steps:
1) the effector independent step at cognitive level and 2) the effector
dependent step at motor level. In fact, recent work reports the successful
application to Western scripts of a handwriting synthesizer, based on this
theory. This paper aims to adapt this scheme for the generation of synthetic
signatures in two Indic scripts, Bengali (Bangla), and Devanagari (Hindi). For
this purpose, we use two different online and offline databases for both
Bengali and Devanagari signatures. This paper reports an effective synthesizer
for static and dynamic signatures written in Devanagari or Bengali scripts. We
obtain promising results with artificially generated signatures in terms of
appearance and performance when we compare the results with those for real
signatures.
</p>
</div>
</dd>
<dt><a name=item280>[280]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17027 title=Abstract>arXiv:2401.17027</a> [<a href=https://arxiv.org/pdf/2401.17027 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17027 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Heterogeneous treatment effect estimation with subpopulation identification for personalized medicine in opioid use disorder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seungyeon Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+W">Wenyu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2023 IEEE International Conference on Data Mining (ICDM)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Deep learning models have demonstrated promising results in estimating
treatment effects (TEE). However, most of them overlook the variations in
treatment outcomes among subgroups with distinct characteristics. This
limitation hinders their ability to provide accurate estimations and treatment
recommendations for specific subgroups. In this study, we introduce a novel
neural network-based framework, named SubgroupTE, which incorporates subgroup
identification and treatment effect estimation. SubgroupTE identifies diverse
subgroups and simultaneously estimates treatment effects for each subgroup,
improving the treatment effect estimation by considering the heterogeneity of
treatment responses. Comparative experiments on synthetic data show that
SubgroupTE outperforms existing models in treatment effect estimation.
Furthermore, experiments on a real-world dataset related to opioid use disorder
(OUD) demonstrate the potential of our approach to enhance personalized
treatment recommendations for OUD patients.
</p>
</div>
</dd>
<dt><a name=item281>[281]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17032 title=Abstract>arXiv:2401.17032</a> [<a href=https://arxiv.org/pdf/2401.17032 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17032 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> M2CURL: Sample-Efficient Multimodal Reinforcement Learning via Self-Supervised Representation Learning for Robotic Manipulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lygerakis%2C+F">Fotios Lygerakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dave%2C+V">Vedant Dave</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rueckert%2C+E">Elmar Rueckert</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project website: <a href=https://sites.google.com/view/M2CURL/home>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
<p class=mathjax>One of the most critical aspects of multimodal Reinforcement Learning (RL) is
the effective integration of different observation modalities. Having robust
and accurate representations derived from these modalities is key to enhancing
the robustness and sample efficiency of RL algorithms. However, learning
representations in RL settings for visuotactile data poses significant
challenges, particularly due to the high dimensionality of the data and the
complexity involved in correlating visual and tactile inputs with the dynamic
environment and task objectives. To address these challenges, we propose
Multimodal Contrastive Unsupervised Reinforcement Learning (M2CURL). Our
approach employs a novel multimodal self-supervised learning technique that
learns efficient representations and contributes to faster convergence of RL
algorithms. Our method is agnostic to the RL algorithm, thus enabling its
integration with any available RL algorithm. We evaluate M2CURL on the Tactile
Gym 2 simulator and we show that it significantly enhances the learning
efficiency in different manipulation tasks. This is evidenced by faster
convergence rates and higher cumulative rewards per episode, compared to
standard RL algorithms without our representation learning approach.
</p>
</div>
</dd>
<dt><a name=item282>[282]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17033 title=Abstract>arXiv:2401.17033</a> [<a href=https://arxiv.org/pdf/2401.17033 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17033 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17033 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multilayer Graph Approach to Deep Subspace Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sindi%C4%8Di%C4%87%2C+L">Lovro Sindičić</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kopriva%2C+I">Ivica Kopriva</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 4 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Deep subspace clustering (DSC) networks based on self-expressive model learn
representation matrix, often implemented in terms of fully connected network,
in the embedded space. After the learning is finished, representation matrix is
used by spectral clustering module to assign labels to clusters. However, such
approach ignores complementary information that exist in other layers of the
encoder (including the input data themselves). Herein, we apply selected linear
subspace clustering algorithm to learn representation matrices from
representations learned by all layers of encoder network including the input
data. Afterward, we learn a multilayer graph that in a multi-view like manner
integrates information from graph Laplacians of all used layers. That improves
further performance of selected DSC network. Furthermore, we also provide
formulation of our approach to cluster out-of-sample/test data points. We
validate proposed approach on four well-known datasets with two DSC networks as
baseline models. In almost all the cases, proposed approach achieved
statistically significant improvement in three performance metrics. MATLAB code
of proposed algorithm is posted on https://github.com/lovro-sinda/MLG-DSC.
</p>
</div>
</dd>
<dt><a name=item283>[283]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17035 title=Abstract>arXiv:2401.17035</a> [<a href=https://arxiv.org/pdf/2401.17035 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17035 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17035 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Kernel Sparse Subspace Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kopriva%2C+I">Ivica Kopriva</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Kernel methods are applied to many problems in pattern recognition, including
subspace clustering (SC). That way, nonlinear problems in the input data space
become linear in mapped high-dimensional feature space. Thereby,
computationally tractable nonlinear algorithms are enabled through implicit
mapping by the virtue of kernel trick. However, kernelization of linear
algorithms is possible only if square of the Froebenious norm of the error term
is used in related optimization problem. That, however, implies normal
distribution of the error. That is not appropriate for non-Gaussian errors such
as gross sparse corruptions that are modeled by -norm. Herein, to the best of
our knowledge, we propose for the first time robust kernel sparse SC (RKSSC)
algorithm for data with gross sparse corruptions. The concept, in principle,
can be applied to other SC algorithms to achieve robustness to the presence of
such type of corruption. We validated proposed approach on two well-known
datasets with linear robust SSC algorithm as a baseline model. According to
Wilcoxon test, clustering performance obtained by the RKSSC algorithm is
statistically significantly better than corresponding performance obtained by
the robust SSC algorithm. MATLAB code of proposed RKSSC algorithm is posted on
https://github.com/ikopriva/RKSSC.
</p>
</div>
</dd>
<dt><a name=item284>[284]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17036 title=Abstract>arXiv:2401.17036</a> [<a href=https://arxiv.org/pdf/2401.17036 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17036 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Intrinsic Data Constraints and Upper Bounds in Binary Classification Performance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jing%2C+F">Fei Jing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zi-Ke Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qingpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 48 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Data Analysis, Statistics and Probability (physics.data-an)
</div>
<p class=mathjax>The structure of data organization is widely recognized as having a
substantial influence on the efficacy of machine learning algorithms,
particularly in binary classification tasks. Our research provides a
theoretical framework suggesting that the maximum potential of binary
classifiers on a given dataset is primarily constrained by the inherent
qualities of the data. Through both theoretical reasoning and empirical
examination, we employed standard objective functions, evaluative metrics, and
binary classifiers to arrive at two principal conclusions. Firstly, we show
that the theoretical upper bound of binary classification performance on actual
datasets can be theoretically attained. This upper boundary represents a
calculable equilibrium between the learning loss and the metric of evaluation.
Secondly, we have computed the precise upper bounds for three commonly used
evaluation metrics, uncovering a fundamental uniformity with our overarching
thesis: the upper bound is intricately linked to the dataset's characteristics,
independent of the classifier in use. Additionally, our subsequent analysis
uncovers a detailed relationship between the upper limit of performance and the
level of class overlap within the binary classification data. This relationship
is instrumental for pinpointing the most effective feature subsets for use in
feature engineering.
</p>
</div>
</dd>
<dt><a name=item285>[285]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17037 title=Abstract>arXiv:2401.17037</a> [<a href=https://arxiv.org/pdf/2401.17037 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17037 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+H">Hwanwoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanz-Alonso%2C+D">Daniel Sanz-Alonso</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)
</div>
<p class=mathjax>This paper studies Bayesian optimization with noise-free observations. We
introduce new algorithms rooted in scattered data approximation that rely on a
random exploration step to ensure that the fill-distance of query points decays
at a near-optimal rate. Our algorithms retain the ease of implementation of the
classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly
match those conjectured in <a href=https://arxiv.org/abs/2002.05096>arXiv:2002.05096</a>, hence solving a COLT open problem.
Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian
optimization strategies in several examples.
</p>
</div>
</dd>
<dt><a name=item286>[286]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17038 title=Abstract>arXiv:2401.17038</a> [<a href=https://arxiv.org/pdf/2401.17038 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17038 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+B">Bowen Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+B">Bo Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+J">Jingyuan Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+T">Tianpeng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yongxiang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Recently, there has been increasing concern about the vulnerability of deep
neural network (DNN)-based synthetic aperture radar (SAR) automatic target
recognition (ATR) to adversarial attacks, where a DNN could be easily deceived
by clean input with imperceptible but aggressive perturbations. This paper
studies the synthetic-to-measured (S2M) transfer setting, where an attacker
generates adversarial perturbation based solely on synthetic data and transfers
it against victim models trained with measured data. Compared with the current
measured-to-measured (M2M) transfer setting, our approach does not need direct
access to the victim model or the measured SAR data. We also propose the
transferability estimation attack (TEA) to uncover the adversarial risks in
this more challenging and practical scenario. The TEA makes full use of the
limited similarity between the synthetic and measured data pairs for blind
estimation and optimization of S2M transferability, leading to feasible
surrogate model enhancement without mastering the victim model and data.
Comprehensive evaluations based on the publicly available synthetic and
measured paired labeled experiment (SAMPLE) dataset demonstrate that the TEA
outperforms state-of-the-art methods and can significantly enhance various
attack algorithms in computer vision and remote sensing applications. Codes and
data are available at https://github.com/scenarri/S2M-TEA.
</p>
</div>
</dd>
<dt><a name=item287>[287]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17039 title=Abstract>arXiv:2401.17039</a> [<a href=https://arxiv.org/pdf/2401.17039 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17039 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Madureira%2C+B">Brielen Madureira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schlangen%2C+D">David Schlangen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to UnImplicit workshop at EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Clarification requests are a mechanism to help solve communication problems,
e.g. due to ambiguity or underspecification, in instruction-following
interactions. Despite their importance, even skilful models struggle with
producing or interpreting such repair acts. In this work, we test three
hypotheses concerning the effects of action taking as an auxiliary task in
modelling iCR policies. Contrary to initial expectations, we conclude that its
contribution to learning an iCR policy is limited, but some information can
still be extracted from prediction uncertainty. We present further evidence
that even well-motivated, Transformer-based models fail to learn good policies
for when to ask Instruction CRs (iCRs), while the task of determining what to
ask about can be more successfully modelled. Considering the implications of
these findings, we further discuss the shortcomings of the data-driven paradigm
for learning meta-communication acts.
</p>
</div>
</dd>
<dt><a name=item288>[288]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17042 title=Abstract>arXiv:2401.17042</a> [<a href=https://arxiv.org/pdf/2401.17042 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17042 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Forecasting VIX using Bayesian Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hort%C3%BAa%2C+H+J">Héctor J. Hortúa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mora-Valencia%2C+A">Andrés Mora-Valencia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Recently, deep learning techniques are gradually replacing traditional
statistical and machine learning models as the first choice for price
forecasting tasks. In this paper, we leverage probabilistic deep learning for
inferring the volatility index VIX. We employ the probabilistic counterpart of
WaveNet, Temporal Convolutional Network (TCN), and Transformers. We show that
TCN outperforms all models with an RMSE around 0.189. In addition, it has been
well known that modern neural networks provide inaccurate uncertainty
estimates. For solving this problem, we use the standard deviation scaling to
calibrate the networks. Furthermore, we found out that MNF with Gaussian prior
outperforms Reparameterization Trick and Flipout models in terms of precision
and uncertainty predictions. Finally, we claim that MNF with Cauchy and
LogUniform prior distributions yield well calibrated TCN and WaveNet networks
being the former that best infer the VIX values.
</p>
</div>
</dd>
<dt><a name=item289>[289]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17043 title=Abstract>arXiv:2401.17043</a> [<a href=https://arxiv.org/pdf/2401.17043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu%2C+Y">Yuanjie Lyu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhiyu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+S">Simin Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+F">Feiyu Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+B">Bo Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenjin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+H">Hao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Huanyong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+T">Tong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 26 Pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Retrieval-Augmented Generation (RAG) is a technique that enhances the
capabilities of large language models (LLMs) by incorporating external
knowledge sources. This method addresses common LLM limitations, including
outdated information and the tendency to produce inaccurate "hallucinated"
content. However, the evaluation of RAG systems is challenging, as existing
benchmarks are limited in scope and diversity. Most of the current benchmarks
predominantly assess question-answering applications, overlooking the broader
spectrum of situations where RAG could prove advantageous. Moreover, they only
evaluate the performance of the LLM component of the RAG pipeline in the
experiments, and neglect the influence of the retrieval component and the
external knowledge database. To address these issues, this paper constructs a
large-scale and more comprehensive benchmark, and evaluates all the components
of RAG systems in various RAG application scenarios. Specifically, we have
categorized the range of RAG applications into four distinct types-Create,
Read, Update, and Delete (CRUD), each representing a unique use case. "Create"
refers to scenarios requiring the generation of original, varied content.
"Read" involves responding to intricate questions in knowledge-intensive
situations. "Update" focuses on revising and rectifying inaccuracies or
inconsistencies in pre-existing texts. "Delete" pertains to the task of
summarizing extensive texts into more concise forms. For each of these CRUD
categories, we have developed comprehensive datasets to evaluate the
performance of RAG systems. We also analyze the effects of various components
of the RAG system, such as the retriever, the context length, the knowledge
base construction, and the LLM. Finally, we provide useful insights for
optimizing the RAG technology for different scenarios.
</p>
</div>
</dd>
<dt><a name=item290>[290]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17044 title=Abstract>arXiv:2401.17044</a> [<a href=https://arxiv.org/pdf/2401.17044 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17044 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scalable Mechanism Design for Multi-Agent Path Finding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Friedrich%2C+P">Paul Friedrich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Curry%2C+M">Michael Curry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dierks%2C+L">Ludwig Dierks</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McAleer%2C+S">Stephen McAleer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiaoyang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sandholm%2C+T">Tuomas Sandholm</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seuken%2C+S">Sven Seuken</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 5 figures. Submitted to IJCAI'24
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)
</div>
<p class=mathjax>Multi-Agent Path Finding (MAPF) involves determining paths for multiple
agents to travel simultaneously through a shared area toward particular goal
locations. This problem is computationally complex, especially when dealing
with large numbers of agents, as is common in realistic applications like
autonomous vehicle coordination. Finding an optimal solution is often
computationally infeasible, making the use of approximate algorithms essential.
Adding to the complexity, agents might act in a self-interested and strategic
way, possibly misrepresenting their goals to the MAPF algorithm if it benefits
them. Although the field of mechanism design offers tools to align incentives,
using these tools without careful consideration can fail when only having
access to approximately optimal outcomes. Since approximations are crucial for
scalable MAPF algorithms, this poses a significant challenge. In this work, we
introduce the problem of scalable mechanism design for MAPF and propose three
strategyproof mechanisms, two of which even use approximate MAPF algorithms. We
test our mechanisms on realistic MAPF domains with problem sizes ranging from
dozens to hundreds of agents. Our findings indicate that they improve welfare
beyond a simple baseline.
</p>
</div>
</dd>
<dt><a name=item291>[291]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17045 title=Abstract>arXiv:2401.17045</a> [<a href=https://arxiv.org/pdf/2401.17045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17045 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explaining Explanations in Probabilistic Logic Programming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vidal%2C+G">Germán Vidal</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL)
</div>
<p class=mathjax>The emergence of tools based on artificial intelligence has also led to the
need of producing explanations which are understandable by a human being. In
some approaches, the system is not transparent (often referred to as a "black
box"), making it difficult to generate appropriate explanations. In this work,
though, we consider probabilistic logic programming, a combination of logic
programming (for knowledge representation) and probability (to model
uncertainty). In this setting, one can say that models are interpretable, which
eases its understanding. However, given a particular query, the usual notion of
"explanation" is associated with a set of choices, one for each random variable
of the model. Unfortunately, this set does not have a causal structure and, in
fact, some of the choices are actually irrelevant to the considered query. In
order to overcome these shortcomings, we present an approach to explaining
explanations which is based on the definition of a query-driven inference
mechanism for probabilistic logic programs.
</p>
</div>
</dd>
<dt><a name=item292>[292]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17049 title=Abstract>arXiv:2401.17049</a> [<a href=https://arxiv.org/pdf/2401.17049 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17049 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17049 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Movable Antenna-Enabled Full-Duplex Wireless
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+J">Jingze Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenyao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+L">Lifeng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+B">Bingli Jiao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>Movable antenna (MA) provides an innovative way to arrange antennas that can
contribute to improved signal quality and more effective interference
management. This method is especially beneficial for full-duplex (FD) wireless,
which struggles with self-interference (SI) that usually overpowers the desired
incoming signals. By dynamically repositioning transmit/receive antennas, we
can mitigate the SI and enhance the reception of incoming signals. Thus, this
paper proposes a novel MA-enabled point-to-point FD wireless system and
formulates the minimum achievable rate of two FD terminals. To maximize the
minimum achievable rate and determine the near-optimal positions of the MAs, we
introduce a solution based on projected particle swarm optimization (PPSO),
which can circumvent common suboptimal positioning issues. Moreover, numerical
results reveal that the PPSO method leads to a better performance compared to
the conventional alternating position optimization (APO). The results also
demonstrate that an MA-enabled FD system outperforms the one using
fixed-position antennas (FPAs).
</p>
</div>
</dd>
<dt><a name=item293>[293]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17050 title=Abstract>arXiv:2401.17050</a> [<a href=https://arxiv.org/pdf/2401.17050 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17050 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lao%2C+D">Danning Lao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bu%2C+J">Jiazi Bu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+J">Junchi Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+W">Wei Shen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>As computer vision continues to advance and finds widespread applications
across various domains, the need for interpretability in deep learning models
becomes paramount. Existing methods often resort to post-hoc techniques or
prototypes to explain the decision-making process, which can be indirect and
lack intrinsic illustration. In this research, we introduce ViTree, a novel
approach for fine-grained visual categorization that combines the popular
vision transformer as a feature extraction backbone with neural decision trees.
By traversing the tree paths, ViTree effectively selects patches from
transformer-processed features to highlight informative local regions, thereby
refining representations in a step-wise manner. Unlike previous tree-based
models that rely on soft distributions or ensembles of paths, ViTree selects a
single tree path, offering a clearer and simpler decision-making process. This
patch and path selectivity enhances model interpretability of ViTree, enabling
better insights into the model's inner workings. Remarkably, extensive
experimentation validates that this streamlined approach surpasses various
strong competitors and achieves state-of-the-art performance while maintaining
exceptional interpretability which is proved by multi-perspective methods. Code
can be found at https://github.com/SJTU-DeepVisionLab/ViTree.
</p>
</div>
</dd>
<dt><a name=item294>[294]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17052 title=Abstract>arXiv:2401.17052</a> [<a href=https://arxiv.org/pdf/2401.17052 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17052 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Making Parametric Anomaly Detection on Tabular Data Non-Parametric Again
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doan%2C+B">Bich-Liên Doan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>Deep learning for tabular data has garnered increasing attention in recent
years, yet employing deep models for structured data remains challenging. While
these models excel with unstructured data, their efficacy with structured data
has been limited. Recent research has introduced retrieval-augmented models to
address this gap, demonstrating promising results in supervised tasks such as
classification and regression. In this work, we investigate using
retrieval-augmented models for anomaly detection on tabular data. We propose a
reconstruction-based approach in which a transformer model learns to
reconstruct masked features of \textit{normal} samples. We test the
effectiveness of KNN-based and attention-based modules to select relevant
samples to help in the reconstruction process of the target sample. Our
experiments on a benchmark of 31 tabular datasets reveal that augmenting this
reconstruction-based anomaly detection (AD) method with non-parametric
relationships via retrieval modules may significantly boost performance.
</p>
</div>
</dd>
<dt><a name=item295>[295]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17053 title=Abstract>arXiv:2401.17053</a> [<a href=https://arxiv.org/pdf/2401.17053 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17053 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhennan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+H">Han Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+T">Taizhang Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+W">Weixuan Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Senbo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+R">Ruikai Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weizhe Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sato%2C+H">Hiroyuki Sato</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Hongdong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+P">Pan Ji</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Video: <a href="https://www.youtube.com/watch?v=PxIBtd6G0mA">this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)
</div>
<p class=mathjax>We present BlockFusion, a diffusion-based model that generates 3D scenes as
unit blocks and seamlessly incorporates new blocks to extend the scene.
BlockFusion is trained using datasets of 3D blocks that are randomly cropped
from complete 3D scene meshes. Through per-block fitting, all training blocks
are converted into the hybrid neural fields: with a tri-plane containing the
geometry features, followed by a Multi-layer Perceptron (MLP) for decoding the
signed distance values. A variational auto-encoder is employed to compress the
tri-planes into the latent tri-plane space, on which the denoising diffusion
process is performed. Diffusion applied to the latent representations allows
for high-quality and diverse 3D scene generation. To expand a scene during
generation, one needs only to append empty blocks to overlap with the current
scene and extrapolate existing latent tri-planes to populate new blocks. The
extrapolation is done by conditioning the generation process with the feature
samples from the overlapping tri-planes during the denoising iterations. Latent
tri-plane extrapolation produces semantically and geometrically meaningful
transitions that harmoniously blend with the existing scene. A 2D layout
conditioning mechanism is used to control the placement and arrangement of
scene elements. Experimental results indicate that BlockFusion is capable of
generating diverse, geometrically consistent and unbounded large 3D scenes with
unprecedented high-quality shapes in both indoor and outdoor scenarios.
</p>
</div>
</dd>
<dt><a name=item296>[296]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17056 title=Abstract>arXiv:2401.17056</a> [<a href=https://arxiv.org/pdf/2401.17056 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17056 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Floor extraction and door detection for visually impaired guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berenguel-Baeta%2C+B">Bruno Berenguel-Baeta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero-Viu%2C+M">Manuel Guerrero-Viu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Nova%2C+A">Alejandro de Nova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bermudez-Cameo%2C+J">Jesus Bermudez-Cameo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perez-Yus%2C+A">Alejandro Perez-Yus</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero%2C+J+J">Jose J. Guerrero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> International Conference on Control, Automation, Robotics and
 Vision 2020, pp. 1222-1229
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Finding obstacle-free paths in unknown environments is a big navigation issue
for visually impaired people and autonomous robots. Previous works focus on
obstacle avoidance, however they do not have a general view of the environment
they are moving in. New devices based on computer vision systems can help
impaired people to overcome the difficulties of navigating in unknown
environments in safe conditions. In this work it is proposed a combination of
sensors and algorithms that can lead to the building of a navigation system for
visually impaired people. Based on traditional systems that use RGB-D cameras
for obstacle avoidance, it is included and combined the information of a
fish-eye camera, which will give a better understanding of the user's
surroundings. The combination gives robustness and reliability to the system as
well as a wide field of view that allows to obtain many information from the
environment. This combination of sensors is inspired by human vision where the
center of the retina (fovea) provides more accurate information than the
periphery, where humans have a wider field of view. The proposed system is
mounted on a wearable device that provides the obstacle-free zones of the
scene, allowing the planning of trajectories for people guidance.
</p>
</div>
</dd>
<dt><a name=item297>[297]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17057 title=Abstract>arXiv:2401.17057</a> [<a href=https://arxiv.org/pdf/2401.17057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> What can Information Guess? Guessing Advantage vs. Rényi Entropy for Small Leakages
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=B%C3%A9guinot%2C+J">Julien Béguinot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rioul%2C+O">Olivier Rioul</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We leverage the Gibbs inequality and its natural generalization to R\'enyi
entropies to derive closed-form parametric expressions of the optimal lower
bounds of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-148-Frame tabindex=0><nobr><span class=math id=MathJax-Span-881 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.52em,2.318em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-882><span class=mi id=MathJax-Span-883 style=font-family:MathJax_Math-italic>ρ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:0.906em"></span></span></nobr></span>th-order guessing entropy (guessing moment) of a secret taking
values on a finite set, in terms of the R\'enyi-Arimoto <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-149-Frame tabindex=0><nobr><span class=math id=MathJax-Span-884 style=width:0.813em;display:inline-block><span style=display:inline-block;position:relative;width:0.639em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-885><span class=mi id=MathJax-Span-886 style=font-family:MathJax_Math-italic>α</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-entropy. This
is carried out in an non-asymptotic regime when side information may be
available. The resulting bounds yield a theoretical solution to a fundamental
problem in side-channel analysis: Ensure that an adversary will not gain much
guessing advantage when the leakage information is sufficiently weakened by
proper countermeasures in a given cryptographic implementation. Practical
evaluation for classical leakage models show that the proposed bounds greatly
improve previous ones for analyzing the capability of an adversary to perform
side-channel attacks.
</p>
</div>
</dd>
<dt><a name=item298>[298]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17058 title=Abstract>arXiv:2401.17058</a> [<a href=https://arxiv.org/pdf/2401.17058 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17058 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Atlanta Scaled layouts from non-central panoramas
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berenguel-Baeta%2C+B">Bruno Berenguel-Baeta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bermudez-Cameo%2C+J">Jesus Bermudez-Cameo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero%2C+J+J">Jose J. Guerrero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Pattern Recognition, Volume 129, Page 108740, year 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
<p class=mathjax>In this work we present a novel approach for 3D layout recovery of indoor
environments using a non-central acquisition system. From a non-central
panorama, full and scaled 3D lines can be independently recovered by geometry
reasoning without geometric nor scale assumptions. However, their sensitivity
to noise and complex geometric modeling has led these panoramas being little
investigated. Our new pipeline aims to extract the boundaries of the structural
lines of an indoor environment with a neural network and exploit the properties
of non-central projection systems in a new geometrical processing to recover an
scaled 3D layout. The results of our experiments show that we improve
state-of-the-art methods for layout reconstruction and line extraction in
non-central projection systems. We completely solve the problem in Manhattan
and Atlanta environments, handling occlusions and retrieving the metric scale
of the room without extra measurements. As far as the authors knowledge goes,
our approach is the first work using deep learning on non-central panoramas and
recovering scaled layouts from single panoramas.
</p>
</div>
</dd>
<dt><a name=item299>[299]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17059 title=Abstract>arXiv:2401.17059</a> [<a href=https://arxiv.org/pdf/2401.17059 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17059 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Approximation Sets for Exploratory Queries
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Davidson%2C+S+B">Susan B.Davidson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Milo%2C+T">Tova Milo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Razmadze%2C+K">Kathy Razmadze</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeevi%2C+G">Gal Zeevi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>
</div>
<p class=mathjax>In data exploration, executing complex non-aggregate queries over large
databases can be time-consuming. Our paper introduces a novel approach to
address this challenge, focusing on finding an optimized subset of data,
referred to as the approximation set, for query execution. The goal is to
maximize query result quality while minimizing execution time. We formalize
this problem as Approximate Non-Aggregates Query Processing (ANAQP) and
establish its NP-completeness. To tackle this, we propose an approximate
solution using advanced Reinforcement Learning architecture, termed ASQP-RL.
This approach overcomes challenges related to the large action space and the
need for generalization beyond a known query workload. Experimental results on
two benchmarks demonstrate the superior performance of ASQP-RL, outperforming
baselines by 30% in accuracy and achieving efficiency gains of 10-35X. Our
research sheds light on the potential of reinforcement learning techniques for
advancing data management tasks. Experimental results on two benchmarks show
that ASQP-RL significantly outperforms the baselines both in terms of accuracy
(30% better) and efficiency (10-35X). This research provides valuable insights
into the potential of RL techniques for future advancements in data management
tasks.
</p>
</div>
</dd>
<dt><a name=item300>[300]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17061 title=Abstract>arXiv:2401.17061</a> [<a href=https://arxiv.org/pdf/2401.17061 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17061 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> OmniSCV: An Omnidirectional Synthetic Image Generator for Computer Vision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berenguel-Baeta%2C+B">Bruno Berenguel-Baeta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bermudez-Cameo%2C+J">Jesus Bermudez-Cameo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero%2C+J+J">Jose J. Guerrero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Sensors 2020, vol. 20, pp. 2066
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Omnidirectional and 360{\deg} images are becoming widespread in industry and
in consumer society, causing omnidirectional computer vision to gain attention.
Their wide field of view allows the gathering of a great amount of information
about the environment from only an image. However, the distortion of these
images requires the development of specific algorithms for their treatment and
interpretation. Moreover, a high number of images is essential for the correct
training of computer vision algorithms based on learning. In this paper, we
present a tool for generating datasets of omnidirectional images with semantic
and depth information. These images are synthesized from a set of captures that
are acquired in a realistic virtual environment for Unreal Engine 4 through an
interface plugin. We gather a variety of well-known projection models such as
equirectangular and cylindrical panoramas, different fish-eye lenses,
catadioptric systems, and empiric models. Furthermore, we include in our tool
photorealistic non-central-projection systems as non-central panoramas and
non-central catadioptric systems. As far as we know, this is the first reported
tool for generating photorealistic non-central images in the literature.
Moreover, since the omnidirectional images are made virtually, we provide
pixel-wise information about semantics and depth as well as perfect knowledge
of the calibration parameters of the cameras. This allows the creation of
ground-truth information with pixel precision for training learning algorithms
and testing 3D vision approaches. To validate the proposed tool, different
computer vision algorithms are tested as line extractions from dioptric and
catadioptric central images, 3D Layout recovery and SLAM using equirectangular
panoramas, and 3D reconstruction from non-central panoramas.
</p>
</div>
</dd>
<dt><a name=item301>[301]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17062 title=Abstract>arXiv:2401.17062</a> [<a href=https://arxiv.org/pdf/2401.17062 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17062 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Outline of an Independent Systematic Blackbox Test for ML-based Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wiesbrock%2C+H">Hans-Werner Wiesbrock</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gro%C3%9Fmann%2C+J">Jürgen Großmann</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
<p class=mathjax>This article proposes a test procedure that can be used to test ML models and
ML-based systems independently of the actual training process. In this way, the
typical quality statements such as accuracy and precision of these models and
system can be verified independently, taking into account their black box
character and the immanent stochastic properties of ML models and their
training data. The article presents first results from a set of test
experiments and suggest extensions to existing test methods reflecting the
stochastic nature of ML models and ML-based systems.
</p>
</div>
</dd>
<dt><a name=item302>[302]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17063 title=Abstract>arXiv:2401.17063</a> [<a href=https://arxiv.org/pdf/2401.17063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SPViz: A DSL-Driven Approach for Software Project Visualization Tooling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rentz%2C+N">Niklas Rentz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=von+Hanxleden%2C+R">Reinhard von Hanxleden</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 14 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>For most service architectures, such as OSGi and Spring,
architecture-specific tools allow software developers and architects to
visualize otherwise obscure configurations hidden in the project files. Such
visualization tools are often used for documentation purposes and help to
better understand programs than with source code alone. However, such tools
often do not address project-specific peculiarities or do not exist at all for
less common architectures, requiring developers to use different visualization
and analysis tools within the same architecture. Furthermore, many generic
modeling tools and architecture visualization tools require their users to
create and maintain models manually.
<br>We here propose a DSL-driven approach that allows software architects to
define and adapt their own project visualization tool. The approach, which we
refer to as Software Project Visualization (SPViz), uses two DSLs, one to
describe architectural elements and their relationships, and one to describe
how these should be visualized. We demonstrate how SPViz can then automatically
synthesize a customized, project-specific visualization tool that can adapt to
changes in the underlying project automatically.
<br>We implemented our approach in an open-source library, also termed SPViz and
discuss and analyze four different tools that follow this concept, including
open-source projects and projects from an industrial partner in the railway
domain.
</p>
</div>
</dd>
<dt><a name=item303>[303]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17064 title=Abstract>arXiv:2401.17064</a> [<a href=https://arxiv.org/pdf/2401.17064 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17064 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Gesture Recognition on Spiking Convolutional Networks Through Sensor Fusion of Event-Based and Depth Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Steffen%2C+L">Lea Steffen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trapp%2C+T">Thomas Trapp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roennau%2C+A">Arne Roennau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dillmann%2C+R">Rüdiger Dillmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>As intelligent systems become increasingly important in our daily lives, new
ways of interaction are needed. Classical user interfaces pose issues for the
physically impaired and are partially not practical or convenient. Gesture
recognition is an alternative, but often not reactive enough when conventional
cameras are used. This work proposes a Spiking Convolutional Neural Network,
processing event- and depth data for gesture recognition. The network is
simulated using the open-source neuromorphic computing framework LAVA for
offline training and evaluation on an embedded system. For the evaluation three
open source data sets are used. Since these do not represent the applied
bi-modality, a new data set with synchronized event- and depth data was
recorded. The results show the viability of temporal encoding on depth
information and modality fusion, even on differently encoded data, to be
beneficial to network performance and generalization capabilities.
</p>
</div>
</dd>
<dt><a name=item304>[304]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17065 title=Abstract>arXiv:2401.17065</a> [<a href=https://arxiv.org/pdf/2401.17065 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17065 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Platoon Fundamental Diagram estimation can be Markovian: evidence from human- and self-driven vehicle trajectories
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Makridis%2C+M+A">Michail A. Makridis</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kouvelas%2C+A">Anastasios Kouvelas</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Laval%2C+J+A">Jorge A. Laval</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 8 figures, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>We propose a simple and effective method to derive the Fundamental Diagram
(FD) from platoon vehicle trajectories. Average traffic state variables are
computed using Edie's generalized definitions within time-dependent trapezoidal
space-time areas. To obtain a clear FD, we employ a bivariate data aggregation
technique to eliminate scatter. Our findings are as follows: (i) The proposed
method demonstrates a remarkably consistent relation between the traffic
variables and a clear triangular shape for autonomously-driven vehicles. (ii)
The FDs are invariant to several factors of heterogeneity such as the platoon
length, vehicle characteristics, road particularities, and data acquisition
accuracy. (iii) ACC-driven vehicle platoons with minimum headway setting
achieve much higher capacity, roughly 90\% than those with a large headway
setting. (iv) Connectivity might increase capacity. (v) Human drivers have a
wider near-capacity operation area, showing different behaviors at high speeds
than low ones, and (vi) Safety concerns might arise due to high values of
backward wave speed for ACC-driven vehicles. Comparative analysis with the
state-of-the-art confirms the validity of our approach. The proposed method
stands out due to its simplicity and accuracy, which paves the way for
practical applications in real-time traffic flow monitoring and control within
modern intelligent transportation systems.
</p>
</div>
</dd>
<dt><a name=item305>[305]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17070 title=Abstract>arXiv:2401.17070</a> [<a href=https://arxiv.org/pdf/2401.17070 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17070 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17070 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ultra-low power sensor devices for monitoring physical activity and respiratory frequency in farmed fish
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martos-Sitcha%2C+J+A">Juan Antonio Martos-Sitcha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sosa%2C+J">Javier Sosa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramos-Valido%2C+D">Dailos Ramos-Valido</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bravo%2C+F+J">Francisco Javier Bravo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gomes%2C+H+L">Henrique Leonel Gomes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calduch-Giner%2C+J+A">Josep A. Calduch-Giner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cabruja%2C+E">Enric Cabruja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vega%2C+A">Aurelio Vega</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferrer%2C+M+A">Miguel Angel Ferrer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lozano%2C+M">Manuel Lozano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montiel-Nelson%2C+J+A">Juan Antonio Montiel-Nelson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Afonso%2C+J+M">Juan Manuel Afonso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perez-Sanchez%2C+J">Jaume Perez-Sanchez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint. Published on Frontiers in Physiology 29 May 2019 Sec. Aquatic Physiology Volume 10 - 2019 | <a href=https://doi.org/10.3389/fphys.2019.00667>this https URL</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Frontiers in Physiology, 10(MAY), 2019
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
<p class=mathjax>Integration of technological solutions aims to improve accuracy, precision
and repeatability in farming operations, and biosensor devices are increasingly
used for understanding basic biology during livestock production. The aim of
this study was to design and validate a miniaturized tri-axial accelerometer
for non-invasive monitoring of farmed fish with re-programmable schedule
protocols.The device was attached to the operculum of gilthead sea bream and
European sea bass juveniles for monitoring their physical activity by
measurements of movement accelerations in x and y-axes, while records of
operculum beats served as a measurement of respiratory frequency. Data
post-processing of exercised fish in swimming test chambers revealed an
exponential increase of fish accelerations with the increase of fish speed from
1 body-length to 4 body-lengths per second, while a close relationship between
oxygen consumption and opercular frequency was consistently found.The
usefulness of low computational load for data pre-processing with on-board
algorithms was verified from low to submaximal exercise, increasing this
procedure the autonomy of the system up to 6 h of data recording with different
programmable schedules. Visual observations regarding tissue damage, feeding
behavior and circulating levels of stress markers did not reveal at short term
a negative impact of device tagging. Reduced plasma levels of triglycerides
revealed a transient inhibition of feed intake in small fish, but this
disturbance was not detected in larger fish. All this considered together is
the proof of concept that miniaturized devices are suitable for non-invasive
and reliable metabolic phenotyping of farmed fish to improve their overall
performance and welfare. Further work is underway for improving the attachment
procedure and the full device packaging.
</p>
</div>
</dd>
<dt><a name=item306>[306]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17072 title=Abstract>arXiv:2401.17072</a> [<a href=https://arxiv.org/pdf/2401.17072 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17072 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aynetdinov%2C+A">Ansar Aynetdinov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akbik%2C+A">Alan Akbik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Instruction-tuned Large Language Models (LLMs) have recently showcased
remarkable advancements in their ability to generate fitting responses to
natural language instructions. However, many current works rely on manual
evaluation to judge the quality of generated responses. Since such manual
evaluation is time-consuming, it does not easily scale to the evaluation of
multiple models and model variants. In this short paper, we propose a
straightforward but remarkably effective evaluation metric called SemScore, in
which we directly compare model outputs to gold target responses using semantic
textual similarity (STS). We conduct a comparative evaluation of the model
outputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluation
metrics for text generation. We find that our proposed SemScore metric
outperforms all other, in many cases more complex, evaluation metrics in terms
of correlation to human evaluation. These findings indicate the utility of our
proposed metric for the evaluation of instruction-tuned LLMs.
</p>
</div>
</dd>
<dt><a name=item307>[307]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17075 title=Abstract>arXiv:2401.17075</a> [<a href=https://arxiv.org/pdf/2401.17075 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17075 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Non-central panorama indoor dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berenguel-Baeta%2C+B">Bruno Berenguel-Baeta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bermudez-Cameo%2C+J">Jesus Bermudez-Cameo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerrero%2C+J+J">Jose J. Guerrero</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Data in Brief 2022, Volume 43, pp. 108375
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Omnidirectional images are one of the main sources of information for
learning based scene understanding algorithms. However, annotated datasets of
omnidirectional images cannot keep the pace of these learning based algorithms
development. Among the different panoramas and in contrast to standard central
ones, non-central panoramas provide geometrical information in the distortion
of the image from which we can retrieve 3D information of the environment [2].
However, due to the lack of commercial non-central devices, up until now there
was no dataset of these kinds of panoramas. In this data paper, we present the
first dataset of non-central panoramas for indoor scene understanding. The
dataset is composed by {\bf 2574} RGB non-central panoramas taken in around 650
different rooms. Each panorama has associated a depth map and annotations to
obtain the layout of the room from the image as a structural edge map, list of
corners in the image, the 3D corners of the room and the camera pose. The
images are taken from photorealistic virtual environments and pixel-wise
automatically annotated.
</p>
</div>
</dd>
<dt><a name=item308>[308]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17082 title=Abstract>arXiv:2401.17082</a> [<a href=https://arxiv.org/pdf/2401.17082 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17082 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Casting manipulation of unknown string by robot arm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tabata%2C+K">Kenta Tabata</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Seki%2C+H">Hiroaki Seki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsuji%2C+T">Tokuo Tsuji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hiramitsu%2C+T">Tatsuhiro Hiramitsu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to IROS 2021
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2021 IEEE/RSJ International Conference on Intelligent Robots and
 Systems (IROS)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Casting manipulation has been studied to expand the robot's movable range. In
this manipulation, the robot throws and reaches the end effector to a distant
target. Usually, a special casting manipulator, which consists of rigid arm
links and specific flexible linear objects, is constructed for an effective
casting manipulation. However, the special manipulator cannot perform normal
manipulations, such as picking and placing, grasping, and operating objects. We
propose that the normal robot arm, which can perform normal tasks, picks up an
unknown string in the surrounding environment and realizes casting manipulation
with it. As the properties of the string are not provided in advance, it is
crucial how to reflect it in casting manipulation. This is realized by the
motion generation of the robot arm with the simulation of string movement,
actual string manipulation by the robot arm, and string parameter estimation
from the actual string movement. After repeating these three steps, the
simulated string movement approximates the actual to realize casting
manipulation with the unknown string. We confirmed the effectiveness of the
proposed method through experiments. The try of this study will lead to
enhancement of the performance of home service robot, exploration robot, rescue
robot and entertainment robot.
</p>
</div>
</dd>
<dt><a name=item309>[309]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17083 title=Abstract>arXiv:2401.17083</a> [<a href=https://arxiv.org/pdf/2401.17083 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17083 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Robot Navigation and and Manipulation with Distilled Vision-Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kangcheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xinhu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaoqun Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hesheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M">Ming Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+K">Kai Tang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICRA 2024 (Oral), Prof. Kangcheng Liu is the corresponding author
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Autonomous robot navigation within the dynamic unknown environment is of
crucial significance for mobile robotic applications including robot navigation
in last-mile delivery and robot-enabled automated supplies in industrial and
hospital delivery applications. Current solutions still suffer from
limitations, such as the robot cannot recognize unknown objects in real time
and cannot navigate freely in a dynamic, narrow, and complex environment. We
propose a complete software framework for autonomous robot perception and
navigation within very dense obstacles and dense human crowds. First, we
propose a framework that accurately detects and segments open-world object
categories in a zero-shot manner, which overcomes the over-segmentation
limitation of the current SAM model. Second, we proposed the distillation
strategy to distill the knowledge to segment the free space of the walkway for
robot navigation without the label. In the meantime, we design the trimming
strategy that works collaboratively with distillation to enable lightweight
inference to deploy the neural network on edge devices such as NVIDIA-TX2 or
Xavier NX during autonomous navigation. Integrated into the robot navigation
system, extensive experiments demonstrate that our proposed framework has
achieved superior performance in terms of both accuracy and efficiency in robot
scene perception and autonomous robot navigation.
</p>
</div>
</dd>
<dt><a name=item310>[310]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17084 title=Abstract>arXiv:2401.17084</a> [<a href=https://arxiv.org/pdf/2401.17084 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17084 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17084 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-150-Frame tabindex=0><nobr><span class=math id=MathJax-Span-887 style=width:2.734em;display:inline-block><span style=display:inline-block;position:relative;width:2.271em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1002.23em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-888><span class=mn id=MathJax-Span-889 style=font-family:MathJax_Main>2</span><span class=mo id=MathJax-Span-890 style=font-family:MathJax_Main;padding-left:0.234em>×</span><span class=mn id=MathJax-Span-891 style=font-family:MathJax_Main;padding-left:0.234em>2</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span> MIMO Gaussian Channels with a Small Discrete-Time Peak-Power Constraint
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dytso%2C+A">Alex Dytso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barletta%2C+L">Luca Barletta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kramer%2C+G">Gerhard Kramer</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 1 figure. Submitted to IEEE ISIT 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>A multi-input multi-output (MIMO) Gaussian channel with two transmit antennas
and two receive antennas is studied that is subject to an input peak-power
constraint. The capacity and the capacity-achieving input distribution are
unknown in general. The problem is shown to be equivalent to a channel with an
identity matrix but where the input lies inside and on an ellipse with
principal axis length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-151-Frame tabindex=0><nobr><span class=math id=MathJax-Span-892 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1000.87em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-893><span class=msubsup id=MathJax-Span-894><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-895 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-896 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> and minor axis length <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-152-Frame tabindex=0><nobr><span class=math id=MathJax-Span-897 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1001.16em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-898><span class=msubsup id=MathJax-Span-899><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-900 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-901 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>. If <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-153-Frame tabindex=0><nobr><span class=math id=MathJax-Span-902 style=width:4.343em;display:inline-block><span style=display:inline-block;position:relative;width:3.591em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.59em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-903><span class=msubsup id=MathJax-Span-904><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-905 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-906 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-907 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=msqrt id=MathJax-Span-908 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-909><span class=mn id=MathJax-Span-910 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.511em;left:0.813em><span style=font-family:MathJax_Main>–</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>,
then the capacity-achieving input has support on the ellipse. A sufficient
condition is derived under which a two-point distribution is optimal. Finally,
if <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-154-Frame tabindex=0><nobr><span class=math id=MathJax-Span-911 style=width:7.295em;display:inline-block><span style=display:inline-block;position:relative;width:6.079em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1006.08em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-912><span class=msubsup id=MathJax-Span-913><span style=display:inline-block;position:relative;width:1.16em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-914 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-915 style=font-size:70.7%;font-family:MathJax_Math-italic>m</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-916 style=font-family:MathJax_Main;padding-left:0.292em>&lt;</span><span class=msubsup id=MathJax-Span-917 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-918 style=font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-919 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-920 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=msqrt id=MathJax-Span-921 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:1.334em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.47em,4.17em,-999.997em);top:-3.99em;left:0.813em><span class=mrow id=MathJax-Span-922><span class=mn id=MathJax-Span-923 style=font-family:MathJax_Main>2</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1000.52em,3.938em,-999.997em);top:-4.511em;left:0.813em><span style=font-family:MathJax_Main>–</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.012em,1000.87em,4.343em,-999.997em);top:-4.048em;left:0em><span style=font-family:MathJax_Main>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, then the capacity-achieving distribution is
discrete.
</p>
</div>
</dd>
<dt><a name=item311>[311]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17086 title=Abstract>arXiv:2401.17086</a> [<a href=https://arxiv.org/pdf/2401.17086 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17086 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Active Generation Network of Human Skeleton for Action Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Long Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+F">Fangming Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiayu Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Data generation is a data augmentation technique for enhancing the
generalization ability for skeleton-based human action recognition. Most
existing data generation methods face challenges to ensure the temporal
consistency of the dynamic information for action. In addition, the data
generated by these methods lack diversity when only a few training samples are
available. To solve those problems, We propose a novel active generative
network (AGN), which can adaptively learn various action categories by motion
style transfer to generate new actions when the data for a particular action is
only a single sample or few samples. The AGN consists of an action generation
network and an uncertainty metric network. The former, with ST-GCN as the
Backbone, can implicitly learn the morphological features of the target action
while preserving the category features of the source action. The latter guides
generating actions. Specifically, an action recognition model generates
prediction vectors for each action, which is then scored using an uncertainty
metric. Finally, UMN provides the uncertainty sampling basis for the generated
actions.
</p>
</div>
</dd>
<dt><a name=item312>[312]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17089 title=Abstract>arXiv:2401.17089</a> [<a href=https://arxiv.org/pdf/2401.17089 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17089 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17089 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Copula-based Estimation of Continuous Sources for a Class of Constrained Rate-Distortion-Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Serra%2C+G">Giuseppe Serra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stavrou%2C+P+A">Photios A. Stavrou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kountouris%2C+M">Marios Kountouris</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
<p class=mathjax>We present a new method to estimate the rate-distortion-perception function
in the perfect realism regime (PR-RDPF), for multivariate continuous sources
subject to a single-letter average distortion constraint. The proposed approach
is not only able to solve the specific problem but also two related problems:
the entropic optimal transport (EOT) and the output-constrained rate-distortion
function (OC-RDF), of which the PR-RDPF represents a special case. Using copula
distributions, we show that the OC-RDF can be cast as an I-projection problem
on a convex set, based on which we develop a parametric solution of the optimal
projection proving that its parameters can be estimated, up to an arbitrary
precision, via the solution of a convex program. Subsequently, we propose an
iterative scheme via gradient methods to estimate the convex program. Lastly,
we characterize a Shannon lower bound (SLB) for the PR-RDPF under a mean
squared error (MSE) distortion constraint. We support our theoretical findings
with numerical examples by assessing the estimation performance of our
iterative scheme using the PR-RDPF with the obtained SLB for various sources.
</p>
</div>
</dd>
<dt><a name=item313>[313]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17092 title=Abstract>arXiv:2401.17092</a> [<a href=https://arxiv.org/pdf/2401.17092 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17092 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NNOSE: Nearest Neighbor Occupational Skill Extraction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mike Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=van+der+Goot%2C+R">Rob van der Goot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kan%2C+M">Min-Yen Kan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Plank%2C+B">Barbara Plank</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at EACL 2024 Main
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The labor market is changing rapidly, prompting increased interest in the
automatic extraction of occupational skills from text. With the advent of
English benchmark job description datasets, there is a need for systems that
handle their diversity well. We tackle the complexity in occupational skill
datasets tasks -- combining and leveraging multiple datasets for skill
extraction, to identify rarely observed skills within a dataset, and overcoming
the scarcity of skills across datasets. In particular, we investigate the
retrieval-augmentation of language models, employing an external datastore for
retrieving similar skills in a dataset-unifying manner. Our proposed method,
\textbf{N}earest \textbf{N}eighbor \textbf{O}ccupational \textbf{S}kill
\textbf{E}xtraction (NNOSE) effectively leverages multiple datasets by
retrieving neighboring skills from other datasets in the datastore. This
improves skill extraction \emph{without} additional fine-tuning. Crucially, we
observe a performance gain in predicting infrequent patterns, with substantial
gains of up to 30\% span-F1 in cross-dataset settings.
</p>
</div>
</dd>
<dt><a name=item314>[314]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17093 title=Abstract>arXiv:2401.17093</a> [<a href=https://arxiv.org/pdf/2401.17093 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17093 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+Z">Zecheng Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Chenfei Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zekai Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+M">Mingheng Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+S">Shengming Yin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lijuan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Juntao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duan%2C+N">Nan Duan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
<p class=mathjax>To leverage LLMs for visual synthesis, traditional methods convert raster
image information into discrete grid tokens through specialized visual modules,
while disrupting the model's ability to capture the true semantic
representation of visual scenes. This paper posits that an alternative
representation of images, vector graphics, can effectively surmount this
limitation by enabling a more natural and semantically coherent segmentation of
the image information. Thus, we introduce StrokeNUWA, a pioneering work
exploring a better visual representation ''stroke tokens'' on vector graphics,
which is inherently visual semantics rich, naturally compatible with LLMs, and
highly compressed. Equipped with stroke tokens, StrokeNUWA can significantly
surpass traditional LLM-based and optimization-based methods across various
metrics in the vector graphic generation task. Besides, StrokeNUWA achieves up
to a 94x speedup in inference over the speed of prior methods with an
exceptional SVG code compression ratio of 6.9%.
</p>
</div>
</dd>
<dt><a name=item315>[315]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17095 title=Abstract>arXiv:2401.17095</a> [<a href=https://arxiv.org/pdf/2401.17095 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17095 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Traffic estimation in unobserved network locations using data-driven macroscopic models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guarda%2C+P">Pablo Guarda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+S">Sean Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 34 pages, 28 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>This paper leverages macroscopic models and multi-source spatiotemporal data
collected from automatic traffic counters and probe vehicles to accurately
estimate traffic flow and travel time in links where these measurements are
unavailable. This problem is critical in transportation planning applications
where the sensor coverage is low and the planned interventions have
network-wide impacts. The proposed model, named the Macroscopic Traffic
Estimator (MaTE), can perform network-wide estimations of traffic flow and
travel time only using the set of observed measurements of these quantities.
Because MaTE is grounded in macroscopic flow theory, all parameters and
variables are interpretable. The estimated traffic flow satisfies fundamental
flow conservation constraints and exhibits an increasing monotonic relationship
with the estimated travel time. Using logit-based stochastic traffic assignment
as the principle for routing flow behavior makes the model fully differentiable
with respect to the model parameters. This property facilitates the application
of computational graphs to learn parameters from vast amounts of spatiotemporal
data. We also integrate neural networks and polynomial kernel functions to
capture link flow interactions and enrich the mapping of traffic flows into
travel times. MaTE also adds a destination choice model and a trip generation
model that uses historical data on the number of trips generated by location.
Experiments on synthetic data show that the model can accurately estimate
travel time and traffic flow in out-of-sample links. Results obtained using
real-world multi-source data from a large-scale transportation network suggest
that MaTE outperforms data-driven benchmarks, especially in travel time
estimation. The estimated parameters of MaTE are also informative about the
hourly change in travel demand and supply characteristics of the transportation
network.
</p>
</div>
</dd>
<dt><a name=item316>[316]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17098 title=Abstract>arXiv:2401.17098</a> [<a href=https://arxiv.org/pdf/2401.17098 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17098 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17098 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CharNet: Generalized Approach for High-Complexity Character Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kriuk%2C+B">Boris Kriuk</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 14 figures, preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Handwritten character recognition (HCR) is a challenging problem for machine
learning researchers. Unlike printed text data, handwritten character datasets
have more variation due to human-introduced bias. With numerous unique
character classes present, some data, such as Logographic Scripts or
Sino-Korean character sequences, bring new complications to the HCR problem.
The classification task on such datasets requires the model to learn
high-complexity details of the images that share similar features. With recent
advances in computational resource availability and further computer vision
theory development, some research teams have effectively addressed the arising
challenges. Although known for achieving high efficiency, many common
approaches are still not generalizable and use dataset-specific solutions to
achieve better results. Due to complex structure and high computing demands,
existing methods frequently prevent the solutions from gaining popularity. This
paper proposes a straightforward, generalizable, and highly effective approach
(CharNet) for detailed character image classification and compares its
performance to that of existing approaches.
</p>
</div>
</dd>
<dt><a name=item317>[317]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17099 title=Abstract>arXiv:2401.17099</a> [<a href=https://arxiv.org/pdf/2401.17099 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17099 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MT-Ranker: Reference-free machine translation evaluation by inter-system ranking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moosa%2C+I+M">Ibraheem Muhammad Moosa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+W">Wenpeng Yin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 4 figures, to be published in ICLR'24, Code available at <a href=https://github.com/ibraheem-moosa/mt-ranker>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Traditionally, Machine Translation (MT) Evaluation has been treated as a
regression problem -- producing an absolute translation-quality score. This
approach has two limitations: i) the scores lack interpretability, and human
annotators struggle with giving consistent scores; ii) most scoring methods are
based on (reference, translation) pairs, limiting their applicability in
real-world scenarios where references are absent. In practice, we often care
about whether a new MT system is better or worse than some competitors. In
addition, reference-free MT evaluation is increasingly practical and necessary.
Unfortunately, these two practical considerations have yet to be jointly
explored. In this work, we formulate the reference-free MT evaluation into a
pairwise ranking problem. Given the source sentence and a pair of translations,
our system predicts which translation is better. In addition to proposing this
new formulation, we further show that this new paradigm can demonstrate
superior correlation with human judgments by merely using indirect supervision
from natural language inference and weak supervision from our synthetic data.
In the context of reference-free evaluation, MT-Ranker, trained without any
human annotations, achieves state-of-the-art results on the WMT Shared Metrics
Task benchmarks DARR20, MQM20, and MQM21. On a more challenging benchmark,
ACES, which contains fine-grained evaluation criteria such as addition,
omission, and mistranslation errors, MT-Ranker marks state-of-the-art against
reference-free as well as reference-based baselines.
</p>
</div>
</dd>
<dt><a name=item318>[318]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17100 title=Abstract>arXiv:2401.17100</a> [<a href=https://arxiv.org/pdf/2401.17100 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17100 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Influence of Presentation and Performance on User Satisfaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pathak%2C+K">Kanaad Pathak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azzopardi%2C+L">Leif Azzopardi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Halvey%2C+M">Martin Halvey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear as a full paper at CHIIR 2024, Sheffield, UK
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)
</div>
<p class=mathjax>The effectiveness of an IR system is gauged not just by its ability to
retrieve relevant results but also by how it presents these results to users;
an engaging presentation often correlates with increased user satisfaction.
While existing research has delved into the link between user satisfaction, IR
performance metrics, and presentation, these aspects have typically been
investigated in isolation. Our research aims to bridge this gap by examining
the relationship between query performance, presentation and user satisfaction.
For our analysis, we conducted a between-subjects experiment comparing the
effectiveness of various result card layouts for an ad-hoc news search
interface. Drawing data from the TREC WaPo 2018 collection, we centered our
study on four specific topics. Within each of these topics, we assessed six
distinct queries with varying nDCG values. Our study involved 164 participants
who were exposed to one of five distinct layouts containing result cards, such
as "title'', "title+image'', or "title+image+summary''. Our findings indicate
that while nDCG is a strong predictor of user satisfaction at the query level,
there exists no linear relationship between the performance of the query,
presentation of results and user satisfaction. However, when considering the
total gain on the initial result page, we observed that presentation does play
a significant role in user satisfaction (at the query level) for certain
layouts with result cards such as, title+image or title+image+summary. Our
results also suggest that the layout differences have complex and multifaceted
impacts on satisfaction. We demonstrate the capacity to equalize user
satisfaction levels between queries of varying performance by changing how
results are presented. This emphasizes the necessity to harmonize both
performance and presentation in IR systems, considering users' diverse
preferences.
</p>
</div>
</dd>
<dt><a name=item319>[319]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17108 title=Abstract>arXiv:2401.17108</a> [<a href=https://arxiv.org/pdf/2401.17108 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17108 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Joint Semantic Communication and Target Sensing for 6G Communication System
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yinchao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shikh-Bahaei%2C+M">Mohammad Shikh-Bahaei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chongwen Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+W">Wei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>This paper investigates the secure resource allocation for a downlink
integrated sensing and communication system with multiple legal users and
potential eavesdroppers. In the considered model, the base station (BS)
simultaneously transmits sensing and communication signals through beamforming
design, where the sensing signals can be viewed as artificial noise to enhance
the security of communication signals. To further enhance the security in the
semantic layer, the semantic information is extracted from the original
information before transmission. The user side can only successfully recover
the received information with the help of the knowledge base shared with the
BS, which is stored in advance. Our aim is to maximize the sum semantic secrecy
rate of all users while maintaining the minimum quality of service for each
user and guaranteeing overall sensing performance. To solve this sum semantic
secrecy rate maximization problem, an iterative algorithm is proposed using the
alternating optimization method. The simulation results demonstrate the
superiority of the proposed algorithm in terms of secure semantic communication
and reliable detection.
</p>
</div>
</dd>
<dt><a name=item320>[320]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17109 title=Abstract>arXiv:2401.17109</a> [<a href=https://arxiv.org/pdf/2401.17109 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17109 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluation in Neural Style Transfer: A Review
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioannou%2C+E">Eleftherios Ioannou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maddock%2C+S">Steve Maddock</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 21 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
</div>
<p class=mathjax>The field of Neural Style Transfer (NST) has witnessed remarkable progress in
the past few years, with approaches being able to synthesize artistic and
photorealistic images and videos of exceptional quality. To evaluate such
results, a diverse landscape of evaluation methods and metrics is used,
including authors' opinions based on side-by-side comparisons, human evaluation
studies that quantify the subjective judgements of participants, and a
multitude of quantitative computational metrics which objectively assess the
different aspects of an algorithm's performance. However, there is no consensus
regarding the most suitable and effective evaluation procedure that can
guarantee the reliability of the results. In this review, we provide an
in-depth analysis of existing evaluation techniques, identify the
inconsistencies and limitations of current evaluation methods, and give
recommendations for standardized evaluation practices. We believe that the
development of a robust evaluation framework will not only enable more
meaningful and fairer comparisons among NST methods but will also enhance the
comprehension and interpretation of research findings in the field.
</p>
</div>
</dd>
<dt><a name=item321>[321]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17115 title=Abstract>arXiv:2401.17115</a> [<a href=https://arxiv.org/pdf/2401.17115 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17115 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17115 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Identifying Quality Mersenne Twister Streams For Parallel Stochastic Simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antunes%2C+B">Benjamin Antunes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mazel%2C+C">Claude Mazel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hill%2C+D+R+C">David R.C Hill</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages, 3 tables, 2 figures. To be published in Winter Simulation Conference 2023. (Accepted paper, already presented at conf) Publication by ACM/IEEE should happen soon. We revised the layout
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>The Mersenne Twister (MT) is a pseudo-random number generator (PRNG) widely
used in High Performance Computing for parallel stochastic simulations. We aim
to assess the quality of common parallelization techniques used to generate
large streams of MT pseudo-random numbers. We compare three techniques:
sequence splitting, random spacing and MT indexed sequence. The TestU01 Big
Crush battery is used to evaluate the quality of 4096 streams for each
technique on three different hardware configurations. Surprisingly, all
techniques exhibited almost 30% of defects with no technique showing better
quality than the others. While all 106 Big Crush tests showed failures, the
failure rate was limited to a small number of tests (maximum of 6 tests failed
per stream, resulting in over 94% success rate). Thanks to 33 CPU years,
high-quality streams identified are given. They can be used for sensitive
parallel simulations such as nuclear medicine and precise high-energy physics
applications.
</p>
</div>
</dd>
<dt><a name=item322>[322]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17117 title=Abstract>arXiv:2401.17117</a> [<a href=https://arxiv.org/pdf/2401.17117 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17117 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+Z">Zian Ning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jianan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S">Shiyu Zhao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Vision-based estimation of the motion of a moving target is usually
formulated as a bearing-only estimation problem where the visual measurement is
modeled as a bearing vector. Although the bearing-only approach has been
studied for decades, a fundamental limitation of this approach is that it
requires extra lateral motion of the observer to enhance the target's
observability. Unfortunately, the extra lateral motion conflicts with the
desired motion of the observer in many tasks. It is well-known that, once a
target has been detected in an image, a bounding box that surrounds the target
can be obtained. Surprisingly, this common visual measurement especially its
size information has not been well explored up to now. In this paper, we
propose a new bearing-angle approach to estimate the motion of a target by
modeling its image bounding box as bearing-angle measurements. Both theoretical
analysis and experimental results show that this approach can significantly
enhance the observability without relying on additional lateral motion of the
observer. The benefit of the bearing-angle approach comes with no additional
cost because a bounding box is a standard output of object detection
algorithms. The approach simply exploits the information that has not been
fully exploited in the past. No additional sensing devices or special detection
algorithms are required.
</p>
</div>
</dd>
<dt><a name=item323>[323]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17118 title=Abstract>arXiv:2401.17118</a> [<a href=https://arxiv.org/pdf/2401.17118 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17118 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explainable data-driven modeling via mixture of experts: towards effective blending of grey and black-box models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leoni%2C+J">Jessica Leoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Breschi%2C+V">Valentina Breschi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Formentin%2C+S">Simone Formentin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanelli%2C+M">Mara Tanelli</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to Automatica
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>Traditional models grounded in first principles often struggle with accuracy
as the system's complexity increases. Conversely, machine learning approaches,
while powerful, face challenges in interpretability and in handling physical
constraints. Efforts to combine these models often often stumble upon
difficulties in finding a balance between accuracy and complexity. To address
these issues, we propose a comprehensive framework based on a "mixture of
experts" rationale. This approach enables the data-based fusion of diverse
local models, leveraging the full potential of first-principle-based priors.
Our solution allows independent training of experts, drawing on techniques from
both machine learning and system identification, and it supports both
collaborative and competitive learning paradigms. To enhance interpretability,
we penalize abrupt variations in the expert's combination. Experimental results
validate the effectiveness of our approach in producing an interpretable
combination of models closely resembling the target phenomena.
</p>
</div>
</dd>
<dt><a name=item324>[324]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17120 title=Abstract>arXiv:2401.17120</a> [<a href=https://arxiv.org/pdf/2401.17120 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17120 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+R">Rong Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+H">Hai-Chuan Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Chuanzhang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 14 figures, The ACM CHI 2024 conference
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Landscape renderings are realistic images of landscape sites, allowing
stakeholders to perceive better and evaluate design ideas. While recent
advances in Generative Artificial Intelligence (GAI) enable automated
generation of landscape renderings, the end-to-end methods are not compatible
with common design processes, leading to insufficient alignment with design
idealizations and limited cohesion of iterative landscape design. Informed by a
formative study for comprehending design requirements, we present PlantoGraphy,
an iterative design system that allows for interactive configuration of GAI
models to accommodate human-centered design practice. A two-stage pipeline is
incorporated: first, concretization module transforms conceptual ideas into
concrete scene layouts with a domain-oriented large language model; and second,
illustration module converts scene layouts into realistic landscape renderings
using a fine-tuned low-rank adaptation diffusion model. PlantoGraphy has
undergone a series of performance evaluations and user studies, demonstrating
its effectiveness in landscape rendering generation and the high recognition of
its interactive functionality.
</p>
</div>
</dd>
<dt><a name=item325>[325]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17121 title=Abstract>arXiv:2401.17121</a> [<a href=https://arxiv.org/pdf/2401.17121 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17121 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Physical Priors Augmented Event-Based 3D Reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaxu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+J">Junhao He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziyi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 6 figures, ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>3D neural implicit representations play a significant component in many
robotic applications. However, reconstructing neural radiance fields (NeRF)
from realistic event data remains a challenge due to the sparsities and the
lack of information when only event streams are available. In this paper, we
utilize motion, geometry, and density priors behind event data to impose strong
physical constraints to augment NeRF training. The proposed novel pipeline can
directly benefit from those priors to reconstruct 3D scenes without additional
inputs. Moreover, we present a novel density-guided patch-based sampling
strategy for robust and efficient learning, which not only accelerates training
procedures but also conduces to expressions of local geometries. More
importantly, we establish the first large dataset for event-based 3D
reconstruction, which contains 101 objects with various materials and
geometries, along with the groundtruth of images and depth maps for all camera
viewpoints, which significantly facilitates other research in the related
fields. The code and dataset will be publicly available at
https://github.com/Mercerai/PAEv3d.
</p>
</div>
</dd>
<dt><a name=item326>[326]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17122 title=Abstract>arXiv:2401.17122</a> [<a href=https://arxiv.org/pdf/2401.17122 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17122 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17122 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Study of Applicability of Simple Closed Loop Input Impedance Model for Grid-Tie Inverters
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Santamargarita%2C+D">Daniel Santamargarita</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Huerta%2C+F">Francisco Huerta</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanz%2C+M">Marina Sanz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lazaro%2C+A">Antonio Lazaro</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=DArco%2C+S">Salvatore DArco</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sanchez%2C+S">Santiago Sanchez</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tedeschi%2C+E">Elisabetta Tedeschi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Roldan%2C+J">Javier Roldan</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IECON 2019, 45th Annual Conference of the IEEE Industrial
 Electronics Society, Lisbon, Portugal, 2019, pp. 2026-2031
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>In recent years the need for DC distribution buses has increased
considerably. As it can be noticed in the transport for example the
distribution systems of the more electric aircrafts, ships, or electric cars.
Given the complexities of the systems presented above, the need to use more and
more switched power converters has arisen. The main problem of the connection
of multiple controlled switched converters acting as source and load is the
degradation of stability that occurs on the DC distribution bus due to the
converter interactions. To study the stability in the distribution bus there
are some wellestablished criteria. These criteria require knowledge of the
input impedance of the converters that act as load and the output impedance of
the equipment that acts as source. In order to reduce the complexity of
obtaining the input impedance a model based on a controlled converter acting as
a constant power load (CPL) is commonly used. This article studies the accuracy
of this model for a commonly used topology in distribution systems nowadays,
Two Level Voltage Source Converter (2L-VSC), studying different scenarios that
make the model become inaccurate.
</p>
</div>
</dd>
<dt><a name=item327>[327]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17123 title=Abstract>arXiv:2401.17123</a> [<a href=https://arxiv.org/pdf/2401.17123 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17123 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shengchao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengpeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiarui Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+W">Weili Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Hanchen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuoxinran Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bolei Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jian Tang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Deep generative models (DGMs) have been widely developed for graph data.
However, much less investigation has been carried out on understanding the
latent space of such pretrained graph DGMs. These understandings possess the
potential to provide constructive guidelines for crucial tasks, such as graph
controllable generation. Thus in this work, we are interested in studying this
problem and propose GraphCG, a method for the unsupervised discovery of
steerable factors in the latent space of pretrained graph DGMs. We first
examine the representation space of three pretrained graph DGMs with six
disentanglement metrics, and we observe that the pretrained representation
space is entangled. Motivated by this observation, GraphCG learns the steerable
factors via maximizing the mutual information between semantic-rich directions,
where the controlled graph moving along the same direction will share the same
steerable factors. We quantitatively verify that GraphCG outperforms four
competitive baselines on two graph DGMs pretrained on two molecule datasets.
Additionally, we qualitatively illustrate seven steerable factors learned by
GraphCG on five pretrained DGMs over five graph datasets, including two for
molecules and three for point clouds.
</p>
</div>
</dd>
<dt><a name=item328>[328]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17124 title=Abstract>arXiv:2401.17124</a> [<a href=https://arxiv.org/pdf/2401.17124 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17124 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spectral Co-Distillation for Personalized Federated Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zihan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H+H">Howard H. Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chong%2C+K+F+E">Kai Fong Ernest Chong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, NeurIPS 2023. Code at <a href=https://github.com/jimmyc96/spectral-dis-FL>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)
</div>
<p class=mathjax>Personalized federated learning (PFL) has been widely investigated to address
the challenge of data heterogeneity, especially when a single generic model is
inadequate in satisfying the diverse performance requirements of local clients
simultaneously. Existing PFL methods are inherently based on the idea that the
relations between the generic global and personalized local models are captured
by the similarity of model weights. Such a similarity is primarily based on
either partitioning the model architecture into generic versus personalized
components, or modeling client relationships via model weights. To better
capture similar (yet distinct) generic versus personalized model
representations, we propose \textit{spectral distillation}, a novel
distillation method based on model spectrum information. Building upon spectral
distillation, we also introduce a co-distillation framework that establishes a
two-way bridge between generic and personalized model training. Moreover, to
utilize the local idle time in conventional PFL, we propose a wait-free local
training protocol. Through extensive experiments on multiple datasets over
diverse heterogeneous data settings, we demonstrate the outperformance and
efficacy of our proposed spectral co-distillation method, as well as our
wait-free training protocol.
</p>
</div>
</dd>
<dt><a name=item329>[329]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17125 title=Abstract>arXiv:2401.17125</a> [<a href=https://arxiv.org/pdf/2401.17125 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17125 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Characterising resource management performance in Kubernetes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Medel%2C+V">Víctor Medel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tolosana-Calasanz%2C+R">Rafael Tolosana-Calasanz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ba%C3%B1ares%2C+J+%C3%81">José Ángel Bañares</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arronategui%2C+U">Unai Arronategui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rana%2C+O+F">Omer F. Rana</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Computers &amp; Electrical Engineering Volume 68, May 2018, Pages
 286-297
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>
</div>
<p class=mathjax>A key challenge for supporting elastic behaviour in cloud systems is to
achieve a good performance in automated (de-)provisioning and scheduling of
computing resources. One of the key aspects that can be significant is the
overheads associated with deploying, terminating and maintaining resources.
Therefore, due to their lower start up and termination overhead, containers are
rapidly replacing Virtual Machines (VMs) in many cloud deployments, as the
computation instance of choice. In this paper, we analyse the performance of
Kubernetes achieved through a Petri net-based performance model. Kubernetes is
a container management system for a distributed cluster environment. Our model
can be characterised using data from a Kubernetes deployment, and can be
exploited for supporting capacity planning and designing Kubernetes-based
elastic applications.
</p>
</div>
</dd>
<dt><a name=item330>[330]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17127 title=Abstract>arXiv:2401.17127</a> [<a href=https://arxiv.org/pdf/2401.17127 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17127 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Personalized Differential Privacy for Ridge Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Acharya%2C+K">Krishna Acharya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boenisch%2C+F">Franziska Boenisch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Naidu%2C+R">Rakshit Naidu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziani%2C+J">Juba Ziani</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)
</div>
<p class=mathjax>The increased application of machine learning (ML) in sensitive domains
requires protecting the training data through privacy frameworks, such as
differential privacy (DP). DP requires to specify a uniform privacy level
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-155-Frame tabindex=0><nobr><span class=math id=MathJax-Span-924 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.41em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-925><span class=mi id=MathJax-Span-926 style=font-family:MathJax_Math-italic>ε</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> that expresses the maximum privacy loss that each data point in
the entire dataset is willing to tolerate. Yet, in practice, different data
points often have different privacy requirements. Having to set one uniform
privacy level is usually too restrictive, often forcing a learner to guarantee
the stringent privacy requirement, at a large cost to accuracy. To overcome
this limitation, we introduce our novel Personalized-DP Output Perturbation
method (PDP-OP) that enables to train Ridge regression models with individual
per data point privacy levels. We provide rigorous privacy proofs for our
PDP-OP as well as accuracy guarantees for the resulting model. This work is the
first to provide such theoretical accuracy guarantees when it comes to
personalized DP in machine learning, whereas previous work only provided
empirical evaluations. We empirically evaluate PDP-OP on synthetic and real
datasets and with diverse privacy distributions. We show that by enabling each
data point to specify their own privacy requirement, we can significantly
improve the privacy-accuracy trade-offs in DP. We also show that PDP-OP
outperforms the personalized privacy techniques of Jorgensen et al. (2015).
</p>
</div>
</dd>
<dt><a name=item331>[331]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17129 title=Abstract>arXiv:2401.17129</a> [<a href=https://arxiv.org/pdf/2401.17129 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17129 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roman%2C+A+S">Adrian S. Roman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balamurugan%2C+B">Baladithya Balamurugan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pothuganti%2C+R">Rithik Pothuganti</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>This technical report details our work towards building an enhanced
audio-visual sound event localization and detection (SELD) network. We build on
top of the audio-only SELDnet23 model and adapt it to be audio-visual by
merging both audio and video information prior to the gated recurrent unit
(GRU) of the audio-only network. Our model leverages YOLO and DETIC object
detectors. We also build a framework that implements audio-visual data
augmentation and audio-visual synthetic data generation. We deliver an
audio-visual SELDnet system that outperforms the existing audio-visual SELD
baseline.
</p>
</div>
</dd>
<dt><a name=item332>[332]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17130 title=Abstract>arXiv:2401.17130</a> [<a href=https://arxiv.org/pdf/2401.17130 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17130 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17130 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Diagonals and Block-Ordered Relations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Backhouse%2C+R">Roland Backhouse</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voermans%2C+E">Ed Voermans</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>More than 70 years ago, Jaques Riguet suggested the existence of an
``analogie frappante'' (striking analogy) between so-called ``relations de
Ferrers'' and a class of difunctional relations, members of which we call
``diagonals''. Inspired by his suggestion, we formulate an ``analogie
frappante'' linking the notion of a block-ordered relation and the notion of
the diagonal of a relation. We formulate several novel properties of the
core/index of a diagonal, and use these properties to rephrase our ``analogie
frappante''. Loosely speaking, we show that a block-ordered relation is a
provisional ordering up to isomorphism and reduction to its core. (Our theorems
make this informal statement precise.) Unlike Riguet (and others who follow his
example), we avoid almost entirely the use of nested complements to express and
reason about properties of these notions: we use factors (aka residuals)
instead. The only (and inevitable) exception to this is to show that our
definition of a ``staircase'' relation is equivalent to Riguet's definition of
a ``relation de Ferrers''. Our ``analogie frappante'' also makes it obvious
that a ``staircase'' relation is not necessarily block-ordered, in spite of the
mental picture of such a relation presented by Riguet.
</p>
</div>
</dd>
<dt><a name=item333>[333]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17133 title=Abstract>arXiv:2401.17133</a> [<a href=https://arxiv.org/pdf/2401.17133 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17133 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guangke Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+F">Fu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Ting Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+X">Xiaoning Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>Singing voice conversion (SVC) automates song covers by converting one
singer's singing voice into another target singer's singing voice with the
original lyrics and melody. However, it raises serious concerns about copyright
and civil right infringements to multiple entities. This work proposes
SongBsAb, the first proactive approach to mitigate unauthorized SVC-based
illegal song covers. SongBsAb introduces human-imperceptible perturbations to
singing voices before releasing them, so that when they are used, the
generation process of SVC will be interfered, resulting in unexpected singing
voices. SongBsAb features a dual prevention effect by causing both (singer)
identity disruption and lyric disruption, namely, the SVC-covered singing voice
neither imitates the target singer nor preserves the original lyrics. To
improve the imperceptibility of perturbations, we refine a psychoacoustic
model-based loss with the backing track as an additional masker, a unique
accompanying element for singing voices compared to ordinary speech voices. To
enhance the transferability, we propose to utilize a frame-level interaction
reduction-based loss. We demonstrate the prevention effectiveness, utility, and
robustness of SongBsAb on three SVC models and two datasets using both
objective and human study-based subjective metrics. Our work fosters an
emerging research direction for mitigating illegal automated song covers.
</p>
</div>
</dd>
<dt><a name=item334>[334]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17134 title=Abstract>arXiv:2401.17134</a> [<a href=https://arxiv.org/pdf/2401.17134 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17134 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Wrist movement classification for adaptive mobile phone based rehabilitation of children with motor skill impairments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schoorl%2C+K">Kayleigh Schoorl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cisneros%2C+T+P">Tamara Pinos Cisneros</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salah%2C+A+A">Albert Ali Salah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schouten%2C+B">Ben Schouten</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 11 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Rehabilitation exercises performed by children with cerebral palsy are
tedious and repetitive. To make them more engaging, we propose to use an
exergame approach, where an adaptive application can help the child remain
stimulated and interested during exercises. In this paper, we describe how the
mobile phone sensors can be used to classify wrist movements of the user during
the rehabilitation exercises to detect if the user is performing the correct
exercise and illustrate the use of our approach in an actual mobile phone
application. We also show how an adaptive difficulty system was added to the
application to allow the system to adjust to the user. We present experimental
results from a pilot with healthy subjects that were constrained to simulate
restricted wrist movements, as well as from tests with a target group of
children with cerebral palsy. Our results show that wrist movement
classification is successfully achieved and results in improved interactions.
</p>
</div>
</dd>
<dt><a name=item335>[335]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17136 title=Abstract>arXiv:2401.17136</a> [<a href=https://arxiv.org/pdf/2401.17136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Systematically Assessing the Security Risks of AI/ML-enabled Connected Healthcare Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elnawawy%2C+M">Mohammed Elnawawy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hallajiyan%2C+M">Mohammadreza Hallajiyan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mitra%2C+G">Gargi Mitra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iqbal%2C+S">Shahrear Iqbal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pattabiraman%2C+K">Karthik Pattabiraman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 5 figures, 3 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
<p class=mathjax>The adoption of machine-learning-enabled systems in the healthcare domain is
on the rise. While the use of ML in healthcare has several benefits, it also
expands the threat surface of medical systems. We show that the use of ML in
medical systems, particularly connected systems that involve interfacing the ML
engine with multiple peripheral devices, has security risks that might cause
life-threatening damage to a patient's health in case of adversarial
interventions. These new risks arise due to security vulnerabilities in the
peripheral devices and communication channels. We present a case study where we
demonstrate an attack on an ML-enabled blood glucose monitoring system by
introducing adversarial data points during inference. We show that an adversary
can achieve this by exploiting a known vulnerability in the Bluetooth
communication channel connecting the glucose meter with the ML-enabled app. We
further show that state-of-the-art risk assessment techniques are not adequate
for identifying and assessing these new risks. Our study highlights the need
for novel risk analysis methods for analyzing the security of AI-enabled
connected health devices.
</p>
</div>
</dd>
<dt><a name=item336>[336]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17139 title=Abstract>arXiv:2401.17139</a> [<a href=https://arxiv.org/pdf/2401.17139 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17139 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Model Evaluation via Matrix Entropy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+L">Lai Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+Z">Zhiquan Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenghai Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jindong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+W">Weiran Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Theory (cs.IT)
</div>
<p class=mathjax>Large language models (LLMs) have revolutionized the field of natural
language processing, extending their strong capabilities into multi-modal
domains. Thus, it is vital to define proper and diversified metrics for the
evaluation of LLMs.
<br>In this paper, we introduce matrix entropy, a novel metric rooted in
information theory and geometry principles to quantify the data compression
proficiency in LLMs. It reflects the model's ability to extract relevant
information and eliminate unnecessary elements, thereby providing insight into
the language model's intrinsic capability. Specifically, we demonstrate its
applicability in both single-modal (language) and multi-modal settings. For
language models, our findings reveal that the matrix entropy of representations
follows a scaling law type reduction when the model scales up, serving as a
complement to the traditional loss scaling law. For the multi-modal setting, we
also propose an evaluation method based on matrix entropy for assessing
alignment quality and we find that modern large multi-modal models exhibit
great alignment performance.
</p>
</div>
</dd>
<dt><a name=item337>[337]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17146 title=Abstract>arXiv:2401.17146</a> [<a href=https://arxiv.org/pdf/2401.17146 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17146 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dependency-Aware Online Caching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dallot%2C+J">Julien Dallot</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fesharaki%2C+A+J">Amirmehdi Jafari Fesharaki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pacut%2C+M">Maciej Pacut</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> INFOCOM 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Data Structures and Algorithms (cs.DS)</span>
</div>
<p class=mathjax>We consider a variant of the online caching problem where the items exhibit
dependencies among each other: an item can reside in the cache only if all its
dependent items are also in the cache. The dependency relations can form any
directed acyclic graph. These requirements arise e.g., in systems such as
CacheFlow (SOSR 2016) that cache forwarding rules for packet classification in
IP-based communication networks.
<br>First, we present an optimal randomized online caching algorithm which
accounts for dependencies among the items. Our randomized algorithm is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-156-Frame tabindex=0><nobr><span class=math id=MathJax-Span-927 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-928><span class=mi id=MathJax-Span-929 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-930 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-931 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-932></span><span class=mi id=MathJax-Span-933 style=font-family:MathJax_Math-italic;padding-left:0.177em>k</span><span class=mo id=MathJax-Span-934 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-competitive, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-157-Frame tabindex=0><nobr><span class=math id=MathJax-Span-935 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-936><span class=mi id=MathJax-Span-937 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is the size of the cache, meaning that our algorithm
never incurs the cost of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-158-Frame tabindex=0><nobr><span class=math id=MathJax-Span-938 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.42em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-939><span class=mi id=MathJax-Span-940 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-941 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-942 style=font-family:MathJax_Main>log</span><span class=mo id=MathJax-Span-943></span><span class=mi id=MathJax-Span-944 style=font-family:MathJax_Math-italic;padding-left:0.177em>k</span><span class=mo id=MathJax-Span-945 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> times higher than even an optimal
algorithm that knows the future input sequence.
<br>Second, we consider the bypassing model, where requests can be served at a
fixed price without fetching the item and its dependencies into the cache -- a
variant of caching with dependencies introduced by Bienkowski et al. at SPAA
2017. For this setting, we give an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-159-Frame tabindex=0><nobr><span class=math id=MathJax-Span-946 style=width:6.947em;display:inline-block><span style=display:inline-block;position:relative;width:5.79em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1005.67em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-947><span class=mi id=MathJax-Span-948 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-949 style=font-family:MathJax_Main>(</span><span class=msqrt id=MathJax-Span-950><span style=display:inline-block;position:relative;width:4.227em;height:0px><span style=position:absolute;clip:rect(3.128em,1003.24em,4.401em,-999.997em);top:-3.99em;left:0.987em><span class=mrow id=MathJax-Span-951><span class=mi id=MathJax-Span-952 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-953 style=font-family:MathJax_Main;padding-left:0.234em>⋅</span><span class=mi id=MathJax-Span-954 style=font-family:MathJax_Main;padding-left:0.234em>log</span><span class=mo id=MathJax-Span-955></span><span class=mi id=MathJax-Span-956 style=font-family:MathJax_Math-italic;padding-left:0.177em>k</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1003.19em,3.938em,-999.997em);top:-4.569em;left:0.987em><span style=display:inline-block;position:relative;width:3.186em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:2.491em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:0.408em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:0.987em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:1.508em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:2.028em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(2.954em,1001.04em,4.517em,-999.997em);top:-3.99em;left:0em><span style=font-family:MathJax_Size1>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-957 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>-competitive
algorithm, which significantly improves the best known competitiveness. We
conduct a small case study, to find out that our algorithm incurs on average 2x
lower cost.
</p>
</div>
</dd>
<dt><a name=item338>[338]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17149 title=Abstract>arXiv:2401.17149</a> [<a href=https://arxiv.org/pdf/2401.17149 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17149 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optical Tactile Sensing for Aerial Multi-Contact Interaction: Design, Integration, and Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aucone%2C+E">Emanuele Aucone</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sferrazza%2C+C">Carmelo Sferrazza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gregor%2C+M">Manuel Gregor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%27Andrea%2C+R">Raffaello D'Andrea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mintchev%2C+S">Stefano Mintchev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Distributed tactile sensing for multi-force detection is crucial for various
aerial robot interaction tasks. However, current contact sensing solutions on
drones only exploit single end-effector sensors and cannot provide distributed
multi-contact sensing. Designed to be easily mounted at the bottom of a drone,
we propose an optical tactile sensor that features a large and curved soft
sensing surface, a hollow structure and a new illumination system. Even when
spaced only 2 cm apart, multiple contacts can be detected simultaneously using
our software pipeline, which provides real-world quantities of 3D contact
locations (mm) and 3D force vectors (N), with an accuracy of 1.5 mm and 0.17 N
respectively. We demonstrate the sensor's applicability and reliability onboard
and in real-time with two demos related to i) the estimation of the compliance
of different perches and subsequent re-alignment and landing on the stiffer
one, and ii) the mapping of sparse obstacles. The implementation of our
distributed tactile sensor represents a significant step towards attaining the
full potential of drones as versatile robots capable of interacting with and
navigating within complex environments.
</p>
</div>
</dd>
<dt><a name=item339>[339]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17150 title=Abstract>arXiv:2401.17150</a> [<a href=https://arxiv.org/pdf/2401.17150 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17150 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GAISSALabel: A tool for energy labeling of ML models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duran%2C+P">Pau Duran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casta%C3%B1o%2C+J">Joel Castaño</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%B3mez%2C+C">Cristina Gómez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Fern%C3%A1ndez%2C+S">Silverio Martínez-Fernández</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages, 2 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>Background: The increasing environmental impact of Information Technologies,
particularly in Machine Learning (ML), highlights the need for sustainable
practices in software engineering. The escalating complexity and energy
consumption of ML models need tools for assessing and improving their energy
efficiency. Goal: This paper introduces GAISSALabel, a web-based tool designed
to evaluate and label the energy efficiency of ML models. Method: GAISSALabel
is a technology transfer development from a former research on energy
efficiency classification of ML, consisting of a holistic tool for assessing
both the training and inference phases of ML models, considering various
metrics such as power draw, model size efficiency, CO2e emissions and more.
Results: GAISSALabel offers a labeling system for energy efficiency, akin to
labels on consumer appliances, making it accessible to ML stakeholders of
varying backgrounds. The tool's adaptability allows for customization in the
proposed labeling system, ensuring its relevance in the rapidly evolving ML
field. Conclusions: GAISSALabel represents a significant step forward in
sustainable software engineering, offering a solution for balancing
high-performance ML models with environmental impacts. The tool's effectiveness
and market relevance will be further assessed through planned evaluations using
the Technology Acceptance Model.
</p>
</div>
</dd>
<dt><a name=item340>[340]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17151 title=Abstract>arXiv:2401.17151</a> [<a href=https://arxiv.org/pdf/2401.17151 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17151 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Open Software Suite for Event-Based Video
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freeman%2C+A+C">Andrew C. Freeman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>While traditional video representations are organized around discrete image
frames, event-based video is a new paradigm that forgoes image frames
altogether. Rather, pixel samples are temporally asynchronous and independent
of one another. Until now, researchers have lacked a cohesive software
framework for exploring the representation, compression, and applications of
event-based video. I present the AD<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-160-Frame tabindex=0><nobr><span class=math id=MathJax-Span-958 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.75em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-959><span class=mi id=MathJax-Span-960 style=font-family:MathJax_Main>Δ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>ER software suite to fill this gap.
This framework includes utilities for transcoding framed and multimodal
event-based video sources to a common representation, rate control mechanisms,
lossy compression, application support, and an interactive GUI for transcoding
and playback. In this paper, I describe these various software components and
their usage.
</p>
</div>
</dd>
<dt><a name=item341>[341]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17154 title=Abstract>arXiv:2401.17154</a> [<a href=https://arxiv.org/pdf/2401.17154 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17154 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Real-time Contact State Estimation in Shape Control of Deformable Linear Objects under Small Environmental Constraints
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kejia Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yansong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+F">Fan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Liding Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haddadin%2C+S">Sami Haddadin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>Controlling the shape of deformable linear objects using robots and
constraints provided by environmental fixtures has diverse industrial
applications. In order to establish robust contacts with these fixtures,
accurate estimation of the contact state is essential for preventing and
rectifying potential anomalies. However, this task is challenging due to the
small sizes of fixtures, the requirement for real-time performances, and the
infinite degrees of freedom of the deformable linear objects. In this paper, we
propose a real-time approach for estimating both contact establishment and
subsequent changes by leveraging the dependency between the applied and
detected contact force on the deformable linear objects. We seamlessly
integrate this method into the robot control loop and achieve an adaptive shape
control framework which avoids, detects and corrects anomalies automatically.
Real-world experiments validate the robustness and effectiveness of our contact
estimation approach across various scenarios, significantly increasing the
success rate of shape control processes.
</p>
</div>
</dd>
<dt><a name=item342>[342]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17157 title=Abstract>arXiv:2401.17157</a> [<a href=https://arxiv.org/pdf/2401.17157 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17157 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CHoKI-based MPC for blood glucose regulation in Artificial Pancreas
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sonzogni%2C+B">Beatrice Sonzogni</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Manzano%2C+J+M">José María Manzano</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Polver%2C+M">Marco Polver</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Previdi%2C+F">Fabio Previdi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ferramosca%2C+A">Antonio Ferramosca</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
<p class=mathjax>This work presents a Model Predictive Control (MPC) for the artificial
pancreas, which is able to autonomously manage basal insulin injections in type
1 diabetic patients. Specifically, the MPC goal is to maintain the patients'
blood glucose level inside the safe range of 70-180 mg/dL, acting on the
insulin amount and respecting all the imposed constraints, taking into
consideration also the Insulin On Board (IOB), to avoid excess of insulin
infusion. MPC uses a model to make predictions of the system behaviour. In this
work, due to the complexity of the diabetes disease that complicates the
identification of a general physiological model, a data-driven learning method
is employed instead. The Componentwise H\"{o}lder Kinky Inference (CHoKI)
method is adopted, to have a customized controller for each patient. For the
data collection phase and also to test the proposed controller, the virtual
patients of the FDA-accepted UVA/Padova simulator are exploited. The proposed
MPC is also tested on a modified version of the simulator, that takes into
consideration also the variability of the insulin sensitivity. The final
results are satisfying since the proposed controller reduces the time in
hypoglycemia (which is more dangerous) if compared to the outcome obtained with
the standard constant basal insulin therapy provided by the simulator,
satisfying also the time in range requirements and avoiding long-term
hyperglycemia events.
</p>
</div>
</dd>
<dt><a name=item343>[343]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17159 title=Abstract>arXiv:2401.17159</a> [<a href=https://arxiv.org/pdf/2401.17159 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17159 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhengyang Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Siemer%2C+S">Stefan Siemer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jha%2C+P">Piyush Jha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Day%2C+J">Joel Day</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Manea%2C+F">Florin Manea</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)
</div>
<p class=mathjax>Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling
users to tailor them for their unique set of instances, thus dramatically
enhancing solver performance for their use case. However, this approach of
strategy customization presents a significant challenge: handcrafting an
optimized strategy for a class of SMT instances remains a complex and demanding
task for both solver developers and users alike.
<br>In this paper, we address this problem of automatic SMT strategy synthesis
via a novel Monte Carlo Tree Search (MCTS) based method. Our method treats
strategy synthesis as a sequential decision-making process, whose search tree
corresponds to the strategy space, and employs MCTS to navigate this vast
search space. The key innovations that enable our method to identify effective
strategies, while keeping costs low, are the ideas of layered and staged MCTS
search. These novel approaches allow for a deeper and more efficient
exploration of the strategy space, enabling us to synthesize more effective
strategies than the default ones in state-of-the-art (SOTA) SMT solvers. We
implement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through
extensive evaluations across 6 important SMT logics, Z3alpha demonstrates
superior performance compared to the SOTA synthesis tool FastSMT, the default
Z3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging
QF_BV benchmark set, Z3alpha solves 42.7% more instances than the default
strategy in the Z3 SMT solver.
</p>
</div>
</dd>
<dt><a name=item344>[344]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17161 title=Abstract>arXiv:2401.17161</a> [<a href=https://arxiv.org/pdf/2401.17161 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17161 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Hybrid Tendon and Ball Chain Continuum Robots for Enhanced Dexterity in Medical Interventions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pittiglio%2C+G">Giovanni Pittiglio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mencattelli%2C+M">Margherita Mencattelli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Donder%2C+A">Abdulhamit Donder</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chitalia%2C+Y">Yash Chitalia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dupont%2C+P+E">Pierre E. Dupont</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Medical Interventions," 2023 IEEE/RSJ International Conference on
 Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 8461-8466
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>A hybrid continuum robot design is introduced that combines a proximal
tendon-actuated section with a distal telescoping section comprised of
permanent-magnet spheres actuated using an external magnet. While,
individually, each section can approach a point in its workspace from one or at
most several orientations, the two-section combination possesses a dexterous
workspace. The paper describes kinematic modeling of the hybrid design and
provides a description of the dexterous workspace. We present experimental
validation which shows that a simplified kinematic model produces tip position
mean and maximum errors of 3% and 7% of total robot length, respectively.
</p>
</div>
</dd>
<dt><a name=item345>[345]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17163 title=Abstract>arXiv:2401.17163</a> [<a href=https://arxiv.org/pdf/2401.17163 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17163 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">John Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+X">Xi Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rejtig%2C+M">Michael Rejtig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+D">David Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagley%2C+R">Ruth Bagley</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horn%2C+M+S">Michael S. Horn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wilensky%2C+U+J">Uri J. Wilensky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Conditionally accepted (with minor revisions) by Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
<p class=mathjax>Large Language Models (LLMs) have the potential to fundamentally change the
way people engage in computer programming. Agent-based modeling (ABM) has
become ubiquitous in natural and social sciences and education, yet no prior
studies have explored the potential of LLMs to assist it. We designed NetLogo
Chat to support the learning and practice of NetLogo, a programming language
for ABM. To understand how users perceive, use, and need LLM-based interfaces,
we interviewed 30 participants from global academia, industry, and graduate
schools. Experts reported more perceived benefits than novices and were more
inclined to adopt LLMs in their workflow. We found significant differences
between experts and novices in their perceptions, behaviors, and needs for
human-AI collaboration. We surfaced a knowledge gap between experts and novices
as a possible reason for the benefit gap. We identified guidance,
personalization, and integration as major needs for LLM-based interfaces to
support the programming of ABM.
</p>
</div>
</dd>
<dt><a name=item346>[346]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17167 title=Abstract>arXiv:2401.17167</a> [<a href=https://arxiv.org/pdf/2401.17167 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17167 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+S">Shijue Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jianqiao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+J">Jiahui Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Weiwen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+Y">Yutai Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xingshan Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shang%2C+L">Lifeng Shang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xin Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Ruifeng Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qun Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>The recent trend of using Large Language Models (LLMs) as intelligent agents
in real-world applications underscores the necessity for comprehensive
evaluations of their capabilities, particularly in complex scenarios involving
planning, creating, and using tools. However, existing benchmarks typically
focus on simple synthesized queries that do not reflect real-world complexity,
thereby offering limited perspectives in evaluating tool utilization. To
address this issue, we present UltraTool, a novel benchmark designed to improve
and evaluate LLMs' ability in tool utilization within real-world scenarios.
UltraTool focuses on the entire process of using tools - from planning and
creating to applying them in complex tasks. It emphasizes real-world
complexities, demanding accurate, multi-step planning for effective
problem-solving. A key feature of UltraTool is its independent evaluation of
planning with natural language, which happens before tool usage and simplifies
the task solving by mapping out the intermediate steps. Thus, unlike previous
work, it eliminates the restriction of pre-defined toolset during planning.
Through extensive experiments on various LLMs, we offer novel insights into the
evaluation of capabilities of LLMs in tool utilization, thereby contributing a
fresh perspective to this rapidly evolving field. The benchmark is publicly
available at https://github.com/JoeYing1019/UltraTool.
</p>
</div>
</dd>
<dt><a name=item347>[347]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17168 title=Abstract>arXiv:2401.17168</a> [<a href=https://arxiv.org/pdf/2401.17168 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17168 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Stale Profile Matching
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ayupov%2C+A">Amir Ayupov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Panchenko%2C+M">Maksim Panchenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pupyrev%2C+S">Sergey Pupyrev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ACM SIGPLAN 33rd International Conference on Compiler Construction (CC 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)
</div>
<p class=mathjax>Profile-guided optimizations rely on profile data for directing compilers to
generate optimized code. To achieve the maximum performance boost, profile data
needs to be collected on the same version of the binary that is being
optimized. In practice however, there is typically a gap between the profile
collection and the release, which makes a portion of the profile invalid for
optimizations. This phenomenon is known as profile staleness, and it is a
serious practical problem for data-center workloads both for compilers and
binary optimizers.
<br>In this paper we thoroughly study the staleness problem and propose the first
practical solution for utilizing profiles collected on binaries built from
several revisions behind the release. Our algorithm is developed and
implemented in a mainstream open-source post-link optimizer, BOLT. An extensive
evaluation on a variety of standalone benchmarks and production services
indicates that the new method recovers up to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-161-Frame tabindex=0><nobr><span class=math id=MathJax-Span-961 style=width:1.565em;display:inline-block><span style=display:inline-block;position:relative;width:1.276em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1001.22em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-962><span class=mn id=MathJax-Span-963 style=font-family:MathJax_Main>0.8</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> of the maximum BOLT benefit,
even when most of the input profile data is stale and would have been discarded
by the optimizer otherwise.
</p>
</div>
</dd>
<dt><a name=item348>[348]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17169 title=Abstract>arXiv:2401.17169</a> [<a href=https://arxiv.org/pdf/2401.17169 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17169 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conditional and Modal Reasoning in Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holliday%2C+W+H">Wesley H. Holliday</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mandelkern%2C+M">Matthew Mandelkern</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 16 figures. Code and data available at <a href=https://github.com/wesholliday/llm-logic>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)
</div>
<p class=mathjax>The reasoning abilities of large language models (LLMs) are the topic of a
growing body of research in artificial intelligence and cognitive science. In
this paper, we probe the extent to which a dozen LLMs are able to distinguish
logically correct inferences from logically fallacious ones. We focus on
inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob
has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must
have a king'). These inference patterns have been of special interest to
logicians, philosophers, and linguists, since they plausibly play a central
role in human reasoning. Assessing LLMs on these inference patterns is thus
highly relevant to the question of how much the reasoning abilities of LLMs
match those of humans. Among the LLMs we tested, all but GPT-4 often make basic
mistakes with conditionals. Moreover, even GPT-4 displays logically
inconsistent judgments across inference patterns involving epistemic modals.
</p>
</div>
</dd>
<dt><a name=item349>[349]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17173 title=Abstract>arXiv:2401.17173</a> [<a href=https://arxiv.org/pdf/2401.17173 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17173 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Zero-Shot Reinforcement Learning via Function Encoders
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ingebrand%2C+T">Tyler Ingebrand</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A">Amy Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Although reinforcement learning (RL) can solve many challenging sequential
decision making problems, achieving zero-shot transfer across related tasks
remains a challenge. The difficulty lies in finding a good representation for
the current task so that the agent understands how it relates to previously
seen tasks. To achieve zero-shot transfer, we introduce the function encoder, a
representation learning algorithm which represents a function as a weighted
combination of learned, non-linear basis functions. By using a function encoder
to represent the reward function or the transition function, the agent has
information on how the current task relates to previously seen tasks via a
coherent vector representation. Thus, the agent is able to achieve transfer
between related tasks at run time with no additional training. We demonstrate
state-of-the-art data efficiency, asymptotic performance, and training
stability in three RL fields by augmenting basic RL algorithms with a function
encoder task representation.
</p>
</div>
</dd>
<dt><a name=item350>[350]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17175 title=Abstract>arXiv:2401.17175</a> [<a href=https://arxiv.org/pdf/2401.17175 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17175 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Integrable Frame Fields using Odeco Tensors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Couplet%2C+M">Mattéo Couplet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chemin%2C+A">Alexandre Chemin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Remacle%2C+J">Jean-François Remacle</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to the SIAM International Meshing Roundtable Workshop 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Geometry (cs.CG)</span>
</div>
<p class=mathjax>We propose a method for computing integrable orthogonal frame fields on
planar surfaces. Frames and their symmetries are implicitly represented using
orthogonally decomposable (odeco) tensors. To formulate an integrability
criterion, we express the frame field's Lie bracket solely in terms of the
tensor representation; this is made possible by studying the sensitivity of the
frame with respect to perturbations in the tensor. We construct an energy
formulation that computes smooth and integrable frame fields, in both isotropic
and anisotropic settings. The user can prescribe any size and orientation
constraints in input, and the solver creates and places the singularities
required to fit the constraints with the correct topology. The computed frame
field can be integrated to a seamless parametrization that is aligned with the
frame field.
</p>
</div>
</dd>
<dt><a name=item351>[351]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17178 title=Abstract>arXiv:2401.17178</a> [<a href=https://arxiv.org/pdf/2401.17178 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17178 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GraphViz2Vec: A Structure-aware Feature Generation Model to Improve Classification in GNNs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chatterjee%2C+S+K">Shraban Kumar Chatterjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kundu%2C+S">Suman Kundu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)
</div>
<p class=mathjax>GNNs are widely used to solve various tasks including node classification and
link prediction. Most of the GNN architectures assume the initial embedding to
be random or generated from popular distributions. These initial embeddings
require multiple layers of transformation to converge into a meaningful latent
representation. While number of layers allow accumulation of larger
neighbourhood of a node it also introduce the problem of over-smoothing. In
addition, GNNs are inept at representing structural information. For example,
the output embedding of a node does not capture its triangles participation. In
this paper, we presented a novel feature extraction methodology GraphViz2Vec
that can capture the structural information of a node's local neighbourhood to
create meaningful initial embeddings for a GNN model. These initial embeddings
helps existing models achieve state-of-the-art results in various
classification tasks. Further, these initial embeddings help the model to
produce desired results with only two layers which in turn reduce the problem
of over-smoothing. The initial encoding of a node is obtained from an image
classification model trained on multiple energy diagrams of its local
neighbourhood. These energy diagrams are generated with the induced sub-graph
of the nodes traversed by multiple random walks. The generated encodings
increase the performance of existing models on classification tasks (with a
mean increase of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-162-Frame tabindex=0><nobr><span class=math id=MathJax-Span-964 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-965><span class=mn id=MathJax-Span-966 style=font-family:MathJax_Main>4.65</span><span class=mi id=MathJax-Span-967 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-163-Frame tabindex=0><nobr><span class=math id=MathJax-Span-968 style=width:3.128em;display:inline-block><span style=display:inline-block;position:relative;width:2.607em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.55em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-969><span class=mn id=MathJax-Span-970 style=font-family:MathJax_Main>2.58</span><span class=mi id=MathJax-Span-971 style=font-family:MathJax_Main>%</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> for the node and link classification
tasks, respectively), with some models achieving state-of-the-art results.
</p>
</div>
</dd>
<dt><a name=item352>[352]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17181 title=Abstract>arXiv:2401.17181</a> [<a href=https://arxiv.org/pdf/2401.17181 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17181 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Transfer Learning for Text Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+K">Kehang Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kenealy%2C+K">Kathleen Kenealy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barua%2C+A">Aditya Barua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fiedel%2C+N">Noah Fiedel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Constant%2C+N">Noah Constant</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In this report, we explore the potential for text diffusion to replace
autoregressive (AR) decoding for the training and deployment of large language
models (LLMs). We are particularly interested to see whether pretrained AR
models can be transformed into text diffusion models through a lightweight
adaptation procedure we call ``AR2Diff''. We begin by establishing a strong
baseline setup for training text diffusion models. Comparing across multiple
architectures and pretraining objectives, we find that training a decoder-only
model with a prefix LM objective is best or near-best across several tasks.
Building on this finding, we test various transfer learning setups for text
diffusion models. On machine translation, we find that text diffusion
underperforms the standard AR approach. However, on code synthesis and
extractive QA, we find diffusion models trained from scratch outperform AR
models in many cases. We also observe quality gains from AR2Diff -- adapting AR
models to use diffusion decoding. These results are promising given that text
diffusion is relatively underexplored and can be significantly faster than AR
decoding for long text generation.
</p>
</div>
</dd>
<dt><a name=item353>[353]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17184 title=Abstract>arXiv:2401.17184</a> [<a href=https://arxiv.org/pdf/2401.17184 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17184 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rigorous Error Analysis for Logarithmic Number Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T+S">Thanh Son Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Solovyev%2C+A">Alexey Solovyev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 14 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Mathematical Software (cs.MS)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>Logarithmic Number Systems (LNS) hold considerable promise in helping reduce
the number of bits needed to represent a high dynamic range of real-numbers
with finite precision, and also efficiently support multiplication and
division. However, under LNS, addition and subtraction turn into non-linear
functions that must be approximated - typically using precomputed table-based
functions. Additionally, multiple layers of error correction are typically
needed to improve result accuracy. Unfortunately, previous efforts have not
characterized the resulting error bound. We provide the first rigorous analysis
of LNS, covering detailed techniques such as co-transformation that are crucial
to implementing subtraction with reasonable accuracy. We provide theorems
capturing the error due to table interpolations, the finite precision of
pre-computed values in the tables, and the error introduced by fix-point
multiplications involved in LNS implementations. We empirically validate our
analysis using a Python implementation, showing that our analytical bounds are
tight, and that our testing campaign generates inputs diverse-enough to almost
match (but not exceed) the analytical bounds. We close with discussions on how
to adapt our analysis to LNS systems with different bases and also discuss many
pragmatic ramifications of our work in the broader arena of scientific
computing and machine learning.
</p>
</div>
</dd>
<dt><a name=item354>[354]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17185 title=Abstract>arXiv:2401.17185</a> [<a href=https://arxiv.org/pdf/2401.17185 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17185 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Camera Asynchronous Ball Localization and Trajectory Prediction with Factor Graphs and Human Poses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Q">Qingyu Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaidi%2C+Z">Zulfiqar Zaidi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gombolay%2C+M">Matthew Gombolay</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The rapid and precise localization and prediction of a ball are critical for
developing agile robots in ball sports, particularly in sports like tennis
characterized by high-speed ball movements and powerful spins. The Magnus
effect induced by spin adds complexity to trajectory prediction during flight
and bounce dynamics upon contact with the ground. In this study, we introduce
an innovative approach that combines a multi-camera system with factor graphs
for real-time and asynchronous 3D tennis ball localization. Additionally, we
estimate hidden states like velocity and spin for trajectory prediction.
Furthermore, to enhance spin inference early in the ball's flight, where
limited observations are available, we integrate human pose data using a
temporal convolutional network (TCN) to compute spin priors within the factor
graph. This refinement provides more accurate spin priors at the beginning of
the factor graph, leading to improved early-stage hidden state inference for
prediction. Our result shows the trained TCN can predict the spin priors with
RMSE of 5.27 Hz. Integrating TCN into the factor graph reduces the prediction
error of landing positions by over 63.6% compared to a baseline method that
utilized an adaptive extended Kalman filter.
</p>
</div>
</dd>
<dt><a name=item355>[355]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17186 title=Abstract>arXiv:2401.17186</a> [<a href=https://arxiv.org/pdf/2401.17186 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17186 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+B">Bang Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yong Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xuxin Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaowei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raza%2C+A">Asif Raza</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yuexian Zou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI'2024, 15 pages (with appendix), 7 figures, 10 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)
</div>
<p class=mathjax>While vision-language pre-trained models (VL-PTMs) have advanced multimodal
research in recent years, their mastery in a few languages like English
restricts their applicability in broader communities. To this end, there is an
increasing interest in developing multilingual VL models via a joint-learning
setup, which, however, could be unrealistic due to expensive costs and data
availability. In this work, we propose to extend VL-PTMs' language capacity by
continual language learning (CLL), where a model needs to update its linguistic
knowledge incrementally without suffering from catastrophic forgetting (CF). We
begin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP,
a prevailing VL-PTM that has acquired image-English text alignment.
Specifically, CLL-CLIP contains an expandable token embedding layer to handle
linguistic differences. It solely trains token embeddings to improve memory
stability and is optimized under cross-modal and cross-lingual objectives to
learn the alignment between images and multilingual texts. To alleviate CF
raised by covariate shift and lexical overlap, we further propose a novel
approach that ensures the identical distribution of all token embeddings during
initialization and regularizes token embedding learning during training. We
construct a CLL benchmark covering 36 languages based on MSCOCO and XM3600
datasets and then evaluate multilingual image-text retrieval performance.
Extensive experiments verify the effectiveness of CLL-CLIP and show that our
approach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 on
XM3600, and improve various state-of-the-art methods consistently. Our code and
data are available at \url{https://github.com/yangbang18/CLFM}.
</p>
</div>
</dd>
<dt><a name=item356>[356]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17187 title=Abstract>arXiv:2401.17187</a> [<a href=https://arxiv.org/pdf/2401.17187 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17187 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Formal Synthesis of Uncertainty Reduction Controllers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carwehl%2C+M">Marc Carwehl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Imrie%2C+C">Calum Imrie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vogel%2C+T">Thomas Vogel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodrigues%2C+G">Genaína Rodrigues</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Calinescu%2C+R">Radu Calinescu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grunske%2C+L">Lars Grunske</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
<p class=mathjax>In its quest for approaches to taming uncertainty in self-adaptive systems
(SAS), the research community has largely focused on solutions that adapt the
SAS architecture or behaviour in response to uncertainty. By comparison,
solutions that reduce the uncertainty affecting SAS (other than through the
blanket monitoring of their components and environment) remain underexplored.
Our paper proposes a more nuanced, adaptive approach to SAS uncertainty
reduction. To that end, we introduce a SAS architecture comprising an
uncertainty reduction controller that drives the adaptive acquisition of new
information within the SAS adaptation loop, and a tool-supported method that
uses probabilistic model checking to synthesise such controllers. The
controllers generated by our method deliver optimal trade-offs between SAS
uncertainty reduction benefits and new information acquisition costs. We
illustrate the use and evaluate the effectiveness of our approach for mobile
robot navigation and server infrastructure management SAS.
</p>
</div>
</dd>
<dt><a name=item357>[357]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17188 title=Abstract>arXiv:2401.17188</a> [<a href=https://arxiv.org/pdf/2401.17188 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17188 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Nested Construction of Polar Codes via Transformers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ankireddy%2C+S+K">Sravan Kumar Ankireddy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hebbar%2C+S+A">S Ashwin Hebbar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+H">Heping Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cho%2C+J">Joonyoung Cho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Charlie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 7 pages; 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Tailoring polar code construction for decoding algorithms beyond successive
cancellation has remained a topic of significant interest in the field.
However, despite the inherent nested structure of polar codes, the use of
sequence models in polar code construction is understudied. In this work, we
propose using a sequence modeling framework to iteratively construct a polar
code for any given length and rate under various channel conditions.
Simulations show that polar codes designed via sequential modeling using
transformers outperform both 5G-NR sequence and Density Evolution based
approaches for both AWGN and Rayleigh fading channels.
</p>
</div>
</dd>
<dt><a name=item358>[358]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17191 title=Abstract>arXiv:2401.17191</a> [<a href=https://arxiv.org/pdf/2401.17191 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17191 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Belief Behavior Graph: Enabling Autonomous Robot Inspection in Unknown Environments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ginting%2C+M+F">Muhammad Fadhil Ginting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+D+D">David D. Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sung-Kyun Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agha-mohammadi%2C+A">Ali-akbar Agha-mohammadi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>This paper addresses the problem of autonomous robotic inspection in complex
and unknown environments. This capability is crucial for efficient and precise
inspections in various real-world scenarios, even when faced with perceptual
uncertainty and lack of prior knowledge of the environment. Existing methods
for real-world autonomous inspections typically rely on predefined targets and
waypoints and often fail to adapt to dynamic or unknown settings. In this work,
we introduce the Semantic Belief Behavior Graph (SB2G) framework as a novel
approach to semantic-aware autonomous robot inspection. SB2G generates a
control policy for the robot, featuring behavior nodes that encapsulate various
semantic-based policies designed for inspecting different classes of objects.
We design an active semantic search behavior to guide the robot in locating
objects for inspection while reducing semantic information uncertainty. The
edges in the SB2G encode transitions between these behaviors. We validate our
approach through simulation and real-world urban inspections using a legged
robotic platform. Our results show that SB2G enables a more efficient
inspection policy, exhibiting performance comparable to human-operated
inspections.
</p>
</div>
</dd>
<dt><a name=item359>[359]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17196 title=Abstract>arXiv:2401.17196</a> [<a href=https://arxiv.org/pdf/2401.17196 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17196 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lei Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alnegheimish%2C+S">Sarah Alnegheimish</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berti-Equille%2C+L">Laure Berti-Equille</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cuesta-Infante%2C+A">Alfredo Cuesta-Infante</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Veeramachaneni%2C+K">Kalyan Veeramachaneni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>In text classification, creating an adversarial example means subtly
perturbing a few words in a sentence without changing its meaning, causing it
to be misclassified by a classifier. A concerning observation is that a
significant portion of adversarial examples generated by existing methods
change only one word. This single-word perturbation vulnerability represents a
significant weakness in classifiers, which malicious users can exploit to
efficiently create a multitude of adversarial examples. This paper studies this
problem and makes the following key contributions: (1) We introduce a novel
metric \r{ho} to quantitatively assess a classifier's robustness against
single-word perturbation. (2) We present the SP-Attack, designed to exploit the
single-word perturbation vulnerability, achieving a higher attack success rate,
better preserving sentence meaning, while reducing computation costs compared
to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims
to improve \r{ho} by applying data augmentation in learning. Experimental
results on 4 datasets and BERT and distilBERT classifiers show that SP-Defense
improves \r{ho} by 14.6% and 13.9% and decreases the attack success rate of
SP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases the
attack success rate of existing attack methods that involve multiple-word
perturbations.
</p>
</div>
</dd>
<dt><a name=item360>[360]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17197 title=Abstract>arXiv:2401.17197</a> [<a href=https://arxiv.org/pdf/2401.17197 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17197 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-efficient Fine-tuning for LLM-based Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+X">Xinyu Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenjie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yongqi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+S">Shuo Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+F">Fuli Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
<p class=mathjax>Leveraging Large Language Models (LLMs) for recommendation has recently
garnered considerable attention, where fine-tuning plays a key role in LLMs'
adaptation. However, the cost of fine-tuning LLMs on rapidly expanding
recommendation data limits their practical application. To address this
challenge, few-shot fine-tuning offers a promising approach to quickly adapt
LLMs to new recommendation data. We propose the task of data pruning for
efficient LLM-based recommendation, aimed at identifying representative samples
tailored for LLMs' few-shot fine-tuning. While coreset selection is closely
related to the proposed task, existing coreset selection methods often rely on
suboptimal heuristic metrics or entail costly optimization on large-scale
recommendation data.
<br>To tackle these issues, we introduce two objectives for the data pruning task
in the context of LLM-based recommendation: 1) high accuracy aims to identify
the influential samples that can lead to high overall performance; and 2) high
efficiency underlines the low costs of the data pruning process. To pursue the
two objectives, we propose a novel data pruning method based on two scores,
i.e., influence score and effort score, to efficiently identify the influential
samples. Particularly, the influence score is introduced to accurately estimate
the influence of sample removal on the overall performance. To achieve low
costs of the data pruning process, we use a small-sized surrogate model to
replace LLMs to obtain the influence score. Considering the potential gap
between the surrogate model and LLMs, we further propose an effort score to
prioritize some hard samples specifically for LLMs. Empirical results on three
real-world datasets validate the effectiveness of our proposed method. In
particular, the proposed method uses only 2% samples to surpass the full data
fine-tuning, reducing time costs by 97%.
</p>
</div>
</dd>
<dt><a name=item361>[361]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17199 title=Abstract>arXiv:2401.17199</a> [<a href=https://arxiv.org/pdf/2401.17199 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17199 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17199 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Mixed Linear and Graded Logic: Proofs, Terms, and Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vollmer%2C+V">Victoria Vollmer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marshall%2C+D">Daniel Marshall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eades%2C+H">Harley Eades III</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orchard%2C+D">Dominic Orchard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)
</div>
<p class=mathjax>Graded modal logics generalise standard modal logics via families of
modalities indexed by an algebraic structure whose operations mediate between
the different modalities. The graded "of-course" modality <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-164-Frame tabindex=0><nobr><span class=math id=MathJax-Span-972 style=width:0.871em;display:inline-block><span style=display:inline-block;position:relative;width:0.697em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.7em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-973><span class=msubsup id=MathJax-Span-974><span style=display:inline-block;position:relative;width:0.697em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.18em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-975 style=font-family:MathJax_Main>!</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.292em><span class=mi id=MathJax-Span-976 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> captures how
many times a proposition is used and has an analogous interpretation to the
of-course modality from linear logic; the of-course modality from linear logic
can be modelled by a linear exponential comonad and graded of-course can be
modelled by a graded linear exponential comonad. Benton showed in his seminal
paper on Linear/Non-Linear logic that the of-course modality can be split into
two modalities connecting intuitionistic logic with linear logic, forming a
symmetric monoidal adjunction. Later, Fujii et al. demonstrated that every
graded comonad can be decomposed into an adjunction and a 'strict action'. We
give a similar result to Benton, leveraging Fujii et al.'s decomposition,
showing that graded modalities can be split into two modalities connecting a
graded logic with a graded linear logic. We propose a sequent calculus, its
proof theory and categorical model, and a natural deduction system which we
show is isomorphic to the sequent calculus. Interestingly, our system can also
be understood as Linear/Non-Linear logic composed with an action that adds the
grading, further illuminating the shared principles between linear logic and a
class of graded modal logics.
</p>
</div>
</dd>
<dt><a name=item362>[362]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17200 title=Abstract>arXiv:2401.17200</a> [<a href=https://arxiv.org/pdf/2401.17200 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17200 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble Techniques
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hryniewska-Guzik%2C+W">Weronika Hryniewska-Guzik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sawicki%2C+B">Bartosz Sawicki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Biecek%2C+P">Przemysław Biecek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>This paper presents a comprehensive comparative analysis of explainable
artificial intelligence (XAI) ensembling methods. Our research brings three
significant contributions. Firstly, we introduce a novel ensembling method,
NormEnsembleXAI, that leverages minimum, maximum, and average functions in
conjunction with normalization techniques to enhance interpretability.
Secondly, we offer insights into the strengths and weaknesses of XAI ensemble
methods. Lastly, we provide a library, facilitating the practical
implementation of XAI ensembling, thus promoting the adoption of transparent
and interpretable deep learning models.
</p>
</div>
</dd>
<dt><a name=item363>[363]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17203 title=Abstract>arXiv:2401.17203</a> [<a href=https://arxiv.org/pdf/2401.17203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CPR++: Object Localization via Single Coarse Point Supervision
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xuehui Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pengfei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kuiran Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+X">Xumeng Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+G">Guorong Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhenjun Han</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Q">Qixiang Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao%2C+J">Jianbin Jiao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accpted by TPAMI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Point-based object localization (POL), which pursues high-performance object
sensing under low-cost data annotation, has attracted increased attention.
However, the point annotation mode inevitably introduces semantic variance due
to the inconsistency of annotated points. Existing POL heavily rely on strict
annotation rules, which are difficult to define and apply, to handle the
problem. In this study, we propose coarse point refinement (CPR), which to our
best knowledge is the first attempt to alleviate semantic variance from an
algorithmic perspective. CPR reduces the semantic variance by selecting a
semantic centre point in a neighbourhood region to replace the initial
annotated point. Furthermore, We design a sampling region estimation module to
dynamically compute a sampling region for each object and use a cascaded
structure to achieve end-to-end optimization. We further integrate a variance
regularization into the structure to concentrate the predicted scores, yielding
CPR++. We observe that CPR++ can obtain scale information and further reduce
the semantic variance in a global region, thus guaranteeing high-performance
object localization. Extensive experiments on four challenging datasets
validate the effectiveness of both CPR and CPR++. We hope our work can inspire
more research on designing algorithms rather than annotation rules to address
the semantic variance problem in POL. The dataset and code will be public at
github.com/ucas-vg/PointTinyBenchmark.
</p>
</div>
</dd>
<dt><a name=item364>[364]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17206 title=Abstract>arXiv:2401.17206</a> [<a href=https://arxiv.org/pdf/2401.17206 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17206 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT Semantic Embeddings K-Means-Infused CRF Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farhan%2C+N">Niloy Farhan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joy%2C+S+S">Saman Sarker Joy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mannan%2C+T+B">Tafseer Binte Mannan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadeque%2C+F">Farig Sadeque</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Named Entity Recognition (NER) is a sub-task of Natural Language Processing
(NLP) that distinguishes entities from unorganized text into predefined
categorization. In recent years, a lot of Bangla NLP subtasks have received
quite a lot of attention; but Named Entity Recognition in Bangla still lags
behind. In this research, we explored the existing state of research in Bangla
Named Entity Recognition. We tried to figure out the limitations that current
techniques and datasets face, and we would like to address these limitations in
our research. Additionally, We developed a Gazetteer that has the ability to
significantly boost the performance of NER. We also proposed a new NER solution
by taking advantage of state-of-the-art NLP tools that outperform conventional
techniques.
</p>
</div>
</dd>
<dt><a name=item365>[365]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17207 title=Abstract>arXiv:2401.17207</a> [<a href=https://arxiv.org/pdf/2401.17207 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17207 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Supervised Representation Learning for Nerve Fiber Distribution Patterns in 3D-PLI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oberstrass%2C+A">Alexander Oberstrass</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muenzing%2C+S+E+A">Sascha E. A. Muenzing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu%2C+M">Meiqi Niu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Palomero-Gallagher%2C+N">Nicola Palomero-Gallagher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schiffer%2C+C">Christian Schiffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Axer%2C+M">Markus Axer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amunts%2C+K">Katrin Amunts</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dickscheid%2C+T">Timo Dickscheid</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>A comprehensive understanding of the organizational principles in the human
brain requires, among other factors, well-quantifiable descriptors of nerve
fiber architecture. Three-dimensional polarized light imaging (3D-PLI) is a
microscopic imaging technique that enables insights into the fine-grained
organization of myelinated nerve fibers with high resolution. Descriptors
characterizing the fiber architecture observed in 3D-PLI would enable
downstream analysis tasks such as multimodal correlation studies, clustering,
and mapping. However, best practices for observer-independent characterization
of fiber architecture in 3D-PLI are not yet available. To this end, we propose
the application of a fully data-driven approach to characterize nerve fiber
architecture in 3D-PLI images using self-supervised representation learning. We
introduce a 3D-Context Contrastive Learning (CL-3D) objective that utilizes the
spatial neighborhood of texture examples across histological brain sections of
a 3D reconstructed volume to sample positive pairs for contrastive learning. We
combine this sampling strategy with specifically designed image augmentations
to gain robustness to typical variations in 3D-PLI parameter maps. The approach
is demonstrated for the 3D reconstructed occipital lobe of a vervet monkey
brain. We show that extracted features are highly sensitive to different
configurations of nerve fibers, yet robust to variations between consecutive
brain sections arising from histological processing. We demonstrate their
practical applicability for retrieving clusters of homogeneous fiber
architecture and performing data mining for interactively selected templates of
specific components of fiber architecture such as U-fibers.
</p>
</div>
</dd>
<dt><a name=item366>[366]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17212 title=Abstract>arXiv:2401.17212</a> [<a href=https://arxiv.org/pdf/2401.17212 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17212 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ContactGen: Contact-Guided Interactive 3D Human Generation for Partners
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+D">Dongjun Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shim%2C+J">Jaehyeok Shim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+J">Jaehoon Jang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+C">Changwoo Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joo%2C+K">Kyungdon Joo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>Among various interactions between humans, such as eye contact and gestures,
physical interactions by contact can act as an essential moment in
understanding human behaviors. Inspired by this fact, given a 3D partner human
with the desired interaction label, we introduce a new task of 3D human
generation in terms of physical contact. Unlike previous works of interacting
with static objects or scenes, a given partner human can have diverse poses and
different contact regions according to the type of interaction. To handle this
challenge, we propose a novel method of generating interactive 3D humans for a
given partner human based on a guided diffusion framework. Specifically, we
newly present a contact prediction module that adaptively estimates potential
contact regions between two input humans according to the interaction label.
Using the estimated potential contact regions as complementary guidances, we
dynamically enforce ContactGen to generate interactive 3D humans for a given
partner human within a guided diffusion model. We demonstrate ContactGen on the
CHI3D dataset, where our method generates physically plausible and diverse
poses compared to comparison methods.
</p>
</div>
</dd>
<dt><a name=item367>[367]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17214 title=Abstract>arXiv:2401.17214</a> [<a href=https://arxiv.org/pdf/2401.17214 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17214 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-FLEX: An Automatic Task Sequence Execution Framework to Enable Reactive Motion Planning for Multi-Robot Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Misra%2C+G">Gaurav Misra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Suzumura%2C+A">Akihiro Suzumura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Campo%2C+A+R">Andres Rodriguez Campo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chenna%2C+K">Kautilya Chenna</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bailey%2C+S">Sean Bailey</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Drinkard%2C+J">John Drinkard</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint submitted to IEEE Robotics and Automation Letters
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
<p class=mathjax>In this letter, an integrated task planning and reactive motion planning
framework termed Multi-FLEX is presented that targets real-world, industrial
multi-robot applications. Reactive motion planning has been attractive for the
purposes of collision avoidance, particularly when there are sources of
uncertainty and variation. Most industrial applications, though, typically
require parts of motion to be at least partially non-reactive in order to
achieve functional objectives. Multi-FLEX resolves this dissonance and enables
such applications to take advantage of reactive motion planning. The Multi-FLEX
framework achieves 1) coordination of motion requests to resolve task-level
conflicts and overlaps, 2) incorporation of application-specific task
constraints into online motion planning using the new concepts of task
dependency accommodation, task decomposition, and task bundling, and 3) online
generation of robot trajectories using a custom, online reactive motion
planner. This planner combines fast-to-create, sparse dynamic roadmaps (to find
a complete path to the goal) with fast-to-execute, short-horizon, online,
optimization-based local planning (for collision avoidance and high
performance). To demonstrate, we use two six-degree-of-freedom, high-speed
industrial robots in a deburring application to show the ability of this
approach to not just handle collision avoidance and task variations, but to
also achieve industrial applications.
</p>
</div>
</dd>
<dt><a name=item368>[368]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17217 title=Abstract>arXiv:2401.17217</a> [<a href=https://arxiv.org/pdf/2401.17217 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17217 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GazeGPT: Augmenting Human Capabilities using Gaze-contingent Contextual AI for Smart Eyewear
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Konrad%2C+R">Robert Konrad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padmanaban%2C+N">Nitish Padmanaban</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buckmaster%2C+J+G">J. Gabriel Buckmaster</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyle%2C+K+C">Kevin C. Boyle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project video: <a href=https://youtu.be/c9K6OC49QXQ>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Multimodal large language models (LMMs) excel in world knowledge and
problem-solving abilities. Through the use of a world-facing camera and
contextual AI, emerging smart accessories aim to provide a seamless interface
between humans and LMMs. Yet, these wearable computing systems lack an
understanding of the user's attention. We introduce GazeGPT as a new user
interaction paradigm for contextual AI. GazeGPT uses eye tracking to help the
LMM understand which object in the world-facing camera view a user is paying
attention to. Using extensive user evaluations, we show that this
gaze-contingent mechanism is a faster and more accurate pointing mechanism than
alternatives; that it augments human capabilities by significantly improving
their accuracy in a dog-breed classification task; and that it is consistently
ranked as more natural than head- or body-driven selection mechanisms for
contextual AI. Moreover, we prototype a variety of application scenarios that
suggest GazeGPT could be of significant value to users as part of future
AI-driven personal assistants.
</p>
</div>
</dd>
<dt><a name=item369>[369]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17221 title=Abstract>arXiv:2401.17221</a> [<a href=https://arxiv.org/pdf/2401.17221 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17221 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MouSi: Poly-Visual-Expert Vision-Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+T">Tao Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+C">Changhao Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Shuo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+S">Senjie Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+S">Sirui Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Junke Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hong%2C+B">Boyang Hong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Lu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+G">Guodong Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Ming Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Caishuang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+R">Rui Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+S">Shihan Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J">Junjie Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+H">Hang Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gui%2C+T">Tao Gui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Current large vision-language models (VLMs) often encounter challenges such
as insufficient capabilities of a single visual component and excessively long
visual tokens. These issues can limit the model's effectiveness in accurately
interpreting complex visual information and over-lengthy contextual
information. Addressing these challenges is crucial for enhancing the
performance and applicability of VLMs. This paper proposes the use of ensemble
experts technique to synergizes the capabilities of individual visual encoders,
including those skilled in image-text matching, OCR, image segmentation, etc.
This technique introduces a fusion network to unify the processing of outputs
from different visual experts, while bridging the gap between image encoders
and pre-trained LLMs. In addition, we explore different positional encoding
schemes to alleviate the waste of positional encoding caused by lengthy image
feature sequences, effectively addressing the issue of position overflow and
length limitations. For instance, in our implementation, this technique
significantly reduces the positional occupancy in models like SAM, from a
substantial 4096 to a more efficient and manageable 64 or even down to 1.
Experimental results demonstrate that VLMs with multiple experts exhibit
consistently superior performance over isolated visual encoders and mark a
significant performance boost as more experts are integrated. We have
open-sourced the training code used in this report. All of these resources can
be found on our project website.
</p>
</div>
</dd>
<dt><a name=item370>[370]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17224 title=Abstract>arXiv:2401.17224</a> [<a href=https://arxiv.org/pdf/2401.17224 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17224 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17224 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evolvable Agents, a Fine Grained Approach for Distributed Evolutionary Computing: Walking towards the Peer-to-Peer Computing Frontiers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laredo%2C+J+L+J">Juan Luis Jiménez Laredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castillo%2C+P+A">Pedro A. Castillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mora%2C+A+M">Antonio M. Mora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merelo%2C+J+J">Juan Julián Merelo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/cs/0703117>arXiv:cs/0703117</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>In this work we propose a fine grained approach with self-adaptive migration
rate for distributed evolutionary computation. Our target is to gain some
insights on the effects caused by communication when the algorithm scales. To
this end, we consider a set of basic topologies in order to avoid the
overlapping of algorithmic effects between communication and topological
structures. We analyse the approach viability by comparing how solution quality
and algorithm speed change when the number of processors increases and compare
it with an Island model based implementation. A finer-grained approach implies
a better chance of achieving a larger scalable system; such a feature is
crucial concerning large-scale parallel architectures such as Peer-to-Peer
systems. In order to check scalability, we perform a threefold experimental
evaluation of this model: First, we concentrate on the algorithmic results when
the problem scales up to eight nodes in comparison with how it does following
the Island model. Second, we analyse the computing time speedup of the approach
while scaling. Finally, we analyse the network performance with the proposed
self-adaptive migration rate policy that depends on the link latency and
bandwidth. With this experimental setup, our approach shows better scalability
than the Island model and a equivalent robustness on the average of the three
test functions under study.
</p>
</div>
</dd>
<dt><a name=item371>[371]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17226 title=Abstract>arXiv:2401.17226</a> [<a href=https://arxiv.org/pdf/2401.17226 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17226 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Knowledge Problems in Protocol Analysis: Extending the Notion of Subterm Convergent
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bunch%2C+C">Carter Bunch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Satterfield%2C+S+D">Saraid Dwyer Satterfield</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erbatur%2C+S">Serdar Erbatur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marshall%2C+A+M">Andrew M. Marshall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ringeissen%2C+C">Christophe Ringeissen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint submitted to Logical Methods in Computer Science
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
<p class=mathjax>We introduce a new form of restricted term rewrite system, the graph-embedded
term rewrite system. These systems, and thus the name, are inspired by the
graph minor relation and are more flexible extensions of the well-known
homeomorphic-embedded property of term rewrite systems. As a motivating
application area, we consider the symbolic analysis of security protocols, and
more precisely the two knowledge problems defined by the deduction problem and
the static equivalence problem. In this field restricted term rewrite systems,
such as subterm convergent ones, have proven useful since the knowledge
problems are decidable for such systems. Many of the same decision procedures
still work for examples of systems which are "beyond subterm convergent".
However, the applicability of the corresponding decision procedures to these
examples must often be proven on an individual basis. This is due to the
problem that they don't fit into an existing syntactic definition for which the
procedures are known to work. Here we show that many of these systems belong to
a particular subclass of graph-embedded convergent systems, called contracting
convergent systems. On the one hand, we show that the knowledge problems are
decidable for the subclass of contracting convergent systems. On the other
hand, we show that the knowledge problems are undecidable for the class of
graph-embedded systems. Going further, we compare and contrast these graph
embedded systems with several notions and properties already known in the
protocol analysis literature. Finally, we provide several combination results,
both for the combination of multiple contracting convergent systems, and then
for the combination of contracting convergent systems with particular
permutative equational theories.
</p>
</div>
</dd>
<dt><a name=item372>[372]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17228 title=Abstract>arXiv:2401.17228</a> [<a href=https://arxiv.org/pdf/2401.17228 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17228 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jeongwoo Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liscio%2C+E">Enrico Liscio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murukannaiah%2C+P+K">Pradeep K. Murukannaiah</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To appear in Findings of EACL 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Recent advances in NLP show that language models retain a discernible level
of knowledge in deontological ethics and moral norms. However, existing works
often treat morality as binary, ranging from right to wrong. This simplistic
view does not capture the nuances of moral judgment. Pluralist moral
philosophers argue that human morality can be deconstructed into a finite
number of elements, respecting individual differences in moral judgment. In
line with this view, we build a pluralist moral sentence embedding space via a
state-of-the-art contrastive learning approach. We systematically investigate
the embedding space by studying the emergence of relationships among moral
elements, both quantitatively and qualitatively. Our results show that a
pluralist approach to morality can be captured in an embedding space. However,
moral pluralism is challenging to deduce via self-supervision alone and
requires a supervised approach with human labels.
</p>
</div>
</dd>
<dt><a name=item373>[373]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17230 title=Abstract>arXiv:2401.17230</a> [<a href=https://arxiv.org/pdf/2401.17230 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17230 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiatong Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aldeneh%2C+Z">Zakaria Aldeneh</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Higuchi%2C+T">Takuya Higuchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theobald%2C+B">Barry-John Theobald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelaziz%2C+A+H">Ahmed Hussen Abdelaziz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 3 figures, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
</div>
<p class=mathjax>This paper introduces ESPnet-SPK, a toolkit designed with several objectives
for training speaker embedding extractors. First, we provide an open-source
platform for researchers in the speaker recognition community to effortlessly
build models. We provide several models, ranging from x-vector to recent
SKA-TDNN. Through the modularized architecture design, variants can be
developed easily. We also aspire to bridge developed models with other domains,
facilitating the broad research community to effortlessly incorporate
state-of-the-art embedding extractors. Pre-trained embedding extractors can be
accessed in an off-the-shelf manner and we demonstrate the toolkit's
versatility by showcasing its integration with two tasks. Another goal is to
integrate with diverse self-supervised learning features. We release a
reproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O
evaluation protocol using WavLM-Large with ECAPA-TDNN.
</p>
</div>
</dd>
<dt><a name=item374>[374]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17231 title=Abstract>arXiv:2401.17231</a> [<a href=https://arxiv.org/pdf/2401.17231 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17231 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReAlnet: Achieving More Human Brain-Like Vision via Human Neural Representational Alignment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zitong Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yile Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Golomb%2C+J+D">Julie D. Golomb</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)
</div>
<p class=mathjax>Despite the remarkable strides made in artificial intelligence, current
object recognition models still lag behind in emulating the mechanism of visual
information processing in human brains. Recent studies have highlighted the
potential of using neural data to mimic brain processing; however, these often
reply on invasive neural recordings from non-human subjects, leaving a critical
gap in our understanding of human visual perception and the development of more
human brain-like vision models. Addressing this gap, we present, for the first
time, "Re(presentational)Al(ignment)net", a vision model aligned with human
brain activity based on non-invasive EEG recordings, demonstrating a
significantly higher similarity to human brain representations. Our innovative
image-to-brain multi-layer encoding alignment framework not only optimizes
multiple layers of the model, marking a substantial leap in neural alignment,
but also enables the model to efficiently learn and mimic human brain's visual
representational patterns across object categories and different neural data
modalities. Furthermore, we discover that alignment with human brain
representations improves the model's adversarial robustness. Our findings
suggest that ReAlnet sets a new precedent in the field, bridging the gap
between artificial and human vision, and paving the way for more brain-like
artificial intelligence systems.
</p>
</div>
</dd>
<dt><a name=item375>[375]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17233 title=Abstract>arXiv:2401.17233</a> [<a href=https://arxiv.org/pdf/2401.17233 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17233 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inf-Sup neural networks for high-dimensional elliptic PDE problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Huo%2C+X">Xiaokai Huo</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+H">Hailiang Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>Solving high dimensional partial differential equations (PDEs) has
historically posed a considerable challenge when utilizing conventional
numerical methods, such as those involving domain meshes. Recent advancements
in the field have seen the emergence of neural PDE solvers, leveraging deep
networks to effectively tackle high dimensional PDE problems. This study
introduces Inf-SupNet, a model-based unsupervised learning approach designed to
acquire solutions for a specific category of elliptic PDEs. The fundamental
concept behind Inf-SupNet involves incorporating the inf-sup formulation of the
underlying PDE into the loss function. The analysis reveals that the global
solution error can be bounded by the sum of three distinct errors: the
numerical integration error, the duality gap of the loss function (training
error), and the neural network approximation error for functions within Sobolev
spaces. To validate the efficacy of the proposed method, numerical experiments
conducted in high dimensions demonstrate its stability and accuracy across
various boundary conditions, as well as for both semi-linear and nonlinear
PDEs.
</p>
</div>
</dd>
<dt><a name=item376>[376]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17234 title=Abstract>arXiv:2401.17234</a> [<a href=https://arxiv.org/pdf/2401.17234 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17234 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17234 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Asynchronous Distributed Genetic Algorithms with Javascript and JSON
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merelo%2C+J+J">Juan Julián Merelo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castillo%2C+P+A">Pedro A. Castillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laredo%2C+J+L+J">Juan Luis Jiménez Laredo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mora%2C+A+M">Antonio M. Mora</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prieto%2C+A">Alberto Prieto</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/cs/0701115>arXiv:cs/0701115</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Neural and Evolutionary Computing (cs.NE)</span>
</div>
<p class=mathjax>In a connected world, spare CPU cycles are up for grabs, if you only make its
obtention easy enough. In this paper we present a distributed evolutionary
computation system that uses the computational capabilities of the ubiquituous
web browser. Using Asynchronous Javascript and JSON (Javascript Object
Notation, a serialization protocol) allows anybody with a web browser (that is,
mostly everybody connected to the Internet) to participate in a genetic
algorithm experiment with little effort, or none at all. Since, in this case,
computing becomes a social activity and is inherently impredictable, in this
paper we will explore the performance of this kind of virtual computer by
solving simple problems such as the Royal Road function and analyzing how many
machines and evaluations it yields. We will also examine possible performance
bottlenecks and how to solve them, and, finally, issue some advice on how to
set up this kind of experiments to maximize turnout and, thus, performance.
</p>
</div>
</dd>
<dt><a name=item377>[377]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17235 title=Abstract>arXiv:2401.17235</a> [<a href=https://arxiv.org/pdf/2401.17235 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17235 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Explicit Good Codes Approaching Distance 1 in Ulam Metric
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldenberg%2C+E">Elazar Goldenberg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Habib%2C+M">Mursalin Habib</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karthik%2C+C+S">C. S. Karthik</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
</div>
<p class=mathjax>The Ulam distance of two permutations on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-165-Frame tabindex=0><nobr><span class=math id=MathJax-Span-977 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-978><span class=mo id=MathJax-Span-979 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-980 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-981 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-166-Frame tabindex=0><nobr><span class=math id=MathJax-Span-982 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-983><span class=mi id=MathJax-Span-984 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> minus the length of
their longest common subsequence. In this paper, we show that for every
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-167-Frame tabindex=0><nobr><span class=math id=MathJax-Span-985 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.26em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-986><span class=mi id=MathJax-Span-987 style=font-family:MathJax_Math-italic>ε</span><span class=mo id=MathJax-Span-988 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-989 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, there exists some <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-168-Frame tabindex=0><nobr><span class=math id=MathJax-Span-990 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.43em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-991><span class=mi id=MathJax-Span-992 style=font-family:MathJax_Math-italic>α</span><span class=mo id=MathJax-Span-993 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-994 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and an infinite set
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-169-Frame tabindex=0><nobr><span class=math id=MathJax-Span-995 style=width:3.302em;display:inline-block><span style=display:inline-block;position:relative;width:2.723em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.565em,1002.72em,2.723em,-999.997em);top:-2.428em;left:0em><span class=mrow id=MathJax-Span-996><span class=mi id=MathJax-Span-997 style=font-family:MathJax_Main>Γ</span><span class=mo id=MathJax-Span-998 style=font-family:MathJax_Main;padding-left:0.292em>⊆</span><span class=texatom id=MathJax-Span-999 style=padding-left:0.292em><span class=mrow id=MathJax-Span-1000><span class=mi id=MathJax-Span-1001 style=font-family:MathJax_AMS>N</span></span></span></span><span style=display:inline-block;width:0px;height:2.433em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, such that for all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-170-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1002 style=width:3.012em;display:inline-block><span style=display:inline-block;position:relative;width:2.491em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.43em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1003><span class=mi id=MathJax-Span-1004 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1005 style=font-family:MathJax_Main;padding-left:0.292em>∈</span><span class=mi id=MathJax-Span-1006 style=font-family:MathJax_Main;padding-left:0.292em>Γ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, there is an
explicit set <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-171-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1007 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1008><span class=msubsup id=MathJax-Span-1009><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1010 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1011 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-172-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1012 style=width:2.665em;display:inline-block><span style=display:inline-block;position:relative;width:2.202em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.2em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1013><span class=mo id=MathJax-Span-1014 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1015 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1016 style=font-family:MathJax_Main>!</span><span class=msubsup id=MathJax-Span-1017><span style=display:inline-block;position:relative;width:0.929em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1018 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1019><span class=mrow id=MathJax-Span-1020><span class=mi id=MathJax-Span-1021 style=font-size:70.7%;font-family:MathJax_Math-italic>α</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> many permutations on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-173-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1022 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1023><span class=mo id=MathJax-Span-1024 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-1025 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1026 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, such that
every pair of permutations in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-174-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1027 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1028><span class=msubsup id=MathJax-Span-1029><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1030 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1031 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> has pairwise Ulam distance at least
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-175-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1032 style=width:5.211em;display:inline-block><span style=display:inline-block;position:relative;width:4.343em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.34em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1033><span class=mo id=MathJax-Span-1034 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1035 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1036 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1037 style=font-family:MathJax_Math-italic;padding-left:0.234em>ε</span><span class=mo id=MathJax-Span-1038 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1039 style=font-family:MathJax_Main;padding-left:0.234em>⋅</span><span class=mi id=MathJax-Span-1040 style=font-family:MathJax_Math-italic;padding-left:0.234em>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>. Moreover, we can compute the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-176-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1041 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1042><span class=msubsup id=MathJax-Span-1043><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.186em,1000.29em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1044 style=font-family:MathJax_Math-italic>i</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.35em><span class=texatom id=MathJax-Span-1045><span class=mrow id=MathJax-Span-1046><span class=mtext id=MathJax-Span-1047 style=font-size:70.7%;font-family:MathJax_Main>th</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>
permutation in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-177-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1048 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1049><span class=msubsup id=MathJax-Span-1050><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1051 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1052 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> in poly<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-178-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1053 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.28em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1054><span class=mo id=MathJax-Span-1055 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1056 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1057 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> time and can also decode in poly<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-179-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1058 style=width:1.681em;display:inline-block><span style=display:inline-block;position:relative;width:1.392em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.28em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1059><span class=mo id=MathJax-Span-1060 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1061 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1062 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> time, a
permutation <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-180-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1063 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1064><span class=mi id=MathJax-Span-1065 style=font-family:MathJax_Math-italic>π<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-181-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1066 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1067><span class=mo id=MathJax-Span-1068 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-1069 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1070 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> to its closest permutation <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-182-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1071 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.04em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1072><span class=msubsup id=MathJax-Span-1073><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1074 style=font-family:MathJax_Math-italic>π<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-1075 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> in <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-183-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1076 style=width:1.508em;display:inline-block><span style=display:inline-block;position:relative;width:1.218em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.22em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1077><span class=msubsup id=MathJax-Span-1078><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1079 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.697em><span class=mi id=MathJax-Span-1080 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, if the
Ulam distance of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-184-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1081 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1082><span class=mi id=MathJax-Span-1083 style=font-family:MathJax_Math-italic>π<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-185-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1084 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.04em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1085><span class=msubsup id=MathJax-Span-1086><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.417em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1087 style=font-family:MathJax_Math-italic>π<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mo id=MathJax-Span-1088 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is less than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-186-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1089 style=width:3.359em;display:inline-block><span style=display:inline-block;position:relative;width:2.781em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.286em,1002.78em,1.565em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1090><span class=mfrac id=MathJax-Span-1091><span style=display:inline-block;position:relative;width:2.549em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1002.38em,4.343em,-999.997em);top:-4.569em;left:50%;margin-left:-1.212em><span class=mrow id=MathJax-Span-1092><span class=mo id=MathJax-Span-1093 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1094 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1095 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mi id=MathJax-Span-1096 style=font-size:70.7%;font-family:MathJax_Math-italic>ε</span><span class=mo id=MathJax-Span-1097 style=font-size:70.7%;font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1098 style=font-size:70.7%;font-family:MathJax_Main>⋅</span><span class=mi id=MathJax-Span-1099 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1100 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1002.55em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:2.549em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.948em"></span></span></nobr></span>.
<br>Previously, it was implicitly known by combining works of Goldreich and
Wigderson [Israel Journal of Mathematics'23] and Farnoud, Skachek, and
Milenkovic [IEEE Transactions on Information Theory'13] in a black-box manner,
that it is possible to explicitly construct <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-187-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1101 style=width:3.764em;display:inline-block><span style=display:inline-block;position:relative;width:3.128em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1003.13em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1102><span class=mo id=MathJax-Span-1103 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1104 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1105 style=font-family:MathJax_Main>!</span><span class=msubsup id=MathJax-Span-1106><span style=display:inline-block;position:relative;width:1.855em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1107 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1108><span class=mrow id=MathJax-Span-1109><span class=mi id=MathJax-Span-1110 style=font-size:70.7%;font-family:MathJax_Main>Ω</span><span class=mo id=MathJax-Span-1111 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1112 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1113 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> many
permutations on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-188-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1114 style=width:1.392em;display:inline-block><span style=display:inline-block;position:relative;width:1.16em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1001.04em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1115><span class=mo id=MathJax-Span-1116 style=font-family:MathJax_Main>[</span><span class=mi id=MathJax-Span-1117 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1118 style=font-family:MathJax_Main>]</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, such that every pair of them have pairwise Ulam distance
at least <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-189-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1119 style=width:5.443em;display:inline-block><span style=display:inline-block;position:relative;width:4.517em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.4em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1120><span class=mfrac id=MathJax-Span-1121><span style=display:inline-block;position:relative;width:0.524em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.533em,1000.41em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-1122 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1123 style=font-size:70.7%;font-family:MathJax_Main>6</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.52em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.524em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-1124 style=font-family:MathJax_Main;padding-left:0.234em>⋅</span><span class=mo id=MathJax-Span-1125 style=font-family:MathJax_Main;padding-left:0.234em>(</span><span class=mn id=MathJax-Span-1126 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1127 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1128 style=font-family:MathJax_Math-italic;padding-left:0.234em>ε</span><span class=mo id=MathJax-Span-1129 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>, for any <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-190-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1130 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.26em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1131><span class=mi id=MathJax-Span-1132 style=font-family:MathJax_Math-italic>ε</span><span class=mo id=MathJax-Span-1133 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1134 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, and the
bound on the distance can be improved to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-191-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1135 style=width:5.443em;display:inline-block><span style=display:inline-block;position:relative;width:4.517em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.4em,2.781em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1136><span class=mfrac id=MathJax-Span-1137><span style=display:inline-block;position:relative;width:0.524em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.533em,1000.41em,4.17em,-999.997em);top:-4.395em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-1138 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.35em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.171em><span class=mn id=MathJax-Span-1139 style=font-size:70.7%;font-family:MathJax_Main>4</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1000.52em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:0.524em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-1140 style=font-family:MathJax_Main;padding-left:0.234em>⋅</span><span class=mo id=MathJax-Span-1141 style=font-family:MathJax_Main;padding-left:0.234em>(</span><span class=mn id=MathJax-Span-1142 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1143 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1144 style=font-family:MathJax_Math-italic;padding-left:0.234em>ε</span><span class=mo id=MathJax-Span-1145 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span> if
the construction of Goldreich and Wigderson is directly analyzed in the Ulam
metric.
</p>
</div>
</dd>
<dt><a name=item378>[378]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17237 title=Abstract>arXiv:2401.17237</a> [<a href=https://arxiv.org/pdf/2401.17237 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17237 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Goal Oriented Adaptive Space Time Finite Element Methods Applied to Touching Domains
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Endtmayer%2C+B">Bernhard Endtmayer</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Schafelner%2C+A">Andreas Schafelner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
<p class=mathjax>We consider goal-oriented adaptive space-time finite-element discretizations
of the parabolic heat equation on completely unstructured simplicial space-time
meshes. In some applications, we are interested in an accurate computation of
some possibly nonlinear functionals at the solution, so called goal
functionals. This motivates the use of adaptive mesh refinements driven by the
dual-weighted residual (DWR) method. The DWR method requires the numerical
solution of a linear adjoint problem that provides the sensitivities for the
mesh refinement. This can be done by means of the same full space-time finite
element discretization as used for the primal linear problem. The numerical
experiment presented demonstrates that this goal-oriented, full space-time
finite element solver efficiently provides accurate numerical results for a
model problem with moving domains and a linear goal functional, where we know
the exact value.
</p>
</div>
</dd>
<dt><a name=item379>[379]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17239 title=Abstract>arXiv:2401.17239</a> [<a href=https://arxiv.org/pdf/2401.17239 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17239 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal control approach for moving bottom detection in one-dimensional shallow waters by surface measurements
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Montecinos%2C+G">Gino Montecinos</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lecaros%2C+R">Rodrigo Lecaros</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=L%C3%B3pez-R%C3%ADos%2C+J">Juan López-Ríos</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zuazua%2C+E">Enrique Zuazua</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 30 pages, 13 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Optimization and Control (math.OC)
</div>
<p class=mathjax>We consider the Boussinesq-Peregrine (BP) system as described by Lannes
[Lannes, D. (2013). The water waves problem: mathematical analysis and
asymptotics (Vol. 188). American Mathematical Soc.], within the shallow water
regime, and study the inverse problem of determining the time and space
variations of the channel bottom profile, from measurements of the wave profile
and its velocity on the free surface. A well-posedness result within a Sobolev
framework for (BP), considering a time dependent bottom, is presented. Then,
the inverse problem is reformulated as a nonlinear PDEconstrained optimization
one. An existence result of the minimum, under constraints on the admissible
set of bottoms, is presented. Moreover, an implementation of the gradient
descent approach, via the adjoint method, is considered. For solving
numerically both, the forward (BP) and its adjoint system, we derive a
universal and low-dissipation scheme, which contains non-conservative products.
The scheme is based on the FORCE-{\alpha} method proposed in [Toro, E. F.,
Saggiorato, B., Tokareva, S., and Hidalgo, A. (2020). Low-dissipation centred
schemes for hyperbolic equations in conservative and non-conservative form.
Journal of Computational Physics, 416, 109545]. Finally, we implement this
methodology to recover three different bottom profiles; a smooth bottom, a
discontinuous one, and a continuous profile with a large gradient. We compare
with two classical discretizations for (BP) and the adjoint system. These
results corroborate the effectiveness of the proposed methodology to recover
bottom profiles.
</p>
</div>
</dd>
<dt><a name=item380>[380]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17244 title=Abstract>arXiv:2401.17244</a> [<a href=https://arxiv.org/pdf/2401.17244 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17244 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang%2C+Y">Yuan Chiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chou%2C+C">Chia-Hong Chou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Riebesell%2C+J">Janosh Riebesell</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI)
</div>
<p class=mathjax>Reducing hallucination of Large Language Models (LLMs) is imperative for use
in the sciences where reproducibility is crucial. However, LLMs inherently lack
long-term memory, making it a nontrivial, ad hoc, and inevitably biased task to
fine-tune them on domain-specific literature and data. Here we introduce LLaMP,
a multimodal retrieval-augmented generation (RAG) framework of multiple
data-aware reasoning-and-acting (ReAct) agents that dynamically interact with
computational and experimental data on Materials Project (MP). Without
fine-tuning, LLaMP demonstrates an ability to comprehend and integrate various
modalities of materials science concepts, fetch relevant data stores on the
fly, process higher-order data (such as crystal structures and elastic
tensors), and summarize multi-step procedures for solid-state synthesis. We
show that LLaMP effectively corrects errors in GPT-3.5's intrinsic knowledge,
reducing a 5.21% MAPE on frequently-documented bandgaps and a significant
1103.54% MAPE on formation energies -- errors that GPT-3.5 seems to derive from
mixed data sources. Additionally, LLaMP substantially reduces the hallucinated
volumetric strain in a diamond cubic silicon structure from 66.3% to 0. The
proposed framework offers an intuitive and nearly hallucination-free approach
to exploring materials informatics and establishes a pathway for knowledge
distillation and fine-tuning other language models. We envision the framework
as a valuable component for scientific hypotheses and a foundation for future
autonomous laboratories where multiple LLM agents communicate and cooperate
with robotics to drive material synthesis and chemical reactions without
hard-coded human logic and intervention.
</p>
</div>
</dd>
<dt><a name=item381>[381]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17247 title=Abstract>arXiv:2401.17247</a> [<a href=https://arxiv.org/pdf/2401.17247 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17247 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Forwarding for Next Generation Relay Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arda%2C+E">Enes Arda</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kutay%2C+E">Emrecan Kutay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yener%2C+A">Aylin Yener</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
<p class=mathjax>We consider cooperative semantic text communications facilitated by a relay
node. We propose two types of semantic forwarding: semantic lossy forwarding
(SLF) and semantic predict-and-forward (SPF). Both are machine learning aided
approaches, and, in particular, utilize attention mechanisms at the relay to
establish a dynamic semantic state, updated upon receiving a new source signal.
In the SLF model, the semantic state is used to decode the received source
signal; whereas in the SPF model, it is used to predict the next source signal,
enabling proactive forwarding. Our proposed forwarding schemes do not need any
channel state information and exhibit consistent performance regardless of the
relay's position. Our results demonstrate that the proposed semantic forwarding
techniques outperform conventional semantic-agnostic baselines.
</p>
</div>
</dd>
<dt><a name=item382>[382]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17252 title=Abstract>arXiv:2401.17252</a> [<a href=https://arxiv.org/pdf/2401.17252 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17252 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17252 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-192-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1146 style=width:1.067em;display:inline-block><span style=display:inline-block;position:relative;width:0.882em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.88em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1147><span class=mi id=MathJax-Span-1148 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.049em></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-Secure <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-193-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1149 style=width:0.928em;display:inline-block><span style=display:inline-block;position:relative;width:0.743em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.74em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1150><span class=mi id=MathJax-Span-1151 style=font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-Byzantine <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-194-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1152 style=width:0.928em;display:inline-block><span style=display:inline-block;position:relative;width:0.743em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.113em,1000.74em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1153><span class=mi id=MathJax-Span-1154 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.141em></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-Colluding Private Information Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nomeir%2C+M">Mohamed Nomeir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aytekin%2C+A">Alptug Aytekin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Quantum Physics (quant-ph)
</div>
<p class=mathjax>We consider the problems arising from the presence of Byzantine servers in a
quantum private information retrieval (QPIR) setting. This is the first work to
precisely define what the capabilities of Byzantine servers could be in a QPIR
context. We show that quantum Byzantine servers have more capabilities than
their classical counterparts due to the possibilities created by the quantum
encoding procedure. We focus on quantum Byzantine servers that can apply any
reversible operations on their individual qudits. In this case, the Byzantine
servers can generate any error, i.e., this covers \emph{all} possible single
qudit operations that can be done by the Byzantine servers on their qudits. We
design a scheme that is resilient to these kinds of manipulations. We show that
the scheme designed achieves superdense coding gain in all cases, i.e., <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-195-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1155 style=width:21.878em;display:inline-block><span style=display:inline-block;position:relative;width:18.232em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.913em,1018.12em,4.054em,-999.997em);top:-3.238em;left:0em><span class=mrow id=MathJax-Span-1156><span class=msubsup id=MathJax-Span-1157><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1158 style=font-family:MathJax_Math-italic>R</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.755em><span class=mi id=MathJax-Span-1159 style=font-size:70.7%;font-family:MathJax_Math-italic>Q</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1160 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mo id=MathJax-Span-1161 style=font-family:MathJax_Main;padding-left:0.292em>max</span><span class=mrow id=MathJax-Span-1162 style=padding-left:0.177em><span class=mo id=MathJax-Span-1163 style=vertical-align:0em><span style=font-family:MathJax_Size2>{</span></span><span class=mn id=MathJax-Span-1164 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1165 style=font-family:MathJax_Main>,</span><span class=mo id=MathJax-Span-1166 style=font-family:MathJax_Main;padding-left:0.177em>min</span><span class=mrow id=MathJax-Span-1167 style=padding-left:0.177em><span class=mo id=MathJax-Span-1168 style=vertical-align:0em><span style=font-family:MathJax_Size2>{</span></span><span class=mn id=MathJax-Span-1169 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1170 style=font-family:MathJax_Main>,</span><span class=mn id=MathJax-Span-1171 style=font-family:MathJax_Main;padding-left:0.177em>2</span><span class=mrow id=MathJax-Span-1172 style=padding-left:0.177em><span class=mo id=MathJax-Span-1173 style=vertical-align:0em><span style=font-family:MathJax_Size2>(</span></span><span class=mn id=MathJax-Span-1174 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1175 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mfrac id=MathJax-Span-1176 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:3.186em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.359em,1003.07em,4.227em,-999.997em);top:-4.453em;left:50%;margin-left:-1.56em><span class=mrow id=MathJax-Span-1177><span class=mi id=MathJax-Span-1178 style=font-size:70.7%;font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1179 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mi id=MathJax-Span-1180 style=font-size:70.7%;font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1181 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1182 style=font-size:70.7%;font-family:MathJax_Main>2</span><span class=mi id=MathJax-Span-1183 style=font-size:70.7%;font-family:MathJax_Math-italic>B</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.585em;left:50%;margin-left:-0.286em><span class=mi id=MathJax-Span-1184 style=font-size:70.7%;font-family:MathJax_Math-italic>N<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1003.19em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:3.186em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mo id=MathJax-Span-1185 style=vertical-align:0em><span style=font-family:MathJax_Size2>)</span></span></span><span class=mo id=MathJax-Span-1186 style=vertical-align:0em><span style=font-family:MathJax_Size2>}</span></span></span><span class=mo id=MathJax-Span-1187 style=vertical-align:0em><span style=font-family:MathJax_Size2>}</span></span></span></span><span style=display:inline-block;width:0px;height:3.244em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.83em;border-left:0px solid;width:0px;height:2.295em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item383>[383]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17256 title=Abstract>arXiv:2401.17256</a> [<a href=https://arxiv.org/pdf/2401.17256 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17256 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weak-to-Strong Jailbreaking on Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xuandong Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+X">Xianjun Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pang%2C+T">Tianyu Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+C">Chao Du</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu-Xiang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
<p class=mathjax>Although significant efforts have been dedicated to aligning large language
models (LLMs), red-teaming reports suggest that these carefully aligned LLMs
could still be jailbroken through adversarial prompts, tuning, or decoding.
Upon examining the jailbreaking vulnerability of aligned LLMs, we observe that
the decoding distributions of jailbroken and aligned models differ only in the
initial generations. This observation motivates us to propose the
weak-to-strong jailbreaking attack, where adversaries can utilize smaller
unsafe/aligned LLMs (e.g., 7B) to guide jailbreaking against significantly
larger aligned LLMs (e.g., 70B). To jailbreak, one only needs to additionally
decode two smaller LLMs once, which involves minimal computation and latency
compared to decoding the larger LLMs. The efficacy of this attack is
demonstrated through experiments conducted on five models from three different
organizations. Our study reveals a previously unnoticed yet efficient way of
jailbreaking, exposing an urgent safety issue that needs to be considered when
aligning LLMs. As an initial attempt, we propose a defense strategy to protect
against such attacks, but creating more advanced defenses remains challenging.
The code for replicating the method is available at
https://github.com/XuandongZhao/weak-to-strong
</p>
</div>
</dd>
<dt><a name=item384>[384]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17258 title=Abstract>arXiv:2401.17258</a> [<a href=https://arxiv.org/pdf/2401.17258 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17258 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> You Only Need One Step: Fast Super-Resolution with Stable Diffusion via Scale Distillation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Noroozi%2C+M">Mehdi Noroozi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hadji%2C+I">Isma Hadji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martinez%2C+B">Brais Martinez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bulat%2C+A">Adrian Bulat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>In this paper, we introduce YONOS-SR, a novel stable diffusion-based approach
for image super-resolution that yields state-of-the-art results using only a
single DDIM step. We propose a novel scale distillation approach to train our
SR model. Instead of directly training our SR model on the scale factor of
interest, we start by training a teacher model on a smaller magnification
scale, thereby making the SR problem simpler for the teacher. We then train a
student model for a higher magnification scale, using the predictions of the
teacher as a target during the training. This process is repeated iteratively
until we reach the target scale factor of the final model. The rationale behind
our scale distillation is that the teacher aids the student diffusion model
training by i) providing a target adapted to the current noise level rather
than using the same target coming from ground truth data for all noise levels
and ii) providing an accurate target as the teacher has a simpler task to
solve. We empirically show that the distilled model significantly outperforms
the model trained for high scales directly, specifically with few steps during
inference. Having a strong diffusion model that requires only one step allows
us to freeze the U-Net and fine-tune the decoder on top of it. We show that the
combination of spatially distilled U-Net and fine-tuned decoder outperforms
state-of-the-art methods requiring 200 steps with only one single step.
</p>
</div>
</dd>
<dt><a name=item385>[385]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17263 title=Abstract>arXiv:2401.17263</a> [<a href=https://arxiv.org/pdf/2401.17263 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17263 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A">Andy Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> code available at <a href=https://github.com/andyz245/rpo>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Despite advances in AI alignment, language models (LM) remain vulnerable to
adversarial attacks or jailbreaking, in which adversaries modify input prompts
to induce harmful behavior. While some defenses have been proposed, they focus
on narrow threat models and fall short of a strong defense, which we posit
should be effective, universal, and practical. To achieve this, we propose the
first adversarial objective for defending LMs against jailbreaking attacks and
an algorithm, robust prompt optimization (RPO), that uses gradient-based token
optimization to enforce harmless outputs. This results in an easily accessible
suffix that significantly improves robustness to both jailbreaks seen during
optimization and unknown, held-out jailbreaks, reducing the attack success rate
on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find
that RPO has a minor effect on normal LM use, is successful under adaptive
attacks, and can transfer to black-box models, reducing the success rate of the
strongest attack on GPT-4 from 92% to 6%.
</p>
</div>
</dd>
<dt><a name=item386>[386]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17264 title=Abstract>arXiv:2401.17264</a> [<a href=https://arxiv.org/pdf/2401.17264 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17264 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proactive Detection of Voice Cloning with Localized Watermarking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roman%2C+R+S">Robin San Roman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandez%2C+P">Pierre Fernandez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%A9fossez%2C+A">Alexandre Défossez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Furon%2C+T">Teddy Furon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tran%2C+T">Tuan Tran</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elsahar%2C+H">Hady Elsahar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code at <a href=https://github.com/facebookresearch/audioseal>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)
</div>
<p class=mathjax>In the rapidly evolving field of speech generative models, there is a
pressing need to ensure audio authenticity against the risks of voice cloning.
We present AudioSeal, the first audio watermarking technique designed
specifically for localized detection of AI-generated speech. AudioSeal employs
a generator/detector architecture trained jointly with a localization loss to
enable localized watermark detection up to the sample level, and a novel
perceptual loss inspired by auditory masking, that enables AudioSeal to achieve
better imperceptibility. AudioSeal achieves state-of-the-art performance in
terms of robustness to real life audio manipulations and imperceptibility based
on automatic and human evaluation metrics. Additionally, AudioSeal is designed
with a fast, single-pass detector, that significantly surpasses existing models
in speed - achieving detection up to two orders of magnitude faster, making it
ideal for large-scale and real-time applications.
</p>
</div>
</dd>
<dt><a name=item387>[387]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17267 title=Abstract>arXiv:2401.17267</a> [<a href=https://arxiv.org/pdf/2401.17267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17267 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReacLLaMA: Merging chemical and textual information in chemical reactivity AI models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hartgers%2C+A">Aline Hartgers</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nugmanov%2C+R">Ramil Nugmanov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chernichenko%2C+K">Kostiantyn Chernichenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wegner%2C+J+K">Joerg Kurt Wegner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)
</div>
<p class=mathjax>Chemical reactivity models are developed to predict chemical reaction
outcomes in the form of classification (success/failure) or regression (product
yield) tasks. The vast majority of the reported models are trained solely on
chemical information such as reactants, products, reagents, and solvents, but
not on the details of a synthetic protocol. Herein incorporation of procedural
text with the aim to augment the Graphormer reactivity model and improve its
accuracy is presented. Two major approaches are used: training an adapter
Graphormer model that is provided with a GPT-2-derived latent representation of
the text procedure (ReacLLaMA-Adapter) and labeling an unlabeled part of a
dataset with the LLaMA 2 model followed by training the Graphormer on an
extended dataset (Zero-Shot Labeling ReacLLaMA). Both methodologies enhance the
discernment of unpromising reactions, thereby providing more accurate models
with improved specificity.
</p>
</div>
</dd>
<dt><a name=item388>[388]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17268 title=Abstract>arXiv:2401.17268</a> [<a href=https://arxiv.org/pdf/2401.17268 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17268 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weaver: Foundation Models for Creative Writing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tiannan Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiamin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jia%2C+Q">Qingrui Jia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+R">Ruoyu Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Huilin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhaowei Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+C">Chunzhao Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Chuou Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J">Jihong Dai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yibin Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jialong Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+S">Shengwei Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Long Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhiwei Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+X">Xinle Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+T">Teng Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+G">Gangan Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+H">Han Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zixin Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang%2C+D">Danjun Xiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunxia Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yuanyuan Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jing Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yiru Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+S">Siran Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiayang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiayi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tayier%2C+Y">Yilihamu Tayier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Z">Zhenyu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuan Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+C">Chengfeng Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yueshu Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yihang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+L">Lei Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xinyue Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yujie Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+S">Siyu Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhule Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiangru Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaohua Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Huajun Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+Y+E">Yuchen Eleanor Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wangchunshu Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
<p class=mathjax>This work introduces Weaver, our first family of large language models (LLMs)
dedicated to content creation. Weaver is pre-trained on a carefully selected
corpus that focuses on improving the writing capabilities of large language
models. We then fine-tune Weaver for creative and professional writing purposes
and align it to the preference of professional writers using a suit of novel
methods for instruction data synthesis and LLM alignment, making it able to
produce more human-like texts and follow more diverse instructions for content
creation. The Weaver family consists of models of Weaver Mini (1.8B), Weaver
Base (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable for
different applications and can be dynamically dispatched by a routing agent
according to query complexity to balance response quality and computation cost.
Evaluation on a carefully curated benchmark for assessing the writing
capabilities of LLMs shows Weaver models of all sizes outperform generalist
LLMs several times larger than them. Notably, our most-capable Weaver Ultra
model surpasses GPT-4, a state-of-the-art generalist LLM, on various writing
scenarios, demonstrating the advantage of training specialized LLMs for writing
purposes. Moreover, Weaver natively supports retrieval-augmented generation
(RAG) and function calling (tool usage). We present various use cases of these
abilities for improving AI-assisted writing systems, including integration of
external knowledge bases, tools, or APIs, and providing personalized writing
assistance. Furthermore, we discuss and summarize a guideline and best
practices for pre-training and fine-tuning domain-specific LLMs.
</p>
</div>
</dd>
<dt><a name=item389>[389]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17270 title=Abstract>arXiv:2401.17270</a> [<a href=https://arxiv.org/pdf/2401.17270 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17270 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> YOLO-World: Real-Time Open-Vocabulary Object Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+T">Tianheng Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+L">Lin Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+W">Wenyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinggang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Work still in progress. Code \&amp; models are available at: <a href=https://github.com/AILab-CVC/YOLO-World>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>The You Only Look Once (YOLO) series of detectors have established themselves
as efficient and practical tools. However, their reliance on predefined and
trained object categories limits their applicability in open scenarios.
Addressing this limitation, we introduce YOLO-World, an innovative approach
that enhances YOLO with open-vocabulary detection capabilities through
vision-language modeling and pre-training on large-scale datasets.
Specifically, we propose a new Re-parameterizable Vision-Language Path
Aggregation Network (RepVL-PAN) and region-text contrastive loss to facilitate
the interaction between visual and linguistic information. Our method excels in
detecting a wide range of objects in a zero-shot manner with high efficiency.
On the challenging LVIS dataset, YOLO-World achieves 35.4 AP with 52.0 FPS on
V100, which outperforms many state-of-the-art methods in terms of both accuracy
and speed. Furthermore, the fine-tuned YOLO-World achieves remarkable
performance on several downstream tasks, including object detection and
open-vocabulary instance segmentation.
</p>
</div>
</dd>
<dt><a name=item390>[390]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17271 title=Abstract>arXiv:2401.17271</a> [<a href=https://arxiv.org/pdf/2401.17271 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17271 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A simple, strong baseline for building damage detection on the xBD dataset
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gerard%2C+S">Sebastian Gerard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Borne-Pons%2C+P">Paul Borne-Pons</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sullivan%2C+J">Josephine Sullivan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
<p class=mathjax>We construct a strong baseline method for building damage detection by
starting with the highly-engineered winning solution of the xView2 competition,
and gradually stripping away components. This way, we obtain a much simpler
method, while retaining adequate performance. We expect the simplified solution
to be more widely and easily applicable. This expectation is based on the
reduced complexity, as well as the fact that we choose hyperparameters based on
simple heuristics, that transfer to other datasets. We then re-arrange the
xView2 dataset splits such that the test locations are not seen during
training, contrary to the competition setup. In this setting, we find that both
the complex and the simplified model fail to generalize to unseen locations.
Analyzing the dataset indicates that this failure to generalize is not only a
model-based problem, but that the difficulty might also be influenced by the
unequal class distributions between events.
<br>Code, including the baseline model, is available under
https://github.com/PaulBorneP/Xview2_Strong_Baseline
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 31 Jan 24</h3>
<dl>
<dt><a name=item391>[391]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16437 title=Abstract>arXiv:2401.16437</a> (cross-list from physics.ao-ph) [<a href=https://arxiv.org/pdf/2401.16437 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16437 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Benchmark Dataset for Tornado Detection and Prediction using Full-Resolution Polarimetric Weather Radar Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Veillette%2C+M+S">Mark S. Veillette</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Kurdzo%2C+J+M">James M. Kurdzo</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Stepanian%2C+P+M">Phillip M. Stepanian</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Cho%2C+J+Y+N">John Y. N. Cho</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Samsi%2C+S">Siddharth Samsi</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=McDonald%2C+J">Joseph McDonald</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 37 pages, 15 Figures, 2 Tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Weather radar is the primary tool used by forecasters to detect and warn for
tornadoes in near-real time. In order to assist forecasters in warning the
public, several algorithms have been developed to automatically detect tornadic
signatures in weather radar observations. Recently, Machine Learning (ML)
algorithms, which learn directly from large amounts of labeled data, have been
shown to be highly effective for this purpose. Since tornadoes are extremely
rare events within the corpus of all available radar observations, the
selection and design of training datasets for ML applications is critical for
the performance, robustness, and ultimate acceptance of ML algorithms. This
study introduces a new benchmark dataset, TorNet to support development of ML
algorithms in tornado detection and prediction. TorNet contains
full-resolution, polarimetric, Level-II WSR-88D data sampled from 10 years of
reported storm events. A number of ML baselines for tornado detection are
developed and compared, including a novel deep learning (DL) architecture
capable of processing raw radar imagery without the need for manual feature
extraction required for existing ML algorithms. Despite not benefiting from
manual feature engineering or other preprocessing, the DL model shows increased
detection performance compared to non-DL and operational baselines. The TorNet
dataset, as well as source code and model weights of the DL baseline trained in
this work, are made freely available.
</p>
</div>
</dd>
<dt><a name=item392>[392]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16458 title=Abstract>arXiv:2401.16458</a> (cross-list from q-fin.RM) [<a href=https://arxiv.org/pdf/2401.16458 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16458 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Sanz-Guerrero%2C+M">Mario Sanz-Guerrero</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Arroyo%2C+J">Javier Arroyo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Risk Management (q-fin.RM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
<p class=mathjax>Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism,
linking borrowers with lenders through online platforms. However, P2P lending
faces the challenge of information asymmetry, as lenders often lack sufficient
data to assess the creditworthiness of borrowers. This paper proposes a novel
approach to address this issue by leveraging the textual descriptions provided
by borrowers during the loan application process. Our methodology involves
processing these textual descriptions using a Large Language Model (LLM), a
powerful tool capable of discerning patterns and semantics within the text.
Transfer learning is applied to adapt the LLM to the specific task at hand.
<br>Our results derived from the analysis of the Lending Club dataset show that
the risk score generated by BERT, a widely used LLM, significantly improves the
performance of credit risk classifiers. However, the inherent opacity of
LLM-based systems, coupled with uncertainties about potential biases,
underscores critical considerations for regulatory frameworks and engenders
trust-related concerns among end-users, opening new avenues for future research
in the dynamic landscape of P2P lending and artificial intelligence.
</p>
</div>
</dd>
<dt><a name=item393>[393]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16595 title=Abstract>arXiv:2401.16595</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.16595 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16595 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Fault-Tolerant Distributed Termination Method for Distributed Optimization Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Alkhraijah%2C+M">Mohannad Alkhraijah</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>This paper proposes a fully distributed termination method for distributed
optimization algorithms solved by multiple agents. The proposed method
guarantees terminating a distributed optimization algorithm after satisfying
the global termination criterion using information from local computations and
neighboring agents. The proposed method requires additional iterations after
satisfying the global terminating criterion to communicate the termination
status. The number of additional iterations is bounded by the diameter of the
communication network. This paper also proposes a fault-tolerant extension of
this termination method that prevents early termination due to faulty agents or
communication errors. We provide a proof of the method's correctness and
demonstrate the proposed method by solving the optimal power flow problem for
electric power grids using the alternating direction method of multipliers.
</p>
</div>
</dd>
<dt><a name=item394>[394]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16596 title=Abstract>arXiv:2401.16596</a> (cross-list from stat.ME) [<a href=https://arxiv.org/pdf/2401.16596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chakraborty%2C+A">Abhinav Chakraborty</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chatterjee%2C+A">Anirban Chatterjee</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Dalal%2C+A">Abhinandan Dalal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To Appear in AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI); Statistics Theory (math.ST); Machine Learning (stat.ML)
</div>
<p class=mathjax>The Ising model, originally developed as a spin-glass model for ferromagnetic
elements, has gained popularity as a network-based model for capturing
dependencies in agents' outputs. Its increasing adoption in healthcare and the
social sciences has raised privacy concerns regarding the confidentiality of
agents' responses. In this paper, we present a novel
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-196-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1188 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.03em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1189><span class=mo id=MathJax-Span-1190 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1191 style=font-family:MathJax_Math-italic>ε</span><span class=mo id=MathJax-Span-1192 style=font-family:MathJax_Main>,</span><span class=mi id=MathJax-Span-1193 style=font-family:MathJax_Math-italic;padding-left:0.177em>δ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1194 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>-differentially private algorithm specifically designed
to protect the privacy of individual agents' outcomes. Our algorithm allows for
precise estimation of the natural parameter using a single network through an
objective perturbation technique. Furthermore, we establish regret bounds for
this algorithm and assess its performance on synthetic datasets and two
real-world networks: one involving HIV status in a social network and the other
concerning the political leaning of online blogs.
</p>
</div>
</dd>
<dt><a name=item395>[395]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16611 title=Abstract>arXiv:2401.16611</a> (cross-list from cond-mat.supr-con) [<a href=https://arxiv.org/pdf/2401.16611 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16611 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Accelerating superconductor discovery through tempered deep learning of the electron-phonon spectral function
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Gibson%2C+J+B">Jason B. Gibson</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Hire%2C+A+C">Ajinkya C. Hire</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Dee%2C+P+M">Philip M. Dee</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Barrera%2C+O">Oscar Barrera</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Geisler%2C+B">Benjamin Geisler</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Hirschfeld%2C+P+J">Peter J. Hirschfeld</a>, 
<a href="https://arxiv.org/search/cond-mat?searchtype=author&amp;query=Hennig%2C+R+G">Richard G. Hennig</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 5 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Superconductivity (cond-mat.supr-con)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)
</div>
<p class=mathjax>Integrating deep learning with the search for new electron-phonon
superconductors represents a burgeoning field of research, where the primary
challenge lies in the computational intensity of calculating the
electron-phonon spectral function, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-197-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1195 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.07em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1196><span class=msubsup id=MathJax-Span-1197><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1198 style=font-family:MathJax_Math-italic>α</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mn id=MathJax-Span-1199 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1200 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-1201 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1202 style=font-family:MathJax_Math-italic>ω</span><span class=mo id=MathJax-Span-1203 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, the essential
ingredient of Midgal-Eliashberg theory of superconductivity. To overcome this
challenge, we adopt a two-step approach. First, we compute <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-198-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1204 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.07em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1205><span class=msubsup id=MathJax-Span-1206><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1207 style=font-family:MathJax_Math-italic>α</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mn id=MathJax-Span-1208 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1209 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-1210 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1211 style=font-family:MathJax_Math-italic>ω</span><span class=mo id=MathJax-Span-1212 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>
for 818 dynamically stable materials. We then train a deep-learning model to
predict <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-199-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1213 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.07em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1214><span class=msubsup id=MathJax-Span-1215><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1216 style=font-family:MathJax_Math-italic>α</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mn id=MathJax-Span-1217 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1218 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-1219 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1220 style=font-family:MathJax_Math-italic>ω</span><span class=mo id=MathJax-Span-1221 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>, using an unconventional training strategy to
temper the model's overfitting, enhancing predictions. Specifically, we train a
Bootstrapped Ensemble of Tempered Equivariant graph neural NETworks (BETE-NET),
obtaining an MAE of 0.21, 45 K, and 43 K for the Eliashberg moments derived
from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-200-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1222 style=width:3.822em;display:inline-block><span style=display:inline-block;position:relative;width:3.186em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1003.07em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1223><span class=msubsup id=MathJax-Span-1224><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1225 style=font-family:MathJax_Math-italic>α</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.639em><span class=mn id=MathJax-Span-1226 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mi id=MathJax-Span-1227 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-1228 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1229 style=font-family:MathJax_Math-italic>ω</span><span class=mo id=MathJax-Span-1230 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span>: <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-201-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1231 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1232><span class=mi id=MathJax-Span-1233 style=font-family:MathJax_Math-italic>λ</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-202-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1234 style=width:1.97em;display:inline-block><span style=display:inline-block;position:relative;width:1.623em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1001.62em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1235><span class=msubsup id=MathJax-Span-1236><span style=display:inline-block;position:relative;width:1.623em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1237 style=font-family:MathJax_Math-italic>ω</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=texatom id=MathJax-Span-1238><span class=mrow id=MathJax-Span-1239><span class=mi id=MathJax-Span-1240 style=font-size:70.7%;font-family:MathJax_Main>log</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-203-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1241 style=width:1.276em;display:inline-block><span style=display:inline-block;position:relative;width:1.045em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1001.04em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1242><span class=msubsup id=MathJax-Span-1243><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1244 style=font-family:MathJax_Math-italic>ω</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.639em><span class=texatom id=MathJax-Span-1245><span class=mrow id=MathJax-Span-1246><span class=mn id=MathJax-Span-1247 style=font-size:70.7%;font-family:MathJax_Main>2</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:0.837em"></span></span></nobr></span>,
respectively, yielding an MAE of 2.5 K for the critical temperature, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-204-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1248 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1249><span class=msubsup id=MathJax-Span-1250><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1251 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1252 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>.
Further, we incorporate domain knowledge of the site-projected phonon density
of states to impose inductive bias into the model's node attributes and enhance
predictions. This methodological innovation decreases the MAE to 0.18, 29 K,
and 28 K, respectively, yielding an MAE of 2.1 K for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-205-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1253 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1254><span class=msubsup id=MathJax-Span-1255><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1256 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1257 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>. We illustrate the
practical application of our model in high-throughput screening for high-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-206-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1258 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1259><span class=msubsup id=MathJax-Span-1260><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1261 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1262 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>
materials. The model demonstrates an average precision nearly five times higher
than random screening, highlighting the potential of ML in accelerating
superconductor discovery. BETE-NET accelerates the search for high-<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-207-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1263 style=width:1.218em;display:inline-block><span style=display:inline-block;position:relative;width:0.987em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1000.99em,1.334em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1264><span class=msubsup id=MathJax-Span-1265><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.7em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1266 style=font-family:MathJax_Math-italic>T<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.582em><span class=mi id=MathJax-Span-1267 style=font-size:70.7%;font-family:MathJax_Math-italic>c</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>
superconductors while setting a precedent for applying ML in materials
discovery, particularly when data is limited.
</p>
</div>
</dd>
<dt><a name=item396>[396]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16612 title=Abstract>arXiv:2401.16612</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.16612 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16612 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning a Gaussian Mixture for Sparsity Regularization in Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Alberti%2C+G+S">Giovanni S. Alberti</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ratti%2C+L">Luca Ratti</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Santacesaria%2C+M">Matteo Santacesaria</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sciutto%2C+S">Silvia Sciutto</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In inverse problems, it is widely recognized that the incorporation of a
sparsity prior yields a regularization effect on the solution. This approach is
grounded on the a priori assumption that the unknown can be appropriately
represented in a basis with a limited number of significant components, while
most coefficients are close to zero. This occurrence is frequently observed in
real-world scenarios, such as with piecewise smooth signals. In this study, we
propose a probabilistic sparsity prior formulated as a mixture of degenerate
Gaussians, capable of modeling sparsity with respect to a generic basis. Under
this premise, we design a neural network that can be interpreted as the Bayes
estimator for linear inverse problems. Additionally, we put forth both a
supervised and an unsupervised training strategy to estimate the parameters of
this network. To evaluate the effectiveness of our approach, we conduct a
numerical comparison with commonly employed sparsity-promoting regularization
techniques, namely LASSO, group LASSO, iterative hard thresholding, and sparse
coding/dictionary learning. Notably, our reconstructions consistently exhibit
lower mean square error values across all <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-208-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1268 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1269><span class=mn id=MathJax-Span-1270 style=font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>D datasets utilized for the
comparisons, even in cases where the datasets significantly deviate from a
Gaussian mixture model.
</p>
</div>
</dd>
<dt><a name=item397>[397]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16613 title=Abstract>arXiv:2401.16613</a> (cross-list from math.AG) [<a href=https://arxiv.org/pdf/2401.16613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16613 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algebraic Complexity and Neurovariety of Linear Convolutional Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shahverdi%2C+V">Vahid Shahverdi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Algebraic Geometry (math.AG)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this paper, we study linear convolutional networks with one-dimensional
filters and arbitrary strides. The neuromanifold of such a network is a
semialgebraic set, represented by a space of polynomials admitting specific
factorizations. Introducing a recursive algorithm, we generate polynomial
equations whose common zero locus corresponds to the Zariski closure of the
corresponding neuromanifold. Furthermore, we explore the algebraic complexity
of training these networks employing tools from metric algebraic geometry. Our
findings reveal that the number of all complex critical points in the
optimization of such a network is equal to the generic Euclidean distance
degree of a Segre variety. Notably, this count significantly surpasses the
number of critical points encountered in the training of a fully connected
linear network with the same number of parameters.
</p>
</div>
</dd>
<dt><a name=item398>[398]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16655 title=Abstract>arXiv:2401.16655</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.16655 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16655 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16655 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rademacher Complexity of Neural ODEs via Chen-Fliess Series
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hanson%2C+J">Joshua Hanson</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Raginsky%2C+M">Maxim Raginsky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages; final version to appear in L4DC 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
<p class=mathjax>We show how continuous-depth neural ODE models can be framed as single-layer,
infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs.
In this net, the output ''weights'' are taken from the signature of the control
input -- a tool used to represent infinite-dimensional paths as a sequence of
tensors -- which comprises iterated integrals of the control input over a
simplex. The ''features'' are taken to be iterated Lie derivatives of the
output function with respect to the vector fields in the controlled ODE model.
The main result of this work applies this framework to derive compact
expressions for the Rademacher complexity of ODE models that map an initial
condition to a scalar output at some terminal time. The result leverages the
straightforward analysis afforded by single-layer architectures. We conclude
with some examples instantiating the bound for some specific systems and
discuss potential follow-up work.
</p>
</div>
</dd>
<dt><a name=item399>[399]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16683 title=Abstract>arXiv:2401.16683</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.16683 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16683 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Polynomial Chaos Expansions on Principal Geodesic Grassmannian Submanifolds for Surrogate Modeling and Uncertainty Quantification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Giovanis%2C+D+G">Dimitris G. Giovanis</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Loukrezis%2C+D">Dimitrios Loukrezis</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shields%2C+M+D">Michael D. Shields</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 50 pages, 17 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)
</div>
<p class=mathjax>In this work we introduce a manifold learning-based surrogate modeling
framework for uncertainty quantification in high-dimensional stochastic
systems. Our first goal is to perform data mining on the available simulation
data to identify a set of low-dimensional (latent) descriptors that efficiently
parameterize the response of the high-dimensional computational model. To this
end, we employ Principal Geodesic Analysis on the Grassmann manifold of the
response to identify a set of disjoint principal geodesic submanifolds, of
possibly different dimension, that captures the variation in the data. Since
operations on the Grassmann require the data to be concentrated, we propose an
adaptive algorithm based on Riemanniann K-means and the minimization of the
sample Frechet variance on the Grassmann manifold to identify "local" principal
geodesic submanifolds that represent different system behavior across the
parameter space. Polynomial chaos expansion is then used to construct a mapping
between the random input parameters and the projection of the response on these
local principal geodesic submanifolds. The method is demonstrated on four test
cases, a toy-example that involves points on a hypersphere, a Lotka-Volterra
dynamical system, a continuous-flow stirred-tank chemical reactor system, and a
two-dimensional Rayleigh-Benard convection problem
</p>
</div>
</dd>
<dt><a name=item400>[400]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16701 title=Abstract>arXiv:2401.16701</a> (cross-list from math.ST) [<a href=https://arxiv.org/pdf/2401.16701 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16701 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16701 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multivariate Priors and the Linearity of Optimal Bayesian Estimators under Gaussian Noise
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Barnes%2C+L+P">Leighton P. Barnes</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Dytso%2C+A">Alex Dytso</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+J">Jingbo Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Statistics Theory (math.ST)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>Consider the task of estimating a random vector <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-209-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1271 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1272><span class=mi id=MathJax-Span-1273 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> from noisy observations
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-210-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1274 style=width:5.906em;display:inline-block><span style=display:inline-block;position:relative;width:4.922em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.92em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1275><span class=mi id=MathJax-Span-1276 style=font-family:MathJax_Math-italic>Y<span style=display:inline-block;overflow:hidden;height:1px;width:0.177em></span></span><span class=mo id=MathJax-Span-1277 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mi id=MathJax-Span-1278 style=font-family:MathJax_Math-italic;padding-left:0.292em>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1279 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mi id=MathJax-Span-1280 style=font-family:MathJax_Math-italic;padding-left:0.234em>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-211-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1281 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1282><span class=mi id=MathJax-Span-1283 style=font-family:MathJax_Math-italic>Z<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a standard normal vector, under the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-212-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1284 style=width:1.334em;display:inline-block><span style=display:inline-block;position:relative;width:1.102em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1001.1em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1285><span class=msubsup id=MathJax-Span-1286><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1287 style=font-family:MathJax_Math-italic>L</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.697em><span class=mi id=MathJax-Span-1288 style=font-size:70.7%;font-family:MathJax_Math-italic>p</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> fidelity
criterion. This work establishes that, for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-213-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1289 style=width:5.095em;display:inline-block><span style=display:inline-block;position:relative;width:4.227em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1004.17em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1290><span class=mn id=MathJax-Span-1291 style=font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1292 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-1293 style=font-family:MathJax_Math-italic;padding-left:0.292em>p</span><span class=mo id=MathJax-Span-1294 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mn id=MathJax-Span-1295 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, the optimal
Bayesian estimator is linear and positive definite if and only if the prior
distribution on <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-214-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1296 style=width:0.987em;display:inline-block><span style=display:inline-block;position:relative;width:0.813em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.81em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1297><span class=mi id=MathJax-Span-1298 style=font-family:MathJax_Math-italic>X<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is a (non-degenerate) multivariate Gaussian. Furthermore,
for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-215-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1299 style=width:2.896em;display:inline-block><span style=display:inline-block;position:relative;width:2.376em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.32em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1300><span class=mi id=MathJax-Span-1301 style=font-family:MathJax_Math-italic>p</span><span class=mo id=MathJax-Span-1302 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1303 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, it is demonstrated that there are infinitely many priors that can
induce such an estimator.
</p>
</div>
</dd>
<dt><a name=item401>[401]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16776 title=Abstract>arXiv:2401.16776</a> (cross-list from stat.CO) [<a href=https://arxiv.org/pdf/2401.16776 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16776 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Yang%2C+X">Xiliang Yang</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Xiong%2C+Y">Yifei Xiong</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=He%2C+Z">Zhijian He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation (stat.CO)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)
</div>
<p class=mathjax>Sequential neural posterior estimation (SNPE) techniques have been recently
proposed for dealing with simulation-based models with intractable likelihoods.
They are devoted to learning the posterior from adaptively proposed simulations
using neural network-based conditional density estimators. As a SNPE technique,
the automatic posterior transformation (APT) method proposed by Greenberg et
al. (2019) performs notably and scales to high dimensional data. However, the
APT method bears the computation of an expectation of the logarithm of an
intractable normalizing constant, i.e., a nested expectation. Although atomic
APT was proposed to solve this by discretizing the normalizing constant, it
remains challenging to analyze the convergence of learning. In this paper, we
propose a nested APT method to estimate the involved nested expectation
instead. This facilitates establishing the convergence analysis. Since the
nested estimators for the loss function and its gradient are biased, we make
use of unbiased multi-level Monte Carlo (MLMC) estimators for debiasing. To
further reduce the excessive variance of the unbiased estimators, this paper
also develops some truncated MLMC estimators by taking account of the trade-off
between the bias and the average cost. Numerical experiments for approximating
complex posteriors with multimodal in moderate dimensions are provided.
</p>
</div>
</dd>
<dt><a name=item402>[402]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16779 title=Abstract>arXiv:2401.16779</a> (cross-list from physics.optics) [<a href=https://arxiv.org/pdf/2401.16779 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16779 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16779 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> All-optical complex field imaging using diffractive processors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+J">Jingxi Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+Y">Yuhang Li</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Gan%2C+T">Tianyi Gan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Shen%2C+C">Che-Yung Shen</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Jarrahi%2C+M">Mona Jarrahi</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ozcan%2C+A">Aydogan Ozcan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 Pages, 6 Figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Applied Physics (physics.app-ph)
</div>
<p class=mathjax>Complex field imaging, which captures both the amplitude and phase
information of input optical fields or objects, can offer rich structural
insights into samples, such as their absorption and refractive index
distributions. However, conventional image sensors are intensity-based and
inherently lack the capability to directly measure the phase distribution of a
field. This limitation can be overcome using interferometric or holographic
methods, often supplemented by iterative phase retrieval algorithms, leading to
a considerable increase in hardware complexity and computational demand. Here,
we present a complex field imager design that enables snapshot imaging of both
the amplitude and quantitative phase information of input fields using an
intensity-based sensor array without any digital processing. Our design
utilizes successive deep learning-optimized diffractive surfaces that are
structured to collectively modulate the input complex field, forming two
independent imaging channels that perform amplitude-to-amplitude and
phase-to-intensity transformations between the input and output planes within a
compact optical design, axially spanning ~100 wavelengths. The intensity
distributions of the output fields at these two channels on the sensor plane
directly correspond to the amplitude and quantitative phase profiles of the
input complex field, eliminating the need for any digital image reconstruction
algorithms. We experimentally validated the efficacy of our complex field
diffractive imager designs through 3D-printed prototypes operating at the
terahertz spectrum, with the output amplitude and phase channel images closely
aligning with our numerical simulations. We envision that this complex field
imager will have various applications in security, biomedical imaging, sensing
and material science, among others.
</p>
</div>
</dd>
<dt><a name=item403>[403]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16782 title=Abstract>arXiv:2401.16782</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.16782 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16782 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Literature Review on Fetus Brain Motion Correction in MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yun Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper provides a comprehensive review of the latest advancements in
fetal motion correction in MRI. We delve into various contemporary
methodologies and technological advancements aimed at overcoming these
challenges. It includes traditional 3D fetal MRI correction methods like Slice
to Volume Registration (SVR), deep learning-based techniques such as
Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) Networks,
Transformers, Generative Adversarial Networks (GANs) and most recent
advancements of Diffusion Models. The insights derived from this literature
review reflect a thorough understanding of both the technical intricacies and
practical implications of fetal motion in MRI studies, offering a reasoned
perspective on potential solutions and future improvements in this field.
</p>
</div>
</dd>
<dt><a name=item404>[404]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16819 title=Abstract>arXiv:2401.16819</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.16819 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16819 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Localizing uniformly moving mono-frequent sources using an inverse 2.5D approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kasess%2C+C+H">Christian H. Kasess</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kreuzer%2C+W">Wolfgang Kreuzer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Soni%2C+P">Prateek Soni</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Waubke%2C+H">Holger Waubke</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 27 pages, 15 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>Localizing linearly moving sound sources using microphone arrays is
particularly challenging as the transient nature of the signal leads to
relatively short observation periods. Commonly, a moving focus is used and most
methods operate at least partially in the time domain. In contrast, here an
inverse source localization algorithm for mono-frequent uniformly moving
sources that acts entirely in the frequency domain is presented. For this, a
2.5D approach is utilized and a transfer function between sources and a
microphone grid is derived. By solving a least squares problem using the data
at the microphone grid, the unknown source distribution in the moving frame can
be determined. For that the measured time signals need to be transformed into
the frequency domain using a windowed discrete Fourier transform (DFT), which
leads to effects such as spectral leakage that depends on the length of the
time interval and the analysis window used. To include these effects in the
numerical model, the calculation of the transfer matrix is modified using the
Fourier transform of the analysis window. Currently, this approach is limited
to mono-frequent sources as this allows a simplification of the calculation and
reduces the computational effort. The least squares problem is solved using a
Tikhonov regularization employing an L-curve approach to determine a suitable
regularization parameter. As a moving source is considered, the Doppler effect
allows to enhance the stability of the system by combining the transfer
functions for multiple frequencies in the measured signals. The performance of
the approach is validated using simulated data of a moving point source with or
without a reflecting ground. Numerical experiments are performed to show the
effect of the choice of frequencies in the receiver spectrum, the effect of the
DFT, the frequency of the source, and the distance of source and receiver.
</p>
</div>
</dd>
<dt><a name=item405>[405]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16831 title=Abstract>arXiv:2401.16831</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.16831 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16831 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16831 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Maximal planar graphs that embed as centers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Preez%2C+B+D">Brandon Du Preez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 18 figures. An early version of this work appeared in the Author's thesis "Distances in Planar Graphs", available on the UCT open thesis repository (2021)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>A maximal planar graph is a graph which can be embedded in the plane such
that every face of the graph is a triangle. The center of a graph is the
subgraph induced by the vertices of minimum eccentricity. We introduce the
notion of quasi-eccentric vertices, and use this to characterize maximal planar
graphs that are the center of some planar graph. We also present some easier to
check only necessary / only sufficient conditions for planar and maximal planar
graphs to be the center of a planar graph. Finally, we use the aforementioned
characterization to prove that all maximal planar graphs of order at most 8 are
the center of some planar graph -- and this bound is sharp.
</p>
</div>
</dd>
<dt><a name=item406>[406]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16850 title=Abstract>arXiv:2401.16850</a> (cross-list from eess.AS) [<a href=https://arxiv.org/pdf/2401.16850 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16850 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16850 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Spatial-Temporal Activity-Informed Diarization and Separation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Hsu%2C+Y">Yicheng Hsu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+S">Ssuhan Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bai%2C+M+R">Mingsian R. Bai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
<p class=mathjax>A robust multichannel speaker diarization and separation system is proposed
by exploiting the spatio-temporal activity of the speakers. The system is
realized in a hybrid architecture that combines the array signal processing
units and the deep learning units. For speaker diarization, a spatial coherence
matrix across time frames is computed based on the whitened relative transfer
functions (wRTFs) of the microphone array. This serves as a robust feature for
subsequent machine learning without the need for prior knowledge of the array
configuration. A computationally efficient Spatial Activity-driven Speaker
Diarization network (SASDnet) is constructed to estimate the speaker activity
directly from the spatial coherence matrix. For speaker separation, we propose
the Global and Local Activity-driven Speaker Extraction network (GLASEnet) to
separate speaker signals via speaker-specific global and local spatial activity
functions. The local spatial activity functions depend on the coherence between
the wRTFs of each time-frequency bin and the target speaker-dominant bins. The
global spatial activity functions are computed from the global spatial
coherence functions based on frequency-averaged local spatial activity
functions. Experimental results have demonstrated superior speaker,
diarization, counting, and separation performance achieved by the proposed
system with low computational complexity compared to the pre-selected
baselines.
</p>
</div>
</dd>
<dt><a name=item407>[407]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16875 title=Abstract>arXiv:2401.16875</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.16875 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16875 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum Circuit Mapping for Universal and Scalable Computing in MZI-based Integrated Photonics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kwon%2C+Y">Yong Kwon</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Baldazzi%2C+A">Alessio Baldazzi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Pavesi%2C+L">Lorenzo Pavesi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Choi%2C+B">Byung-Soo Choi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)
</div>
<p class=mathjax>Linear optical quantum computing (LOQC) offers a quantum computation paradigm
based on well-established and robust technology and flexible environmental
conditions following DiVincenzo's criteria. Within this framework, integrated
photonics can be utilized to achieve gate-based quantum computing, defining
qubits by path-encoding, quantum gates through the use of Mach-Zehnder
interferometers (MZIs) as fundamental building blocks, and measurements through
single-photon detectors. In particular, universal two-qubit gates can be
achieved by suitable structures of MZIs together with post-selection or
heralding. The most resource-efficient choice is given by the post-selected CZ
gate. However, this implementation is characterized by a design which has a
non-regular structure and cannot be cascaded. This limits the implementation of
large-scale LOQC. Starting from these issues, we suggest an approach to move
toward a universal and scalable LOQC on the integrated photonic platform. First
of all, choosing the post-selected CZ as universal two-qubit gate, we extend
the path-encoded dual-rail qubit to a triplet of waveguides, composed of an
auxiliary waveguide and the pair of waveguides corresponding to the qubit basis
states. Additionally, we introduce a swap photonic network that maps the
regularly-labeled structure of the new path-encoded qubits to the structure
needed for the post-selected CZ. We also discuss the optical swap gate that
allows the connection of non-nearest neighbor path-encoded qubits. In this way,
we can deterministically exchange the locations of the qubits and execute
controlled quantum gates between any path-encoded qubits. Next, by truncating
the auxiliary waveguides after any post-selected CZ, we find that it is
possible to cascade this optical gate when it acts on different pairs that
share only one qubit.
</p>
</div>
</dd>
<dt><a name=item408>[408]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16879 title=Abstract>arXiv:2401.16879</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.16879 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16879 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16879 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal Control of a Stochastic Power System -- Algorithms and Mathematical Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wang%2C+Z">Zhen Wang</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Xi%2C+K">Kaihua Xi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Cheng%2C+A">Aijie Cheng</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin%2C+H+X">Hai Xiang Lin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=van+Schuppen%2C+J+H">Jan H. van Schuppen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, 2 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
<p class=mathjax>The considered optimal control problem of a stochastic power system, is to
select the set of power supply vectors which infimizes the probability that the
phase-angle differences of any power flow of the network, endangers the
transient stability of the power system by leaving a critical subset. The set
of control laws is restricted to be a periodically recomputed set of fixed
power supply vectors based on predictions of power demand for the next short
horizon. Neither state feedback nor output feedback is used. The associated
control objective function is Lipschitz continuous, nondifferentiable, and
nonconvex. The results of the paper include that a minimum exists in the value
range of the control objective function. Furthermore, it includes a two-step
procedure to compute an approximate minimizer based on two key methods: (1) a
projected generalized subgradient method for computing an initial vector, and
(2) a steepest descent method for approximating a local minimizer. Finally, it
includes two convergence theorems that an approximation sequence converges to a
local minimum.
</p>
</div>
</dd>
<dt><a name=item409>[409]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16920 title=Abstract>arXiv:2401.16920</a> (cross-list from q-fin.PM) [<a href=https://arxiv.org/pdf/2401.16920 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16920 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sparse Portfolio Selection via Topological Data Analysis based Clustering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Goel%2C+A">Anubha Goel</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Filipovi%C4%87%2C+D">Damir Filipović</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Pasricha%2C+P">Puneet Pasricha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Statistical Finance (q-fin.ST)
</div>
<p class=mathjax>This paper uses topological data analysis (TDA) tools and introduces a
data-driven clustering-based stock selection strategy tailored for sparse
portfolio construction. Our asset selection strategy exploits the topological
features of stock price movements to select a subset of topologically similar
(different) assets for a sparse index tracking (Markowitz) portfolio. We
introduce new distance measures, which serve as an input to the clustering
algorithm, on the space of persistence diagrams and landscapes that consider
the time component of a time series. We conduct an empirical analysis on the
S\&amp;P index from 2009 to 2020, including a study on the COVID-19 data to
validate the robustness of our methodology. Our strategy to integrate TDA with
the clustering algorithm significantly enhanced the performance of sparse
portfolios across various performance measures in diverse market scenarios.
</p>
</div>
</dd>
<dt><a name=item410>[410]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16922 title=Abstract>arXiv:2401.16922</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.16922 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16922 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Properties of Quantum States Without the I.I.D. Assumption
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Fawzi%2C+O">Omar Fawzi</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Kueng%2C+R">Richard Kueng</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Markham%2C+D">Damian Markham</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Oufkir%2C+A">Aadil Oufkir</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Probability (math.PR); Statistics Theory (math.ST)
</div>
<p class=mathjax>We develop a framework for learning properties of quantum states beyond the
assumption of independent and identically distributed (i.i.d.) input states. We
prove that, given any learning problem (under reasonable assumptions), an
algorithm designed for i.i.d. input states can be adapted to handle input
states of any nature, albeit at the expense of a polynomial increase in copy
complexity. Furthermore, we establish that algorithms which perform
non-adaptive incoherent measurements can be extended to encompass non-i.i.d.
input states while maintaining comparable error probabilities. This allows us,
among others applications, to generalize the classical shadows of Huang, Kueng,
and Preskill to the non-i.i.d. setting at the cost of a small loss in
efficiency. Additionally, we can efficiently verify any pure state using
Clifford measurements, in a way that is independent of the ideal state. Our
main techniques are based on de Finetti-style theorems supported by tools from
information theory. In particular, we prove a new randomized local de Finetti
theorem that can be of independent interest.
</p>
</div>
</dd>
<dt><a name=item411>[411]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16928 title=Abstract>arXiv:2401.16928</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.16928 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16928 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic MRI reconstruction using low-rank plus sparse decomposition with smoothness regularization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ting%2C+C">Chee-Ming Ting</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Noman%2C+F">Fuad Noman</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Phan%2C+R+C+-">Raphaël C.-W. Phan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ombao%2C+H">Hernando Ombao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>The low-rank plus sparse (L+S) decomposition model has enabled better
reconstruction of dynamic magnetic resonance imaging (dMRI) with separation
into background (L) and dynamic (S) component. However, use of low-rank prior
alone may not fully explain the slow variations or smoothness of the background
part at the local scale. In this paper, we propose a smoothness-regularized L+S
(SR-L+S) model for dMRI reconstruction from highly undersampled k-t-space data.
We exploit joint low-rank and smooth priors on the background component of dMRI
to better capture both its global and local temporal correlated structures.
Extending the L+S formulation, the low-rank property is encoded by the nuclear
norm, while the smoothness by a general \ell_{p}-norm penalty on the local
differences of the columns of L. The additional smoothness regularizer can
promote piecewise local consistency between neighboring frames. By smoothing
out the noise and dynamic activities, it allows accurate recovery of the
background part, and subsequently more robust dMRI reconstruction. Extensive
experiments on multi-coil cardiac and synthetic data shows that the SR-L+S
model outp
</p>
</div>
</dd>
<dt><a name=item412>[412]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16942 title=Abstract>arXiv:2401.16942</a> (cross-list from econ.TH) [<a href=https://arxiv.org/pdf/2401.16942 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16942 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robust Price Discrimination
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Arieli%2C+I">Itai Arieli</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Babichenko%2C+Y">Yakov Babichenko</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Madmon%2C+O">Omer Madmon</a>, 
<a href="https://arxiv.org/search/econ?searchtype=author&amp;query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)
</div>
<p class=mathjax>We consider a model of third-degree price discrimination, in which the seller
has a valuation for the product which is unknown to the market designer, who
aims to maximize the buyers' surplus by revealing information regarding the
buyer's valuation to the seller. Our main result shows that the regret is
bounded by <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-216-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1304 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.48em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1305><span class=msubsup id=MathJax-Span-1306><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1307 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.871em><span class=mo id=MathJax-Span-1308 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1309 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1310 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1311 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1312><span class=mrow id=MathJax-Span-1313><span class=mo id=MathJax-Span-1314 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-1315 style=font-family:MathJax_Math-italic>e</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-217-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1316 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1317><span class=msubsup id=MathJax-Span-1318><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1319 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.871em><span class=mo id=MathJax-Span-1320 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1321 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1322 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1323 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> is the optimal buyer surplus in the case
where the seller has zero valuation for the product. This bound is attained by
randomly drawing a seller valuation and applying the segmentation of Bergemann
et al. (2015) with respect to the drawn valuation. We show that the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-218-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1324 style=width:4.285em;display:inline-block><span style=display:inline-block;position:relative;width:3.533em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1003.48em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1325><span class=msubsup id=MathJax-Span-1326><span style=display:inline-block;position:relative;width:1.276em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.75em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1327 style=font-family:MathJax_Math-italic>U<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.871em><span class=mo id=MathJax-Span-1328 style=font-size:70.7%;font-family:MathJax_Main>∗</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1329 style=font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1330 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1331 style=font-family:MathJax_Main>)</span><span class=texatom id=MathJax-Span-1332><span class=mrow id=MathJax-Span-1333><span class=mo id=MathJax-Span-1334 style=font-family:MathJax_Main>/</span></span></span><span class=mi id=MathJax-Span-1335 style=font-family:MathJax_Math-italic>e</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
bound is tight in the case of binary buyer valuation.
</p>
</div>
</dd>
<dt><a name=item413>[413]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16963 title=Abstract>arXiv:2401.16963</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.16963 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16963 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16963 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sub-Optimal Fast Fourier Series Approximation for Initial Trajectory Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gunsaulus%2C+C">Caleb Gunsaulus</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=De+Vries%2C+C">Carl De Vries</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Brown%2C+W">William Brown</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+Y">Youngro Lee</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vijayakumar%2C+M">Madhusudan Vijayakumar</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Abdelkhalik%2C+O">Ossama Abdelkhalik</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2021 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, Virtual, August 9-11, 2021
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Space Physics (physics.space-ph)
</div>
<p class=mathjax>The Finite Fourier Series (FFS) Shape-Based (SB) trajectory approximation
method has been used to rapidly generate initial trajectories that satisfy the
dynamics, trajectory boundary conditions, and limitation on maximum thrust
acceleration. The FFS SB approach solves a nonlinear programming problem (NLP)
in searching for feasible trajectories. This paper extends the development of
the FFS SB approach to generate sub optimal solutions. Specifically, the
objective function of the NLP problem is modified to include also a measure for
the time of flight. Numerical results presented in this paper show several
solutions that differ from those of the original FFS SB ones. The sub-optimal
trajectories generated using a time of flight minimization are shown to be
physically feasible trajectories and potential candidates for direct solvers.
</p>
</div>
</dd>
<dt><a name=item414>[414]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16981 title=Abstract>arXiv:2401.16981</a> (cross-list from astro-ph.IM) [<a href=https://arxiv.org/pdf/2401.16981 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16981 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16981 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Selection of gamma events from IACT images with deep learning methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Gres%2C+E+O">E. O. Gres</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Kryukov%2C+A+P">A. P. Kryukov</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Demichev%2C+A+P">A. P. Demichev</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Dubenskaya%2C+J+J">J. J. Dubenskaya</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Polyakov%2C+S+P">S. P. Polyakov</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Vlaskina%2C+A+A">A. A. Vlaskina</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Zhurov%2C+D+P">D. P. Zhurov</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Version of article, submitted to journal
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Moscow Univ. Phys. 78, 1 (2023) 45-51
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Machine Learning (cs.LG)
</div>
<p class=mathjax>Imaging Atmospheric Cherenkov Telescopes (IACTs) of gamma ray observatory
TAIGA detect the Extesnive Air Showers (EASs) originating from the cosmic or
gamma rays interactions with the atmosphere. Thereby, telescopes obtain images
of the EASs. The ability to segregate gamma rays images from the hadronic
cosmic ray background is one of the main features of this type of detectors.
However, in actual IACT observations simultaneous observation of the background
and the source of gamma ray is needed. This observation mode (called wobbling)
modifies images of events, which affects the quality of selection by neural
networks.
<br>Thus, in this work, the results of the application of neural networks (NN)
for image classification task on Monte Carlo (MC) images of TAIGA-IACTs are
presented. The wobbling mode is considered together with the image adaptation
for adequate analysis by NNs. Simultaneously, we explore several neural network
structures that classify events both directly from images or through Hillas
parameters extracted from images. In addition, by employing NNs, MC simulation
data are used to evaluate the quality of the segregation of rare gamma events
with the account of all necessary image modifications.
</p>
</div>
</dd>
<dt><a name=item415>[415]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16985 title=Abstract>arXiv:2401.16985</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.16985 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16985 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multiple Yield Curve Modeling and Forecasting using Deep Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Richman%2C+R">Ronald Richman</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Scognamiglio%2C+S">Salvatore Scognamiglio</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This manuscript introduces deep learning models that simultaneously describe
the dynamics of several yield curves. We aim to learn the dependence structure
among the different yield curves induced by the globalization of financial
markets and exploit it to produce more accurate forecasts. By combining the
self-attention mechanism and nonparametric quantile regression, our model
generates both point and interval forecasts of future yields. The architecture
is designed to avoid quantile crossing issues affecting multiple quantile
regression models. Numerical experiments conducted on two different datasets
confirm the effectiveness of our approach. Finally, we explore potential
extensions and enhancements by incorporating deep ensemble methods and transfer
learning mechanisms.
</p>
</div>
</dd>
<dt><a name=item416>[416]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16986 title=Abstract>arXiv:2401.16986</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.16986 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16986 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Machine Learning for Cost-Effective Allocation of Development Aid
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kuzmanovic%2C+M">Milan Kuzmanovic</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Frauen%2C+D">Dennis Frauen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Hatt%2C+T">Tobias Hatt</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>The Sustainable Development Goals (SDGs) of the United Nations provide a
blueprint of a better future by 'leaving no one behind', and, to achieve the
SDGs by 2030, poor countries require immense volumes of development aid. In
this paper, we develop a causal machine learning framework for predicting
heterogeneous treatment effects of aid disbursements to inform effective aid
allocation. Specifically, our framework comprises three components: (i) a
balancing autoencoder that uses representation learning to embed
high-dimensional country characteristics while addressing treatment selection
bias; (ii) a counterfactual generator to compute counterfactual outcomes for
varying aid volumes to address small sample-size settings; and (iii) an
inference model that is used to predict heterogeneous treatment-response
curves. We demonstrate the effectiveness of our framework using data with
official development aid earmarked to end HIV/AIDS in 105 countries, amounting
to more than USD 5.2 billion. For this, we first show that our framework
successfully computes heterogeneous treatment-response curves using
semi-synthetic data. Then, we demonstrate our framework using real-world HIV
data. Our framework points to large opportunities for a more effective aid
allocation, suggesting that the total number of new HIV infections could be
reduced by up to 3.3% (~50,000 cases) compared to the current allocation
practice.
</p>
</div>
</dd>
<dt><a name=item417>[417]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17029 title=Abstract>arXiv:2401.17029</a> (cross-list from astro-ph.CO) [<a href=https://arxiv.org/pdf/2401.17029 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17029 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LADDER: Revisiting the Cosmic Distance Ladder with Deep Learning Approaches and Exploring its Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Shah%2C+R">Rahul Shah</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Saha%2C+S">Soumadeep Saha</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Mukherjee%2C+P">Purba Mukherjee</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Garain%2C+U">Utpal Garain</a>, 
<a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Pal%2C+S">Supratik Pal</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 4 figures, 3 tables. Comments are welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)
</div>
<p class=mathjax>We investigate the prospect of reconstructing the ``cosmic distance ladder''
of the Universe using a novel deep learning framework called LADDER - Learning
Algorithm for Deep Distance Estimation and Reconstruction. LADDER is trained on
the apparent magnitude data from the Pantheon Type Ia supernovae compilation,
incorporating the full covariance information among data points, to produce
predictions along with corresponding errors. After employing several validation
tests with a number of deep learning models, we pick LADDER as the best
performing one. We then demonstrate applications of our method in the
cosmological context, that include serving as a model-independent tool for
consistency checks for other datasets like baryon acoustic oscillations,
calibration of high-redshift datasets such as gamma ray bursts, use as a
model-independent mock catalog generator for future probes, etc. Our analysis
advocates for interesting yet cautious consideration of machine learning
applications in these contexts.
</p>
</div>
</dd>
<dt><a name=item418>[418]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17077 title=Abstract>arXiv:2401.17077</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17077 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17077 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamical Survival Analysis with Controlled Latent States
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bleistein%2C+L">Linus Bleistein</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Nguyen%2C+V">Van-Tuan Nguyen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Fermanian%2C+A">Adeline Fermanian</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Guilloux%2C+A">Agathe Guilloux</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 41 pages, 27 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>We consider the task of learning individual-specific intensities of counting
processes from a set of static variables and irregularly sampled time series.
We introduce a novel modelization approach in which the intensity is the
solution to a controlled differential equation. We first design a neural
estimator by building on neural controlled differential equations. In a second
time, we show that our model can be linearized in the signature space under
sufficient regularity conditions, yielding a signature-based estimator which we
call CoxSig. We provide theoretical learning guarantees for both estimators,
before showcasing the performance of our models on a vast array of simulated
and real-world datasets from finance, predictive maintenance and food supply
chain management.
</p>
</div>
</dd>
<dt><a name=item419>[419]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17094 title=Abstract>arXiv:2401.17094</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.17094 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17094 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17094 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Constructing rotatable permutations of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-219-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1336 style=width:1.854em;display:inline-block><span style=display:inline-block;position:relative;width:1.53em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0em,1001.53em,1.438em,-999.998em);top:-1.016em;left:0em><span class=mrow id=MathJax-Span-1337><span class=msubsup id=MathJax-Span-1338><span style=display:inline-block;position:relative;width:1.53em;height:0px><span style=position:absolute;clip:rect(3.15em,1000.6em,4.123em,-999.998em);top:-3.979em;left:0em><span class=texatom id=MathJax-Span-1339><span class=mrow id=MathJax-Span-1340><span class=mi id=MathJax-Span-1341 style=font-family:MathJax_AMS>F</span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;clip:rect(3.382em,1000.42em,4.123em,-999.998em);top:-4.396em;left:0.604em><span class=mn id=MathJax-Span-1342 style=font-size:70.7%;font-family:MathJax_Main>3</span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;clip:rect(3.336em,1000.93em,4.123em,-999.998em);top:-3.701em;left:0.604em><span class=texatom id=MathJax-Span-1343><span class=mrow id=MathJax-Span-1344><span class=msubsup id=MathJax-Span-1345><span style=display:inline-block;position:relative;width:0.836em;height:0px><span style=position:absolute;clip:rect(3.382em,1000.33em,4.123em,-999.998em);top:-3.979em;left:0em><span class=mn id=MathJax-Span-1346 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.984em></span></span><span style=position:absolute;top:-4.257em;left:0.373em><span class=mi id=MathJax-Span-1347 style=font-size:50%;font-family:MathJax_Math-italic>m</span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.984em></span></span></span></span></span><span style=display:inline-block;width:0px;height:1.021em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.386em;border-left:0px solid;width:0px;height:1.503em"></span></span></nobr></span> with <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-220-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1348 style=width:0.604em;display:inline-block><span style=display:inline-block;position:relative;width:0.512em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.391em,1000.47em,2.317em,-999.998em);top:-2.174em;left:0em><span class=mrow id=MathJax-Span-1349><span class=mn id=MathJax-Span-1350 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.178em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.947em"></span></span></nobr></span>-homogeneous functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chi%2C+Y">Yunwen Chi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+K">Kangquan Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Qu%2C+L">Longjiang Qu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Information Theory (cs.IT)
</div>
<p class=mathjax>In the literature, there are many results about permutation polynomials over
finite fields. However, very few permutations of vector spaces are constructed
although it has been shown that permutations of vector spaces have many
applications in cryptography, especially in constructing permutations with low
differential and boomerang uniformities.
<br>In this paper, motivated by the butterfly structure
\cite{perrin2016cryptanalysis} and the work of Qu and Li \cite{qu2023}, we
investigate rotatable permutations from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-221-Frame tabindex=0><span class=math id=MathJax-Span-1351><span class=noError id=MathJax-Span-1352>$\gf_{2^m}^3$</span></span></span> to itself with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-222-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1353 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1354><span class=mi id=MathJax-Span-1355 style=font-family:MathJax_Math-italic>d<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-homogenous functions.
<br>Based on the theory of equations of low degree, the resultant of polynomials,
and some skills of exponential sums, we construct five infinite classes of
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-223-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1356 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.392em,1000.47em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1357><span class=mn id=MathJax-Span-1358 style=font-family:MathJax_Main>3</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-homogeneous rotatable permutations from <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-224-Frame tabindex=0><span class=math id=MathJax-Span-1359><span class=noError id=MathJax-Span-1360>$\gf_{2^m}^3$</span></span></span> to itself, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-225-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1361 style=width:1.045em;display:inline-block><span style=display:inline-block;position:relative;width:0.871em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.87em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1362><span class=mi id=MathJax-Span-1363 style=font-family:MathJax_Math-italic>m</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>
is odd. Moreover, we demonstrate that the corresponding permutation polynomials
of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-226-Frame tabindex=0><span class=math id=MathJax-Span-1364><span class=noError id=MathJax-Span-1365>$\gf_{2^{3m}}$</span></span></span> of our newly constructed permutations of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-227-Frame tabindex=0><span class=math id=MathJax-Span-1366><span class=noError id=MathJax-Span-1367>$\gf_{2^m}^3$</span></span></span> are
QM-inequivalent to the known ones.
</p>
</div>
</dd>
<dt><a name=item420>[420]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17104 title=Abstract>arXiv:2401.17104</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.17104 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17104 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rodrigues%2C+L">Livia Rodrigues</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bocchetta%2C+M">Martina Bocchetta</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Puonti%2C+O">Oula Puonti</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Greve%2C+D">Douglas Greve</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Londe%2C+A+C">Ana Carolina Londe</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fran%C3%A7a%2C+M">Marcondes França</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Appenzeller%2C+S">Simone Appenzeller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rittner%2C+L">Leticia Rittner</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>Purpose: To develop a method for automated segmentation of hypothalamus
subregions informed by ultra-high resolution ex vivo magnetic resonance images
(MRI), which generalizes across MRI sequences and resolutions without
retraining.
<br>Materials and Methods: We trained our deep learning method, H-synEx, with
synthetic images derived from label maps built from ultra-high resolution ex
vivo MRI scans, which enables finer-grained manual segmentation when compared
with 1mm isometric in vivo images. We validated this retrospective study using
1535 in vivo images from six datasets and six MRI sequences. The quantitative
evaluation used the Dice Coefficient (DC) and Average Hausdorff distance (AVD).
Statistical analysis compared hypothalamic subregion volumes in controls,
Alzheimer's disease (AD), and behavioral variant frontotemporal dementia
(bvFTD) subjects using the area under the curve (AUC) and Wilcoxon rank sum
test.
<br>Results: H-SynEx can segment the hypothalamus across various MRI sequences,
encompassing FLAIR sequences with significant slice spacing (5mm). Using
hypothalamic volumes on T1w images to distinguish control from AD and bvFTD
patients, we observed AUC values of 0.74 and 0.79 respectively. Additionally,
AUC=0.66 was found for volume variation on FLAIR scans when comparing control
and non-patients.
<br>Conclusion: Our results show that H-SynEx successfully leverages information
from ultra-high resolution scans to segment in vivo from different MRI
sequences such as T1w, T2w, PD, qT1, FA, and FLAIR. We also found that our
automated segmentation was able to discriminate controls versus patients on
FLAIR images with 5mm spacing. H-SynEx is openly available at
https://github.com/liviamarodrigues/hsynex.
</p>
</div>
</dd>
<dt><a name=item421>[421]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17112 title=Abstract>arXiv:2401.17112</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.17112 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17112 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17112 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the Mod-6 Town Rules
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vishwanathan%2C+S">Sundar Vishwanathan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 4 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)
</div>
<p class=mathjax>This note presents an upper bound of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-228-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1368 style=width:3.475em;display:inline-block><span style=display:inline-block;position:relative;width:2.896em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1369><span class=mn id=MathJax-Span-1370 style=font-family:MathJax_Main>1.252</span><span class=mi id=MathJax-Span-1371 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> on the size of a set system
that satisfies the mod-6 town rules. Under these rules the sizes of the sets
are not congruent to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-229-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1372 style=width:4.17em;display:inline-block><span style=display:inline-block;position:relative;width:3.475em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.42em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1373><span class=mn id=MathJax-Span-1374 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1375 style=font-family:MathJax_Main;padding-left:0.292em;padding-right:0.292em>mod</span><span class=mn id=MathJax-Span-1376 style=font-family:MathJax_Main>6</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> while the sizes of all pairwise intersections
are congruent to <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-230-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1377 style=width:4.17em;display:inline-block><span style=display:inline-block;position:relative;width:3.475em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1003.42em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1378><span class=mn id=MathJax-Span-1379 style=font-family:MathJax_Main>0</span><span class=mo id=MathJax-Span-1380 style=font-family:MathJax_Main;padding-left:0.292em;padding-right:0.292em>mod</span><span class=mn id=MathJax-Span-1381 style=font-family:MathJax_Main>6</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>.
</p>
</div>
</dd>
<dt><a name=item422>[422]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17116 title=Abstract>arXiv:2401.17116</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17116 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17116 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Quantum error mitigation and correction mediated by Yang-Baxter equation and artificial neural network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gulania%2C+S">Sahil Gulania</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Alexeev%2C+Y">Yuri Alexeev</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Gray%2C+S+K">Stephen K. Gray</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Peng%2C+B">Bo Peng</a>, 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Govind%2C+N">Niranjan Govind</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)
</div>
<p class=mathjax>Quantum computing shows great potential, but errors pose a significant
challenge. This study explores new strategies for mitigating quantum errors
using artificial neural networks (ANN) and the Yang-Baxter equation (YBE).
Unlike traditional error correction methods, which are computationally
intensive, we investigate artificial error mitigation. The manuscript
introduces the basics of quantum error sources and explores the potential of
using classical computation for error mitigation. The Yang-Baxter equation
plays a crucial role, allowing us to compress time dynamics simulations into
constant-depth circuits. By introducing controlled noise through the YBE, we
enhance the dataset for error mitigation. We train an ANN model on partial data
from quantum simulations, demonstrating its effectiveness in correcting errors
in time-evolving quantum states.
</p>
</div>
</dd>
<dt><a name=item423>[423]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17172 title=Abstract>arXiv:2401.17172</a> (cross-list from physics.comp-ph) [<a href=https://arxiv.org/pdf/2401.17172 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17172 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Domain-Independent Green's Function For Elliptic Partial Differential Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Negi%2C+P">Pawan Negi</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Cheng%2C+M">Maggie Cheng</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Krishnamurthy%2C+M">Mahesh Krishnamurthy</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Ying%2C+W">Wenjun Ying</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Li%2C+S">Shuwang Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)
</div>
<p class=mathjax>Green's function characterizes a partial differential equation (PDE) and maps
its solution in the entire domain as integrals. Finding the analytical form of
Green's function is a non-trivial exercise, especially for a PDE defined on a
complex domain or a PDE with variable coefficients. In this paper, we propose a
novel boundary integral network to learn the domain-independent Green's
function, referred to as BIN-G. We evaluate the Green's function in the BIN-G
using a radial basis function (RBF) kernel-based neural network. We train the
BIN-G by minimizing the residual of the PDE and the mean squared errors of the
solutions to the boundary integral equations for prescribed test functions. By
leveraging the symmetry of the Green's function and controlling refinements of
the RBF kernel near the singularity of the Green function, we demonstrate that
our numerical scheme enables fast training and accurate evaluation of the
Green's function for PDEs with variable coefficients. The learned Green's
function is independent of the domain geometries, forcing terms, and boundary
conditions in the boundary integral formulation. Numerical experiments verify
the desired properties of the method and the expected accuracy for the
two-dimensional Poisson and Helmholtz equations with variable coefficients.
</p>
</div>
</dd>
<dt><a name=item424>[424]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17174 title=Abstract>arXiv:2401.17174</a> (cross-list from q-bio.BM) [<a href=https://arxiv.org/pdf/2401.17174 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17174 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A large dataset curation and benchmark for drug target interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Golts%2C+A">Alex Golts</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ratner%2C+V">Vadim Ratner</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Shoshan%2C+Y">Yoel Shoshan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Raboh%2C+M">Moshe Raboh</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Polaczek%2C+S">Sagi Polaczek</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ozery-Flato%2C+M">Michal Ozery-Flato</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Shats%2C+D">Daniel Shats</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Hazan%2C+L">Liam Hazan</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ravid%2C+S">Sivan Ravid</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Hexter%2C+E">Efrat Hexter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Bioactivity data plays a key role in drug discovery and repurposing. The
resource-demanding nature of \textit{in vitro} and \textit{in vivo}
experiments, as well as the recent advances in data-driven computational
biochemistry research, highlight the importance of \textit{in silico} drug
target interaction (DTI) prediction approaches. While numerous large public
bioactivity data sources exist, research in the field could benefit from better
standardization of existing data resources. At present, different research
works that share similar goals are often difficult to compare properly because
of different choices of data sources and train/validation/test split
strategies. Additionally, many works are based on small data subsets, leading
to results and insights of possible limited validity. In this paper we propose
a way to standardize and represent efficiently a very large dataset curated
from multiple public sources, split the data into train, validation and test
sets based on different meaningful strategies, and provide a concrete
evaluation protocol to accomplish a benchmark. We analyze the proposed data
curation, prove its usefulness and validate the proposed benchmark through
experimental studies based on an existing neural network model.
</p>
</div>
</dd>
<dt><a name=item425>[425]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17177 title=Abstract>arXiv:2401.17177</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17177 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17177 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Driven Discovery of PDEs via the Adjoint Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sadr%2C+M">Mohsen Sadr</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tohme%2C+T">Tony Tohme</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Youcef-Toumi%2C+K">Kamal Youcef-Toumi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>In this work, we present an adjoint-based method for discovering the
underlying governing partial differential equations (PDEs) given data. The idea
is to consider a parameterized PDE in a general form, and formulate the
optimization problem that minimizes the error of PDE solution from data. Using
variational calculus, we obtain an evolution equation for the Lagrange
multipliers (adjoint equations) allowing us to compute the gradient of the
objective function with respect to the parameters of PDEs given data in a
straightforward manner. In particular, for a family of parameterized and
nonlinear PDEs, we show how the corresponding adjoint equations can be derived.
Here, we show that given smooth data set, the proposed adjoint method can
recover the true PDE up to machine accuracy. However, in the presence of noise,
the accuracy of the adjoint method becomes comparable to the famous PDE
Functional Identification of Nonlinear Dynamics method known as PDE-FIND (Rudy
et al., 2017). Even though the presented adjoint method relies on
forward/backward solvers, it outperforms PDE-FIND for large data sets thanks to
the analytic expressions for gradients of the cost function with respect to
each PDE parameter.
</p>
</div>
</dd>
<dt><a name=item426>[426]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17182 title=Abstract>arXiv:2401.17182</a> (cross-list from quant-ph) [<a href=https://arxiv.org/pdf/2401.17182 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17182 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Detailed Error Analysis of the HHL Algorithm
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Phillips%2C+X+L+C">Xinbo Li Christopher Phillips</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)
</div>
<p class=mathjax>We reiterate the contribution made by Harrow, Hassidim, and Llyod to the
quantum matrix equation solver with the emphasis on the algorithm description
and the error analysis derivation details. Moreover, the behavior of the
amplitudes of the phase register on the completion of the Quantum Phase
Estimation is studied. This study is beneficial for the comprehension of the
choice of the phase register size and its interrelation with the Hamiltonian
simulation duration in the algorithm setup phase.
</p>
</div>
</dd>
<dt><a name=item427>[427]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17205 title=Abstract>arXiv:2401.17205</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17205 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17205 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adaptive Experiment Design with Synthetic Controls
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=H%C3%BCy%C3%BCk%2C+A">Alihan Hüyük</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Qian%2C+Z">Zhaozhi Qian</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of the 27th International Conference on Artificial Intelligence and Statistics
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>Clinical trials are typically run in order to understand the effects of a new
treatment on a given population of patients. However, patients in large
populations rarely respond the same way to the same treatment. This
heterogeneity in patient responses necessitates trials that investigate effects
on multiple subpopulations - especially when a treatment has marginal or no
benefit for the overall population but might have significant benefit for a
particular subpopulation. Motivated by this need, we propose Syntax, an
exploratory trial design that identifies subpopulations with positive treatment
effect among many subpopulations. Syntax is sample efficient as it (i) recruits
and allocates patients adaptively and (ii) estimates treatment effects by
forming synthetic controls for each subpopulation that combines control samples
from other subpopulations. We validate the performance of Syntax and provide
insights into when it might have an advantage over conventional trial designs
through experiments.
</p>
</div>
</dd>
<dt><a name=item428>[428]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17219 title=Abstract>arXiv:2401.17219</a> (cross-list from math.CO) [<a href=https://arxiv.org/pdf/2401.17219 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.17219 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.17219 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Faster coloring and embedding in dense hypergraphs via stability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hou%2C+J">Jianfeng Hou</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Liu%2C+X">Xizhi Liu</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhao%2C+H">Hongbin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages + references, comments are welcome
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)
</div>
<p class=mathjax>The classical Andr\'{a}sfai-Erd\H{o}s-S\'{o}s Theorem states that for
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-231-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1382 style=width:2.723em;display:inline-block><span style=display:inline-block;position:relative;width:2.26em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.2em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1383><span class=mi id=MathJax-Span-1384 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1385 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-1386 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, every <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-232-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1387 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1388><span class=mi id=MathJax-Span-1389 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-vertex <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-233-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1390 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1002.14em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1391><span class=msubsup id=MathJax-Span-1392><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1393 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=texatom id=MathJax-Span-1394><span class=mrow id=MathJax-Span-1395><span class=mi id=MathJax-Span-1396 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1397 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1398 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-free graph with minimum degree
greater than <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-234-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1399 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.755em,1002.55em,2.549em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1400><span class=mfrac id=MathJax-Span-1401><span style=display:inline-block;position:relative;width:1.681em;height:0px;margin-right:0.119em;margin-left:0.119em><span style=position:absolute;clip:rect(3.302em,1001.51em,4.227em,-999.997em);top:-4.453em;left:50%;margin-left:-0.749em><span class=mrow id=MathJax-Span-1402><span class=mn id=MathJax-Span-1403 style=font-size:70.7%;font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-1404 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1405 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1406 style=font-size:70.7%;font-family:MathJax_Main>4</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.302em,1001.51em,4.227em,-999.997em);top:-3.585em;left:50%;margin-left:-0.749em><span class=mrow id=MathJax-Span-1407><span class=mn id=MathJax-Span-1408 style=font-size:70.7%;font-family:MathJax_Main>3</span><span class=mi id=MathJax-Span-1409 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1410 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1411 style=font-size:70.7%;font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(0.871em,1001.68em,1.276em,-999.997em);top:-1.328em;left:0em><span style="display:inline-block;overflow:hidden;vertical-align:0em;border-top:1.3px solid;width:1.681em;height:0px"></span><span style=display:inline-block;width:0px;height:1.102em></span></span></span></span><span class=mi id=MathJax-Span-1412 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.622em;border-left:0px solid;width:0px;height:1.878em"></span></span></nobr></span> must be <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-235-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1413 style=width:0.524em;display:inline-block><span style=display:inline-block;position:relative;width:0.408em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1000.41em,2.376em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1414><span class=mi id=MathJax-Span-1415 style=font-family:MathJax_Main>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>-partite. We establish a
simple criterion for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-236-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1416 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1417><span class=mi id=MathJax-Span-1418 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-graphs, <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-237-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1419 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.26em,2.491em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1420><span class=mi id=MathJax-Span-1421 style=font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-1422 style=font-family:MathJax_Main;padding-left:0.292em>≥</span><span class=mn id=MathJax-Span-1423 style=font-family:MathJax_Main;padding-left:0.292em>2</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.205em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span>, to exhibit an
Andr\'{a}sfai-Erd\H{o}s-S\'{o}s-type property (AES), leading to a
classification of most previously studied hypergraph families with this
property.
<br>For every AES <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-238-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1424 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1425><span class=mi id=MathJax-Span-1426 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-239-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1427 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1428><span class=mi id=MathJax-Span-1429 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>, we present a simple algorithm to decide the
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-240-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1430 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1431><span class=mi id=MathJax-Span-1432 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-freeness of an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-241-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1433 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1434><span class=mi id=MathJax-Span-1435 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-vertex <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-242-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1436 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1437><span class=mi id=MathJax-Span-1438 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-graph with minimum degree greater than
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-243-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1439 style=width:8.857em;display:inline-block><span style=display:inline-block;position:relative;width:7.352em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1007.18em,2.839em,-999.997em);top:-2.254em;left:0em><span class=mrow id=MathJax-Span-1440><span class=mo id=MathJax-Span-1441 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1442 style=font-family:MathJax_Math-italic>π<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1443 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1444 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span><span class=mo id=MathJax-Span-1445 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1446 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=msubsup id=MathJax-Span-1447 style=padding-left:0.234em><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1448 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1449 style=font-size:70.7%;font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1450 style=font-family:MathJax_Main>)</span><span class=mrow id=MathJax-Span-1451><span class=TeXmathchoice id=MathJax-Span-1452><span class=texatom id=MathJax-Span-1453><span class=mrow id=MathJax-Span-1454><span class=mo id=MathJax-Span-1455 style=vertical-align:0em><span style=font-family:MathJax_Size1>(</span></span></span></span></span><span class=mfrac id=MathJax-Span-1456><span style=display:inline-block;position:relative;width:1.218em;height:0px><span style=position:absolute;clip:rect(3.533em,1000.41em,4.17em,-999.997em);top:-4.453em;left:50%;margin-left:-0.229em><span class=mi id=MathJax-Span-1457 style=font-size:70.7%;font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.359em,1001.16em,4.227em,-999.997em);top:-3.643em;left:50%;margin-left:-0.634em><span class=mrow id=MathJax-Span-1458><span class=mi id=MathJax-Span-1459 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span class=mo id=MathJax-Span-1460 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1461 style=font-size:70.7%;font-family:MathJax_Main>1</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=TeXmathchoice id=MathJax-Span-1462><span class=texatom id=MathJax-Span-1463><span class=mrow id=MathJax-Span-1464><span class=mo id=MathJax-Span-1465 style=vertical-align:0em><span style=font-family:MathJax_Size1>)</span></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.26em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.552em;border-left:0px solid;width:0px;height:1.67em"></span></span></nobr></span> in time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-244-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1466 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1467><span class=mi id=MathJax-Span-1468 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1469 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1470><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1471 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-1472 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1473 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, where <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-245-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1474 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.9em,2.549em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1475><span class=msubsup id=MathJax-Span-1476><span style=display:inline-block;position:relative;width:1.102em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1477 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=mi id=MathJax-Span-1478 style=font-size:70.7%;font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1479 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1480 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.274em;border-left:0px solid;width:0px;height:1.115em"></span></span></nobr></span> is a constant. In particular, for the complete graph <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-246-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1481 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1002.14em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1482><span class=msubsup id=MathJax-Span-1483><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1484 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=texatom id=MathJax-Span-1485><span class=mrow id=MathJax-Span-1486><span class=mi id=MathJax-Span-1487 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1488 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1489 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>, we can
take <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-247-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1490 style=width:9.899em;display:inline-block><span style=display:inline-block;position:relative;width:8.22em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1008.22em,2.665em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1491><span class=msubsup id=MathJax-Span-1492><span style=display:inline-block;position:relative;width:2.028em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1493 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=texatom id=MathJax-Span-1494><span class=mrow id=MathJax-Span-1495><span class=msubsup id=MathJax-Span-1496><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1497 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.582em><span class=texatom id=MathJax-Span-1498><span class=mrow id=MathJax-Span-1499><span class=mi id=MathJax-Span-1500 style=font-size:50%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1501 style=font-size:50%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1502 style=font-size:50%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1503 style=font-family:MathJax_Main;padding-left:0.292em>=</span><span class=mo id=MathJax-Span-1504 style=font-family:MathJax_Main;padding-left:0.292em>(</span><span class=mn id=MathJax-Span-1505 style=font-family:MathJax_Main>3</span><span class=msubsup id=MathJax-Span-1506><span style=display:inline-block;position:relative;width:0.871em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1507 style=font-family:MathJax_Main>ℓ</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=mn id=MathJax-Span-1508 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1509 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1510 style=font-family:MathJax_Main;padding-left:0.234em>ℓ</span><span class=msubsup id=MathJax-Span-1511><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1512 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1513><span class=mrow id=MathJax-Span-1514><span class=mo id=MathJax-Span-1515 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1516 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.531em"></span></span></nobr></span>. Based on a result by
Chen-Huang-Kanj-Xia, we show that for every fixed <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-248-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1517 style=width:3.244em;display:inline-block><span style=display:inline-block;position:relative;width:2.665em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.61em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1518><span class=mi id=MathJax-Span-1519 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mo id=MathJax-Span-1520 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1521 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, this problem cannot
be solved in time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-249-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1522 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.86em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1523><span class=msubsup id=MathJax-Span-1524><span style=display:inline-block;position:relative;width:1.855em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1525 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1526><span class=mrow id=MathJax-Span-1527><span class=mi id=MathJax-Span-1528 style=font-size:70.7%;font-family:MathJax_Math-italic>o</span><span class=mo id=MathJax-Span-1529 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1530 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1531 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> if we replace <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-250-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1532 style=width:2.433em;display:inline-block><span style=display:inline-block;position:relative;width:2.028em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.35em,1002.03em,1.45em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1533><span class=msubsup id=MathJax-Span-1534><span style=display:inline-block;position:relative;width:2.028em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.41em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1535 style=font-family:MathJax_Math-italic>ε</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.466em><span class=texatom id=MathJax-Span-1536><span class=mrow id=MathJax-Span-1537><span class=msubsup id=MathJax-Span-1538><span style=display:inline-block;position:relative;width:1.508em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.64em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1539 style=font-size:70.7%;font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.874em;left:0.582em><span class=texatom id=MathJax-Span-1540><span class=mrow id=MathJax-Span-1541><span class=mi id=MathJax-Span-1542 style=font-size:50%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1543 style=font-size:50%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1544 style=font-size:50%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.413em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span> with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-251-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1545 style=width:3.591em;display:inline-block><span style=display:inline-block;position:relative;width:2.954em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1002.95em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1546><span class=mo id=MathJax-Span-1547 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1548 style=font-family:MathJax_Math-italic>C<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span class=mi id=MathJax-Span-1549 style=font-family:MathJax_Main>ℓ</span><span class=msubsup id=MathJax-Span-1550><span style=display:inline-block;position:relative;width:1.392em;height:0px><span style=position:absolute;clip:rect(3.07em,1000.29em,4.401em,-999.997em);top:-3.99em;left:0em><span class=mo id=MathJax-Span-1551 style=font-family:MathJax_Main>)</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.408em><span class=texatom id=MathJax-Span-1552><span class=mrow id=MathJax-Span-1553><span class=mo id=MathJax-Span-1554 style=font-size:70.7%;font-family:MathJax_Main>−</span><span class=mn id=MathJax-Span-1555 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> unless ETH fails. Furthermore, we establish an algorithm to
decide the <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-252-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1556 style=width:2.607em;display:inline-block><span style=display:inline-block;position:relative;width:2.144em;height:0px;font-size:120%><span style=position:absolute;clip:rect(0.119em,1002.14em,1.392em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1557><span class=msubsup id=MathJax-Span-1558><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1559 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=texatom id=MathJax-Span-1560><span class=mrow id=MathJax-Span-1561><span class=mi id=MathJax-Span-1562 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1563 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1564 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span>-freeness of an <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-253-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1565 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1566><span class=mi id=MathJax-Span-1567 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-vertex graph with
<span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-254-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1568 style=width:8.105em;display:inline-block><span style=display:inline-block;position:relative;width:6.716em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1006.72em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1569><span class=texatom id=MathJax-Span-1570><span class=mrow id=MathJax-Span-1571><span class=mi id=MathJax-Span-1572 style=font-family:MathJax_Main>e</span><span class=mi id=MathJax-Span-1573 style=font-family:MathJax_Main>x</span></span></span><span class=mo id=MathJax-Span-1574 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1575 style=font-family:MathJax_Math-italic>n</span><span class=mo id=MathJax-Span-1576 style=font-family:MathJax_Main>,</span><span class=msubsup id=MathJax-Span-1577 style=padding-left:0.177em><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.128em,1000.87em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1578 style=font-family:MathJax_Math-italic>K<span style=display:inline-block;overflow:hidden;height:1px;width:0.061em></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-3.817em;left:0.871em><span class=texatom id=MathJax-Span-1579><span class=mrow id=MathJax-Span-1580><span class=mi id=MathJax-Span-1581 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1582 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mn id=MathJax-Span-1583 style=font-size:70.7%;font-family:MathJax_Main>1</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1584 style=font-family:MathJax_Main>)</span><span class=mo id=MathJax-Span-1585 style=font-family:MathJax_Main;padding-left:0.234em>−</span><span class=mi id=MathJax-Span-1586 style=font-family:MathJax_Math-italic;padding-left:0.234em>k</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span> edges in time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-255-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1587 style=width:4.806em;display:inline-block><span style=display:inline-block;position:relative;width:3.996em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.218em,1004em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1588><span class=mo id=MathJax-Span-1589 style=font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1590 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1591 style=font-family:MathJax_Main;padding-left:0.234em>+</span><span class=mn id=MathJax-Span-1592 style=font-family:MathJax_Main;padding-left:0.234em>1</span><span class=mo id=MathJax-Span-1593 style=font-family:MathJax_Main>)</span><span class=msubsup id=MathJax-Span-1594><span style=display:inline-block;position:relative;width:1.045em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1595 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mn id=MathJax-Span-1596 style=font-size:70.7%;font-family:MathJax_Main>2</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.462em"></span></span></nobr></span> for <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-256-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1597 style=width:5.327em;display:inline-block><span style=display:inline-block;position:relative;width:4.401em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1004.4em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1598><span class=mi id=MathJax-Span-1599 style=font-family:MathJax_Math-italic>k</span><span class=mo id=MathJax-Span-1600 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=mi id=MathJax-Span-1601 style=font-family:MathJax_Math-italic;padding-left:0.292em>n</span><span class=texatom id=MathJax-Span-1602><span class=mrow id=MathJax-Span-1603><span class=mo id=MathJax-Span-1604 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-1605 style=font-family:MathJax_Main>30</span><span class=mi id=MathJax-Span-1606 style=font-family:MathJax_Main>ℓ</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>
and <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-257-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1607 style=width:5.327em;display:inline-block><span style=display:inline-block;position:relative;width:4.401em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1004.34em,2.723em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1608><span class=mi id=MathJax-Span-1609 style=font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1610 style=font-family:MathJax_Main;padding-left:0.292em>≤</span><span class=msqrt id=MathJax-Span-1611 style=padding-left:0.292em><span style=display:inline-block;position:relative;width:2.607em;height:0px><span style=position:absolute;clip:rect(3.07em,1001.57em,4.401em,-999.997em);top:-3.99em;left:0.987em><span class=mrow id=MathJax-Span-1612><span class=mi id=MathJax-Span-1613 style=font-family:MathJax_Math-italic>n</span><span class=texatom id=MathJax-Span-1614><span class=mrow id=MathJax-Span-1615><span class=mo id=MathJax-Span-1616 style=font-family:MathJax_Main>/</span></span></span><span class=mn id=MathJax-Span-1617 style=font-family:MathJax_Main>6</span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(3.533em,1001.57em,3.938em,-999.997em);top:-4.569em;left:0.987em><span style=display:inline-block;position:relative;width:1.565em;height:0px><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:-0.055em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;font-family:MathJax_Main;top:-3.99em;left:0.871em>−<span style=display:inline-block;width:0px;height:3.996em></span></span><span style=font-family:MathJax_Main;position:absolute;top:-3.99em;left:0.408em>−<span style=display:inline-block;width:0px;height:3.996em></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;clip:rect(2.954em,1001.04em,4.517em,-999.997em);top:-3.99em;left:0em><span style=font-family:MathJax_Size1>√</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.483em;border-left:0px solid;width:0px;height:1.601em"></span></span></nobr></span>, partially improving upon the recently provided
running time of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-258-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1618 style=width:5.211em;display:inline-block><span style=display:inline-block;position:relative;width:4.343em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1004.34em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1619><span class=msubsup id=MathJax-Span-1620><span style=display:inline-block;position:relative;width:2.202em;height:0px><span style=position:absolute;clip:rect(3.128em,1001.74em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mn id=MathJax-Span-1621 style=font-family:MathJax_Main>2.49</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.395em;left:1.797em><span class=mi id=MathJax-Span-1622 style=font-size:70.7%;font-family:MathJax_Math-italic>k</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=msubsup id=MathJax-Span-1623><span style=display:inline-block;position:relative;width:2.144em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1624 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1625><span class=mrow id=MathJax-Span-1626><span class=mi id=MathJax-Span-1627 style=font-size:70.7%;font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1628 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mn id=MathJax-Span-1629 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1630 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> by Fomin--Golovach--Sagunov--Simonov.
Moreover, we show that for every fixed <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-259-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1631 style=width:2.781em;display:inline-block><span style=display:inline-block;position:relative;width:2.318em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.334em,1002.26em,2.433em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1632><span class=mi id=MathJax-Span-1633 style=font-family:MathJax_Math-italic>δ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span><span class=mo id=MathJax-Span-1634 style=font-family:MathJax_Main;padding-left:0.292em>&gt;</span><span class=mn id=MathJax-Span-1635 style=font-family:MathJax_Main;padding-left:0.292em>0</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.135em;border-left:0px solid;width:0px;height:1.045em"></span></span></nobr></span>, this problem cannot be
solved in time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-260-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1636 style=width:2.26em;display:inline-block><span style=display:inline-block;position:relative;width:1.855em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.86em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1637><span class=msubsup id=MathJax-Span-1638><span style=display:inline-block;position:relative;width:1.855em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1639 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1640><span class=mrow id=MathJax-Span-1641><span class=mi id=MathJax-Span-1642 style=font-size:70.7%;font-family:MathJax_Math-italic>o</span><span class=mo id=MathJax-Span-1643 style=font-size:70.7%;font-family:MathJax_Main>(</span><span class=mi id=MathJax-Span-1644 style=font-size:70.7%;font-family:MathJax_Main>ℓ</span><span class=mo id=MathJax-Span-1645 style=font-size:70.7%;font-family:MathJax_Main>)</span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.253em"></span></span></nobr></span> if <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-261-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1646 style=width:0.639em;display:inline-block><span style=display:inline-block;position:relative;width:0.524em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.52em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1647><span class=mi id=MathJax-Span-1648 style=font-family:MathJax_Math-italic>k</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span> is of order <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-262-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1649 style=width:2.318em;display:inline-block><span style=display:inline-block;position:relative;width:1.913em;height:0px;font-size:120%><span style=position:absolute;clip:rect(-0.055em,1001.91em,1.16em,-999.997em);top:-0.981em;left:0em><span class=mrow id=MathJax-Span-1650><span class=msubsup id=MathJax-Span-1651><span style=display:inline-block;position:relative;width:1.913em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1652 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=texatom id=MathJax-Span-1653><span class=mrow id=MathJax-Span-1654><span class=mn id=MathJax-Span-1655 style=font-size:70.7%;font-family:MathJax_Main>1</span><span class=mo id=MathJax-Span-1656 style=font-size:70.7%;font-family:MathJax_Main>+</span><span class=mi id=MathJax-Span-1657 style=font-size:70.7%;font-family:MathJax_Math-italic>δ<span style=display:inline-block;overflow:hidden;height:1px;width:0.003em></span></span></span></span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span></span><span style=display:inline-block;width:0px;height:0.987em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:1.184em"></span></span></nobr></span> unless ETH
fails.
<br>As an intermediate step, we show that for a specific class of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-263-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1658 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1659><span class=mi id=MathJax-Span-1660 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-graphs <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-264-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1661 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1662><span class=mi id=MathJax-Span-1663 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>,
the (surjective) <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-265-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1664 style=width:0.929em;display:inline-block><span style=display:inline-block;position:relative;width:0.755em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.045em,1000.75em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1665><span class=mi id=MathJax-Span-1666 style=font-family:MathJax_Math-italic>F<span style=display:inline-block;overflow:hidden;height:1px;width:0.119em></span></span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.976em"></span></span></nobr></span>-coloring problem can be solved in time <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-266-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1667 style=width:3.07em;display:inline-block><span style=display:inline-block;position:relative;width:2.549em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1002.43em,2.607em,-999.997em);top:-2.196em;left:0em><span class=mrow id=MathJax-Span-1668><span class=mi id=MathJax-Span-1669 style=font-family:MathJax_Math-italic>O</span><span class=mo id=MathJax-Span-1670 style=font-family:MathJax_Main>(</span><span class=msubsup id=MathJax-Span-1671><span style=display:inline-block;position:relative;width:0.987em;height:0px><span style=position:absolute;clip:rect(3.359em,1000.58em,4.17em,-999.997em);top:-3.99em;left:0em><span class=mi id=MathJax-Span-1672 style=font-family:MathJax_Math-italic>n</span><span style=display:inline-block;width:0px;height:3.996em></span></span><span style=position:absolute;top:-4.337em;left:0.582em><span class=mi id=MathJax-Span-1673 style=font-size:70.7%;font-family:MathJax_Math-italic>r</span><span style=display:inline-block;width:0px;height:3.996em></span></span></span></span><span class=mo id=MathJax-Span-1674 style=font-family:MathJax_Main>)</span></span><span style=display:inline-block;width:0px;height:2.202em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.344em;border-left:0px solid;width:0px;height:1.323em"></span></span></nobr></span>, provided
the input <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-267-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1675 style=width:0.582em;display:inline-block><span style=display:inline-block;position:relative;width:0.466em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.47em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1676><span class=mi id=MathJax-Span-1677 style=font-family:MathJax_Math-italic>r</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span>-graph has <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-268-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1678 style=width:0.697em;display:inline-block><span style=display:inline-block;position:relative;width:0.582em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.276em,1000.58em,2.086em,-999.997em);top:-1.907em;left:0em><span class=mrow id=MathJax-Span-1679><span class=mi id=MathJax-Span-1680 style=font-family:MathJax_Math-italic>n</span></span><span style=display:inline-block;width:0px;height:1.913em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.066em;border-left:0px solid;width:0px;height:0.698em"></span></span></nobr></span> vertices and a large minimum degree, refining
several previous results.
</p>
</div>
</dd>
<dt><a name=item429>[429]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17246 title=Abstract>arXiv:2401.17246</a> (cross-list from eess.IV) [<a href=https://arxiv.org/pdf/2401.17246 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17246 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SLIC: A Learned Image Codec Using Structure and Color
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Prativadibhayankaram%2C+S">Srivatsa Prativadibhayankaram</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Panda%2C+M+P">Mahadev Prasad Panda</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Richter%2C+T">Thomas Richter</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Sparenberg%2C+H">Heiko Sparenberg</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=F%C3%B6%C3%9Fel%2C+S">Siegfried Fößel</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kaup%2C+A">André Kaup</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepter paper for Data Compression Conference 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
<p class=mathjax>We propose the structure and color based learned image codec (SLIC) in which
the task of compression is split into that of luminance and chrominance. The
deep learning model is built with a novel multi-scale architecture for Y and UV
channels in the encoder, where the features from various stages are combined to
obtain the latent representation. An autoregressive context model is employed
for backward adaptation and a hyperprior block for forward adaptation. Various
experiments are carried out to study and analyze the performance of the
proposed model, and to compare it with other image codecs. We also illustrate
the advantages of our method through the visualization of channel impulse
responses, latent channels and various ablation studies. The model achieves
Bj{\o}ntegaard delta bitrate gains of 7.5% and 4.66% in terms of MS-SSIM and
CIEDE2000 metrics with respect to other state-of-the-art reference codecs.
</p>
</div>
</dd>
<dt><a name=item430>[430]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17257 title=Abstract>arXiv:2401.17257</a> (cross-list from math.OC) [<a href=https://arxiv.org/pdf/2401.17257 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17257 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low Thrust Trajectory Design Using A Semi-Analytic Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vijayakumar%2C+M">Madhusudan Vijayakumar</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Abdelkhalik%2C+O">Ossama Abdelkhalik</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 2022 AAS/AIAA Astrodynamics Specialist Conference, Charlotte, NC, August 7-11, 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Space Physics (physics.space-ph)
</div>
<p class=mathjax>Space missions that use low-thrust propulsion technology are becoming
increasingly popular since they utilize propellant more efficiently and thus
reduce mission costs. However, optimizing continuous-thrust trajectories is
complex, time-consuming, and extremely sensitive to initial guesses. Hence,
generating approximate trajectories that can be used as reliable initial
guesses in trajectory generators is essential. This paper presents a
semi-analytic approach for designing planar and three-dimensional trajectories
using Hills equations. The spacecraft is assumed to be acted upon by a constant
thrust acceleration magnitude. The proposed equations are employed in a
Nonlinear Programming Problem (NLP) solver to obtain the thrust directions.
Their applicability is tested for various design scenarios like orbit raising,
orbit insertion, and rendezvous. The trajectory solutions are then validated as
initial guesses in high-fidelity optimal control tools. The usefulness of this
method lies in the preliminary stages of low-thrust mission design, where speed
and reliability are key.
</p>
</div>
</dd>
<dt><a name=item431>[431]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.17269 title=Abstract>arXiv:2401.17269</a> (cross-list from stat.ML) [<a href=https://arxiv.org/pdf/2401.17269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.17269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Effect of Weight Quantization on Learning Models by Typical Case Analysis
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kashiwamura%2C+S">Shuhei Kashiwamura</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sakata%2C+A">Ayaka Sakata</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Imaizumi%2C+M">Masaaki Imaizumi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
<p class=mathjax>This paper examines the quantization methods used in large-scale data
analysis models and their hyperparameter choices. The recent surge in data
analysis scale has significantly increased computational resource requirements.
To address this, quantizing model weights has become a prevalent practice in
data analysis applications such as deep learning. Quantization is particularly
vital for deploying large models on devices with limited computational
resources. However, the selection of quantization hyperparameters, like the
number of bits and value range for weight quantization, remains an
underexplored area. In this study, we employ the typical case analysis from
statistical physics, specifically the replica method, to explore the impact of
hyperparameters on the quantization of simple learning models. Our analysis
yields three key findings: (i) an unstable hyperparameter phase, known as
replica symmetry breaking, occurs with a small number of bits and a large
quantization width; (ii) there is an optimal quantization width that minimizes
error; and (iii) quantization delays the onset of overparameterization, helping
to mitigate overfitting as indicated by the double descent phenomenon. We also
discover that non-uniform quantization can enhance stability. Additionally, we
develop an approximate message-passing algorithm to validate our theoretical
results.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 31 Jan 24</h3>
<dl>
<dt><a name=item432>[432]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/1808.02950 title=Abstract>arXiv:1808.02950</a> (replaced) [<a href=https://arxiv.org/pdf/1808.02950 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/1808.02950 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low-complexity 8-point DCT Approximation Based on Angle Similarity for Image and Video Coding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Oliveira%2C+R+S">R. S. Oliveira</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Cintra%2C+R+J">R. J. Cintra</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bayer%2C+F+M">F. M. Bayer</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=da+Silveira%2C+T+L+T">T. L. T. da Silveira</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Madanayake%2C+A">A. Madanayake</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Leite%2C+A">A. Leite</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Corrected typo in formula for the coding gain. 16 pages, 12 figures, 10 tables
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Multidimensional Systems and Signal Processing, 1-32, 2018
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM); Signal Processing (eess.SP); Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item433>[433]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2103.02851 title=Abstract>arXiv:2103.02851</a> (replaced) [<a href=https://arxiv.org/e-print/2103.02851 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Visual Motion Imagery Classification with Deep Neural Network based on Functional Connectivity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwon%2C+B">Byoung-Hee Kwon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+J">Ji-Hoon Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Research has advanced further
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item434>[434]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2201.05741 title=Abstract>arXiv:2201.05741</a> (replaced) [<a href=https://arxiv.org/pdf/2201.05741 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2201.05741 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2201.05741 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving, Tracking and Stopping Streaming Linear Inverse Problems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pritchard%2C+N">Nathaniel Pritchard</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Patel%2C+V">Vivak Patel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 25 pages, 4 figures, 6 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Computation (stat.CO)
</div>
</div>
</dd>
<dt><a name=item435>[435]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.02097 title=Abstract>arXiv:2202.02097</a> (replaced) [<a href=https://arxiv.org/pdf/2202.02097 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.02097 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the velocity-stress formulation for geometrically nonlinear elastodynamics and its structure-preserving discretization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Thoma%2C+T">Tobias Thoma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kotyczka%2C+P">Paul Kotyczka</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Egger%2C+H">Herbert Egger</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The new version of the manuscript is a result of discussions with our new author. In the first version, we focused on the generation of explicit state space models, our attention is now on the consistent structure-preserving discretization in space and time for geometrically nonlinear elastodynamics. (15 pages, submitted to Mathematical and Computer Modelling of Dynamical Systems)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item436>[436]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2202.12193 title=Abstract>arXiv:2202.12193</a> (replaced) [<a href=https://arxiv.org/pdf/2202.12193 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2202.12193 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Decomposition-Based Synthesis for Applying Divide-and-Conquer-Like Algorithmic Paradigms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+R">Ruyi Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yuwei Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yingfei Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Di Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Z">Zhenjiang Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at TOPLAS
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>
</div>
</div>
</dd>
<dt><a name=item437>[437]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2204.02521 title=Abstract>arXiv:2204.02521</a> (replaced) [<a href=https://arxiv.org/pdf/2204.02521 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2204.02521 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2204.02521 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Optimal service resource management strategy for IoT-based health information system considering value co-creation of users
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+J">Ji Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+V+C">Vincent CS Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Haiyan Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fang, J., Lee, V.C.S. and Wang, H. (2024), "Optimal service resource management strategy for IoT-based health information system considering value co-creation of users", Industrial Management &amp; Data Systems, Vol. ahead-of-print No. ahead-of-print. <a href=https://doi.org/10.1108/IMDS-03-2023-0173>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item438>[438]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2205.01362 title=Abstract>arXiv:2205.01362</a> (replaced) [<a href=https://arxiv.org/pdf/2205.01362 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2205.01362 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2205.01362 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TracInAD: Measuring Influence for Anomaly Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doan%2C+B">Bich-Liên Doan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Daniel%2C+F">Fabrice Daniel</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> 2022 International Joint Conference on Neural Networks (IJCNN)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item439>[439]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2206.01900 title=Abstract>arXiv:2206.01900</a> (replaced) [<a href=https://arxiv.org/pdf/2206.01900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2206.01900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fujii%2C+K">Keisuke Fujii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takeuchi%2C+K">Koh Takeuchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuribayashi%2C+A">Atsushi Kuribayashi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takeishi%2C+N">Naoya Takeishi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kawahara%2C+Y">Yoshinobu Kawahara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takeda%2C+K">Kazuya Takeda</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 16 pages, 11 figures. Accepted in IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Methodology (stat.ME); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item440>[440]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.06233 title=Abstract>arXiv:2208.06233</a> (replaced) [<a href=https://arxiv.org/pdf/2208.06233 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.06233 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamic Sensor Matching based on Geomagnetic Inertial Navigation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+S">Simone Müller</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kranzlm%C3%BCller%2C+D">Dieter Kranzlmüller</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Page 16-25
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Journal of WSCG, 2022, Vol.30., No.1-2, ISSN 1213-6972
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item441>[441]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.09781 title=Abstract>arXiv:2208.09781</a> (replaced) [<a href=https://arxiv.org/pdf/2208.09781 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2208.09781 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2208.09781 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Co-Optimizing Distributed Energy Resources in Linear Complexity under Net Energy Metering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alahmed%2C+A+S">Ahmed S. Alahmed</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tong%2C+L">Lang Tong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhao%2C+Q">Qing Zhao</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, 8 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item442>[442]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2208.14874 title=Abstract>arXiv:2208.14874</a> (replaced) [<a href=https://arxiv.org/pdf/2208.14874 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2208.14874 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Robots as Mental Well-being Coaches: Design and Ethical Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Axelsson%2C+M">Minja Axelsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Spitale%2C+M">Micol Spitale</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gunes%2C+H">Hatice Gunes</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 57 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item443>[443]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2209.02614 title=Abstract>arXiv:2209.02614</a> (replaced) [<a href=https://arxiv.org/pdf/2209.02614 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2209.02614 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Variable binding and substitution for (nameless) dummies
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirschowitz%2C+A">André Hirschowitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hirschowitz%2C+T">Tom Hirschowitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lafont%2C+A">Ambroise Lafont</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Maggesi%2C+M">Marco Maggesi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Expanded version of the FoSSaCS 2022 paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item444>[444]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.07599 title=Abstract>arXiv:2210.07599</a> (replaced) [<a href=https://arxiv.org/pdf/2210.07599 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.07599 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Online Harassment of Japanese Celebrities and Influencers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takano%2C+M">Masanori Takano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taka%2C+F">Fumiaki Taka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ogiue%2C+C">Chiki Ogiue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagata%2C+N">Natsuki Nagata</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages, 7 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item445>[445]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2210.14991 title=Abstract>arXiv:2210.14991</a> (replaced) [<a href=https://arxiv.org/pdf/2210.14991 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2210.14991 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reachability Verification Based Reliability Assessment for Deep Reinforcement Learning Controlled Robotics and Autonomous Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yi Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Sen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item446>[446]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2211.14297 title=Abstract>arXiv:2211.14297</a> (replaced) [<a href=https://arxiv.org/pdf/2211.14297 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2211.14297 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2211.14297 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Doubly robust nearest neighbors in factor models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Dwivedi%2C+R">Raaz Dwivedi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tian%2C+K">Katherine Tian</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tomkins%2C+S">Sabina Tomkins</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Klasnja%2C+P">Predrag Klasnja</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Murphy%2C+S">Susan Murphy</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shah%2C+D">Devavrat Shah</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item447>[447]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.00281 title=Abstract>arXiv:2212.00281</a> (replaced) [<a href=https://arxiv.org/pdf/2212.00281 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.00281 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Localization vs. Semantics: Visual Representations in Unimodal and Multimodal Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuowan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+C">Cihang Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL 2024. Code is released at <a href=https://github.com/Lizw14/visual_probing>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item448>[448]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.03687 title=Abstract>arXiv:2212.03687</a> (replaced) [<a href=https://arxiv.org/pdf/2212.03687 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.03687 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> revTPL: The Reversible Temporal Process Language
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bocchi%2C+L">Laura Bocchi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lanese%2C+I">Ivan Lanese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mezzina%2C+C+A">Claudio Antares Mezzina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuen%2C+S">Shoji Yuen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item449>[449]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2212.10789 title=Abstract>arXiv:2212.10789</a> (replaced) [<a href=https://arxiv.org/pdf/2212.10789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2212.10789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shengchao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+W">Weili Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengpeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiarui Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiao%2C+Z">Zhuoran Qiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Ling Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+J">Jian Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item450>[450]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.07535 title=Abstract>arXiv:2301.07535</a> (replaced) [<a href=https://arxiv.org/pdf/2301.07535 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.07535 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> News and Load: A Quantitative Exploration of Natural Language Processing Applications for Forecasting Day-ahead Electricity System Demand
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yun Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Camal%2C+S">Simon Camal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Michiorri%2C+A">Andrea Michiorri</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 8 figures, 13 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item451>[451]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2301.08245 title=Abstract>arXiv:2301.08245</a> (replaced) [<a href=https://arxiv.org/pdf/2301.08245 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2301.08245 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Costanzino%2C+A">Alex Costanzino</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tosi%2C+F">Fabio Tosi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poggi%2C+M">Matteo Poggi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salti%2C+S">Samuele Salti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mattoccia%2C+S">Stefano Mattoccia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extension of the paper "Open Challenges in Deep Stereo: the Booster Dataset" presented at CVPR 2022. Accepted at TPAMI
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item452>[452]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.00736 title=Abstract>arXiv:2302.00736</a> (replaced) [<a href=https://arxiv.org/pdf/2302.00736 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.00736 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approximating the Shapley Value without Marginal Contributions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolpaczki%2C+P">Patrick Kolpaczki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bengs%2C+V">Viktor Bengs</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muschalik%2C+M">Maximilian Muschalik</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=H%C3%BCllermeier%2C+E">Eyke Hüllermeier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)
</div>
</div>
</dd>
<dt><a name=item453>[453]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.07621 title=Abstract>arXiv:2302.07621</a> (replaced) [<a href=https://arxiv.org/pdf/2302.07621 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.07621 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ambiguous Contracts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%BCtting%2C+P">Paul Dütting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feldman%2C+M">Michal Feldman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peretz%2C+D">Daniel Peretz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Samuelson%2C+L">Larry Samuelson</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Science and Game Theory (cs.GT)</span>
</div>
</div>
</dd>
<dt><a name=item454>[454]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.09631 title=Abstract>arXiv:2302.09631</a> (replaced) [<a href=https://arxiv.org/pdf/2302.09631 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.09631 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rewriting Modulo Traced Comonoid Structure
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghica%2C+D+R">Dan R. Ghica</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaye%2C+G">George Kaye</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Extended version, 32 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)
</div>
</div>
</dd>
<dt><a name=item455>[455]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.10662 title=Abstract>arXiv:2302.10662</a> (replaced) [<a href=https://arxiv.org/pdf/2302.10662 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.10662 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Snakes and Ladders: a Treewidth Story
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Chaplick%2C+S">Steven Chaplick</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kelk%2C+S">Steven Kelk</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Meuwese%2C+R">Ruben Meuwese</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mihalak%2C+M">Matus Mihalak</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Stamoulis%2C+G">Georgios Stamoulis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Compared to the earlier arXiv/WG version we have added analytical (as opposed to empirical) tightness bounds, and an extended discussion. See also Authors note 2 at the end of the introduction about earlier work in this area by Marchand et al
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS); Populations and Evolution (q-bio.PE)
</div>
</div>
</dd>
<dt><a name=item456>[456]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2302.14699 title=Abstract>arXiv:2302.14699</a> (replaced) [<a href=https://arxiv.org/pdf/2302.14699 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2302.14699 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Analysis of Tennenbaum's Theorem in Constructive Type Theory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hermes%2C+M">Marc Hermes</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Kirst%2C+D">Dominik Kirst</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages, extension of conference paper published at FSCD 2022
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic (math.LO)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item457>[457]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.05369 title=Abstract>arXiv:2303.05369</a> (replaced) [<a href=https://arxiv.org/pdf/2303.05369 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.05369 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-dependent Generalization Bounds via Variable-Size Compressibility
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sefidgaran%2C+M">Milad Sefidgaran</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zaidi%2C+A">Abdellatif Zaidi</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item458>[458]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.05929 title=Abstract>arXiv:2303.05929</a> (replaced) [<a href=https://arxiv.org/pdf/2303.05929 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.05929 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Uncovering the Handwritten Text in the Margins: End-to-end Handwritten Text Detection and Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+L">Liang Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Frankem%C3%B6lle%2C+J">Jonas Frankemölle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Axelsson%2C+A">Adam Axelsson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vats%2C+E">Ekta Vats</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item459>[459]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.08107 title=Abstract>arXiv:2303.08107</a> (replaced) [<a href=https://arxiv.org/pdf/2303.08107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2303.08107 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2303.08107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Far-reaching consequences of trait-based social preferences for the structure and function of animal social networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Brask%2C+J+B">Josefine Bohr Brask</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Koher%2C+A">Andreas Koher</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Croft%2C+D+P">Darren P. Croft</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lehmann%2C+S">Sune Lehmann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages + Methods and Appendix (39 pages total). 4 figures + 11 supplementary figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Populations and Evolution (q-bio.PE)
</div>
</div>
</dd>
<dt><a name=item460>[460]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.10211 title=Abstract>arXiv:2303.10211</a> (replaced) [<a href=https://arxiv.org/pdf/2303.10211 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.10211 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SITReg: Multi-resolution architecture for symmetric, inverse consistent, and topology preserving image registration
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Honkamaa%2C+J">Joel Honkamaa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marttinen%2C+P">Pekka Marttinen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item461>[461]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.12779 title=Abstract>arXiv:2303.12779</a> (replaced) [<a href=https://arxiv.org/pdf/2303.12779 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.12779 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D Signals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karpur%2C+A">Arjun Karpur</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perrotta%2C+G">Guilherme Perrotta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin-Brualla%2C+R">Ricardo Martin-Brualla</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+H">Howard Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Araujo%2C+A">André Araujo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 3DV 2024, oral paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item462>[462]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.14623 title=Abstract>arXiv:2303.14623</a> (replaced) [<a href=https://arxiv.org/pdf/2303.14623 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.14623 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Inverse Reinforcement Learning without Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Swamy%2C+G">Gokul Swamy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choudhury%2C+S">Sanjiban Choudhury</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bagnell%2C+J+A">J. Andrew Bagnell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item463>[463]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.16376 title=Abstract>arXiv:2303.16376</a> (replaced) [<a href=https://arxiv.org/pdf/2303.16376 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.16376 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Unified Learning Model for Estimating Fiber Orientation Distribution Functions on Heterogeneous Multi-shell Diffusion-weighted MRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+T">Tianyuan Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Newlin%2C+N">Nancy Newlin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kanakaraj%2C+P">Praitayini Kanakaraj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=nath%2C+V">Vishwesh nath</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+L+Y">Leon Y Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramadass%2C+K">Karthik Ramadass</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schilling%2C+K">Kurt Schilling</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landman%2C+B+A">Bennett A. Landman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item464>[464]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.16613 title=Abstract>arXiv:2303.16613</a> (replaced) [<a href=https://arxiv.org/pdf/2303.16613 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.16613 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data inaccuracy quantification and uncertainty propagation for bibliometric indicators
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Donner%2C+P">Paul Donner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 31 pages, 5 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Digital Libraries (cs.DL)</span>
</div>
</div>
</dd>
<dt><a name=item465>[465]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.17043 title=Abstract>arXiv:2303.17043</a> (replaced) [<a href=https://arxiv.org/pdf/2303.17043 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.17043 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Federated Learning for Heterogeneous Bandits with Unobserved Contexts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiabin Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moothedath%2C+S">Shana Moothedath</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item466>[466]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2303.18136 title=Abstract>arXiv:2303.18136</a> (replaced) [<a href=https://arxiv.org/pdf/2303.18136 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2303.18136 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ardito%2C+C">Carmelo Ardito</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deldjoo%2C+Y">Yashar Deldjoo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Noia%2C+T">Tommaso Di Noia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nazary%2C+F">Fatemeh Nazary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Servedio%2C+G">Giovanni Servedio</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in AdvML@KDD'22
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item467>[467]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.03823 title=Abstract>arXiv:2304.03823</a> (replaced) [<a href=https://arxiv.org/e-print/2304.03823 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multidimensional adaptive order GP-WENO via kernel-based reconstruction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=May%2C+I">Ian May</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lee%2C+D">Dongwook Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be replaced by a newer paper with much broader scope
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item468>[468]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.09157 title=Abstract>arXiv:2304.09157</a> (replaced) [<a href=https://arxiv.org/pdf/2304.09157 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.09157 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural networks for geospatial data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Zhan%2C+W">Wentao Zhan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Datta%2C+A">Abhirup Datta</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)
</div>
</div>
</dd>
<dt><a name=item469>[469]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.11501 title=Abstract>arXiv:2304.11501</a> (replaced) [<a href=https://arxiv.org/pdf/2304.11501 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.11501 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Lost in Translationese? Reducing Translation Effect Using Abstract Meaning Representation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wein%2C+S">Shira Wein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider%2C+N">Nathan Schneider</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL 2024 Camera-ready
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item470>[470]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14176 title=Abstract>arXiv:2304.14176</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14176 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.14176 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exploring the flavor structure of quarks and leptons with reinforcement learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Nishimura%2C+S">Satsuki Nishimura</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Miyao%2C+C">Coh Miyao</a>, 
<a href="https://arxiv.org/search/hep-ph?searchtype=author&amp;query=Otsuka%2C+H">Hajime Otsuka</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 45 pages, 15 figures, v3: published version
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. High Energ. Phys. 2023, 21 (2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Theory (hep-th)
</div>
</div>
</dd>
<dt><a name=item471>[471]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2304.14604 title=Abstract>arXiv:2304.14604</a> (replaced) [<a href=https://arxiv.org/pdf/2304.14604 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2304.14604 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Deep Neural-network Prior for Orbit Recovery from Method of Moments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Khoo%2C+Y">Yuehaw Khoo</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Paul%2C+S">Sounak Paul</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sharon%2C+N">Nir Sharon</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> J. Comput. Appl. Math. 115782 (2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Methodology (stat.ME)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item472>[472]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.02480 title=Abstract>arXiv:2305.02480</a> (replaced) [<a href=https://arxiv.org/pdf/2305.02480 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.02480 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Quantitative Analysis and Guidelines of Data Streaming Accelerator in Modern Intel Xeon Scalable Processors
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kuper%2C+R">Reese Kuper</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong%2C+I">Ipoom Jeong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yifan Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jiayu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+R">Ren Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ranganathan%2C+N">Narayan Ranganathan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+N+S">Nam Sung Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has been accepted by ASPLOS'24. Please refer to the linked DOI for the official version of this paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Hardware Architecture (cs.AR)</span>; Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item473>[473]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.03923 title=Abstract>arXiv:2305.03923</a> (replaced) [<a href=https://arxiv.org/pdf/2305.03923 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.03923 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Active Continual Learning: On Balancing Knowledge Retention and Learnability
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+T">Thuy-Trang Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khadivi%2C+S">Shahram Khadivi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ghorbanali%2C+M">Mahsa Ghorbanali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phung%2C+D">Dinh Phung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item474>[474]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.04577 title=Abstract>arXiv:2305.04577</a> (replaced) [<a href=https://arxiv.org/pdf/2305.04577 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2305.04577 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2305.04577 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-energy Grid Expansion Planning Under Uncertainty: A Robust Optimization Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Mostafa%2C+M">Marwan Mostafa</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Babazadeh%2C+D">Davood Babazadeh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Becker%2C+C">Christian Becker</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE PES GM 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item475>[475]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.05731 title=Abstract>arXiv:2305.05731</a> (replaced) [<a href=https://arxiv.org/pdf/2305.05731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.05731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> 'Put the Car on the Stand': SMT-based Oracles for Investigating Decisions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Judson%2C+S">Samuel Judson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elacqua%2C+M">Matthew Elacqua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cano%2C+F">Filip Cano</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antonopoulos%2C+T">Timos Antonopoulos</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C3%B6nighofer%2C+B">Bettina Könighofer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shapiro%2C+S+J">Scott J. Shapiro</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Piskac%2C+R">Ruzica Piskac</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Computers and Society (cs.CY); Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item476>[476]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.06272 title=Abstract>arXiv:2305.06272</a> (replaced) [<a href=https://arxiv.org/pdf/2305.06272 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.06272 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FedPDD: A Privacy-preserving Double Distillation Framework for Cross-silo Federated Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+S">Sheng Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+D">Dashan Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu%2C+H">Hanlin Gu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+D">Daning Hu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IJCNN2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item477>[477]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.07269 title=Abstract>arXiv:2305.07269</a> (replaced) [<a href=https://arxiv.org/pdf/2305.07269 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.07269 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meta-Optimization for Higher Model Generalizability in Single-Image Depth Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Cho-Ying Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yiqi Zhong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Junying Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumann%2C+U">Ulrich Neumann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> long version; short version accepted to CVPR 2023 Workshop on Adversarial Machine Learning on Computer Vision and CVPR 2023 Workshop on Computer Vision for Mixed Reality
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item478>[478]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.10163 title=Abstract>arXiv:2305.10163</a> (replaced) [<a href=https://arxiv.org/pdf/2305.10163 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.10163 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Large Language Models Leverage External Knowledge to Extend Clinical Insight Beyond Language Boundaries
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiageng Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+Z">Zhaopeng Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Minghui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+C">Changzheng Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jie Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item479>[479]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.10565 title=Abstract>arXiv:2305.10565</a> (replaced) [<a href=https://arxiv.org/pdf/2305.10565 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.10565 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Measurement Based Evaluation and Mitigation of Flood Attacks on a LAN Test-Bed
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nasereddin%2C+M">Mohammed Nasereddin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nak%C4%B1p%2C+M">Mert Nakıp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gelenbe%2C+E">Erol Gelenbe</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)
</div>
</div>
</dd>
<dt><a name=item480>[480]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.11789 title=Abstract>arXiv:2305.11789</a> (replaced) [<a href=https://arxiv.org/pdf/2305.11789 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.11789 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neubig%2C+G">Graham Neubig</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EACL2024 Findings
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item481>[481]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.11863 title=Abstract>arXiv:2305.11863</a> (replaced) [<a href=https://arxiv.org/pdf/2305.11863 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.11863 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Scaling laws for language encoding models in fMRI
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Antonello%2C+R">Richard Antonello</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaidya%2C+A">Aditya Vaidya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huth%2C+A+G">Alexander G. Huth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to the Thirty-seventh Annual Conference on Neural Information Processing Systems (NeurIPS 2023). Please cite NeurIPS version
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item482>[482]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13009 title=Abstract>arXiv:2305.13009</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13009 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13009 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Textually Pretrained Speech Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hassid%2C+M">Michael Hassid</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Remez%2C+T">Tal Remez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T+A">Tu Anh Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gat%2C+I">Itai Gat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Conneau%2C+A">Alexis Conneau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Copet%2C+J">Jade Copet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Defossez%2C+A">Alexandre Defossez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dupoux%2C+E">Emmanuel Dupoux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schwartz%2C+R">Roy Schwartz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adi%2C+Y">Yossi Adi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> NeurIPS 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item483>[483]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.13795 title=Abstract>arXiv:2305.13795</a> (replaced) [<a href=https://arxiv.org/pdf/2305.13795 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.13795 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Batra%2C+S">Sumeet Batra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tjanaka%2C+B">Bryon Tjanaka</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Petrenko%2C+A">Aleksei Petrenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sukhatme%2C+G">Gaurav Sukhatme</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted as a spotlight paper at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item484>[484]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.15357 title=Abstract>arXiv:2305.15357</a> (replaced) [<a href=https://arxiv.org/pdf/2305.15357 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.15357 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ma%2C+Y">Yiyang Ma</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+H">Huan Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+W">Wenhan Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fu%2C+J">Jianlong Fu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Liu%2C+J">Jiaying Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item485>[485]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.16284 title=Abstract>arXiv:2305.16284</a> (replaced) [<a href=https://arxiv.org/pdf/2305.16284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.16284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaled%2C+A">Ahmed Khaled</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishchenko%2C+K">Konstantin Mishchenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 22 pages, 1 table, 4 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item486>[486]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2305.18712 title=Abstract>arXiv:2305.18712</a> (replaced) [<a href=https://arxiv.org/pdf/2305.18712 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2305.18712 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J">Jianfei Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+H">Hanjie Qian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yuecong Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published at ICLR 2024, project and code available at <a href=https://sleepyseal.github.io/TransferScoreWeb/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item487>[487]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.00919 title=Abstract>arXiv:2306.00919</a> (replaced) [<a href=https://arxiv.org/pdf/2306.00919 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.00919 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning About Social Context from Smartphone Data: Generalization Across Countries and Daily Life Moments
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mader%2C+A+R">Aurel Ruben Mader</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meegahapola%2C+L">Lakmal Meegahapola</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gatica-Perez%2C+D">Daniel Gatica-Perez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ACM CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item488>[488]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01433 title=Abstract>arXiv:2306.01433</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01433 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01433 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Blind Audio Bandwidth Extension: A Diffusion-Based Zero-Shot Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Moliner%2C+E">Eloi Moliner</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Elvander%2C+F">Filip Elvander</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=V%C3%A4lim%C3%A4ki%2C+V">Vesa Välimäki</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item489>[489]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.01685 title=Abstract>arXiv:2306.01685</a> (replaced) [<a href=https://arxiv.org/pdf/2306.01685 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.01685 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MKOR: Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 Updates
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mozaffari%2C+M">Mohammad Mozaffari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+S">Sikan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dehnavi%2C+M+M">Maryam Mehri Dehnavi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item490>[490]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.05284 title=Abstract>arXiv:2306.05284</a> (replaced) [<a href=https://arxiv.org/pdf/2306.05284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.05284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Simple and Controllable Music Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Copet%2C+J">Jade Copet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gat%2C+I">Itai Gat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Remez%2C+T">Tal Remez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kant%2C+D">David Kant</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adi%2C+Y">Yossi Adi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%A9fossez%2C+A">Alexandre Défossez</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published at Neurips 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item491>[491]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.07735 title=Abstract>arXiv:2306.07735</a> (replaced) [<a href=https://arxiv.org/pdf/2306.07735 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.07735 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discrete Graph Auto-Encoder
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boget%2C+Y">Yoann Boget</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gregorova%2C+M">Magda Gregorova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kalousis%2C+A">Alexandros Kalousis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Thoroughly revised the paper originally titled "Vector-Quantized Graph Auto-Encoder. Implemented comprehensive modifications across all sections. Incorporated additional experiments to enhance the study. Maintained the fundamental structure and essence of the original work, ensuring it remains a continuation of the same project
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item492>[492]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09267 title=Abstract>arXiv:2306.09267</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2306.09267 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2306.09267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Are ChatGPT and Other Similar Systems the Modern Lernaean Hydras of AI?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioannidis%2C+D">Dimitrios Ioannidis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kepner%2C+J">Jeremy Kepner</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bowne%2C+A">Andrew Bowne</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bryant%2C+H+S">Harriet S. Bryant</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 40 pages, 100+ references, to appear in Fordham Law Review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Machine Learning (cs.LG); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item493>[493]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.09649 title=Abstract>arXiv:2306.09649</a> (replaced) [<a href=https://arxiv.org/pdf/2306.09649 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.09649 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J+J">Jackie Junrui Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yingtian Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuhan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+K">Karina Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosli%2C+D+W">Daniel Wan Rosli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jain%2C+A">Anisha Jain</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shuning Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+T">Tianshi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landay%2C+J+A">James A. Landay</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lam%2C+M+S">Monica S. Lam</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item494>[494]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.11489 title=Abstract>arXiv:2306.11489</a> (replaced) [<a href=https://arxiv.org/pdf/2306.11489 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.11489 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Linyao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hongyang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X">Xiao Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xindong Wu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item495>[495]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.11560 title=Abstract>arXiv:2306.11560</a> (replaced) [<a href=https://arxiv.org/pdf/2306.11560 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.11560 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MILD: Modeling the Instance Learning Dynamics for Learning with Noisy Labels
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+C">Chuanyang Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+S">Shipeng Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhitong Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xuming He</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item496>[496]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.15516 title=Abstract>arXiv:2306.15516</a> (replaced) [<a href=https://arxiv.org/pdf/2306.15516 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.15516 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A logic-based framework for database repairs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fr%C3%B6hlich%2C+N">Nicolas Fröhlich</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meier%2C+A">Arne Meier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pardal%2C+N">Nina Pardal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Virtema%2C+J">Jonni Virtema</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages + 1 page references + 1 page Appendix
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)
</div>
</div>
</dd>
<dt><a name=item497>[497]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2306.17041 title=Abstract>arXiv:2306.17041</a> (replaced) [<a href=https://arxiv.org/pdf/2306.17041 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2306.17041 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Matroidal Entropy Functions: Constructions, Characterizations and Representations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qi Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+M">Minquan Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+B">Baoming Bai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 3 figures, accepted by IEEE Transactions on Information Theory
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Combinatorics (math.CO)
</div>
</div>
</dd>
<dt><a name=item498>[498]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00238 title=Abstract>arXiv:2307.00238</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00238 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.00238 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unified Transfer Learning Models in High-Dimensional Linear Regression
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Liu%2C+S+S">Shuo Shuo Liu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item499>[499]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00673 title=Abstract>arXiv:2307.00673</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00673 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.00673 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> ENN: A Neural Network with DCT Adaptive Activation Functions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Martinez-Gost%2C+M">Marc Martinez-Gost</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=P%C3%A9rez-Neira%2C+A">Ana Pérez-Neira</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lagunas%2C+M+%C3%81">Miguel Ángel Lagunas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper accepted in IEEE Journal of Selected Topics in Signal Processing (JSTSP) Special Series on AI in Signal &amp; Data Science - Toward Explainable, Reliable, and Sustainable Machine Learning
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
</div>
</div>
</dd>
<dt><a name=item500>[500]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.00684 title=Abstract>arXiv:2307.00684</a> (replaced) [<a href=https://arxiv.org/pdf/2307.00684 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.00684 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.00684 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Proximal Algorithm for Network Slimming
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bui%2C+K">Kevin Bui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+F">Fanghui Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+F">Fredrick Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+Y">Yingyong Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xin%2C+J">Jack Xin</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted to LOD'23; fixed typo
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item501>[501]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.02879 title=Abstract>arXiv:2307.02879</a> (replaced) [<a href=https://arxiv.org/pdf/2307.02879 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.02879 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.02879 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Algorithms for computing norms and characteristic polynomials on general Drinfeld modules
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Caruso%2C+X">Xavier Caruso</a> (LFANT, CANARI), 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leudi%C3%A8re%2C+A">Antoine Leudière</a> (CARAMBA)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Symbolic Computation (cs.SC)</span>; Number Theory (math.NT)
</div>
</div>
</dd>
<dt><a name=item502>[502]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.05012 title=Abstract>arXiv:2307.05012</a> (replaced) [<a href=https://arxiv.org/pdf/2307.05012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2307.05012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Best approximation results and essential boundary conditions for novel types of weak adversarial network discretizations for PDEs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bertoluzza%2C+S">Silvia Bertoluzza</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Burman%2C+E">Erik Burman</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=He%2C+C">Cuiyu He</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 29 pages, 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item503>[503]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.05727 title=Abstract>arXiv:2307.05727</a> (replaced) [<a href=https://arxiv.org/pdf/2307.05727 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.05727 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.05727 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Open-Source Knowledge Graph Ecosystem for the Life Sciences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Callahan%2C+T+J">Tiffany J. Callahan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tripodi%2C+I+J">Ignacio J. Tripodi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stefanski%2C+A+L">Adrianne L. Stefanski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cappelletti%2C+L">Luca Cappelletti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taneja%2C+S+B">Sanya B. Taneja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wyrwa%2C+J+M">Jordan M. Wyrwa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Casiraghi%2C+E">Elena Casiraghi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matentzoglu%2C+N+A">Nicolas A. Matentzoglu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Reese%2C+J">Justin Reese</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silverstein%2C+J+C">Jonathan C. Silverstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoyt%2C+C+T">Charles Tapley Hoyt</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyce%2C+R+D">Richard D. Boyce</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malec%2C+S+A">Scott A. Malec</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Unni%2C+D+R">Deepak R. Unni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Joachimiak%2C+M+P">Marcin P. Joachimiak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Robinson%2C+P+N">Peter N. Robinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mungall%2C+C+J">Christopher J. Mungall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cavalleri%2C+E">Emanuele Cavalleri</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fontana%2C+T">Tommaso Fontana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Valentini%2C+G">Giorgio Valentini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mesiti%2C+M">Marco Mesiti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gillenwater%2C+L+A">Lucas A. Gillenwater</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santangelo%2C+B">Brook Santangelo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vasilevsky%2C+N+A">Nicole A. Vasilevsky</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hoehndorf%2C+R">Robert Hoehndorf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bennett%2C+T+D">Tellen D. Bennett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ryan%2C+P+B">Patrick B. Ryan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hripcsak%2C+G">George Hripcsak</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kahn%2C+M+G">Michael G. Kahn</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bada%2C+M">Michael Bada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baumgartner%2C+W+A">William A. Baumgartner Jr</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hunter%2C+L+E">Lawrence E. Hunter</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE)
</div>
</div>
</dd>
<dt><a name=item504>[504]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2307.11714 title=Abstract>arXiv:2307.11714</a> (replaced) [<a href=https://arxiv.org/pdf/2307.11714 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2307.11714 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2307.11714 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanguy%2C+E">Eloi Tanguy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR)
</div>
</div>
</dd>
<dt><a name=item505>[505]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.04823 title=Abstract>arXiv:2308.04823</a> (replaced) [<a href=https://arxiv.org/pdf/2308.04823 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2308.04823 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2308.04823 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating the Generation Capabilities of Large Chinese Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+H">Hui Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+J">Jingyuan Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+M">Meng Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+C">Chen Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ning%2C+B">Bin Ning</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+N">Na Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item506>[506]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.05697 title=Abstract>arXiv:2308.05697</a> (replaced) [<a href=https://arxiv.org/pdf/2308.05697 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.05697 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SSLRec: A Self-Supervised Learning Framework for Recommendation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+X">Xubin Ren</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+L">Lianghao Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+W">Wei Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianle Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+X">Xuheng Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Published as a WSDM'24 full paper (oral presentation)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item507>[507]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.09857 title=Abstract>arXiv:2308.09857</a> (replaced) [<a href=https://arxiv.org/pdf/2308.09857 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.09857 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiffCharge: Generating EV Charging Scenarios via a Denoising Diffusion Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Li%2C+S">Siyang Li</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Xiong%2C+H">Hui Xiong</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+Y">Yize Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at IEEE Transactions on Smart Grid; 10 pages, 14 figures; Code available at <a href=https://github.com/LSY-Cython/DiffCharge>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item508>[508]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.11696 title=Abstract>arXiv:2308.11696</a> (replaced) [<a href=https://arxiv.org/pdf/2308.11696 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.11696 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient Benchmarking of Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perlitz%2C+Y">Yotam Perlitz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bandel%2C+E">Elron Bandel</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gera%2C+A">Ariel Gera</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arviv%2C+O">Ofir Arviv</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ein-Dor%2C+L">Liat Ein-Dor</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shnarch%2C+E">Eyal Shnarch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Slonim%2C+N">Noam Slonim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shmueli-Scheuer%2C+M">Michal Shmueli-Scheuer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choshen%2C+L">Leshem Choshen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item509>[509]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.12113 title=Abstract>arXiv:2308.12113</a> (replaced) [<a href=https://arxiv.org/pdf/2308.12113 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2308.12113 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2308.12113 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancements in Point Cloud Data Augmentation for Deep Learning: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Q">Qinfeng Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+L">Lei Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weng%2C+N">Ningxin Weng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item510>[510]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.14355 title=Abstract>arXiv:2308.14355</a> (replaced) [<a href=https://arxiv.org/pdf/2308.14355 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.14355 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuchen Yan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chaozhuo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Senzhang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xing Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+S">Sunghun Kim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item511>[511]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.14418 title=Abstract>arXiv:2308.14418</a> (replaced) [<a href=https://arxiv.org/pdf/2308.14418 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.14418 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Scale and Multi-Layer Contrastive Learning for Domain Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ballas%2C+A">Aristotelis Ballas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Diou%2C+C">Christos Diou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Manuscript under review at: IEEE Transactions on Artificial Intelligence
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item512>[512]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.15427 title=Abstract>arXiv:2308.15427</a> (replaced) [<a href=https://arxiv.org/pdf/2308.15427 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.15427 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+W">Wenjie Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fu%2C+J">Jiawei Fu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yanqing Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jing%2C+H">Haodong Jing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shitao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICRA 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item513>[513]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2308.16505 title=Abstract>arXiv:2308.16505</a> (replaced) [<a href=https://arxiv.org/pdf/2308.16505 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2308.16505 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+J">Jianxun Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+Y">Yuxuan Lei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+J">Jing Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lian%2C+D">Defu Lian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 18 pages, 17 figures, 7 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item514>[514]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.00203 title=Abstract>arXiv:2309.00203</a> (replaced) [<a href=https://arxiv.org/pdf/2309.00203 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.00203 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-Driven Projection for Reducing Dimensionality of Linear Programs: Generalization Bound and Learning Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sakaue%2C+S">Shinsaku Sakaue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oki%2C+T">Taihei Oki</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item515>[515]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01745 title=Abstract>arXiv:2309.01745</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.01745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kohl%2C+G">Georg Kohl</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Li-Wei Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Thuerey%2C+N">Nils Thuerey</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Source code available at <a href=https://github.com/tum-pbs/autoreg-pde-diffusion>this https URL</a> and further information and videos at <a href=https://ge.in.tum.de/publications/2023-acdm-kohl>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)
</div>
</div>
</dd>
<dt><a name=item516>[516]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01750 title=Abstract>arXiv:2309.01750</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01750 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.01750 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.01750 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On CNF formulas irredundant with respect to unit clause propagation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Savick%C3%BD%2C+P">Petr Savický</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 19 pages, improvements for better readability
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Combinatorics (math.CO)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item517>[517]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.01854 title=Abstract>arXiv:2309.01854</a> (replaced) [<a href=https://arxiv.org/pdf/2309.01854 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.01854 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.01854 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dynamical Stability of Threshold Networks over Undirected Signed Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goles%2C+E">Eric Goles</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=R%C3%ADos-Wilson%2C+M">Martín Ríos-Wilson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sen%C3%A9%2C+S">Sylvain Sené</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Discrete Mathematics (cs.DM)</span>
</div>
</div>
</dd>
<dt><a name=item518>[518]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02169 title=Abstract>arXiv:2309.02169</a> (replaced) [<a href=https://arxiv.org/e-print/2309.02169 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Dual Relation Alignment for Composed Image Retrieval
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xintong Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaxiong Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yujiao Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+X">Xueming Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> there are method changes in our model, hence the new architecture and experiments differs from the original one, which is the reason for withdraw
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item519>[519]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02351 title=Abstract>arXiv:2309.02351</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02351 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02351 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Exact Inference for Continuous-Time Gaussian Process Dynamics
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ensinger%2C+K">Katharina Ensinger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tagliapietra%2C+N">Nicholas Tagliapietra</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziesche%2C+S">Sebastian Ziesche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at The 38th Annual AAAI Conference on Artificial Intelligence. 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item520>[520]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.02873 title=Abstract>arXiv:2309.02873</a> (replaced) [<a href=https://arxiv.org/pdf/2309.02873 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.02873 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Hybrid Dynamics Models With Simulator-Informed Latent States
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ensinger%2C+K">Katharina Ensinger</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ziesche%2C+S">Sebastian Ziesche</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at The 38th Annual AAAI Conference on Artificial Intelligence, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item521>[521]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.04045 title=Abstract>arXiv:2309.04045</a> (replaced) [<a href=https://arxiv.org/pdf/2309.04045 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2309.04045 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2309.04045 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Low-rank Matrix Sensing With Dithered One-Bit Quantization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeganegi%2C+F">Farhang Yeganegi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eamaz%2C+A">Arian Eamaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soltanalian%2C+M">Mojtaba Soltanalian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2308.00695>arXiv:2308.00695</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item522>[522]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.04284 title=Abstract>arXiv:2309.04284</a> (replaced) [<a href=https://arxiv.org/pdf/2309.04284 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.04284 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Viewing the process of generating counterfactuals as a source of knowledge
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lemaire%2C+V">Vincent Lemaire</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boudec%2C+N+L">Nathan Le Boudec</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guyomard%2C+V">Victor Guyomard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fessant%2C+F">Françoise Fessant</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item523>[523]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.05973 title=Abstract>arXiv:2309.05973</a> (replaced) [<a href=https://arxiv.org/pdf/2309.05973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.05973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Circuit Breaking: Removing Model Behaviors with Targeted Ablation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Maximilian Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Davies%2C+X">Xander Davies</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nadeau%2C+M">Max Nadeau</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> Workshop on Challenges in Deployable Generative AI at
 International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA.
 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item524>[524]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.06924 title=Abstract>arXiv:2309.06924</a> (replaced) [<a href=https://arxiv.org/pdf/2309.06924 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.06924 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhaodong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaobai Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item525>[525]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.07900 title=Abstract>arXiv:2309.07900</a> (replaced) [<a href=https://arxiv.org/pdf/2309.07900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.07900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ambiguity-Aware In-Context Learning with Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+L">Lingyu Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhary%2C+A">Aditi Chaudhary</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+K">Krishna Srinivasan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hashimoto%2C+K">Kazuma Hashimoto</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Raman%2C+K">Karthik Raman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 15 pages in total
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)
</div>
</div>
</dd>
<dt><a name=item526>[526]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08345 title=Abstract>arXiv:2309.08345</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08345 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08345 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shu%2C+Y">Yiheng Shu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhiwei Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item527>[527]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.08648 title=Abstract>arXiv:2309.08648</a> (replaced) [<a href=https://arxiv.org/pdf/2309.08648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.08648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MAPLE: Mobile App Prediction Leveraging Large Language Model Embeddings
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khaokaew%2C+Y">Yonchanok Khaokaew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+H">Hao Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item528>[528]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.11515 title=Abstract>arXiv:2309.11515</a> (replaced) [<a href=https://arxiv.org/pdf/2309.11515 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.11515 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards Differential Privacy in Sequential Recommendation: A Noisy Graph Neural Network Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+W">Wentao Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+H">Hui Fang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ACM Transactions on Knowledge Discovery from Data
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item529>[529]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12570 title=Abstract>arXiv:2309.12570</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12570 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12570 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakrabarty%2C+T">Tuhin Chakrabarty</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padmakumar%2C+V">Vishakh Padmakumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muresan%2C+S">Smaranda Muresan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item530>[530]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.12813 title=Abstract>arXiv:2309.12813</a> (replaced) [<a href=https://arxiv.org/pdf/2309.12813 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.12813 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Automatically Testing Functional Properties of Code Translation Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eniser%2C+H+F">Hasan Ferit Eniser</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=W%C3%BCstholz%2C+V">Valentin Wüstholz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Christakis%2C+M">Maria Christakis</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages including appendix and references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)
</div>
</div>
</dd>
<dt><a name=item531>[531]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.13516 title=Abstract>arXiv:2309.13516</a> (replaced) [<a href=https://arxiv.org/pdf/2309.13516 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.13516 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+C">Cho-Ying Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Q">Quankai Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+C">Chin-Cheng Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+T">Te-Lin Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jing-Wen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neumann%2C+U">Ulrich Neumann</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Add Depth-Anything
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)
</div>
</div>
</dd>
<dt><a name=item532>[532]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.13596 title=Abstract>arXiv:2309.13596</a> (replaced) [<a href=https://arxiv.org/pdf/2309.13596 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.13596 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data Collection to Model Development
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+R">Runkai Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Heng%2C+Y">Yuwen Heng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuanda Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shilei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+H">Heng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+C">Changhao Yao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiawen Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICRA2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item533>[533]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2309.17401 title=Abstract>arXiv:2309.17401</a> (replaced) [<a href=https://arxiv.org/pdf/2309.17401 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2309.17401 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Adversarial Machine Learning in Latent Representations of Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+M">Milin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Abdi%2C+M">Mohammad Abdi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item534>[534]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00489 title=Abstract>arXiv:2310.00489</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00489 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00489 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interpretable Imitation Learning with Dynamic Causal Relations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+W">Wenchao Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+S">Suhang Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Lu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuncong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yanchi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+W">Wei Cheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Haifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by WSDM 2024 as an oral paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item535>[535]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.00863 title=Abstract>arXiv:2310.00863</a> (replaced) [<a href=https://arxiv.org/pdf/2310.00863 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.00863 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Syllable-level lyrics generation from melody exploiting character-level language model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lasocki%2C+K">Karol Lasocki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yi Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takasu%2C+A">Atsuhiro Takasu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item536>[536]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.01140 title=Abstract>arXiv:2310.01140</a> (replaced) [<a href=https://arxiv.org/pdf/2310.01140 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.01140 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Neural Processing of Tri-Plane Hybrid Neural Fields
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cardace%2C+A">Adriano Cardace</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ballerini%2C+F">Francesco Ballerini</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+A">Allan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salti%2C+S">Samuele Salti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item537>[537]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.02720 title=Abstract>arXiv:2310.02720</a> (replaced) [<a href=https://arxiv.org/pdf/2310.02720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.02720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiatong Shi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Inaguma%2C+H">Hirofumi Inaguma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+X">Xutai Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kulikov%2C+I">Ilia Kulikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+A">Anna Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ICLR2024 as spotlight
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item538>[538]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04639 title=Abstract>arXiv:2310.04639</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04639 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04639 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> X-Transfer: A Transfer Learning-Based Framework for GAN-Generated Fake Image Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+S">Shu Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+B">Bin Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C+S">Ching Sheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+X">Xi Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jinrong Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 3 figures, and 6 tables; references added
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item539>[539]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.04987 title=Abstract>arXiv:2310.04987</a> (replaced) [<a href=https://arxiv.org/pdf/2310.04987 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.04987 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Data-centric Graph Learning: A Survey
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yuxin Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bo%2C+D">Deyu Bo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+C">Cheng Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zhiyuan Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhongjian Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jixi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yufei Peng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)
</div>
</div>
</dd>
<dt><a name=item540>[540]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.06457 title=Abstract>arXiv:2310.06457</a> (replaced) [<a href=https://arxiv.org/pdf/2310.06457 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.06457 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Small-Signal Stability and SCR Enhancement of Offshore WPPs with Synchronous Condensers
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Ghimire%2C+S">Sulav Ghimire</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kkuni%2C+K+V">Kanakesh V. Kkuni</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guest%2C+E+D">Emerson D. Guest</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jensen%2C+K+H">Kim H. Jensen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+G">Guangya Yang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item541>[541]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.09499 title=Abstract>arXiv:2310.09499</a> (replaced) [<a href=https://arxiv.org/pdf/2310.09499 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.09499 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shao%2C+H">Hang Shao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+B">Bei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qian%2C+Y">Yanmin Qian</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by ICASSP2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item542>[542]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.10012 title=Abstract>arXiv:2310.10012</a> (replaced) [<a href=https://arxiv.org/pdf/2310.10012 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.10012 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai%2C+Y">Yu-Lin Tsai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu%2C+C">Chia-Yi Hsu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+C">Chulin Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Chih-Hsun Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jia-You Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C">Chia-Mu Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+C">Chun-Ying Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper has already been accepted by ICLR 2024. The final version will be uploaded after the camera-ready submission
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item543>[543]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.10434 title=Abstract>arXiv:2310.10434</a> (replaced) [<a href=https://arxiv.org/pdf/2310.10434 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.10434 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equivariant Matrix Function Neural Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Batatia%2C+I">Ilyes Batatia</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Schaaf%2C+L+L">Lars L. Schaaf</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chen%2C+H">Huajie Chen</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Cs%C3%A1nyi%2C+G">Gábor Csányi</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ortner%2C+C">Christoph Ortner</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Faber%2C+F+A">Felix A. Faber</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> International Conference on Learning Representations, 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)
</div>
</div>
</dd>
<dt><a name=item544>[544]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.11760 title=Abstract>arXiv:2310.11760</a> (replaced) [<a href=https://arxiv.org/pdf/2310.11760 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.11760 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.11760 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Security-Constrained Optimal Power Management Algorithm for Shipboard Microgrids with Battery Energy Storage System and Fuel Cell
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=D%27Agostino%2C+F">Fabio D'Agostino</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Gallo%2C+M">Marco Gallo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Saviozzi%2C+M">Matteo Saviozzi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Silvestro%2C+F">Federico Silvestro</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to SPEEDAM 2024. arXiv admin note: substantial text overlap with <a href=https://arxiv.org/abs/2304.03621>arXiv:2304.03621</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Systems and Control (eess.SY)</span>
</div>
</div>
</dd>
<dt><a name=item545>[545]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.12337 title=Abstract>arXiv:2310.12337</a> (replaced) [<a href=https://arxiv.org/pdf/2310.12337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.12337 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.12337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Compiler Testing With Relaxed Memory Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Geeson%2C+L">Luke Geeson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+L">Lee Smith</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, Accepted to IEEE/ACM International Symposium on Code Generation and Optimization
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Hardware Architecture (cs.AR); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item546>[546]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.13139 title=Abstract>arXiv:2310.13139</a> (replaced) [<a href=https://arxiv.org/pdf/2310.13139 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.13139 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.13139 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graph Neural Networks with polynomial activations have limited expressivity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khalife%2C+S">Sammy Khalife</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>
</div>
</div>
</dd>
<dt><a name=item547>[547]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14307 title=Abstract>arXiv:2310.14307</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14307 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.14307 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Social Media Perceptions of 51% Attacks on Proof-of-Work Cryptocurrencies: A Natural Language Processing Approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baruwa%2C+Z">Zsofia Baruwa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacherjee%2C+S">Sanjay Bhattacherjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandnani%2C+S+R">Sahil Rey Chandnani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhen Zhu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>
</div>
</div>
</dd>
<dt><a name=item548>[548]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14336 title=Abstract>arXiv:2310.14336</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14336 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.14336 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Learning Interpretable Rules for Scalable Data Representation and Classification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhuo Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Ning Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianyong Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by IEEE TPAMI in October 2023; Interpretable ML; Neuro-Symbolic AI; Preliminary conference version (NeurIPS 2021) available at <a href=https://arxiv.org/abs/2109.15103>arXiv:2109.15103</a>
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence (
 Volume: 46, Issue: 2, February 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item549>[549]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.14526 title=Abstract>arXiv:2310.14526</a> (replaced) [<a href=https://arxiv.org/pdf/2310.14526 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.14526 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Towards a Pretrained Model for Restless Bandits via Multi-arm Generalization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yunfan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behari%2C+N">Nikhil Behari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hughes%2C+E">Edward Hughes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+E">Edwin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nagaraj%2C+D">Dheeraj Nagaraj</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tuyls%2C+K">Karl Tuyls</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taneja%2C+A">Aparna Taneja</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tambe%2C+M">Milind Tambe</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item550>[550]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15011 title=Abstract>arXiv:2310.15011</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15011 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.15011 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.15011 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Interference Management by Harnessing Multi-Domain Resources in Spectrum-Sharing Aided Satellite-Ground Integrated Networks
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X">Xiaojin Ding</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lei%2C+Y">Yue Lei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yulong Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+G">Gengxin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Submitted to IEEE Transactions on Vehicular Technology
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Signal Processing (eess.SP)
</div>
</div>
</dd>
<dt><a name=item551>[551]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15169 title=Abstract>arXiv:2310.15169</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15169 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15169 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+H">Haonan Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+M">Menghan Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Y">Yingqing He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xintao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shan%2C+Y">Ying Shan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ICLR 2024, Project Page: <a href=http://haonanqiu.com/projects/FreeNoise.html>this http URL</a>, Code Repo: <a href=https://github.com/AILab-CVC/FreeNoise>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item552>[552]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.15706 title=Abstract>arXiv:2310.15706</a> (replaced) [<a href=https://arxiv.org/pdf/2310.15706 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.15706 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Solving the flexible job-shop scheduling problem through an enhanced deep reinforcement learning approach
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Echeverria%2C+I">Imanol Echeverria</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murua%2C+M">Maialen Murua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santana%2C+R">Roberto Santana</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item553>[553]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.17807 title=Abstract>arXiv:2310.17807</a> (replaced) [<a href=https://arxiv.org/pdf/2310.17807 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.17807 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Clover: Closed-Loop Verifiable Code Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+C">Chuyue Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padon%2C+O">Oded Padon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barrett%2C+C">Clark Barrett</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item554>[554]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.18156 title=Abstract>arXiv:2310.18156</a> (replaced) [<a href=https://arxiv.org/pdf/2310.18156 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2310.18156 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2310.18156 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Sufficient Incorrectness Logic: SIL and Separation SIL
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ascari%2C+F">Flavio Ascari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruni%2C+R">Roberto Bruni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gori%2C+R">Roberta Gori</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Logozzo%2C+F">Francesco Logozzo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 42 pages, 14 figures. New version to include a completeness result for Separation SIL and improve related work discussion
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item555>[555]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2310.18897 title=Abstract>arXiv:2310.18897</a> (replaced) [<a href=https://arxiv.org/pdf/2310.18897 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2310.18897 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Enhancing Low-Order Discontinuous Galerkin Methods with Neural Ordinary Differential Equations for Compressible Navier--Stokes Equations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Kang%2C+S">Shinhoo Kang</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Constantinescu%2C+E+M">Emil M. Constantinescu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 figures, 2 tables, 27 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)
</div>
</div>
</dd>
<dt><a name=item556>[556]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.04507 title=Abstract>arXiv:2311.04507</a> (replaced) [<a href=https://arxiv.org/pdf/2311.04507 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.04507 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+C+T">Cam-Van Thi Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mai%2C+A">Anh-Tuan Mai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+T">The-Son Le</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kieu%2C+H">Hai-Dang Kieu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+D">Duc-Trong Le</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> EMNLP 2023
</div>
<div class=list-journal-ref>
<span class=descriptor>Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
 Processing
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item557>[557]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.05545 title=Abstract>arXiv:2311.05545</a> (replaced) [<a href=https://arxiv.org/pdf/2311.05545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.05545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Extending Regev's factoring algorithm to compute discrete logarithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Eker%C3%A5%2C+M">Martin Ekerå</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%A4rtner%2C+J">Joel Gärtner</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> A number of improvements have been made, and further details on the robustness of the post-processing and other practical implementation considerations added
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item558>[558]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.06911 title=Abstract>arXiv:2311.06911</a> (replaced) [<a href=https://arxiv.org/pdf/2311.06911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.06911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unveiling Human Factors and Message Attributes in a Smishing Study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timko%2C+D">Daniel Timko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castillo%2C+D+H">Daniel Hernandez Castillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC)
</div>
</div>
</dd>
<dt><a name=item559>[559]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11143 title=Abstract>arXiv:2311.11143</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11143 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11143 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Goal-Oriented Communications for Remote Inference under Two-Way Delay with Memory
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ari%2C+C">Cagri Ari</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shisher%2C+M+K+C">Md Kamran Chowdhury Shisher</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Uysal%2C+E">Elif Uysal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 pages, 3 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Networking and Internet Architecture (cs.NI)</span>
</div>
</div>
</dd>
<dt><a name=item560>[560]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.11482 title=Abstract>arXiv:2311.11482</a> (replaced) [<a href=https://arxiv.org/pdf/2311.11482 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.11482 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Meta Prompting for AGI Systems
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yifan Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item561>[561]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.14720 title=Abstract>arXiv:2311.14720</a> (replaced) [<a href=https://arxiv.org/pdf/2311.14720 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.14720 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Perceptions and Detection of AI Use in Manuscript Preparation for Academic Journals
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chemaya%2C+N">Nir Chemaya</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin%2C+D">Daniel Martin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)
</div>
</div>
</dd>
<dt><a name=item562>[562]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.16267 title=Abstract>arXiv:2311.16267</a> (replaced) [<a href=https://arxiv.org/pdf/2311.16267 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.16267 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yu-Chen Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar%2C+A">Akhilesh Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+N">Norman Chang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenliang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zakir%2C+M">Muhammad Zakir</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Apte%2C+R">Rucha Apte</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+H">Haiyang He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jang%2C+J+R">Jyh-Shing Roger Jang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item563>[563]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17227 title=Abstract>arXiv:2311.17227</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17227 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17227 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hua%2C+W">Wenyue Hua</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fan%2C+L">Lizhou Fan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+L">Lingyao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+K">Kai Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ji%2C+J">Jianchao Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yingqiang Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hemphill%2C+L">Libby Hemphill</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 47 pages, 9 figures, 5 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item564>[564]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.17972 title=Abstract>arXiv:2311.17972</a> (replaced) [<a href=https://arxiv.org/pdf/2311.17972 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.17972 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Infilling Code Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+L">Lin Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hongxia Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Code available at <a href=https://github.com/LZhengisme/self-infilling>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Programming Languages (cs.PL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item565>[565]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2311.18420 title=Abstract>arXiv:2311.18420</a> (replaced) [<a href=https://arxiv.org/pdf/2311.18420 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2311.18420 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TeG-DG: Textually Guided Domain Generalization for Face Anti-Spoofing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mu%2C+L">Lianrui Mu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+J">Jianhong Bai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+X">Xiaoxuan He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+J">Jiangnan Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaoyu Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang%2C+J">Jiedong Zhuang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H">Haoji Hu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item566>[566]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00506 title=Abstract>arXiv:2312.00506</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00506 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.00506 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.00506 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative AI enhances individual creativity but reduces the collective diversity of novel content
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Doshi%2C+A+R">Anil R. Doshi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hauser%2C+O+P">Oliver P. Hauser</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)
</div>
</div>
</dd>
<dt><a name=item567>[567]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.00894 title=Abstract>arXiv:2312.00894</a> (replaced) [<a href=https://arxiv.org/pdf/2312.00894 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.00894 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Leveraging Large Language Models to Improve REST API Testing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+M">Myeongsoo Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stennett%2C+T">Tyler Stennett</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shah%2C+D">Dhruv Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha%2C+S">Saurabh Sinha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> To be published in the 46th IEEE/ACM International Conference on Software Engineering - New Ideas and Emerging Results Track (ICSE-NIER 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>
</div>
</div>
</dd>
<dt><a name=item568>[568]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.03731 title=Abstract>arXiv:2312.03731</a> (replaced) [<a href=https://arxiv.org/pdf/2312.03731 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.03731 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+X">Xingtong Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yuan Fang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by WWW2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item569>[569]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.05934 title=Abstract>arXiv:2312.05934</a> (replaced) [<a href=https://arxiv.org/pdf/2312.05934 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.05934 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ovadia%2C+O">Oded Ovadia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brief%2C+M">Menachem Brief</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mishaeli%2C+M">Moshik Mishaeli</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elisha%2C+O">Oren Elisha</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item570>[570]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.07228 title=Abstract>arXiv:2312.07228</a> (replaced) [<a href=https://arxiv.org/pdf/2312.07228 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.07228 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.07228 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toxic language detection: a systematic review of Arabic datasets
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bensalem%2C+I">Imene Bensalem</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rosso%2C+P">Paolo Rosso</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zitouni%2C+H">Hanane Zitouni</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item571>[571]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.08676 title=Abstract>arXiv:2312.08676</a> (replaced) [<a href=https://arxiv.org/pdf/2312.08676 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.08676 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Junjie Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 2 figures, accepted to ICASSP 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item572>[572]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11341 title=Abstract>arXiv:2312.11341</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11341 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2312.11341 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2312.11341 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> On the existence of MRD self-dual codes
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Berhuy%2C+G">Grégory Berhuy</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item573>[573]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11509 title=Abstract>arXiv:2312.11509</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11509 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11509 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Toward a Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Constas%2C+P">Pavlos Constas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rawal%2C+V">Vikram Rawal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oliveira%2C+M+H">Matthew Honorio Oliveira</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Constas%2C+A">Andreas Constas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Aditya Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung%2C+K">Kaison Cheung</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sultani%2C+N">Najma Sultani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+C">Carrie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altomare%2C+M">Micol Altomare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Akzam%2C+M">Michael Akzam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+V">Vhea He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Altomare%2C+L">Lauren Altomare</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Murqi%2C+H">Heraa Murqi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khan%2C+A">Asad Khan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bhanshali%2C+N+A">Nimit Amikumar Bhanshali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rachad%2C+Y">Youssef Rachad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guerzhoy%2C+M">Michael Guerzhoy</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In Proc. Machine Learning for Cognitive and Mental Health Workshop (ML4CMH) at AAAI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item574>[574]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.11678 title=Abstract>arXiv:2312.11678</a> (replaced) [<a href=https://arxiv.org/pdf/2312.11678 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.11678 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Misinformation as a harm: structured approaches for fact-checking prioritization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sehat%2C+C+M">Connie Moon Sehat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Ryan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie%2C+P">Peipei Nie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prabhakar%2C+T">Tarunima Prabhakar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to CSCW 2024, with clean up for typos and figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item575>[575]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.12141 title=Abstract>arXiv:2312.12141</a> (replaced) [<a href=https://arxiv.org/pdf/2312.12141 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.12141 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Locating Factual Knowledge in Large Language Models: Exploring the Residual Stream and Analyzing Subvalues in Vocabulary Space
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zeping Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ananiadou%2C+S">Sophia Ananiadou</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Preprint
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item576>[576]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.14057 title=Abstract>arXiv:2312.14057</a> (replaced) [<a href=https://arxiv.org/pdf/2312.14057 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.14057 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Weighted least-squares approximation with determinantal point processes and generalized volume sampling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nouy%2C+A">Anthony Nouy</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Michel%2C+B">Bertrand Michel</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> In this revised version, conjecture (13) on DPP and (16) on volume sampling have been modified, including a convexity requirement. Proofs of propositions 5.4 and 5.12 have been modified accordingly. Remarks 5.5 and 5.6 have been added to discuss alternatives to conjecture (13) on DPP
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item577>[577]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.14185 title=Abstract>arXiv:2312.14185</a> (replaced) [<a href=https://arxiv.org/pdf/2312.14185 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.14185 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Auto311: A Confidence-guided Automated System for Non-emergency Calls
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zirong Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+X">Xutong Sun</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuanhe Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+M">Meiyi Ma</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by AAAI-2024, Sub-Track: Social Impacts
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item578>[578]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15282 title=Abstract>arXiv:2312.15282</a> (replaced) [<a href=https://arxiv.org/pdf/2312.15282 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.15282 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Causal Forecasting for Pricing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Schultz%2C+D">Douglas Schultz</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Stephan%2C+J">Johannes Stephan</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Sieber%2C+J">Julian Sieber</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Yeh%2C+T">Trudie Yeh</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Kunz%2C+M">Manuel Kunz</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Doupe%2C+P">Patrick Doupe</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Januschowski%2C+T">Tim Januschowski</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item579>[579]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15910 title=Abstract>arXiv:2312.15910</a> (replaced) [<a href=https://arxiv.org/pdf/2312.15910 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.15910 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Reinforcement Unlearning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+D">Dayong Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tianqing Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+C">Congcong Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+D">Derui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xue%2C+M">Minhui Xue</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+S">Sheng Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+W">Wanlei Zhou</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item580>[580]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.15964 title=Abstract>arXiv:2312.15964</a> (replaced) [<a href=https://arxiv.org/e-print/2312.15964 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Semantic Guidance Tuning for Text-To-Image Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+H">Hyun Kang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+D">Dohae Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shin%2C+M">Myungjin Shin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+I">In-Kwon Lee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Rework is being done
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item581>[581]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.16693 title=Abstract>arXiv:2312.16693</a> (replaced) [<a href=https://arxiv.org/pdf/2312.16693 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.16693 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+X">Xun Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+M">Mingwu Zheng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hou%2C+L">Liang Hou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuan Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yufan Deng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+P">Pengfei Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Di Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yufan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+W">Weiming Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zha%2C+Z">Zhengjun Zha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Haibin Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item582>[582]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2312.17163 title=Abstract>arXiv:2312.17163</a> (replaced) [<a href=https://arxiv.org/pdf/2312.17163 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2312.17163 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FENet: Focusing Enhanced Network for Lane Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+L">Liman Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong%2C+H">Hanyang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages including appendix. The Code is available at <a href=https://github.com/HanyangZhong/FENet>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item583>[583]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.00595 title=Abstract>arXiv:2401.00595</a> (replaced) [<a href=https://arxiv.org/pdf/2401.00595 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.00595 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> State of What Art? A Call for Multi-Prompt LLM Evaluation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mizrahi%2C+M">Moran Mizrahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan%2C+G">Guy Kaplan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malkin%2C+D">Dan Malkin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dror%2C+R">Rotem Dror</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahaf%2C+D">Dafna Shahaf</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stanovsky%2C+G">Gabriel Stanovsky</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item584>[584]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.01145 title=Abstract>arXiv:2401.01145</a> (replaced) [<a href=https://arxiv.org/pdf/2401.01145 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.01145 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> HAAQI-Net: A non-intrusive neural music quality assessment model for hearing aids
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wisnu%2C+D+A+M+G">Dyah A. M. G. Wisnu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Pratiwi%2C+E">Epri Pratiwi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Rini%2C+S">Stefano Rini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zezario%2C+R+E">Ryandhimas E. Zezario</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item585>[585]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02383 title=Abstract>arXiv:2401.02383</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02383 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.02383 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.02383 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venkatrayappa%2C+D">Darshan Venkatrayappa</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tremeau%2C+A">Alain Tremeau</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Muselet%2C+D">Damien Muselet</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Colantoni%2C+P">Philippe Colantoni</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> arXiv admin note: text overlap with <a href=https://arxiv.org/abs/2008.09062>arXiv:2008.09062</a> by other authors
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item586>[586]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02771 title=Abstract>arXiv:2401.02771</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02771 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02771 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Powerformer: A Section-adaptive Transformer for Power Flow Adjustment
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kaixuan Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+W">Wei Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shunyu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yaoquan Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yihe Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qing%2C+Y">Yunpeng Qing</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Quan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+J">Jie Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 8 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item587>[587]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02777 title=Abstract>arXiv:2401.02777</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02777 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02777 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+N">Na Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+L">Liangyu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tian%2C+X">Xiaoyu Tian</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou%2C+W">Wei Zou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+K">Kaijiang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cui%2C+M">Ming Cui</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item588>[588]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.02847 title=Abstract>arXiv:2401.02847</a> (replaced) [<a href=https://arxiv.org/pdf/2401.02847 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.02847 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generating Non-Stationary Textures using Self-Rectification
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao%2C+R">Rongjun Xiao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lischinski%2C+D">Dani Lischinski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project page: <a href=https://github.com/xiaorongjun000/Self-Rectification>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item589>[589]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04394 title=Abstract>arXiv:2401.04394</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04394 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04394 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SonicVisionLM: Playing Sound with Vision Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+S">Shengye Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+Q">Qile He</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+M">Mengtian Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)
</div>
</div>
</dd>
<dt><a name=item590>[590]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.04478 title=Abstract>arXiv:2401.04478</a> (replaced) [<a href=https://arxiv.org/pdf/2401.04478 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.04478 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Schuh%2C+M+G">Maximilian G. Schuh</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Boldini%2C+D">Davide Boldini</a>, 
<a href="https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sieber%2C+S+A">Stephan A. Sieber</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13(+9) pages(+appendix), 5 figures, 11 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item591>[591]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05859 title=Abstract>arXiv:2401.05859</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05859 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.05859 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.05859 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> New Construction of <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-269-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1681 style=width:0.558em;display:inline-block><span style=display:inline-block;position:relative;width:0.465em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.345em,1000.47em,2.271em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1682><span class=mi id=MathJax-Span-1683 style=font-family:MathJax_Math-italic>q<span style=display:inline-block;overflow:hidden;height:1px;width:0.002em></span></span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.275em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span>-ary Codes Correcting a Burst of at most <span class=MathJax_Preview style=display:none></span><span class=MathJax id=MathJax-Element-270-Frame tabindex=0><nobr><span class=math id=MathJax-Span-1684 style=width:0.465em;display:inline-block><span style=display:inline-block;position:relative;width:0.373em;height:0px;font-size:120%><span style=position:absolute;clip:rect(1.16em,1000.33em,2.086em,-999.998em);top:-1.942em;left:0em><span class=mrow id=MathJax-Span-1685><span class=mi id=MathJax-Span-1686 style=font-family:MathJax_Math-italic>t</span></span><span style=display:inline-block;width:0px;height:1.947em></span></span></span><span style="display:inline-block;overflow:hidden;vertical-align:-0.053em;border-left:0px solid;width:0px;height:0.892em"></span></span></nobr></span> Deletions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+W">Wentu Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+K">Kui Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item592>[592]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.05925 title=Abstract>arXiv:2401.05925</a> (replaced) [<a href=https://arxiv.org/pdf/2401.05925 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.05925 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with Dual Feature Fusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+B">Bin Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yongjia Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhaohui Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Z">Zejian Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 9 pages, 8 figures, correct writing details
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item593>[593]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06031 title=Abstract>arXiv:2401.06031</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06031 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06031 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+H">Huaming Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinyi Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiayu Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhibo Jin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Choo%2C+K+R">Kim-Kwang Raymond Choo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shen%2C+J">Jun Shen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+D">Dong Yuan</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted by SIAM International Conference on Data Mining (SDM24)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item594>[594]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.06071 title=Abstract>arXiv:2401.06071</a> (replaced) [<a href=https://arxiv.org/pdf/2401.06071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.06071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GroundingGPT:Language Enhanced Multi-modal Grounding Model
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhaowei Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qi Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+H">Hang Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yiqing Cai</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qi%2C+Q">Qi Qi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+R">Ran Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pan%2C+J">Junting Pan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zefeng Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vu%2C+V+T">Van Tu Vu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhida Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+T">Tao Wang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item595>[595]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.07914 title=Abstract>arXiv:2401.07914</a> (replaced) [<a href=https://arxiv.org/pdf/2401.07914 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.07914 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Graphical Symplectic Algebra
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Booth%2C+R+I">Robert I. Booth</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carette%2C+T">Titouan Carette</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Comfort%2C+C">Cole Comfort</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fixed minor errors, typos from previous version. Made more printer friendly
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Symplectic Geometry (math.SG); Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item596>[596]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08237 title=Abstract>arXiv:2401.08237</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08237 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08237 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Far- versus Near-Field RIS Modeling and Beam Design
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Delbari%2C+M">Mohamadreza Delbari</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Jamali%2C+V">Vahid Jamali</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Information Theory (cs.IT)
</div>
</div>
</dd>
<dt><a name=item597>[597]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08406 title=Abstract>arXiv:2401.08406</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08406 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08406 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balaguer%2C+A">Angels Balaguer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benara%2C+V">Vinamra Benara</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+Freitas+Cunha%2C+R+L">Renato Luiz de Freitas Cunha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+M.+Estev%C3%A3o+Filho%2C+R">Roberto de M. Estevão Filho</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hendry%2C+T">Todd Hendry</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Holstein%2C+D">Daniel Holstein</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Marsman%2C+J">Jennifer Marsman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mecklenburg%2C+N">Nick Mecklenburg</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malvar%2C+S">Sara Malvar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nunes%2C+L+O">Leonardo O. Nunes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padilha%2C+R">Rafael Padilha</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharp%2C+M">Morris Sharp</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+B">Bruno Silva</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+S">Swati Sharma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aski%2C+V">Vijay Aski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chandra%2C+R">Ranveer Chandra</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item598>[598]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08572 title=Abstract>arXiv:2401.08572</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08572 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08572 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The illusion of artificial inclusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agnew%2C+W">William Agnew</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bergman%2C+A+S">A. Stevie Bergman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chien%2C+J">Jennifer Chien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%C3%ADaz%2C+M">Mark Díaz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=El-Sayed%2C+S">Seliem El-Sayed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pittman%2C+J">Jaylen Pittman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mohamed%2C+S">Shakir Mohamed</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McKee%2C+K+R">Kevin R. McKee</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computers and Society (cs.CY)</span>
</div>
</div>
</dd>
<dt><a name=item599>[599]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.08876 title=Abstract>arXiv:2401.08876</a> (replaced) [<a href=https://arxiv.org/pdf/2401.08876 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.08876 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dongping Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chatzimparmpas%2C+A">Angelos Chatzimparmpas</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kamali%2C+N">Negar Kamali</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 28 pages, 11 figures, 8 tables. Accepted by ACM CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item600>[600]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09003 title=Abstract>arXiv:2401.09003</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09003 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09003 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Augmenting Math Word Problems via Iterative Question Composing
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoxiong Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yifan Luo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+A+C">Andrew Chi-Chih Yao</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item601>[601]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09071 title=Abstract>arXiv:2401.09071</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09071 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09071 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guo%2C+J">Jingwei Guo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+K">Kaizhu Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yi%2C+X">Xinping Yi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su%2C+Z">Zixian Su</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item602>[602]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.09785 title=Abstract>arXiv:2401.09785</a> (replaced) [<a href=https://arxiv.org/pdf/2401.09785 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.09785 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Instant Answering in E-Commerce Buyer-Seller Messaging using Message-to-Question Reformulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fetahu%2C+B">Besnik Fetahu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta%2C+T">Tejas Mehta</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Q">Qun Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vedula%2C+N">Nikhita Vedula</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rokhlenko%2C+O">Oleg Rokhlenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malmasi%2C+S">Shervin Malmasi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at ECIR 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item603>[603]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10107 title=Abstract>arXiv:2401.10107</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10107 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10107 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10107 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Palo%2C+G">Gianpaolo Palo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Fiorillo%2C+L">Luigi Fiorillo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Monachino%2C+G">Giuliana Monachino</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Bechny%2C+M">Michal Bechny</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Melnykowycz%2C+M">Mark Melnykowycz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tzovara%2C+A">Athina Tzovara</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Agostini%2C+V">Valentina Agostini</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Faraci%2C+F+D">Francesca Dalia Faraci</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 figures, 1 table
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)
</div>
</div>
</dd>
<dt><a name=item604>[604]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10337 title=Abstract>arXiv:2401.10337</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10337 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10337 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Noise Contrastive Estimation-based Matching Framework for Low-Resource Security Attack Pattern Recognition
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Tu Nguyen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=%C5%A0rndi%C4%87%2C+N">Nedim Šrndić</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Neth%2C+A">Alexander Neth</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> accepted at EACL 2024, in ARR October 2023
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)
</div>
</div>
</dd>
<dt><a name=item605>[605]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10545 title=Abstract>arXiv:2401.10545</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10545 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10545 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deldjoo%2C+Y">Yashar Deldjoo</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>
</div>
</div>
</dd>
<dt><a name=item606>[606]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10746 title=Abstract>arXiv:2401.10746</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10746 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.10746 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Junqueira%2C+B">Bruna Junqueira</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Aristimunha%2C+B">Bruno Aristimunha</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chevallier%2C+S">Sylvain Chevallier</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=de+Camargo%2C+R+Y">Raphael Y. de Camargo</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 14 pages and 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item607>[607]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.10893 title=Abstract>arXiv:2401.10893</a> (replaced) [<a href=https://arxiv.org/pdf/2401.10893 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.10893 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.10893 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Location Sensitive Embedding for Knowledge Graph Reasoning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Banerjee%2C+D">Deepak Banerjee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ishaan%2C+A">Anjali Ishaan</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)
</div>
</div>
</dd>
<dt><a name=item608>[608]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.11254 title=Abstract>arXiv:2401.11254</a> (replaced) [<a href=https://arxiv.org/pdf/2401.11254 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.11254 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cima%2C+L">Lorenzo Cima</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Trujillo%2C+A">Amaury Trujillo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Avvenuti%2C+M">Marco Avvenuti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cresci%2C+S">Stefano Cresci</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)
</div>
</div>
</dd>
<dt><a name=item609>[609]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12007 title=Abstract>arXiv:2401.12007</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12007 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12007 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Tensor-view Topological Graph Neural Network
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wen%2C+T">Tao Wen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+E">Elynn Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuzhou Chen</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted at AISTATS 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item610>[610]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12114 title=Abstract>arXiv:2401.12114</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12114 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12114 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Improved accuracy of continuum surface flux models for metal additive manufacturing melt pool simulations
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Much%2C+N">Nils Much</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schreter-Fleischhacker%2C+M">Magdalena Schreter-Fleischhacker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Munch%2C+P">Peter Munch</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kronbichler%2C+M">Martin Kronbichler</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wall%2C+W+A">Wolfgang A. Wall</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meier%2C+C">Christoph Meier</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computational Engineering, Finance, and Science (cs.CE)</span>
</div>
</div>
</dd>
<dt><a name=item611>[611]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12443 title=Abstract>arXiv:2401.12443</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Patch2QL: Discover Cognate Defects in Open Source Software Supply Chain With Auto-generated Static Analysis Rules
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+F">Fuwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yongzhi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zhiqiang Dong</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)
</div>
</div>
</dd>
<dt><a name=item612>[612]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12585 title=Abstract>arXiv:2401.12585</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12585 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12585 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SLANG: New Concept Comprehension of Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mei%2C+L">Lingrui Mei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+S">Shenghua Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yiwei Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bi%2C+B">Baolong Bi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+X">Xueqi Chen</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item613>[613]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12648 title=Abstract>arXiv:2401.12648</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12648 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12648 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+H">Hao Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mao%2C+H">Hua Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woo%2C+W+L">Wai Lok Woo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+J">Jie Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Peng%2C+X">Xi Peng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item614>[614]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12872 title=Abstract>arXiv:2401.12872</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12872 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12872 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chenyang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+T">Tiansu Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaffer%2C+E">Eric Shaffer</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soltanaghai%2C+E">Elahe Soltanaghai</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> ACM CHI 2024 Paper
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item615>[615]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12900 title=Abstract>arXiv:2401.12900</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12900 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12900 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Animation with 3D Gaussian Splatting
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhenyu Bao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu%2C+G">Guoping Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+K">Kanglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 10 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)
</div>
</div>
</dd>
<dt><a name=item616>[616]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12946 title=Abstract>arXiv:2401.12946</a> (replaced) [<a href=https://arxiv.org/e-print/2401.12946 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zimeng Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+R">Rui Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+C">Cheng Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuan Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xin%2C+S">Shiqing Xin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lingjie Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Komura%2C+T">Taku Komura</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+X">Xiaoming Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> This paper needs major revisions in layout/content
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG); Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item617>[617]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.12973 title=Abstract>arXiv:2401.12973</a> (replaced) [<a href=https://arxiv.org/pdf/2401.12973 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.12973 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> In-Context Language Learning: Architectures and Algorithms
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aky%C3%BCrek%2C+E">Ekin Akyürek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+B">Bailin Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yoon Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Fixes a typo in the title, and adds additional references
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item618>[618]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.13802 title=Abstract>arXiv:2401.13802</a> (replaced) [<a href=https://arxiv.org/pdf/2401.13802 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.13802 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Investigating the Efficacy of Large Language Models for Code Clone Detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Khajezade%2C+M">Mohamad Khajezade</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J+J">Jie JW Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fard%2C+F+H">Fatemeh Hendijani Fard</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rodr%C3%ADguez-P%C3%A9rez%2C+G">Gema Rodríguez-Pérez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shehata%2C+M+S">Mohamed Sami Shehata</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item619>[619]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14000 title=Abstract>arXiv:2401.14000</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14000 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14000 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Mapping the Design Space of Teachable Social Media Feed Experiences
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Feng%2C+K+J+K">K. J. Kevin Feng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koo%2C+X">Xander Koo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tan%2C+L">Lawrence Tan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruckman%2C+A">Amy Bruckman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McDonald%2C+D+W">David W. McDonald</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> CHI 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Human-Computer Interaction (cs.HC)</span>
</div>
</div>
</dd>
<dt><a name=item620>[620]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14066 title=Abstract>arXiv:2401.14066</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14066 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14066 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+N">Nisha Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+W">Weiming Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+F">Fan Tang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+R">Ronghui Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X">Xiu Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item621>[621]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14126 title=Abstract>arXiv:2401.14126</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14126 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14126 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14126 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> An Indexed Linear Logic for Idempotent Intersection Types (Long version)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Breuvart%2C+F">Flavien Breuvart</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olimpieri%2C+F">Federico Olimpieri</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Logic in Computer Science (cs.LO)</span>
</div>
</div>
</dd>
<dt><a name=item622>[622]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14265 title=Abstract>arXiv:2401.14265</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14265 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14265 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Worst-Case Per-User Error Bound for Asynchronous Unsourced Multiple Access
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J">Jyun-Sian Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+P">Pin-Hsun Lin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mross%2C+M+A">Marcel A. Mross</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item623>[623]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14319 title=Abstract>arXiv:2401.14319</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14319 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.14319 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.14319 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Quantum "Lifting Theorem" for Constructions of Pseudorandom Generators from Random Oracles
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Katz%2C+J">Jonathan Katz</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sela%2C+B">Ben Sela</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>
</div>
</div>
</dd>
<dt><a name=item624>[624]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14321 title=Abstract>arXiv:2401.14321</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14321 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14321 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Du%2C+C">Chenpeng Du</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+H">Hankun Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yang%2C+Y">Yifan Yang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Niu%2C+Z">Zhikang Niu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang%2C+H">Hui Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chen%2C+X">Xie Chen</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)
</div>
</div>
</dd>
<dt><a name=item625>[625]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14360 title=Abstract>arXiv:2401.14360</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14360 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14360 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bangla Texts
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Elahi%2C+K+T">Kazi Toufique Elahi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman%2C+T+B">Tasnuva Binte Rahman</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahriar%2C+S">Shakil Shahriar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sarker%2C+S">Samir Sarker</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shahariar%2C+G+M">G. M. Shahariar</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted in The 9th Workshop on Noisy and User-generated Text (W-NUT), 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item626>[626]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14423 title=Abstract>arXiv:2401.14423</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14423 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14423 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Prompt Design and Engineering: Introduction and Advanced Methods
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amatriain%2C+X">Xavier Amatriain</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item627>[627]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14424 title=Abstract>arXiv:2401.14424</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14424 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14424 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y">Yanjie Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Weijun Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+L">Lina Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+M">Min Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jingyi Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+W">Wenqiang Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+M">Meilan Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+S">Shu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yusong Deng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 24 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item628>[628]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14673 title=Abstract>arXiv:2401.14673</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14673 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14673 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Generative Expressive Robot Behaviors using Large Language Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahadevan%2C+K">Karthik Mahadevan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chien%2C+J">Jonathan Chien</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+N">Noah Brown</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhuo Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parada%2C+C">Carolina Parada</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+F">Fei Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+A">Andy Zeng</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Takayama%2C+L">Leila Takayama</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>
</div>
</div>
</dd>
<dt><a name=item629>[629]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.14698 title=Abstract>arXiv:2401.14698</a> (replaced) [<a href=https://arxiv.org/pdf/2401.14698 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.14698 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Under the Surface: Tracking the Artifactuality of LLM-Generated Data
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Das%2C+D">Debarati Das</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=De+Langis%2C+K">Karin De Langis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Martin-Boyle%2C+A">Anna Martin-Boyle</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+M">Minhwa Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Z+M">Zae Myung Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hayati%2C+S+A">Shirley Anugrah Hayati</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Owan%2C+R">Risako Owan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+B">Bin Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Parkar%2C+R">Ritik Parkar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koo%2C+R">Ryan Koo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J">Jonginn Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tyagi%2C+A">Aahan Tyagi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ferland%2C+L">Libby Ferland</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roy%2C+S">Sanjali Roy</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+V">Vincent Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Core Authors: Debarati Das, Karin De Langis, Anna Martin-Boyle, Jaehyung Kim, Minhwa Lee and Zae Myung Kim | Project lead : Debarati Das | PI : Dongyeop Kang
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item630>[630]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15139 title=Abstract>arXiv:2401.15139</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15139 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15139 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Machkour%2C+J">Jasin Machkour</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Palomar%2C+D+P">Daniel P. Palomar</a>, 
<a href="https://arxiv.org/search/q-fin?searchtype=author&amp;query=Muma%2C+M">Michael Muma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)
</div>
</div>
</dd>
<dt><a name=item631>[631]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15204 title=Abstract>arXiv:2401.15204</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15204 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15204 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LYT-Net: Lightweight YUV Transformer-based Network for Low-Light Image Enhancement
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brateanu%2C+A">A. Brateanu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Balmez%2C+R">R. Balmez</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Avram%2C+A">A. Avram</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Orhei%2C+C">C. Orhei</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 10 pages, 6 figures, submitted to ICIP
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)
</div>
</div>
</dd>
<dt><a name=item632>[632]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15266 title=Abstract>arXiv:2401.15266</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15266 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15266 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15266 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> SAM-based instance segmentation models for the automation of structural damage detection
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ye%2C+Z">Zehao Ye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lovell%2C+L">Lucy Lovell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faramarzi%2C+A">Asaad Faramarzi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ninic%2C+J">Jelena Ninic</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item633>[633]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15313 title=Abstract>arXiv:2401.15313</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15313 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15313 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Multi-Robot Relative Pose Estimation in SE(2) with Observability Analysis: A Comparison of Extended Kalman Filtering and Robust Pose Graph Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shin%2C+K">Kihoon Shin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sim%2C+H">Hyunjae Sim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nam%2C+S">Seungwon Nam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yonghee Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J">Jae Hu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim%2C+K+K">Kwang-Ki K. Kim</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 21 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY); Optimization and Control (math.OC)
</div>
</div>
</dd>
<dt><a name=item634>[634]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15328 title=Abstract>arXiv:2401.15328</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15328 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15328 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Theuma%2C+A">Adrian Theuma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Accepted to EACL2024; code, model and dataset are available at <a href=https://raven-lm.github.io/>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>
</div>
</div>
</dd>
<dt><a name=item635>[635]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15378 title=Abstract>arXiv:2401.15378</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15378 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15378 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15378 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alan%2C+A+Y">Ahmet Yusuf Alan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karaarslan%2C+E">Enis Karaarslan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aydin%2C+O">Omer Aydin</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item636>[636]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15443 title=Abstract>arXiv:2401.15443</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15443 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15443 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DiffuserLite: Towards Real-time Diffusion Planning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dong%2C+Z">Zibin Dong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hao%2C+J">Jianye Hao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yifu Yuan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ni%2C+F">Fei Ni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yitian Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+P">Pengyi Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng%2C+Y">Yan Zheng</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>
</div>
</div>
</dd>
<dt><a name=item637>[637]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15687 title=Abstract>arXiv:2401.15687</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15687 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15687 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qingcheng Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Long%2C+P">Pengyu Long</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qixuan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+D">Dafei Qin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang%2C+H">Han Liang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+L">Longwen Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yingliang Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+J">Jingyi Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Project Page: <a href=https://sites.google.com/view/media2face>this https URL</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)
</div>
</div>
</dd>
<dt><a name=item638>[638]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15688 title=Abstract>arXiv:2401.15688</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15688 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15688 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie%2C+E">Enze Xie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+A">Aoxue Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongdao Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+X">Xihui Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item639>[639]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15745 title=Abstract>arXiv:2401.15745</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15745 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15745 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> The computation of approximate feedback Stackelberg equilibria in multi-player nonlinear constrained dynamic games
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Li%2C+J">Jingqi Li</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Tomlin%2C+C">Claire Tomlin</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> The copyright of version 1 is mistakenly selected. This manuscript is currently under review by SIAM Journal on Optimization
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item640>[640]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15771 title=Abstract>arXiv:2401.15771</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15771 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15771 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Bayesian Nonparametrics Meets Data-Driven Robust Optimization
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bariletto%2C+N">Nicola Bariletto</a>, 
<a href="https://arxiv.org/search/stat?searchtype=author&amp;query=Ho%2C+N">Nhat Ho</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item641>[641]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15803 title=Abstract>arXiv:2401.15803</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15803 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15803 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+L">Liguo Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Song%2C+Y">Yinglei Song</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yichao Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhou Yu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sodamin%2C+M">Michael Sodamin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hongshen Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Liang Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+L">Lian Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+H">Haichuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+G">Guang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)
</div>
</div>
</dd>
<dt><a name=item642>[642]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15870 title=Abstract>arXiv:2401.15870</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15870 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15870 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> DF* PageRank: Improved Incrementally Expanding Approaches for Updating PageRank on Dynamic Graphs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 17 pages, 13 figures, 2 tables
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)
</div>
</div>
</dd>
<dt><a name=item643>[643]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15911 title=Abstract>arXiv:2401.15911</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15911 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.15911 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.15911 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Distribution-consistency Structural Causal Models
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gong%2C+H">Heyang Gong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+C">Chaochao Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)
</div>
</div>
</dd>
<dt><a name=item644>[644]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15915 title=Abstract>arXiv:2401.15915</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15915 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15915 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Unrestricted Error-Type Codebook Generation for Error Correction Code in DNA Storage Inspired by NLP
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yi Lu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yun Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+C">Chenghao Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Si%2C+G">Guangxiang Si</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 6 pages, 5 figures, this paper is submitted to the 2024 IEEE International Symposium on Information Theory (ISIT 2024)
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item645>[645]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15935 title=Abstract>arXiv:2401.15935</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15935 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15935 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Self-Supervised Learning in Event Sequences: A Comparative Study and Hybrid Approach of Generative Modeling and Contrastive Learning
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Moskvoretskii%2C+V">Viktor Moskvoretskii</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Osin%2C+D">Dmitry Osin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shvetsov%2C+E">Egor Shvetsov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Udovichenko%2C+I">Igor Udovichenko</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhelnin%2C+M">Maxim Zhelnin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dukhovny%2C+A">Andrey Dukhovny</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhimerikina%2C+A">Anna Zhimerikina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efimov%2C+A">Albert Efimov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Burnaev%2C+E">Evgeny Burnaev</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 11 pages, 9 figures
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)
</div>
</div>
</dd>
<dt><a name=item646>[646]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.15946 title=Abstract>arXiv:2401.15946</a> (replaced) [<a href=https://arxiv.org/pdf/2401.15946 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.15946 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Approaching Maximum Likelihood Decoding Performance via Reshuffling ORBGRAND
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wan%2C+L">Li Wan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyi Zhang</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item647>[647]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16063 title=Abstract>arXiv:2401.16063</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16063 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16063 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16063 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Shannon Capacity of Channels with Markov Insertions, Deletions and Substitutions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morozov%2C+R">Ruslan Morozov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Duman%2C+T+M">Tolga M. Duman</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 20 pages, 1 figure
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>
</div>
</div>
</dd>
<dt><a name=item648>[648]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16067 title=Abstract>arXiv:2401.16067</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16067 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16067 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Encoding Time and Energy Model for SVT-AV1 based on Video Complexity
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Eicherm%C3%BCller%2C+L">Lena Eichermüller</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Chaudhari%2C+G">Gaurang Chaudhari</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Katsavounidis%2C+I">Ioannis Katsavounidis</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Lei%2C+Z">Zhijun Lei</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Tmar%2C+H">Hassene Tmar</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Herglotz%2C+C">Christian Herglotz</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&amp;query=Kaup%2C+A">André Kaup</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 5 pages, 1 figure, accepted for IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2024
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM)
</div>
</div>
</dd>
<dt><a name=item649>[649]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16160 title=Abstract>arXiv:2401.16160</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16160 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16160 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts in Instruction Finetuning MLLMs
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S">Shaoxiang Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jie%2C+Z">Zequn Jie</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+L">Lin Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Computer Vision and Pattern Recognition (cs.CV)</span>
</div>
</div>
</dd>
<dt><a name=item650>[650]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16250 title=Abstract>arXiv:2401.16250</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16250 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16250 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16250 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Efficient solution of ill-posed integral equations through averaging
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Griebel%2C+M">Michael Griebel</a>, 
<a href="https://arxiv.org/search/math?searchtype=author&amp;query=Jahn%2C+T">Tim Jahn</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 35 pages
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Numerical Analysis (math.NA)</span>
</div>
</div>
</dd>
<dt><a name=item651>[651]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16251 title=Abstract>arXiv:2401.16251</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16251 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16251 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Cross-silo Federated Learning with Record-level Personalized Differential Privacy
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Junxu Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lou%2C+J">Jian Lou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong%2C+L">Li Xiong</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinfei Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meng%2C+X">Xiaofeng Meng</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 12 pages, 7 figures, under review
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
</div>
</div>
</dd>
<dt><a name=item652>[652]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16263 title=Abstract>arXiv:2401.16263</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16263 title="Download PDF">pdf</a>, <a href=https://arxiv.org/format/2401.16263 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Collaboration Petri Nets: Verification, Equivalence, and Discovery (Extended Version)
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Benzin%2C+J">Janik-Vasily Benzin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Formal Languages and Automata Theory (cs.FL)</span>
</div>
</div>
</dd>
<dt><a name=item653>[653]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16312 title=Abstract>arXiv:2401.16312</a> (replaced) [<a href=https://arxiv.org/pdf/2401.16312 title="Download PDF">pdf</a>, <a href=https://arxiv.org/ps/2401.16312 title="Download PostScript">ps</a>, <a href=https://arxiv.org/format/2401.16312 title="Other formats">other</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> Degradability of Modified Landau-Streater Type Low-Noise Quantum Channels in High Dimensions
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lo%2C+Y">Yun-Feng Lo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yen-Chi Lee</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hsieh%2C+M">Min-Hsiu Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> 13 pages, 1 figure, comments welcome! v2: Introduction enhanced
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)
</div>
</div>
</dd>
<dt><a name=item654>[654]</a>&nbsp; <span class=list-identifier><a href=https://arxiv.org/abs/2401.16356 title=Abstract>arXiv:2401.16356</a> (replaced) [<a href=https://arxiv.org/e-print/2401.16356 title="Download source">src</a>]</span></dt>
<dd>
<div class=meta>
<div class="list-title mathjax">
<span class="descriptor sf-hidden">Title:</span> cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and Glitch Generation
</div>
<div class=list-authors>
<span class="descriptor sf-hidden">Authors:</span> 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Dooney%2C+T">Tom Dooney</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Curier%2C+L">Lyana Curier</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Tan%2C+D">Daniel Tan</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Lopez%2C+M">Melissa Lopez</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Van+Den+Broeck%2C+C">Chris Van Den Broeck</a>, 
<a href="https://arxiv.org/search/physics?searchtype=author&amp;query=Bromuri%2C+S">Stefano Bromuri</a>
</div>
<div class="list-comments mathjax">
<span class=descriptor>Comments:</span> Paper to be internally reviewed within collaboration. It will be resubmitted after passing the internal rewiew
</div>
<div class=list-subjects>
<span class=descriptor>Subjects:</span> <span class=primary-subject>Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); General Relativity and Quantum Cosmology (gr-qc)
</div>
</div>
</dd>
</dl>
<ul>
<li><a href="https://arxiv.org/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href=#item391>Cross-lists</a></li>
<li><a href=#item432>Replacements</a></li>
</ul>
<small>[ total of 654 entries: <b>1-654</b> ]</small><br>
<small>[ showing up to 2000 entries per page: <a href="https://arxiv.org/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font color=#999999>more</font> ]</small><br>
</div>
<br><small><a id=mathjax_toggle href=javascript:void(0)>Disable MathJax</a> (<a href=https://arxiv.org/help/mathjax>What is MathJax?</a>)</small>
<hr class=sf-hidden>
<p>Links to:
<a href=https://arxiv.org/ accesskey=a>arXiv</a>,
<a href=https://arxiv.org/form/cs>form interface</a>,
<a href=https://arxiv.org/find/cs>find</a>,
<a href=https://arxiv.org/archive/cs>cs</a>, <a href=https://arxiv.org/list/cs/recent>recent</a>, <a href=https://arxiv.org/list/cs/2401>2401</a>,
<a href=https://arxiv.org/help/contact>contact</a>,
<a href=https://arxiv.org/help/ accesskey=h><span class=accesskey>h</span>elp</a>&nbsp;
<small>(<a href=https://arxiv.org/help/accesskeys>Access key</a> information)</small>
</p>
<hr class=sf-hidden>
</div>
 <footer style=clear:both>
 <div class="columns is-desktop" role=navigation aria-label=Secondary style="margin:-0.75em -0.75em 0.75em -0.75em">
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/about>About</a></li>
 <li><a href=https://arxiv.org/help>Help</a></li>
 </ul>
 </div>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>
 <a href=https://arxiv.org/help/contact> Contact</a>
 </li>
 <li>
 <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg>
 <a href=https://arxiv.org/help/subscribe> Subscribe</a>
 </li>
 </ul>
 </div>
 </div>
 </div>
 
 
 <div class=column style=padding:0>
 <div class=columns>
 <div class=column>
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/license>Copyright</a></li>
 <li><a href=https://arxiv.org/help/policies/privacy_policy>Privacy Policy</a></li>
 </ul>
 </div>
 <div class="column sorry-app-links">
 <ul style=list-style:none;line-height:2>
 <li><a href=https://arxiv.org/help/web_accessibility>Web Accessibility Assistance</a></li>
 <li>
 <p class=help>
 <a class=a11y-main-link href=https://status.arxiv.org/ target=_blank>arXiv Operational Status <svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 256 512" class="icon filter-dark_grey" role=presentation><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"></path></svg></a><br>
 Get status notifications via
 <a class=is-link href=https://subscribe.sorryapp.com/24846f03/email/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="icon filter-black" role=presentation><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>email</a>
 or <a class=is-link href=https://subscribe.sorryapp.com/24846f03/slack/new target=_blank><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 448 512" class="icon filter-black" role=presentation><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>slack</a>
 </p>
 </li>
 </ul>
 </div>
 </div>
 </div> 
 
 </div>
 </footer>
<div style=position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px;margin:0px><div id=MathJax_Font_Test style=position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-family:MathJax_Size2,sans-serif class=sf-hidden></div></div>